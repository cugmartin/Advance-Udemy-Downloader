#!/usr/bin/env python3
"""
‰ΩøÁî®Âê¥ÊÅ©Ëææ‚Äú‰∏âÊ≠•ÁøªËØëÊ≥ï‚ÄùÂ∞Ü Markdown Ëã±ÊñáÊñáÊ°£ÁøªËØëÊàê‰∏≠Êñá„ÄÇ

ËÑöÊú¨‰ºöÔºö
1. ËØªÂèñ .env ‰∏≠ÁöÑÊ®°Âûã„ÄÅAPI KeyÔºàÂëΩ‰ª§Ë°åÂèØË¶ÜÁõñÔºâ
2. ËØªÂèñ MarkdownÔºàÊñá‰ª∂ÊàñÁõÆÂΩïÔºâ
3. ÂØπÈïøÊñáÊú¨Ëá™Âä®ÂàÜÊÆµÔºåÈÄêÊÆµËØ∑Ê±Ç LLM ÁøªËØë
4. ‰ªÖËæìÂá∫ÊúÄÁªàÁöÑ‰ºòÂåñËØëÊñáÔºå‰øùÁïô Markdown ÁªìÊûÑ
"""

from __future__ import annotations

import argparse
import os
import re
import sys
import time
from pathlib import Path
from textwrap import dedent
from typing import Iterable, List, Optional

from dotenv import load_dotenv

try:
    from openai import (
        APIConnectionError,
        APIError,
        APITimeoutError,
        OpenAI,
        RateLimitError,
    )
except ImportError:  # pragma: no cover - ÊòéÁ°ÆÊèêÁ§∫Áº∫Â§±‰æùËµñ
    print("ÈîôËØØ: Áº∫Â∞ë openai ‰æùËµñÔºåËØ∑ÂÖàËøêË°å `pip install openai`", file=sys.stderr)
    sys.exit(1)


PROJECT_ROOT = Path(__file__).resolve().parents[1]
load_dotenv(PROJECT_ROOT / ".env")

DEFAULT_PROVIDER = os.getenv("TRANSLATE_PROVIDER", "openai")
DEFAULT_MODEL = os.getenv("TRANSLATE_MODEL", "gpt-4o-mini")
DEFAULT_API_KEY = os.getenv("TRANSLATE_API_KEY") or os.getenv("OPENAI_API_KEY")
DEFAULT_BASE_URL = os.getenv("TRANSLATE_BASE_URL") or os.getenv("OPENAI_BASE_URL")
DEFAULT_CHUNK_SIZE = int(os.getenv("TRANSLATE_CHUNK_SIZE", "2800"))
DEFAULT_REQUEST_TIMEOUT = float(os.getenv("TRANSLATE_REQUEST_TIMEOUT", "60"))
DEFAULT_MAX_RETRIES = int(os.getenv("TRANSLATE_MAX_RETRIES", "3"))
DEFAULT_RETRY_DELAY = float(os.getenv("TRANSLATE_RETRY_DELAY", "5"))

CHINESE_CHAR_RE = re.compile(r"[\u4e00-\u9fff]")


def is_probably_chinese(text: str, threshold: float = 0.25) -> bool:
    if not text:
        return False
    total = len(text)
    hits = len(CHINESE_CHAR_RE.findall(text))
    return (hits / max(total, 1)) >= threshold


def chunk_markdown(text: str, chunk_size: int) -> Iterable[str]:
    if len(text) <= chunk_size:
        yield text
        return
    buffer: List[str] = []
    current_len = 0
    for paragraph in text.split("\n\n"):
        paragraph_block = paragraph + "\n\n"
        if current_len + len(paragraph_block) > chunk_size and buffer:
            yield "".join(buffer).rstrip()
            buffer = [paragraph_block]
            current_len = len(paragraph_block)
        else:
            buffer.append(paragraph_block)
            current_len += len(paragraph_block)
    if buffer:
        yield "".join(buffer).rstrip()


def create_client(
    api_key: str | None,
    base_url: str | None,
    timeout: float | None,
) -> OpenAI:
    if not api_key:
        raise SystemExit(
            "ÈîôËØØ: Êú™Êèê‰æõÁøªËØë API Key„ÄÇËØ∑Âú® .env ‰∏≠ËÆæÁΩÆ TRANSLATE_API_KEY/OPENAI_API_KEYÔºåÊàñ‰ΩøÁî® --api-key ÂèÇÊï∞„ÄÇ"
        )
    kwargs = {"api_key": api_key}
    if base_url:
        kwargs["base_url"] = base_url
    if timeout:
        kwargs["timeout"] = timeout
    return OpenAI(**kwargs)


def translate_chunk(
    client: OpenAI,
    model: str,
    chunk: str,
    source_lang: str,
    target_lang: str,
    max_retries: int,
    retry_delay: float,
    show_stage_logs: bool,
) -> str:
    retryable_errors = (
        APITimeoutError,
        APIConnectionError,
        RateLimitError,
        APIError,
    )
    stage_total = 3

    def log_stage(message: str) -> None:
        if show_stage_logs:
            print(message, flush=True)

    def run_stage(
        stage_index: int,
        stage_name: str,
        description: str,
        messages_builder,
        temperature: float = 0.2,
    ) -> str:
        last_error: Exception | None = None
        log_stage(f"    üü° Èò∂ÊÆµ {stage_index}/{stage_total}Ôºö{stage_name}Ôºà{description}Ôºâ")
        for attempt in range(1, max_retries + 1):
            try:
                response = client.chat.completions.create(
                    model=model,
                    temperature=temperature,
                    messages=messages_builder(),
                )
                content = response.choices[0].message.content.strip()
                log_stage(f"    ‚úÖ Èò∂ÊÆµ {stage_index}/{stage_total} ÂÆåÊàê")
                return content
            except retryable_errors as err:
                last_error = err
                if attempt == max_retries:
                    break
                delay = retry_delay * attempt
                log_stage(
                    f"    ‚ö†Ô∏è Èò∂ÊÆµ {stage_index}/{stage_total} Â§±Ë¥•ÔºàÁ¨¨ {attempt}/{max_retries} Ê¨°ÔºâÔºö{err}. {delay:.1f}s ÂêéÈáçËØï..."
                )
                time.sleep(delay)
        assert last_error is not None
        raise last_error

    # Èò∂ÊÆµ 1ÔºöÂàùÊ≠•ÁøªËØë
    def stage1_messages():
        return [
            {
                "role": "system",
                "content": "You are a meticulous bilingual translator. Produce a faithful Markdown translation from "
                f"{source_lang} to {target_lang}, preserving structure, code blocks, inline math, and links.",
            },
            {
                "role": "user",
                "content": dedent(
                    f"""
                    ËØ∑Â∞Ü‰ª•‰∏ã Markdown ÊÆµËêΩ‰ªé {source_lang} ÁøªËØëÊàê {target_lang}„ÄÇÂä°ÂøÖÂø†ÂÆû‰º†ËææÂê´‰πâÔºå‰∏çË¶ÅÊ∂¶Ëâ≤Ôºö
                    ```markdown
                    {chunk}
                    ```
                    """
                ).strip(),
            },
        ]

    initial_translation = run_stage(
        stage_index=1,
        stage_name="ÂàùÊ≠•ÁøªËØë",
        description="Âø†ÂÆû‰øùÁïô Markdown ÁªìÊûÑ",
        messages_builder=stage1_messages,
        temperature=0.1,
    )

    # Èò∂ÊÆµ 2ÔºöÂèçÊÄùËØÑ‰º∞
    def stage2_messages():
        return [
            {
                "role": "system",
                "content": "You are a bilingual reviewer. Compare the source and translation, then list concrete improvement points covering accuracy, terminology, tone, and formatting. Keep it concise.",
            },
            {
                "role": "user",
                "content": dedent(
                    f"""
                    ÂéüÊñá MarkdownÔºö
                    ```markdown
                    {chunk}
                    ```

                    ÂàùÊ≠•ËØëÊñáÔºö
                    ```markdown
                    {initial_translation}
                    ```

                    ËØ∑Áî® 3-6 Êù°Ë¶ÅÁÇπÂàóÂá∫ÂèØ‰ª•ÊîπËøõÁöÑÂú∞ÊñπÔºåÊØèÊù°ÂºÄÂ§¥‰ΩøÁî® `-`„ÄÇ
                    """
                ).strip(),
            },
        ]

    review_notes = run_stage(
        stage_index=2,
        stage_name="ÂèçÊÄùËØÑ‰º∞",
        description="ÂàóÂá∫ÊîπËøõË¶ÅÁÇπ",
        messages_builder=stage2_messages,
        temperature=0.0,
    )

    if show_stage_logs and review_notes:
        log_stage("      üìã ÊîπËøõË¶ÅÁÇπÔºö")
        for line in review_notes.splitlines():
            log_stage(f"        {line}")

    # Èò∂ÊÆµ 3Ôºö‰ºòÂåñÊ∂¶Ëâ≤
    def stage3_messages():
        return [
            {
                "role": "system",
                "content": "You are a senior bilingual technical editor. Apply the improvement notes and produce a polished Markdown translation. Only output the final Markdown, no explanations.",
            },
            {
                "role": "user",
                "content": dedent(
                    f"""
                    ÂéüÊñá MarkdownÔºö
                    ```markdown
                    {chunk}
                    ```

                    ÂàùÊ≠•ËØëÊñáÔºö
                    ```markdown
                    {initial_translation}
                    ```

                    ÊîπËøõË¶ÅÁÇπÔºö
                    {review_notes}

                    ËØ∑Ê†πÊçÆÊîπËøõË¶ÅÁÇπËæìÂá∫Ê∂¶Ëâ≤ÂêéÁöÑÊúÄÁªàËØëÊñáÔºå‰ªÖËæìÂá∫ Markdown„ÄÇ
                    """
                ).strip(),
            },
        ]

    final_translation = run_stage(
        stage_index=3,
        stage_name="‰ºòÂåñÊ∂¶Ëâ≤",
        description="ËêΩÂÆûÊîπËøõË¶ÅÁÇπÂπ∂ËæìÂá∫ÊúÄÁªàËØëÊñá",
        messages_builder=stage3_messages,
        temperature=0.2,
    )

    return final_translation


def translate_text(
    client: OpenAI,
    model: str,
    text: str,
    source_lang: str,
    target_lang: str,
    chunk_size: int,
    max_retries: int,
    retry_delay: float,
    show_progress: bool,
    show_stage_logs: bool,
) -> str:
    translated_chunks: List[str] = []
    chunks = list(chunk_markdown(text, chunk_size))
    total = len(chunks)
    for index, chunk in enumerate(chunks, start=1):
        if show_progress:
            print(f"‚è≥ ÁøªËØëËøõÂ∫¶: {index}/{total}ÔºàÊú¨ÊÆµ {len(chunk)} Â≠óÁ¨¶Ôºâ", flush=True)
        translated_chunks.append(
            translate_chunk(
                client,
                model,
                chunk,
                source_lang,
                target_lang,
                max_retries,
                retry_delay,
                show_stage_logs,
            )
        )
    return "\n\n".join(translated_chunks).strip() + "\n"


def translate_file(
    client: OpenAI,
    model: str,
    input_file: Path,
    output_file: Optional[Path],
    source_lang: str,
    target_lang: str,
    chunk_size: int,
    max_retries: int,
    retry_delay: float,
    show_progress: bool,
    show_stage_logs: bool,
    overwrite: bool,
    skip_if_chinese: bool,
) -> None:
    if not input_file.exists():
        raise FileNotFoundError(f"ËæìÂÖ•Êñá‰ª∂‰∏çÂ≠òÂú®: {input_file}")
    if input_file.suffix.lower() != ".md":
        raise ValueError(f"‰ªÖÊîØÊåÅ .md Êñá‰ª∂: {input_file}")

    text = input_file.read_text(encoding="utf-8")
    if skip_if_chinese and is_probably_chinese(text):
        print(f"‚ö†Ô∏è  Ë∑≥Ëøá {input_file.name}ÔºàÊ£ÄÊµã‰∏∫‰∏≠ÊñáÔºâ")
        return

    destination = output_file or input_file.with_name(f"{input_file.stem}_zh{input_file.suffix}")
    if destination.exists() and not overwrite:
        print(f"‚ö†Ô∏è  ÁõÆÊ†áÊñá‰ª∂Â∑≤Â≠òÂú®Ôºå‰ΩøÁî® --overwrite ÂèØË¶ÜÁõñ: {destination}")
        return

    print(
        f"\n{'='*60}\nÁøªËØëÊñá‰ª∂: {input_file}\nËæìÂá∫Êñá‰ª∂: {destination}\n{'='*60}",
        flush=True,
    )
    translation = translate_text(
        client=client,
        model=model,
        text=text,
        source_lang=source_lang,
        target_lang=target_lang,
        chunk_size=chunk_size,
        max_retries=max_retries,
        retry_delay=retry_delay,
        show_progress=show_progress,
        show_stage_logs=show_stage_logs,
    )
    destination.parent.mkdir(parents=True, exist_ok=True)
    destination.write_text(translation, encoding="utf-8")
    print(f"‚úÖ Â∑≤ÁîüÊàê: {destination}", flush=True)


def translate_directory(
    client: OpenAI,
    model: str,
    input_dir: Path,
    output_dir: Optional[Path],
    source_lang: str,
    target_lang: str,
    chunk_size: int,
    max_retries: int,
    retry_delay: float,
    show_progress: bool,
    show_stage_logs: bool,
    overwrite: bool,
    skip_if_chinese: bool,
    recursive: bool,
) -> None:
    if not input_dir.is_dir():
        raise FileNotFoundError(f"ËæìÂÖ•ÁõÆÂΩï‰∏çÂ≠òÂú®: {input_dir}")

    md_files = sorted(
        input_dir.rglob("*.md") if recursive else input_dir.glob("*.md"),
        key=lambda p: str(p),
    )
    if not md_files:
        print(f"‚ö†Ô∏è  ÁõÆÂΩï‰∏≠Êú™ÊâæÂà∞ Markdown Êñá‰ª∂: {input_dir}")
        return

    for path in md_files:
        relative = path.relative_to(input_dir)
        target_file = (
            (output_dir / relative).with_name(f"{relative.stem}_zh{relative.suffix}")
            if output_dir
            else path.with_name(f"{path.stem}_zh{path.suffix}")
        )
        translate_file(
            client=client,
            model=model,
            input_file=path,
            output_file=target_file,
            source_lang=source_lang,
            target_lang=target_lang,
            chunk_size=chunk_size,
            max_retries=max_retries,
            retry_delay=retry_delay,
            show_progress=show_progress,
            show_stage_logs=show_stage_logs,
            overwrite=overwrite,
            skip_if_chinese=skip_if_chinese,
        )


def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="‰ΩøÁî®Âê¥ÊÅ©Ëææ‰∏âÊ≠•Ê≥ïÁøªËØë Markdown ÊñáÊ°£ÔºàÊîØÊåÅÊñá‰ª∂ÊàñÁõÆÂΩïÔºâ„ÄÇ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=dedent(
            """
            Á§∫‰æãÔºö
              python scripts/translate_md_ng.py docs/course.md
              python scripts/translate_md_ng.py docs/ --output docs/zh/ --recursive
              python scripts/translate_md_ng.py docs/course.md --model gpt-4o-mini --chunk-size 2000
            """
        ),
    )
    parser.add_argument("input", type=Path, help="ËæìÂÖ• Markdown Êñá‰ª∂ÊàñÁõÆÂΩï")
    parser.add_argument("--output", "-o", type=Path, help="ËæìÂá∫Êñá‰ª∂ÊàñÁõÆÂΩïÔºàÈªòËÆ§‰∏éËæìÂÖ•ÂêåÁõÆÂΩïÔºåËøΩÂä† _zhÔºâ")
    parser.add_argument("--model", type=str, default=None, help="Ë¶ÜÁõñ .env ‰∏≠ÁöÑ TRANSLATE_MODEL")
    parser.add_argument("--api-key", type=str, default=None, help="Ë¶ÜÁõñ .env ‰∏≠ÁöÑ TRANSLATE_API_KEY/OPENAI_API_KEY")
    parser.add_argument("--base-url", type=str, default=None, help="Ë¶ÜÁõñ .env ‰∏≠ÁöÑ TRANSLATE_BASE_URL/OPENAI_BASE_URL")
    parser.add_argument("--source-lang", type=str, default="English", help="Ê∫êËØ≠Ë®ÄÊèèËø∞ÔºàÈªòËÆ§ EnglishÔºâ")
    parser.add_argument("--target-lang", type=str, default="Chinese", help="ÁõÆÊ†áËØ≠Ë®ÄÊèèËø∞ÔºàÈªòËÆ§ ChineseÔºâ")
    parser.add_argument(
        "--chunk-size",
        type=int,
        default=DEFAULT_CHUNK_SIZE,
        help=f"ÂàÜÊÆµÂ§ßÂ∞èÔºàÂ≠óÁ¨¶Êï∞ÔºåÈªòËÆ§ {DEFAULT_CHUNK_SIZE}Ôºâ",
    )
    parser.add_argument(
        "--request-timeout",
        type=float,
        default=DEFAULT_REQUEST_TIMEOUT,
        help=f"ÂçïÊ¨°ËØ∑Ê±ÇË∂ÖÊó∂Êó∂Èó¥ÔºàÁßíÔºåÈªòËÆ§ {DEFAULT_REQUEST_TIMEOUT}Ôºâ",
    )
    parser.add_argument(
        "--max-retries",
        type=int,
        default=DEFAULT_MAX_RETRIES,
        help=f"ËØ∑Ê±ÇÂ§±Ë¥•ÈáçËØïÊ¨°Êï∞ÔºàÈªòËÆ§ {DEFAULT_MAX_RETRIES}Ôºâ",
    )
    parser.add_argument(
        "--retry-delay",
        type=float,
        default=DEFAULT_RETRY_DELAY,
        help=(
            "È¶ñÊ¨°ÈáçËØïÁ≠âÂæÖÁßíÊï∞ÔºàÈöèÂêéÊåâÂ∞ùËØïÊ¨°Êï∞Á∫øÊÄßÈÄíÂ¢ûÔºå"
            f"ÈªòËÆ§ {DEFAULT_RETRY_DELAY}Ôºâ"
        ),
    )
    parser.add_argument(
        "--progress",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="ËæìÂá∫ÊåâÂàÜÊÆµÔºàchunkÔºâÁöÑÁøªËØëËøõÂ∫¶Êó•ÂøóÔºàÈªòËÆ§ÂºÄÂêØÔºâ",
    )
    parser.add_argument(
        "--stage-logs",
        action=argparse.BooleanOptionalAction,
        default=True,
        help="ÊâìÂç∞Âê¥ÊÅ©Ëææ‰∏âÊ≠•Ê≥ïÂêÑÈò∂ÊÆµÁöÑËØ¶ÁªÜÊó•ÂøóÔºàÈªòËÆ§ÂºÄÂêØÔºâ",
    )
    parser.add_argument("--overwrite", action="store_true", help="Ë¶ÜÁõñÂ∑≤Â≠òÂú®ÁöÑ _zh Êñá‰ª∂")
    parser.add_argument("--recursive", "-r", action="store_true", help="ÈÄíÂΩíÁøªËØëÂ≠êÁõÆÂΩïÔºà‰ªÖËæìÂÖ•‰∏∫ÁõÆÂΩïÊó∂ÁîüÊïàÔºâ")
    parser.add_argument(
        "--skip-if-chinese",
        action="store_true",
        default=True,
        help="Ê£ÄÊµãÂà∞Â∑≤‰∏∫‰∏≠ÊñáÊó∂Ë∑≥ËøáÔºàÈªòËÆ§ÂºÄÂêØÔºâ",
    )
    return parser


def main() -> None:
    parser = build_arg_parser()
    args = parser.parse_args()

    model = args.model or DEFAULT_MODEL
    api_key = args.api_key or DEFAULT_API_KEY
    base_url = args.base_url or DEFAULT_BASE_URL
    request_timeout = args.request_timeout
    max_retries = args.max_retries
    retry_delay = args.retry_delay
    show_progress = args.progress
    show_stage_logs = args.stage_logs

    client = create_client(api_key, base_url, request_timeout)

    input_path = args.input.resolve()
    if input_path.is_file():
        translate_file(
            client=client,
            model=model,
            input_file=input_path,
            output_file=args.output,
            source_lang=args.source_lang,
            target_lang=args.target_lang,
            chunk_size=args.chunk_size,
            max_retries=max_retries,
            retry_delay=retry_delay,
            show_progress=show_progress,
            show_stage_logs=show_stage_logs,
            overwrite=args.overwrite,
            skip_if_chinese=args.skip_if_chinese,
        )
    elif input_path.is_dir():
        translate_directory(
            client=client,
            model=model,
            input_dir=input_path,
            output_dir=args.output,
            source_lang=args.source_lang,
            target_lang=args.target_lang,
            chunk_size=args.chunk_size,
            max_retries=max_retries,
            retry_delay=retry_delay,
            show_progress=show_progress,
            show_stage_logs=show_stage_logs,
            overwrite=args.overwrite,
            skip_if_chinese=args.skip_if_chinese,
            recursive=args.recursive,
        )
    else:
        parser.error(f"ËæìÂÖ•Ë∑ØÂæÑ‰∏çÂ≠òÂú®: {input_path}")


if __name__ == "__main__":
    main()
