{
  "EN:ZH:In this final lesson, let's take a step back and look at the bigger picture of how everything you've": "在最后一课中，让我们退后一步，从大局出发，看看你所做的一切是如何",
  "EN:ZH:learned so far in this course comes together to help you scale customer success with confidence.": "在本课程中所学到的知识将帮助您满怀信心地扩大客户成功。",
  "EN:ZH:Whether you're just starting out or managing a growing team, the tools inside Tdoe are designed to": "无论您是刚刚起步，还是在管理一个不断壮大的团队，Tdoe 内的工具都旨在",
  "EN:ZH:not only make your life easier, but to elevate the experience for every customer who interacts with": "不仅让您的生活更轻松，而且提升每一位与您互动的客户的体验",
  "EN:ZH:your brand throughout this journey.": "您的品牌将贯穿整个旅程。",
  "EN:ZH:We've explored how to set up Livechat, automate responses with ROI, manage email communication, and": "我们探讨了如何设置 Livechat、利用投资回报率自动回复、管理电子邮件沟通，以及",
  "EN:ZH:design intelligent chatbot flows.": "设计智能聊天机器人流程",
  "EN:ZH:These aren't just features, they are building blocks for a support system that grows with your business.": "这些不仅仅是功能，它们还是与企业共同成长的支持系统的基石。",
  "EN:ZH:When used together, they give you the power to be available 24 over seven.": "当它们一起使用时，就能为您提供 24 小时全天候服务。",
  "EN:ZH:Resolve issues faster and make every interaction feel more personal, even when you're not the one handling": "更快地解决问题，让每次互动都更有人情味，即使不是您在处理问题",
  "EN:ZH:it directly.": "直接",
  "EN:ZH:Now, scaling doesn't mean doing more work, it means doing smarter work.": "现在，扩大规模并不意味着做更多的工作，而是意味着做更聪明的工作。",
  "EN:ZH:And with studio, that means allowing automation to handle repetitive questions while your team focuses": "对于工作室而言，这意味着允许自动化处理重复性问题，而您的团队则专注于",
  "EN:ZH:on what truly requires a human touch.": "什么是真正需要人情味的东西。",
  "EN:ZH:It means having analytics that tell you what's working and what's not, so you're always making informed": "这意味着要有分析方法来告诉你哪些有效，哪些无效，这样你就能随时做出明智的决策。",
  "EN:ZH:decisions, and it means integrating with the platforms your customers already use like email, Facebook,": "决定，这意味着要与客户已经使用的平台（如电子邮件、Facebook）进行整合、",
  "EN:ZH:Instagram or WhatsApp.": "Instagram 或 WhatsApp。",
  "EN:ZH:So no matter where they reach out, your response is ready and consistent.": "因此，无论他们从哪里联系您，您都能随时做出一致的回应。",
  "EN:ZH:Let's be honest as your business grows, customer expectations don't just increase, they evolve.": "老实说，随着企业的发展，客户的期望值不仅会提高，还会不断变化。",
  "EN:ZH:They expect fast replies, helpful guidance, and a sense that you know who they are.": "他们希望得到快速回复、有益的指导，以及您了解他们的感觉。",
  "EN:ZH:Scaling customer success with confidence means being ready for that shift.": "满怀信心地扩大客户成功率意味着为这种转变做好准备。",
  "EN:ZH:And thanks to what you've built with Tdoe, you are.": "多亏了您与 Tdoe 的合作，您才能做到这一点。",
  "EN:ZH:Here's something to reflect on.": "这里有一点值得反思。",
  "EN:ZH:Picture your support process six months from now.": "想象一下六个月后的支持流程。",
  "EN:ZH:What if your chatbot is resolving 60% of customer questions on its own?": "如果您的聊天机器人能自行解决 60% 的客户问题呢？",
  "EN:ZH:What if your agents are spending their time only on high value, complex issues?": "如果您的代理只把时间花在高价值、复杂的问题上怎么办？",
  "EN:ZH:What if you are seeing more sales simply because you responded to visitors faster and more personally?": "如果仅仅因为您对访客的回应更快、更个性化，您就能看到更多的销售额呢？",
  "EN:ZH:That's not a dream scenario.": "这不是梦境。",
  "EN:ZH:It's exactly what this setup is made for.": "这正是这种设置的目的。",
  "EN:ZH:So here's your next step.": "所以，这是你的下一步。",
  "EN:ZH:Keep refining what you've built.": "不断完善自己的成果。",
  "EN:ZH:Update your flows as new questions come in.": "在收到新问题时更新您的流程。",
  "EN:ZH:Let Lero learn and improve.": "让 Lero 学习和进步。",
  "EN:ZH:Review your analytics regularly and don't hesitate to try new integrations as your customer base expands.": "定期查看分析结果，随着客户群的扩大，毫不犹豫地尝试新的集成。",
  "EN:ZH:This isn't about reaching perfection.": "这不是要达到完美。",
  "EN:ZH:It's about creating a support system that's smart, responsive, and always evolving with your goals.": "这就是要创建一个支持系统，这个系统要聪明、反应迅速，并始终与你的目标同步发展。",
  "EN:ZH:Thank you for spending this time learning how to bring AI into your customer support with purpose and": "感谢您花这么多时间学习如何将人工智能有目的、有计划地应用到客户支持中。",
  "EN:ZH:clarity.": "明确性。",
  "EN:ZH:You've taken big steps toward building a stronger, more scalable experience for your customers and": "您在为客户打造更强大、更可扩展的体验方面迈出了一大步，并且",
  "EN:ZH:for your team.": "为你的团队服务。",
  "EN:ZH:I appreciate you joining me on this journey.": "感谢您和我一起踏上这段旅程。",
  "EN:ZH:I'll see you out there.": "我们外面见",
  "EN:ZH:Making support smarter, smoother, and more human.": "让支持更智能、更顺畅、更人性化。",
  "EN:ZH:One interaction at a time.": "一次互动",
  "EN:ZH:In this lesson, let's focus on something that often gets overlooked how to stay updated with tedious": "在这一课中，让我们重点讨论一些经常被忽视的问题，即如何通过乏味的",
  "EN:ZH:latest features and the evolving landscape of AI in customer support.": "最新功能以及人工智能在客户支持中不断发展的前景。",
  "EN:ZH:Because as much as you've learned so far, the tools you're using today are only going to get smarter,": "因为正如您目前所学到的一样，您现在使用的工具只会越来越智能、",
  "EN:ZH:faster, and more capable tomorrow.": "更快、能力更强的明天。",
  "EN:ZH:And the more proactive you are about keeping up, the more confident and competitive your support strategy": "你越是积极主动，你的支持战略就越有信心和竞争力",
  "EN:ZH:will be.": "将是",
  "EN:ZH:Let's start with Td0 itself.": "让我们从 Td0 本身说起。",
  "EN:ZH:The platform is constantly rolling out new updates, sometimes small improvements, other times major": "该平台不断推出新的更新，有时是微小的改进，有时则是重大改进。",
  "EN:ZH:new features like expanded integrations, new AI capabilities, or smarter automation tools.": "新功能，如扩展的集成、新的人工智能功能或更智能的自动化工具。",
  "EN:ZH:The best way to stay in the loop is directly from your dashboard.": "保持联系的最佳方式是直接从您的仪表板进行操作。",
  "EN:ZH:You'll often see announcements, tips, or update banners right inside the app.": "您经常会在应用内看到公告、提示或更新横幅。",
  "EN:ZH:Make it a habit to check the What's New section or the notification bell.": "养成查看 \"最新消息 \"部分或通知铃声的习惯。",
  "EN:ZH:It takes less than a minute, but it can save you hours down the line by showing you how to do something": "这只需不到一分钟的时间，但却能为您节省数小时的时间，告诉您如何做某事",
  "EN:ZH:better or faster.": "更好或更快。",
  "EN:ZH:Another great resource is Tedious Blog and help center.": "另一个很好的资源是 Tedious 博客和帮助中心。",
  "EN:ZH:These aren't just support articles, they often include real use cases, AI trends, and practical examples": "这些不仅仅是辅助性文章，通常还包括实际使用案例、人工智能趋势和实用范例",
  "EN:ZH:that show how other businesses are using the same tools you're working with.": "展示其他企业如何使用与您相同的工具。",
  "EN:ZH:If you're ever feeling stuck or wondering how are other people using this feature?": "如果您感到困惑或想知道其他人是如何使用这项功能的？",
  "EN:ZH:That's the first place to look.": "这是第一个要找的地方。",
  "EN:ZH:You'll find walkthroughs, strategies, and even previews of upcoming releases.": "您可以在这里找到攻略、策略，甚至是即将发布的版本预览。",
  "EN:ZH:Now, beyond video itself, it's also important to keep your eyes on the bigger picture, especially": "现在，除了视频本身，关注更广阔的视野也很重要，尤其是",
  "EN:ZH:with AI.": "与人工智能。",
  "EN:ZH:The world of AI in customer service is changing fast.": "人工智能在客户服务领域的应用日新月异。",
  "EN:ZH:What felt new a year ago is now standard, and what seems experimental today will likely be mainstream": "一年前觉得新鲜的东西现在已经成为标准，而今天看似实验性的东西很可能会成为主流",
  "EN:ZH:soon.": "很快",
  "EN:ZH:Subscribing to newsletters like inside AI, following industry leaders on LinkedIn, or even just setting": "订阅诸如 inside AI 等新闻简报，在 LinkedIn 上关注行业领导者，甚至仅仅设置",
  "EN:ZH:up Google Alerts for terms like AI and customer support, can help you stay informed without needing": "为人工智能和客户支持等术语设置 Google Alerts，可以帮助您随时了解信息，而无需",
  "EN:ZH:to hunt for information.": "寻找信息。",
  "EN:ZH:Finally, remember this staying updated isn't about chasing every new trend.": "最后，请记住，与时俱进并不是要追逐每一种新潮流。",
  "EN:ZH:It's about being aware of what's possible so you can make better decisions.": "这是为了让你意识到什么是可能的，从而做出更好的决定。",
  "EN:ZH:If you know a feature has improved, you can revisit how you're using it.": "如果你知道某项功能有所改进，就可以重新审视自己的使用方式。",
  "EN:ZH:If a new AI tool is launched, you can explore whether it fits your workflow.": "如果有新的人工智能工具推出，您可以探索它是否适合您的工作流程。",
  "EN:ZH:The point is to keep learning not just once, but continuously as your support strategy evolves.": "关键是要不断学习，而不是只学一次，而是随着支持战略的发展而不断学习。",
  "EN:ZH:Thanks for joining.": "感谢您的加入。",
  "EN:ZH:Staying current is how you stay ahead and you're already taking the right steps by being here.": "与时俱进才能保持领先，而你们在这里已经迈出了正确的一步。",
  "EN:ZH:I'll see you in the next one.": "我们下一届再见。",
  "EN:ZH:Your feedback is important to us to leave a review.": "您的反馈对我们留下评论非常重要。",
  "EN:ZH:Go to the My Learning page and click on the course that you wish to review.": "转到 \"我的学习 \"页面，点击您要复习的课程。",
  "EN:ZH:Your input will help us make our course better.": "您的意见将帮助我们把课程做得更好。",
  "EN:ZH:Since you have already bought the course, all updates will be provided to you free of charge.": "由于您已经购买了课程，所有更新都将免费提供给您。",
  "EN:ZH:My goal is to always make the best lessons possible.": "我的目标是尽可能做出最好的课程。",
  "EN:ZH:Once you are at the leave a rating section, we would appreciate it if you gave us your honest rating": "在 \"留下评价 \"部分，我们希望您能给我们诚实的评价。",
  "EN:ZH:along with written feedback.": "以及书面反馈。",
  "EN:ZH:The written feedback will really help us determine the areas of the course that need improvement in": "书面反馈将真正帮助我们确定课程中需要改进的方面，包括",
  "EN:ZH:your feedback.": "您的反馈",
  "EN:ZH:Please let us know if the course, audio and video is good.": "如果课程、音频和视频效果良好，请告诉我们。",
  "EN:ZH:If you feel that we are lacking information and some topics, please tell us in your feedback.": "如果您认为我们缺少信息和某些主题，请在反馈中告诉我们。",
  "EN:ZH:If you have topics that you think we should add, you can also let us know.": "如果您认为我们应该添加一些主题，也可以告诉我们。",
  "EN:ZH:Here are some constructive criticism examples we received from our students.": "以下是我们从学生那里收到的一些建设性批评范例。",
  "EN:ZH:These students told us that SimilarWeb did not offer data for small sites, since SimilarWeb does not": "这些学生告诉我们，SimilarWeb 没有为小型网站提供数据，因为 SimilarWeb 没有",
  "EN:ZH:offer data for smaller sites.": "为小型网站提供数据。",
  "EN:ZH:We offered our students an alternative tool called SEMrush.": "我们为学生提供了一款名为 SEMrush 的替代工具。",
  "EN:ZH:Another student told us that we did not have enough practical tasks within the lesson, so we added": "另一名学生告诉我们，课上的实践任务不够多，因此我们增加了",
  "EN:ZH:tables, checklists and additional practical materials.": "表格、核对表和其他实用资料。",
  "EN:ZH:We take all of your feedback very seriously, and we will do our absolute best to improve the course.": "我们会认真对待您的所有反馈意见，并尽最大努力改进课程。",
  "EN:ZH:Thank you for your review and detailed critiques.": "感谢您的评论和详细点评。",
  "EN:ZH:Hey guys, it's Anthony Warnock and our Q&A session.": "大家好，这里是 Anthony Warnock 和我们的问答环节。",
  "EN:ZH:One of the most popular questions in this session is how can I get my certificate?": "本环节中最热门的问题之一是如何获得证书？",
  "EN:ZH:Of course, user experience of Udemy platform is not the best one and sometimes it's rather difficult": "当然，Udemy 平台的用户体验并不是最好的，有时甚至相当困难。",
  "EN:ZH:to find your certificate.": "找到您的证书。",
  "EN:ZH:Let's do it!": "开始吧",
  "EN:ZH:The first step you have login to your account.": "第一步，您必须登录您的账户。",
  "EN:ZH:After that you are going to my learning.": "之后，你们将进入我的学习阶段。",
  "EN:ZH:You are going to my learning tab and here we are.": "您将进入我的 \"学习 \"选项卡，我们就在这里。",
  "EN:ZH:You can see all the courses that you are enrolled on Udemy.": "您可以查看您在 Udemy 上注册的所有课程。",
  "EN:ZH:Let's check any one course where I have 100% completed.": "让我们来看看我 100%完成的任何一门课程。",
  "EN:ZH:In this case, it's ultimate unofficial Udemy online courses guide.": "在这种情况下，它就是非官方的 Udemy 在线课程终极指南。",
  "EN:ZH:If you didn't complete whole course, you won't get certificate even you have 1% of video or any article": "如果您没有完成整个课程，即使您有 1%的视频或文章，也不会获得证书。",
  "EN:ZH:that you didn't read.": "你没读过",
  "EN:ZH:You want to get this certificate.": "你想获得这张证书。",
  "EN:ZH:So before asking Udemy or me or any other person to give you certificate, please check.": "因此，在要求 Udemy 或我或其他人为您颁发证书之前，请先核实一下。",
  "EN:ZH:Did you finish the course.": "你完成课程了吗？",
  "EN:ZH:In case I have less than 100% of completeness, you won't get.": "如果我的完整性达不到 100%，你就得不到。",
  "EN:ZH:Certificate of the course.": "课程证书",
  "EN:ZH:For example, Udemy Masters I watched just 96% of course.": "例如，Udemy Masters 我只看了 96% 的课程。",
  "EN:ZH:So when I try to go here and I want to go to my progress, I can just see that I've completed 63 of": "因此，当我试着转到这里并想查看我的进度时，我可以看到我已经完成了 63 个",
  "EN:ZH:64 complete lectures, and in this case, I need to finish one more.": "64 个完整的讲座，在这种情况下，我还需要完成一个讲座。",
  "EN:ZH:I need to find one more lecture before I will get the certificate.": "我需要再找一个讲座，然后才能拿到证书。",
  "EN:ZH:Let's check.": "让我们检查一下。",
  "EN:ZH:I have checked one lecture that I finished it.": "我已经检查过一次讲座，我完成了它。",
  "EN:ZH:Can I get certificate?": "我能获得证书吗？",
  "EN:ZH:Yes, now I can get certificate.": "是的，现在我可以拿到证书了。",
  "EN:ZH:I can just click here, get certificate Get my certificate, I can download it.": "我可以点击这里，获取证书 获取我的证书，我可以下载它。",
  "EN:ZH:I can download it as a PDF.": "我可以下载 PDF 格式的文件。",
  "EN:ZH:I can share it in social networks, I can post it to Facebook, to LinkedIn, etc. and in this case": "我可以在社交网络上分享它，我可以把它发布到 Facebook、LinkedIn 等网站上，在这种情况下",
  "EN:ZH:I have to get my certificate.": "我必须拿到证书。",
  "EN:ZH:But one more time.": "但请再来一次。",
  "EN:ZH:If you didn't complete the course, if you didn't have 100% of completeness here, you will not get": "如果你没有完成课程，如果你没有 100%完成这里的课程，你将不会获得",
  "EN:ZH:your certification yet.": "您还没有获得认证。",
  "EN:ZH:Let's check one another course, for example the Ultimate Udemy guide.": "让我们再看看另一门课程，例如 Udemy 终极指南。",
  "EN:ZH:And in this case I have 100% done and I can get certificate here and get certificate.": "在这种情况下，我已经 100% 完成了工作，我可以在这里获得证书并拿到证书。",
  "EN:ZH:It's easy to do if you have such issue, you have have such problem.": "如果你有这样的问题，你就很容易做到。",
  "EN:ZH:Just check any lecture, any materials, assignments, etc. in course and if you already done them you": "只需检查课程中的任何讲座、任何材料、作业等，如果您已经完成，您就可以",
  "EN:ZH:have 100%.": "有 100%。",
  "EN:ZH:You will get your certificate and I congratulate you.": "你们将获得证书，我向你们表示祝贺。",
  "EN:ZH:You can now post it to LinkedIn and do your best.": "现在，您可以将其发布到 LinkedIn 上，并尽自己最大的努力。",
  "EN:ZH:Thank you for your attention.": "感谢您的关注。",
  "EN:ZH:It wasn't on very new.": "它并不新。",
  "EN:ZH:Instructor: Hello and welcome back.": "讲师你好，欢迎回来。",
  "EN:ZH:Today, we are talking about the machine learning process.": "今天，我们要讨论的是机器学习过程。",
  "EN:ZH:As you will see from the practical tutorials of this course,": "您将从本课程的实践教程中了解到这一点、",
  "EN:ZH:there is a specific step-by-step process": "有一个具体的步骤",
  "EN:ZH:that we typically always follow": "我们通常总是遵循",
  "EN:ZH:when building machine learning models.": "建立机器学习模型时。",
  "EN:ZH:So, let's have a look at what this process entails.": "那么，让我们来看看这个过程需要什么。",
  "EN:ZH:This process has three main steps.": "这个过程有三个主要步骤。",
  "EN:ZH:The first one is called data pre-processing,": "第一种称为数据预处理、",
  "EN:ZH:and here we import the data, we clean the data,": "在这里，我们导入数据，清理数据、",
  "EN:ZH:and we split the data into training and test sets.": "并将数据分为训练集和测试集。",
  "EN:ZH:A quick note is that in this course,": "在本课程中，有一点需要注意、",
  "EN:ZH:we won't be focusing a lot on cleaning the data.": "我们不会把太多精力放在清理数据上。",
  "EN:ZH:That's because our data is pre-cleaned,": "这是因为我们的数据是经过预先清洗的、",
  "EN:ZH:so that we can really hone in our other skills": "这样我们才能真正磨练我们的其他技能",
  "EN:ZH:related to machine learning.": "与机器学习有关。",
  "EN:ZH:But bear in mind that in real-world situations,": "但请记住，在现实世界中、",
  "EN:ZH:clean the data is quite an important step.": "清理数据是相当重要的一步。",
  "EN:ZH:Next, we move onto modeling, where we first build the model,": "接下来，我们进入建模阶段，首先要建立模型、",
  "EN:ZH:then we train the model, and we make the prediction.": "然后我们训练模型，进行预测。",
  "EN:ZH:So, this is the fun part of machine learning,": "这就是机器学习的乐趣所在、",
  "EN:ZH:and in this course you'll get a great exposure": "在本课程中，您将有机会接触到",
  "EN:ZH:to several different models": "到几种不同的模式",
  "EN:ZH:and you'll be able to practice your skills there.": "您可以在那里练习您的技能。",
  "EN:ZH:And finally, we move on to evaluations.": "最后，我们开始评估。",
  "EN:ZH:We will calculate some performance metrics": "我们将计算一些性能指标",
  "EN:ZH:and make a verdict about our model,": "并对我们的模型做出判断、",
  "EN:ZH:whether it's a good-fitting model": "是否是一个好的拟合模型",
  "EN:ZH:and if it works for our data or not.": "以及它是否适用于我们的数据。",
  "EN:ZH:And this is a very important step to make sure": "这是一个非常重要的步骤，以确保",
  "EN:ZH:that the models we build really serve the purpose": "我们所建立的模型能真正达到目的",
  "EN:ZH:that they're designed for.": "它们的设计目的",
  "EN:ZH:So, there we go. That's the machine learning process.": "就是这样。这就是机器学习的过程。",
  "EN:ZH:And in this course,": "在这门课程中",
  "EN:ZH:you'll definitely have lots of opportunities": "你一定会有很多机会",
  "EN:ZH:to get some great hands-on experience with it.": "以获得一些很好的实践经验。",
  "EN:ZH:And I look forward to seeing you next time.": "期待下次再见。",
  "EN:ZH:Until then, enjoy machine learning.": "在此之前，请享受机器学习。",
  "EN:ZH:-: Hello and welcome back.": "-:你好，欢迎回来。",
  "EN:ZH:Today we're talking about the importance": "今天我们要讨论的是",
  "EN:ZH:of splitting your data set": "分割数据集",
  "EN:ZH:into a training set and a test set.": "分为训练集和测试集。",
  "EN:ZH:Let's imagine that you are tasked to predict the sale prices": "假设你的任务是预测销售价格",
  "EN:ZH:of cars, and that is your dependent variable.": "这就是因变量。",
  "EN:ZH:And your independent variables are the mileage": "自变量是里程",
  "EN:ZH:of the car and its age.": "车况和车龄。",
  "EN:ZH:And in your data that are supplied to you": "在提供给您的数据中",
  "EN:ZH:you have 20 cars in total.": "你们一共有 20 辆车。",
  "EN:ZH:Of course, that's not a lot, but for illustrative purposes": "当然，这并不是很多，但为了说明问题",
  "EN:ZH:for our tutorial, that will be sufficient.": "对于我们的教程来说，这就足够了。",
  "EN:ZH:So what splitting your data implies is separating a part": "因此，拆分数据意味着将部分数据分离出来",
  "EN:ZH:of your data out before you do anything.": "在您做任何事情之前，请先将您的数据取出。",
  "EN:ZH:And usually that's about 20% of the data.": "而这通常只占数据的 20%左右。",
  "EN:ZH:So since we have 20 cars here": "既然我们这里有 20 辆车",
  "EN:ZH:that's about four cars that we separate out.": "这大约是我们分出的四辆车。",
  "EN:ZH:So what that means is that the bulk of our data": "因此，这意味着我们的大部分数据",
  "EN:ZH:80% will be our training set": "80% 将是我们的训练集",
  "EN:ZH:and the separated 20% will be our test set.": "而分离出来的 20% 将是我们的测试集。",
  "EN:ZH:We'll use our training set to build the model.": "我们将使用训练集来构建模型。",
  "EN:ZH:So in this case we're building a linear regression": "因此，在这种情况下，我们要做的是线性回归",
  "EN:ZH:and then we will take the cars": "然后我们将把汽车",
  "EN:ZH:from the test set": "来自测试集",
  "EN:ZH:we will apply our model to them.": "我们将对它们应用我们的模型。",
  "EN:ZH:So they haven't been part of the model creation process.": "因此，他们没有参与模型创建过程。",
  "EN:ZH:The model has no information about these cars.": "该模型没有关于这些汽车的信息。",
  "EN:ZH:And now we're applying this model to them.": "现在，我们将这一模式应用到他们身上。",
  "EN:ZH:And it's predicting certain values, certain prices.": "它预测的是特定的价值、特定的价格。",
  "EN:ZH:But the good news is that": "但好消息是",
  "EN:ZH:because this is something we separated": "因为这是我们分开",
  "EN:ZH:in advance as part of the data that was given to us": "作为提供给我们的数据的一部分",
  "EN:ZH:we actually know the actual prices.": "我们实际上知道实际价格。",
  "EN:ZH:So now we can compare the predicted values": "现在我们可以比较预测值了",
  "EN:ZH:which were generated using a model that has never": "这些数据是使用一个从未",
  "EN:ZH:seen these cars before, and we can compare that": "我们可以比较一下",
  "EN:ZH:to the actual values that we know what these cars sold for.": "我们知道这些汽车的实际售价。",
  "EN:ZH:And so from that we can evaluate our model.": "因此，我们可以据此评估我们的模型。",
  "EN:ZH:Is it doing a good job?": "它做得好吗？",
  "EN:ZH:Is it doing a not so good job?": "它做得不好吗？",
  "EN:ZH:And do we need to improve it?": "我们需要改进吗？",
  "EN:ZH:And that's how we split a training set and a test set.": "这就是我们如何拆分训练集和测试集的方法。",
  "EN:ZH:And that's why it's important to do that.": "这就是为什么这样做很重要。",
  "EN:ZH:I look forward to seeing you on the next tutorial.": "我期待着在下一次教程中见到你。",
  "EN:ZH:And until then, enjoy machine learning.": "在此之前，请享受机器学习的乐趣。",
  "EN:ZH:Today, we've got an important tutorial.": "今天，我们有一个重要的教程。",
  "EN:ZH:We're talking about feature scaling.": "我们说的是功能扩展。",
  "EN:ZH:Now, before we dive into": "现在，在我们深入探讨",
  "EN:ZH:the technical aspects of feature scaling,": "特征缩放的技术方面、",
  "EN:ZH:I would like to present you with an image": "我想向大家展示一幅图片",
  "EN:ZH:that hopefully will help you remember": "希望能帮助您记住",
  "EN:ZH:what feature scaling is applied to.": "对哪些特征进行缩放。",
  "EN:ZH:Now, even without knowing anything about feature scaling,": "现在，即使对功能缩放一无所知、",
  "EN:ZH:please remember that feature scaling": "请记住，功能缩放",
  "EN:ZH:is always applied to columns.": "总是应用于列。",
  "EN:ZH:So feature scaling would be applied to this column,": "因此，特征缩放将应用于这一列、",
  "EN:ZH:to this column, to this column, to this column.": "到这一栏，到这一栏，到这一栏。",
  "EN:ZH:Feature scaling is never applied across columns,": "特征缩放从不跨列应用、",
  "EN:ZH:so you wouldn't apply feature scaling to data inside a row.": "所以你不会对一行内的数据应用特征缩放。",
  "EN:ZH:Just remember, feature scaling is always applied to columns.": "请记住，特征缩放始终应用于列。",
  "EN:ZH:Now, with that out of the way,": "好了，话不多说、",
  "EN:ZH:let's have a look at what feature scaling actually is.": "让我们来看看什么是功能缩放。",
  "EN:ZH:So there are multiple types of feature scaling,": "因此，有多种类型的特征缩放、",
  "EN:ZH:multiple techniques.": "多种技术。",
  "EN:ZH:We're going to look at the two main ones,": "我们将讨论两个主要问题、",
  "EN:ZH:normalization and standardization.": "规范化和标准化。",
  "EN:ZH:Normalization is the process": "规范化是一个过程",
  "EN:ZH:of taking the minimum inside a column,": "的最小值、",
  "EN:ZH:subtracting that minimum": "减去最小值",
  "EN:ZH:from every single value inside that column,": "该列中的每一个值、",
  "EN:ZH:and then dividing by the difference": "然后除以差值",
  "EN:ZH:between the maximum and the minimum.": "介于最大值和最小值之间。",
  "EN:ZH:So basically,": "所以基本上",
  "EN:ZH:every single value in a column is adjusted this way": "列中的每个值都是这样调整的",
  "EN:ZH:and you will end up with a new column or an adjusted column": "您将得到一个新列或一个调整过的列",
  "EN:ZH:with values which are all between 0 and 1.": "的值都在 0 和 1 之间。",
  "EN:ZH:Standardization, on the other hand,": "另一方面，标准化、",
  "EN:ZH:the process is similar,": "过程是相似的、",
  "EN:ZH:but instead of subtracting the minimum,": "但不是减去最小值、",
  "EN:ZH:we subtract the average,": "我们减去平均数、",
  "EN:ZH:and we divide by the standard deviation.": "除以标准偏差。",
  "EN:ZH:As a result, all of the values,": "因此，所有的值",
  "EN:ZH:or almost all of the values inside the column": "或列内几乎所有的值",
  "EN:ZH:will be between -3 and 3.": "将介于 -3 和 3 之间。",
  "EN:ZH:If you have some extreme values or some outliers,": "如果有一些极端值或异常值、",
  "EN:ZH:then they can end up outside": "然后，他们可以在外面",
  "EN:ZH:of these -3 and 3 boundaries.": "这些 -3 和 3 边界。",
  "EN:ZH:So that is normalization standardization.": "这就是标准化。",
  "EN:ZH:In the practical tutorials with Adlon,": "在与阿德伦的实践教程中、",
  "EN:ZH:you'll be looking at standardization.": "你将会看到标准化。",
  "EN:ZH:And for simplicity's sake, in these intuition tutorials,": "为了简单起见，在这些直觉教程中、",
  "EN:ZH:we'll have a look at normalization.": "我们来看看正常化。",
  "EN:ZH:So let's imagine we have a data set": "假设我们有一个数据集",
  "EN:ZH:where we have two columns,": "其中有两列、",
  "EN:ZH:annual income of a person and their age.": "个人年收入和年龄。",
  "EN:ZH:Just simple data with those two columns,": "只有这两列简单的数据、",
  "EN:ZH:and again, for simplicity's sake,": "再说一遍，为了简单起见、",
  "EN:ZH:we're only going to have three rows.": "我们只有三行。",
  "EN:ZH:We're going to have a blue person,": "我们将有一个蓝色的人、",
  "EN:ZH:a purple person, and a red person.": "一个紫色的人，和一个红色的人。",
  "EN:ZH:Now here is the data.": "下面是数据。",
  "EN:ZH:We have blue person making $70,000 a year,": "我们有一个年薪 7 万美元的蓝人、",
  "EN:ZH:and their age is 45 years.": "年龄为 45 岁。",
  "EN:ZH:Purple person makes $60,000 a year,": "紫色人年薪 6 万美元、",
  "EN:ZH:and their age is 44 years.": "年龄为 44 岁。",
  "EN:ZH:And red person makes $52,000 a year,": "而红人的年薪为 52 000 美元、",
  "EN:ZH:and their age is 40 years.": "年龄为 40 岁。",
  "EN:ZH:Now the task at hand is going to be slightly different": "现在，我们手头的任务将略有不同",
  "EN:ZH:to the regressions and classifications": "到回归和分类",
  "EN:ZH:that we've been discussing.": "我们一直在讨论这个问题。",
  "EN:ZH:The task at hand is to see": "当前的任务是",
  "EN:ZH:which of the two people to the purple person": "这两个人中谁是紫色人",
  "EN:ZH:is most similar to just based on this data.": "最相似。",
  "EN:ZH:Would you say that the purple person": "你认为紫色的人",
  "EN:ZH:is more similar to the blue person,": "与蓝色人种更为相似、",
  "EN:ZH:or would you say that the purple person": "还是说紫色的人",
  "EN:ZH:is more similar to the red person?": "与红人更相似？",
  "EN:ZH:This is more relevant for the clustering tasks": "这与聚类任务更为相关",
  "EN:ZH:or clustering algorithms that we'll be discussing": "或我们将要讨论的聚类算法",
  "EN:ZH:in the following section of the course.": "在课程的下一节中。",
  "EN:ZH:But it is just such a simple illustrative example": "但这只是一个简单的说明性例子",
  "EN:ZH:that we're going to use it here.": "我们将在这里使用它。",
  "EN:ZH:We're gonna talk about it here": "我们将在这里讨论",
  "EN:ZH:to show the importance of feature scaling.": "以显示特征缩放的重要性。",
  "EN:ZH:So once again, if you'd like to pause this video,": "所以，如果你想暂停这段视频，请再次暂停、",
  "EN:ZH:please go ahead,": "请讲、",
  "EN:ZH:and try to see would you group": "并尝试看看您是否会将",
  "EN:ZH:the purple person with the blue person,": "紫色的人和蓝色的人、",
  "EN:ZH:or would you group the purple person with the red person?": "或者，你会把紫色的人和红色的人放在一起？",
  "EN:ZH:And now let's have a look at it together.": "现在，让我们一起来看看吧。",
  "EN:ZH:So let's look at the differences.": "让我们来看看它们的区别。",
  "EN:ZH:The difference here in salary is $10,000,": "这里的工资差距是 10 000 美元、",
  "EN:ZH:and here it is $8,000.": "而这里是 8000 美元。",
  "EN:ZH:And in terms of age, the difference": "在年龄方面，差异",
  "EN:ZH:between the purple and the blue person is one year,": "紫色人和蓝色人之间的距离是一年、",
  "EN:ZH:and between the purple and the red person is four years.": "而在紫色和红色之间则是四年。",
  "EN:ZH:Now what can happen with unscaled features as we see here,": "现在，我们看到了未缩放功能的情况、",
  "EN:ZH:is that the values, the unit values of one column": "就是一列的数值、单位数值",
  "EN:ZH:can be so much larger than the unit values of the other": "的单位值可以比其他单位值大很多",
  "EN:ZH:that it might overpower.": "它可能会压倒一切。",
  "EN:ZH:So for example, we can see": "例如，我们可以看到",
  "EN:ZH:that the values of 10,000 and 8,000": "即 10 000 和 8 000 的数值",
  "EN:ZH:are much much greater than the values of 1 and 4.": "远远大于 1 和 4 的值。",
  "EN:ZH:So we might make the erroneous conclusion that, okay,": "因此，我们可能会得出一个错误的结论：好吧、",
  "EN:ZH:we're going to ignore values 1 and 4": "我们将忽略数值 1 和 4",
  "EN:ZH:because those are such small differences": "因为差别太小了",
  "EN:ZH:compared to 10,000 and 8,000,": "分别为 10 000 人和 8 000 人、",
  "EN:ZH:we're gonna focus on these large of magnitude numbers,": "我们将重点关注这些大数量级的数字、",
  "EN:ZH:10,000 and 8,000,": "10,000 和 8,000、",
  "EN:ZH:and out of them we'll say": "我们会说",
  "EN:ZH:that the purple person is clearly closer to the red person": "紫色的人显然更接近红色的人",
  "EN:ZH:because that value is 8,000.": "因为这个值是 8000。",
  "EN:ZH:It's $2,000 less, or 2000 units less than the value": "少了 2000 美元，也就是少了 2000 个单位的价值",
  "EN:ZH:the difference between the purple and the blue person.": "紫色人和蓝色人的区别。",
  "EN:ZH:And as a result,": "因此",
  "EN:ZH:we would group the purple person with the red person.": "我们将把紫色的人和红色的人归为一组。",
  "EN:ZH:Now we don't want this": "现在我们不想这样",
  "EN:ZH:or similar things happening in our algorithms,": "或类似的事情在我们的算法中发生、",
  "EN:ZH:and that's why we need to normalize variables": "因此，我们需要对变量进行归一化处理",
  "EN:ZH:because we can't compare.": "因为我们无法比较。",
  "EN:ZH:Right now, we're comparing salaries to years,": "现在，我们正在比较工资和年限、",
  "EN:ZH:it's like comparing apples and oranges.": "这就像苹果和橘子的比较。",
  "EN:ZH:These are non-comparable things.": "这些都是不可比较的。",
  "EN:ZH:What if years was expressed not in years, but in minutes,": "如果 \"年 \"不是用 \"年 \"来表示，而是用 \"分钟 \"来表示呢？",
  "EN:ZH:then those values would be much higher,": "那么这些数值就会高得多、",
  "EN:ZH:or in seconds would be even higher.": "或更高。",
  "EN:ZH:And even if you have the same units of measurement": "即使测量单位相同",
  "EN:ZH:like dollars and dollars in two columns,": "如美元和美元两栏、",
  "EN:ZH:they still might not be comparable": "还是不能相提并论",
  "EN:ZH:because they're relating to different things.": "因为它们涉及不同的事物。",
  "EN:ZH:So it's important to scale your features.": "因此，扩展功能非常重要。",
  "EN:ZH:And so let's apply normalization.": "因此，让我们应用正常化。",
  "EN:ZH:As a quick reminder,": "提醒一下",
  "EN:ZH:this is what the formula for normalization is like.": "这就是正常化的公式。",
  "EN:ZH:So we're going to apply it to the columns one by one.": "因此，我们要逐列应用。",
  "EN:ZH:So we are applying it to the dollar column first.": "因此，我们首先将其应用于美元一栏。",
  "EN:ZH:After normalizing, our values will look like this.": "正常化后，我们的数值将如下所示。",
  "EN:ZH:So let's go back for a second and go here.": "所以，让我们先回到这里。",
  "EN:ZH:So I'll let you pause this video": "所以我让你暂停这段视频",
  "EN:ZH:if you'd like to do the manual calculations,": "如果您想手动计算的话、",
  "EN:ZH:this is the result.": "这就是结果。",
  "EN:ZH:And once we apply it to the years column,": "一旦我们把它应用到年份一栏、",
  "EN:ZH:our values will look like this.": "我们的价值观将是这样的",
  "EN:ZH:Once again, from here we end up here.": "再一次，我们从这里出发，最终到达这里。",
  "EN:ZH:And now, we can compare like for like.": "现在，我们可以进行同类比较了。",
  "EN:ZH:Based on this image, based on the this data,": "根据这张图片，根据这些数据、",
  "EN:ZH:which do you think the purple person is closest to?": "你认为紫色的人最接近哪个？",
  "EN:ZH:Well, I think the answer is obvious.": "我想答案是显而易见的。",
  "EN:ZH:The purple person is almost right in the middle": "紫色的人几乎就在中间",
  "EN:ZH:between the red and the blue people.": "红人和蓝人之间。",
  "EN:ZH:They're at 0.444.": "现在是 0.444。",
  "EN:ZH:Whereas in the age column, the purple person is closest": "而在年龄一栏中，紫色的人最接近",
  "EN:ZH:to the blue person and it's very clear.": "到蓝色的人，就非常清楚了。",
  "EN:ZH:So there we go.": "就这样吧。",
  "EN:ZH:That's a quick illustrative example,": "这是一个简单的示例、",
  "EN:ZH:very simplistic,": "非常简单、",
  "EN:ZH:but yet illustrative example of feature scaling.": "但却能说明特征缩放的例子。",
  "EN:ZH:And I hope you enjoy seeing": "希望你们喜欢看到",
  "EN:ZH:that together with Adlon in the practical tutorials.": "与阿德伦一起参加实践教程。",
  "EN:ZH:On that note, I look forward": "在这方面，我期待着",
  "EN:ZH:to seeing you back here next time.": "希望下次还能在这里见到你。",
  "EN:ZH:Hello and welcome to the first lesson.": "大家好，欢迎来到第一课。",
  "EN:ZH:I'm excited to guide you through one of the most transformational shifts in the customer support landscape.": "我很高兴能引导您完成客户支持领域最具变革性的转变之一。",
  "EN:ZH:Artificial intelligence is no longer just a buzzword.": "人工智能不再只是一个流行词。",
  "EN:ZH:It's become an essential part of how businesses deliver fast, seamless, and personalized service.": "它已成为企业提供快速、无缝和个性化服务的重要组成部分。",
  "EN:ZH:Let's start with a familiar scenario.": "让我们从一个熟悉的场景开始。",
  "EN:ZH:You're running a growing e-commerce business.": "您正在经营一家成长型电子商务企业。",
  "EN:ZH:More orders, more questions, and suddenly your small support team is drowning in tickets.": "更多的订单、更多的问题，一下子就把您的小型支持团队淹没在各种单子中。",
  "EN:ZH:Agents are juggling long queues, repetitive questions, and increasingly impatient customers.": "座席人员要应付长长的队伍、重复的问题和越来越不耐烦的客户。",
  "EN:ZH:This is exactly where AI shines not as a replacement for your team, but as a powerful enhancement.": "这正是人工智能的闪光点，它不是团队的替代品，而是强大的增强剂。",
  "EN:ZH:Modern AI can handle routine queries like where's my order?": "现代人工智能可以处理日常查询，比如我的订单在哪里？",
  "EN:ZH:Or how do I return this instantly and around the clock?": "或者，我怎样才能 24 小时即时返回？",
  "EN:ZH:But it goes further AI can detect customer sentiment, personalize responses, and even act proactively,": "不过，人工智能还能检测客户情绪、个性化回复，甚至主动采取行动、",
  "EN:ZH:say a visitor keeps returning to your pricing page.": "比方说，访客不断返回您的定价页面。",
  "EN:ZH:AI can jump in with a helpful message or even a personalized offer.": "人工智能可以提供有用的信息，甚至是个性化的报价。",
  "EN:ZH:That kind of real time engagement helps customers feel seen and keeps them from bouncing.": "这种实时互动能让客户感到自己被关注，从而避免跳单。",
  "EN:ZH:And the shift isn't theoretical.": "而这种转变并不是理论上的。",
  "EN:ZH:Right now, over 57% of businesses already use AI to improve support.": "目前，超过 57% 的企业已经使用人工智能来改善支持。",
  "EN:ZH:Tools like AI.": "人工智能等工具。",
  "EN:ZH:Copilot can summarize tickets, draft responses, and surface relevant articles mid chat.": "Copilot 可以在聊天过程中汇总票单、起草回复并显示相关文章。",
  "EN:ZH:It's no wonder 78% of agents report higher efficiency and resolution times drop by as much as 50% when": "这就难怪有 78% 的代理报告称效率提高了，解决时间缩短了 50%。",
  "EN:ZH:AI is in the mix, We're also seeing a shift in customer behavior.": "我们也看到了客户行为的转变。",
  "EN:ZH:Around 67% of users now prefer self-service options like AI powered help centers and, across every": "约有 67% 的用户现在更喜欢人工智能支持的帮助中心等自助服务选项，而且在所有用户中",
  "EN:ZH:channel, email, chat, social customers expect fast, frictionless responses.": "渠道、电子邮件、聊天、社交客户都希望得到快速、无摩擦的响应。",
  "EN:ZH:In fact, 88% expect a reply within one hour.": "事实上，88% 的人希望在一小时内得到回复。",
  "EN:ZH:But AI can deliver in seconds, keeping pace with expectations that human teams alone can't meet.": "但是，人工智能可以在几秒钟内完成任务，跟上人们的期望，这是人类团队所无法企及的。",
  "EN:ZH:Even cultural differences are becoming important.": "甚至文化差异也变得重要起来。",
  "EN:ZH:For example, customers in Germany and Japan use fewer emojis, while Ethiopians are most likely to": "例如，德国和日本的客户使用的表情符号较少，而埃塞俄比亚人最有可能使用",
  "EN:ZH:say thank you.": "说谢谢。",
  "EN:ZH:AI systems can now be trained to adapt messaging styles by region, helping global brands sound more": "现在，人工智能系统经过训练后，可以根据地区调整信息风格，帮助全球品牌更好地传播信息。",
  "EN:ZH:local and human.": "当地和人类。",
  "EN:ZH:And this isn't just about solving problems faster, it's about creating connected experiences across": "这不仅是为了更快地解决问题，更是为了创造跨领域的互联体验。",
  "EN:ZH:the entire journey.": "整个旅程。",
  "EN:ZH:Customers move between channels, chat to email to social, and they expect consistency.": "客户在不同渠道之间流动，从聊天到电子邮件再到社交网络，他们希望保持一致。",
  "EN:ZH:AI makes that possible by keeping context across touchpoints, which boosts satisfaction and loyalty.": "人工智能通过保持各接触点之间的联系，提高了满意度和忠诚度。",
  "EN:ZH:So here's something to think about.": "因此，这里有一些值得思考的问题。",
  "EN:ZH:If AI could take over just the repetitive 60% of your team's work, how much more attention could they": "如果人工智能可以接管团队中 60% 的重复性工作，那么他们可以",
  "EN:ZH:give to real conversations?": "给真正的对话？",
  "EN:ZH:The ones that build trust?": "建立信任？",
  "EN:ZH:The bottom line AI isn't replacing customer support, it's redefining it.": "最重要的一点是，人工智能不是要取代客户支持，而是要重新定义客户支持。",
  "EN:ZH:It allows you to scale without sacrificing quality, deliver smarter service, and empower your team": "它使您能够在不牺牲质量的情况下扩大规模，提供更智能的服务，并增强团队的能力",
  "EN:ZH:to focus on what humans do best.": "专注于人类最擅长的事情。",
  "EN:ZH:Connecting.": "连接",
  "EN:ZH:Thanks for joining me in this lesson.": "感谢您参与本课。",
  "EN:ZH:Let's talk about a decision every support leader eventually faces.": "让我们来谈谈每位支持领导者最终都会面临的一个决定。",
  "EN:ZH:How do you know if the AI customer service platform you're investing in is actually going to deliver": "您如何知道您投资的人工智能客户服务平台是否能真正实现",
  "EN:ZH:results?": "结果如何？",
  "EN:ZH:Many of these platforms make an excellent first impression.": "其中许多平台都能给人留下极佳的第一印象。",
  "EN:ZH:They promise intelligent automation, effortless integration, and personalized service.": "他们承诺提供智能自动化、轻松集成和个性化服务。",
  "EN:ZH:But once you start using them in real life scenarios, the reality doesn't always match the promise.": "但是，一旦你开始在现实生活中使用它们，现实并不总是与承诺相符。",
  "EN:ZH:The real test of any AI tool is how it performs during day to day support.": "对任何人工智能工具的真正考验在于它在日常支持中的表现。",
  "EN:ZH:It should make your operations faster and more efficient, not create extra friction.": "它应该让你的运营更快、更高效，而不是制造额外的摩擦。",
  "EN:ZH:If it can quickly resolve frequent questions, route requests intelligently, and escalate to a human": "如果它能快速解决常见问题、智能路由请求并升级到人工服务",
  "EN:ZH:at just the right moment, you're on the right track.": "在正确的时刻，你就走在了正确的道路上。",
  "EN:ZH:But if your agents spend time correcting the bots responses or stepping in to clarify half answered": "但是，如果您的座席人员花费时间纠正机器人的回复，或介入澄清机器人回答的一半问题",
  "EN:ZH:questions, that's a sign the tool is creating more problems than it solves.": "问题，这说明该工具造成的问题比解决的问题还多。",
  "EN:ZH:Compatibility is just as critical.": "兼容性同样至关重要。",
  "EN:ZH:An AI platform should work smoothly with your existing tools your help desk CRM e-commerce platform,": "人工智能平台应与现有工具、服务台、客户关系管理和电子商务平台顺利协作、",
  "EN:ZH:without requiring a massive IT overhaul.": "无需对信息技术进行大规模改造。",
  "EN:ZH:Whether you're using Shopify, WordPress, or HubSpot, the integration experience should feel seamless.": "无论您使用的是 Shopify、WordPress 还是 HubSpot，整合体验都应该是无缝的。",
  "EN:ZH:Audio, for example, is known for exactly that.": "例如，音频正是以这一点而闻名。",
  "EN:ZH:It's a user friendly, budget conscious platform favored by small to mid-sized businesses.": "这是一个用户友好、注重预算的平台，深受中小型企业的青睐。",
  "EN:ZH:It's Lyra AI chatbot handles up to 70% of routine queries, and it supports multiple channels out of": "它的 Lyra 人工智能聊天机器人可处理多达 70% 的常规查询，并支持多种渠道，包括",
  "EN:ZH:the box.": "盒子。",
  "EN:ZH:Other platforms like intercom, Zendesk, and Freshdesk come in.": "其他平台，如 intercom、Zendesk 和 Freshdesk 也会加入进来。",
  "EN:ZH:Intercom offers conversational AI, behavioral segmentation, and product tours that adapt to different": "Intercom 提供对话式人工智能、行为细分和产品导览，以适应不同的用户需求。",
  "EN:ZH:user levels.": "用户级别。",
  "EN:ZH:Great for SaaS companies and digital brands, Zendesk is a favorite for enterprise teams needing omnichannel": "Zendesk 非常适合 SaaS 公司和数字品牌，是需要全渠道服务的企业团队的最爱。",
  "EN:ZH:support, deep reporting, and customizable workflows.": "支持、深度报告和可定制的工作流程。",
  "EN:ZH:Freshdesk offers similar scalability with a cleaner interface and tiered pricing that grows with your": "Freshdesk 具有类似的可扩展性，界面更简洁，分层定价可随您的需求增长。",
  "EN:ZH:team.": "团队",
  "EN:ZH:Other tools like desk 365 bring serious value for Microsoft centric teams, offering integrated ticketing,": "办公桌 365 等其他工具为以微软为中心的团队带来了重要价值，提供了集成的票务服务、",
  "EN:ZH:SLAs, and strong automation features at a lower cost.": "SLA 和强大的自动化功能，而且成本更低。",
  "EN:ZH:Crisp, on the other hand, provides a more fluid messaging experience with a shared inbox and co-browsing": "另一方面，Crisp 通过共享收件箱和共同浏览提供了更流畅的信息体验。",
  "EN:ZH:tools ideal for startups that want simplicity and speed.": "这些工具非常适合希望简单快捷的初创企业。",
  "EN:ZH:Then there are niche platforms like Tars, yellow AI and chatbot that excel in areas like no code automation,": "还有一些利基平台，如 Tars、黄色人工智能和聊天机器人，它们在无代码自动化等领域表现出色、",
  "EN:ZH:multilingual support and lead conversion journeys, and for teams looking to deeply customize their": "多语言支持和引导转换旅程，以及为希望深度定制其",
  "EN:ZH:AI and scale automation across complex systems.": "在复杂系统中实现人工智能和规模自动化。",
  "EN:ZH:GPT bots AI delivers enterprise grade flexibility, expert guidance, and high performance conversational": "GPT 机器人人工智能提供企业级灵活性、专家指导和高性能会话功能",
  "EN:ZH:agents.": "代理商。",
  "EN:ZH:As you weigh your options, think beyond surface level features.": "在权衡选择时，不要只考虑表面功能。",
  "EN:ZH:Can the platform adapt to the different types of customers you serve?": "平台能否适应您所服务的不同类型客户？",
  "EN:ZH:First time buyers, returning users, VIPs, or tech savvy power users?": "是首次购买者、老用户、VIP 还是精通技术的高级用户？",
  "EN:ZH:Can it shift tone, automate key tasks, and adjust workflows based on real customer needs?": "它能否根据客户的实际需求转变基调、自动执行关键任务并调整工作流程？",
  "EN:ZH:Does it offer the visibility you need to track what the AI is doing well and where it's falling short?": "它是否能提供所需的可见性，以跟踪人工智能在哪些方面做得好，在哪些方面做得不够？",
  "EN:ZH:And importantly, does the vendor stand behind the product with strong support and a roadmap that evolves": "更重要的是，供应商是否为产品提供强有力的支持和不断发展的路线图。",
  "EN:ZH:with you?": "和你在一起？",
  "EN:ZH:Take a closer look at the platform you're using, or the one you're evaluating, and ask whether it's": "请仔细查看您正在使用或正在评估的平台，并询问它是否符合以下条件",
  "EN:ZH:helping your team scale or holding you back.": "是帮助团队扩大规模，还是拖团队后腿？",
  "EN:ZH:If it can't adapt to your complexity, integrate easily, or flex to different user types, it may be": "如果它无法适应您的复杂性、无法轻松集成或无法灵活适应不同的用户类型，那么它可能是",
  "EN:ZH:time to consider an alternative that can grow with you.": "是时候考虑一种能与您共同成长的替代方案了。",
  "EN:ZH:Thanks for joining this lesson.": "感谢您参加本次课程。",
  "EN:ZH:Today we're getting hands on.": "今天，我们来亲身体验一下。",
  "EN:ZH:Over the past few years, my team and I have tested dozens of customer support platforms including Zendesk,": "在过去几年里，我和我的团队测试了包括 Zendesk 在内的数十个客户支持平台、",
  "EN:ZH:Freshdesk, intercom, crisp, Zoho Desk Live, Agent Desk 365, and several lesser known tools.": "Freshdesk、intercom、crisp、Zoho Desk Live、Agent Desk 365 以及一些不太知名的工具。",
  "EN:ZH:Each of them had something valuable to offer.": "他们每个人都能提供一些有价值的东西。",
  "EN:ZH:Some excelled at flexible automation.": "有些人擅长灵活的自动化。",
  "EN:ZH:Others stood out with strong CRM integrations or robust analytics.": "其他公司则凭借强大的客户关系管理集成或强大的分析功能脱颖而出。",
  "EN:ZH:But finding a platform that truly strikes the right balance between automation and a human touch proved": "但事实证明，要找到一个真正能在自动化和人性化之间取得适当平衡的平台并不容易。",
  "EN:ZH:to be a real challenge.": "是一个真正的挑战。",
  "EN:ZH:Most either leaned too heavily on bots or placed too much of the burden on human agents.": "大多数公司要么过于依赖机器人，要么将过多的负担放在人工代理身上。",
  "EN:ZH:One platform I can confidently recommend is Td0.": "我可以自信地推荐一个平台，那就是 Td0。",
  "EN:ZH:It's built on AI at its core and designed to integrate seamlessly into your existing support workflows": "它以人工智能为核心，旨在无缝集成到您现有的支持工作流程中",
  "EN:ZH:without overwhelming your team.": "而不会让你的团队不堪重负。",
  "EN:ZH:Td0 doesn't just add automation for the sake of it.": "Td0 并不是为了自动化而自动化。",
  "EN:ZH:It helps you maintain that personal connection with your customers, which is critical for modern service.": "它可以帮助您与客户保持个人联系，这对现代服务至关重要。",
  "EN:ZH:We're going to break down the key parts of the platform.": "我们将分解该平台的关键部分。",
  "EN:ZH:Explore how the AI works behind the scenes, and walk you through exactly how you can use Tdoe to improve": "探索人工智能在幕后是如何工作的，并指导您如何使用 Tdoe 来改善您的工作。",
  "EN:ZH:your customer experience without placing extra pressure on your support team.": "您的客户体验，而不会给您的支持团队带来额外压力。",
  "EN:ZH:So let's start with the basics.": "那我们就从最基本的开始吧。",
  "EN:ZH:At its core, Tdoe combines live chat, AI agent, and ticketing into a single interface.": "Tdoe 的核心是将即时聊天、人工智能代理和票务整合到一个界面中。",
  "EN:ZH:That means you can communicate with customers in real time, while also setting up automated flows to": "这意味着您可以与客户实时沟通，同时还可以设置自动流程，以便",
  "EN:ZH:answer common questions throughout conversations and collect information, all without needing to be": "在整个对话过程中回答常见问题并收集信息，而无需",
  "EN:ZH:online 24 over seven.": "在线 24 超过 7。",
  "EN:ZH:For many teams, there was always a trade off between leaning on automation and risking losing your": "对于许多团队来说，在依赖自动化和冒着失去自己的",
  "EN:ZH:personal touch, or relying on human agents and struggling to keep up.": "个人接触，或依赖人工代理，难以跟上时代的步伐。",
  "EN:ZH:Over time, some tools began to bridge that gap.": "随着时间的推移，一些工具开始弥补这一差距。",
  "EN:ZH:TDL, for example, emerged as one that didn't force a choice.": "例如，《TDL》的出现并没有强迫人们做出选择。",
  "EN:ZH:Instead, it offered a way for teams to blend both by letting automation handle the routine while allowing": "相反，它为团队提供了一种融合两者的方法，即让自动化处理日常事务，同时允许",
  "EN:ZH:people to focus on what really needed a human voice.": "让人们关注真正需要人类声音的东西。",
  "EN:ZH:One of the standout features is tediously raw AI, a conversational bot that understands natural language": "最突出的功能之一是乏味的原始人工智能，这是一个能理解自然语言的对话机器人",
  "EN:ZH:and can handle customer queries without a script.": "无需脚本即可处理客户查询。",
  "EN:ZH:That means it's not just clicking through a decision tree, but is actually interpreting what your customer": "这意味着它不仅仅是点击决策树，而是真正解读客户的需求。",
  "EN:ZH:says and responding in context.": "说，并根据上下文作出回应。",
  "EN:ZH:And because it learns from your help center articles and previous chats, the more you use it, the": "而且，由于它会从帮助中心的文章和以前的聊天记录中学习，您使用得越多，它就会",
  "EN:ZH:smarter it becomes.": "变得更聪明。",
  "EN:ZH:That's also where Lytro's flexibility really stands out.": "这也是 Lytro 的灵活性真正突出的地方。",
  "EN:ZH:You can control exactly which data sources it draws from, fine tune its tone of voice, and define": "您可以精确控制它从哪些数据源获取数据，微调它的语音语调，并定义",
  "EN:ZH:the processes it follows, ensuring its behavior is perfectly aligned with your brand's style and standards.": "所遵循的流程，确保其行为完全符合您的品牌风格和标准。",
  "EN:ZH:You also get access to AI powered tools that help your live agents.": "您还可以使用人工智能工具来帮助您的即时代理。",
  "EN:ZH:For example, audio can suggest replies in real time, summarize long conversations, and analyze the": "例如，音频可以实时建议回复、总结冗长的对话并分析对话内容。",
  "EN:ZH:tone of customer messages.": "客户信息的语气。",
  "EN:ZH:This kind of support cuts down on response time and helps your team keep their focus, especially during": "这种支持可缩短响应时间，帮助您的团队保持专注，尤其是在以下情况下",
  "EN:ZH:high volume periods.": "高流量时期。",
  "EN:ZH:One of the best ways to see Tvo's capabilities is to build a simple chat bot.": "了解 Tvo 功能的最佳方式之一就是构建一个简单的聊天机器人。",
  "EN:ZH:For instance, let's say you want to create a bot that greets visitors and asks if they need help tracking": "例如，假设您想创建一个机器人来接待访客，并询问他们是否需要帮助跟踪",
  "EN:ZH:their order.": "他们的订单。",
  "EN:ZH:You can drag and drop blocks inside the visual builder to create that flow in minutes, without the": "您可以在可视化生成器中拖放图块，在几分钟内创建流程，而不需要",
  "EN:ZH:need for any coding.": "无需任何编码。",
  "EN:ZH:The AI can take it from there by matching the customer's message to the right intent, and either providing": "人工智能可以将客户的信息与正确的意图相匹配，并提供",
  "EN:ZH:the answer itself or handing off to a live agent if needed.": "或在需要时转给在线客服。",
  "EN:ZH:Think about your own business for a moment.": "想想你自己的企业吧。",
  "EN:ZH:Are there repeat questions your team gets every day?": "您的团队每天都会遇到重复的问题吗？",
  "EN:ZH:Things like what's your shipping policy?": "比如你们的运输政策是什么？",
  "EN:ZH:Or do you offer discounts for first time buyers?": "或者，你们是否为首次购房者提供折扣？",
  "EN:ZH:In my opinion, video is designed to scale with your needs.": "在我看来，视频可以根据您的需求进行扩展。",
  "EN:ZH:Whether you're running a small online shop or managing support for a larger brand.": "无论您是经营一家小型网店，还是管理对大型品牌的支持。",
  "EN:ZH:The platform gives you the tools to automate smartly, respond faster, and personalize every interaction": "该平台为您提供了各种工具，使您能够智能地实现自动化，更快地做出响应，并个性化每次互动",
  "EN:ZH:with ease.": "轻松自如。",
  "EN:ZH:Thanks for being part of this lesson.": "感谢您参与这一课。",
  "EN:ZH:In this lesson, we'll examine how Tedo operates within the broader landscape of customer service and": "在本课中，我们将探讨 Tedo 如何在更广泛的客户服务领域中运作，以及",
  "EN:ZH:automation platforms.": "自动化平台。",
  "EN:ZH:Many tools in this category offer live chat, chat, bot builders, and automated workflows.": "该类别中的许多工具都提供即时聊天、聊天、机器人生成器和自动工作流。",
  "EN:ZH:The focus here is to understand how Tedo functions in practice and how it compares to other solutions": "这里的重点是了解 Tedo 在实践中是如何运作的，以及与其他解决方案相比有何优势",
  "EN:ZH:used by support teams.": "支持团队使用。",
  "EN:ZH:Tedo is positioned as an AI driven platform that combines live chat, chatbot automation, a ticketing": "Tedo 定位为人工智能驱动的平台，它将即时聊天、聊天机器人自动化、票务服务和其他功能结合在一起。",
  "EN:ZH:system, and analytics within a single interface.": "在单个界面内即可实现系统和分析功能。",
  "EN:ZH:It is designed to help businesses manage customer interactions from multiple channels such as website,": "它旨在帮助企业管理来自网站等多个渠道的客户互动、",
  "EN:ZH:chat, email and social media through a shared inbox.": "聊天、电子邮件和社交媒体。",
  "EN:ZH:One of those key features is flows, its visual chatbot builder, which enables users to set up conversation": "其中一项重要功能是可视化聊天机器人生成器 flows，它能让用户建立对话",
  "EN:ZH:flows using drag and drop components without needing programming knowledge.": "使用拖放组件实现流程，无需编程知识。",
  "EN:ZH:This setup can be helpful for businesses that want to implement automation without a long development": "这种设置可以帮助企业在不需要长期开发的情况下实施自动化。",
  "EN:ZH:process.": "过程。",
  "EN:ZH:The platform also includes a natural language processing tool called Lairo.": "该平台还包括一个名为 Lairo 的自然语言处理工具。",
  "EN:ZH:Unlike systems that rely solely on decision trees or fixed options, Lairo is designed to interpret": "与仅依赖决策树或固定选项的系统不同，来罗旨在解释",
  "EN:ZH:open ended questions and respond by drawing from the company's existing help center content.": "开放式问题，并利用公司现有的帮助中心内容进行回答。",
  "EN:ZH:This reduces the need for ongoing manual updates to flows, responses and allows for more flexible interaction": "这就减少了对流程和响应进行持续手动更新的需要，并实现了更灵活的互动",
  "EN:ZH:with users.": "与用户一起。",
  "EN:ZH:According to case studies and user feedback, Lairo AI resolves approximately 70% of repeated queries.": "根据案例研究和用户反馈，来罗人工智能可解决约 70% 的重复查询。",
  "EN:ZH:In one example, a company automated over 85% of its customer inquiries while maintaining 24 over seven": "在一个例子中，一家公司自动处理了 85% 以上的客户咨询，同时在 7 个月内保持 24",
  "EN:ZH:availability.": "可用性。",
  "EN:ZH:Tito brings together all conversations, both automated and human, into one dashboard.": "Tito 将所有对话（包括自动对话和人工对话）汇集到一个仪表板中。",
  "EN:ZH:This allows support agents to follow chatbot interactions and step in when necessary without switching": "这样，支持代理就能跟踪聊天机器人的互动，并在必要时介入，而无需切换",
  "EN:ZH:between separate tools.": "在不同的工具之间进行切换。",
  "EN:ZH:Additional features such as pre-chat surveys and flow based triggers, help teams manage leads and guide": "聊天前调查和基于流程的触发器等附加功能可帮助团队管理潜在客户并提供指导",
  "EN:ZH:visitors through specific actions.": "通过具体的行动来吸引游客。",
  "EN:ZH:The platform is widely used among small and mid-sized businesses.": "该平台在中小型企业中广泛使用。",
  "EN:ZH:Reviews on platforms like G2, Capterra and Shopify consistently note Tda's usability, with average": "G2、Capterra 和 Shopify 等平台上的评论一致指出 Tda 的可用性，平均",
  "EN:ZH:ratings around 4.7 out of five.": "评分约为 4.7 分（满分为 5 分）。",
  "EN:ZH:However, several limitations are also noted.": "不过，我们也注意到一些局限性。",
  "EN:ZH:The free version has limited functionality and more advanced features, particularly those related to": "免费版功能有限，但具有更多高级功能，尤其是与以下方面相关的功能",
  "EN:ZH:AI and automation, require paid upgrades.": "人工智能和自动化，需要付费升级。",
  "EN:ZH:Users have also mentioned restricted CRM integration options, challenges in adapting the tool as teams": "用户还提到，客户关系管理集成选项受到限制，团队在调整工具时面临挑战",
  "EN:ZH:scale, and inconsistencies in support availability for organizations with broader or more complex needs.": "规模，以及对有更广泛或更复杂需求的组织提供的支持不一致。",
  "EN:ZH:Other platforms may offer different advantages.": "其他平台可能具有不同的优势。",
  "EN:ZH:Desk 365 integrates with Microsoft 365 and includes tools for automated ticketing and email management.": "Desk 365 与 Microsoft 365 集成，包括自动票单和电子邮件管理工具。",
  "EN:ZH:Intercom provides features for proactive messaging, customer segmentation, and onboarding flows.": "Intercom 提供主动信息发送、客户细分和入职流程等功能。",
  "EN:ZH:Although its AI resolution rate is lower than Leiros around 51%, Zendesk is commonly used by larger": "虽然 Zendesk 的人工智能解决率低于 Leiros（约 51%），但较大型企业普遍使用 Zendesk。",
  "EN:ZH:support teams due to its omnichannel infrastructure, workflow, customization, and analytics.": "由于其全渠道基础架构、工作流程、定制和分析功能，可为支持团队提供支持。",
  "EN:ZH:Freshdesk offers similar functions with a distinct user interface and pricing model.": "Freshdesk 以独特的用户界面和定价模式提供类似的功能。",
  "EN:ZH:Crisp includes tools for shared inboxes, live translation, and integrations with e-commerce systems.": "Crisp 包括共享收件箱、实时翻译以及与电子商务系统集成的工具。",
  "EN:ZH:Additional alternatives include Helpscout, which focuses on shared inboxes and basic automation within": "其他替代方案包括 Helpscout，该方案侧重于共享收件箱和基本自动化。",
  "EN:ZH:an email first environment.": "电子邮件优先的环境。",
  "EN:ZH:Kayako, which supports multi-channel messaging but does not include AI chatbot functionality.": "Kayako 支持多渠道信息传递，但不包括人工智能聊天机器人功能。",
  "EN:ZH:Gorgias, which specializes in e-commerce support with Shopify integration, and gladly, which emphasizes": "Gorgias 专门提供与 Shopify 集成的电子商务支持，而 gladly 则强调",
  "EN:ZH:voice and omnichannel service.": "语音和全渠道服务。",
  "EN:ZH:Dok2 and Olark also offer basic live chat with some automation features, but with more limited scalability": "Dok2 和 Olark 也提供基本的即时聊天功能和一些自动化功能，但可扩展性较为有限",
  "EN:ZH:and fewer AI tools.": "更少的人工智能工具。",
  "EN:ZH:Now let's talk about brand tone of voice, something often overlooked in automation.": "现在让我们来谈谈品牌的语气，这是自动化中经常被忽视的问题。",
  "EN:ZH:Titiyo allows you to tailor your AI agent's responses so that they reflect your company's personality.": "Titiyo 允许您定制人工智能代理的回复，使其反映贵公司的个性。",
  "EN:ZH:If your brand is friendly and casual, your AI agent can greet customers warmly and use conversational": "如果您的品牌亲切随和，您的人工智能代理可以热情地与客户打招呼，并使用对话式",
  "EN:ZH:phrasing.": "措辞。",
  "EN:ZH:If your brand is formal and professional, it can maintain a respectful, precise tone in every response.": "如果你的品牌是正式和专业的，它就能在每次回复中保持尊重和准确的语气。",
  "EN:ZH:This consistency matters because it ensures customers feel the same brand experience, whether they're": "这种一致性非常重要，因为它能确保客户感受到相同的品牌体验，无论他们是在",
  "EN:ZH:speaking to a person or to your AI agent.": "与人或您的人工智能代理交谈。",
  "EN:ZH:Over time, this builds trust and keeps your brand identity intact across all touchpoints.": "随着时间的推移，这将建立信任，并在所有接触点上保持品牌形象的完整性。",
  "EN:ZH:Train Lyra to provide personalized support.": "训练 Lyra 提供个性化支持。",
  "EN:ZH:Customer interactions are more than just responses.": "客户互动不仅仅是回应。",
  "EN:ZH:They are opportunities to build trust, strengthen your brand, and create lasting relationships with": "它们是建立信任、强化品牌并与以下人员建立持久关系的机会",
  "EN:ZH:Lyra.": "天琴座",
  "EN:ZH:Guidance.": "指导。",
  "EN:ZH:You can move beyond generic automation and fully tailor how your AI agent behaves.": "您可以超越一般的自动化，完全定制人工智能代理的行为方式。",
  "EN:ZH:This feature gives you precise control over Lyra's communication style, tone, and escalation behavior.": "该功能可让您精确控制 Lyra 的沟通风格、语气和升级行为。",
  "EN:ZH:You can use built in prompt templates or craft your own to align Lyra's responses with your support,": "您可以使用内置的提示模板或制作自己的模板，使 Lyra 的回答与您的支持相一致、",
  "EN:ZH:workflows, and brand voice.": "工作流程和品牌声音。",
  "EN:ZH:By training your Lyra agent, you're not just speeding up responses, you're creating a more consistent,": "通过培训 Lyra 代理，你不仅能加快响应速度，还能创建更一致的响应、",
  "EN:ZH:human like support experience that leads to higher customer satisfaction and smoother operations.": "提供人性化的支持体验，从而提高客户满意度，使运营更加顺畅。",
  "EN:ZH:Email support is another area where Tio's AI agent excels.": "电子邮件支持是 Tio 人工智能代理的另一个优势领域。",
  "EN:ZH:While many automation tools focus on chat alone, Titiyo applies the same AI intelligence to emails.": "许多自动化工具只关注聊天，而 Titiyo 将同样的人工智能智能应用于电子邮件。",
  "EN:ZH:Imagine a customer sending a question to your support email address on a Sunday evening.": "想象一下，一位客户在周日晚上向您的支持电子邮件地址发送了一个问题。",
  "EN:ZH:The AI agent can read the email, understand the request, search your help center and send a helpful,": "人工智能代理可以阅读电子邮件、了解请求、搜索帮助中心并发送帮助、",
  "EN:ZH:accurate response.": "准确答复。",
  "EN:ZH:Within seconds, your customer gets fast resolution and your team comes in Monday morning with fewer": "在几秒钟内，您的客户就能得到快速解决，而您的团队在周一早上就能以更少的时间投入工作。",
  "EN:ZH:open tickets.": "开票。",
  "EN:ZH:This not only boosts customer satisfaction, but also reduces response backlogs and operational costs.": "这不仅提高了客户满意度，还减少了响应积压和运营成本。",
  "EN:ZH:When comparing T'do with these alternatives, several factors may guide decision making ease of setup,": "在将 T'do 与这些替代品进行比较时，有几个因素可以作为决策依据，即安装的难易程度、",
  "EN:ZH:integration, compatibility, automation, depth, performance, visibility, and support.": "集成、兼容性、自动化、深度、性能、可见性和支持。",
  "EN:ZH:Reliability.": "可靠性。",
  "EN:ZH:While Tedo enables a high degree of automation for routine queries, other platforms may be more suitable": "虽然 Tedo 可以实现日常查询的高度自动化，但其他平台可能更加适合",
  "EN:ZH:for teams with specific structural or technical requirements.": "为有特殊结构或技术要求的团队提供。",
  "EN:ZH:This concludes the lesson.": "本课到此结束。",
  "EN:ZH:In the next lesson, we'll explore how real time AI tools can be implemented effectively across various": "在下一课中，我们将探讨如何在不同的领域有效实施实时人工智能工具。",
  "EN:ZH:stages of customer interaction.": "客户互动的各个阶段。",
  "EN:ZH:Dear students, I am committed to giving you my very best to make your progress smoother.": "亲爱的同学们，我将竭尽全力，让你们的学习更加顺利。",
  "EN:ZH:I have added a practical companion to this course, a personal gift from me, the book AI for business.": "我还为本课程增加了一个实用的配套课程，这是我送给自己的个人礼物，即《商业人工智能》一书。",
  "EN:ZH:You'll find it in the course resources.": "您可以在课程资源中找到。",
  "EN:ZH:It's a short, focused guide that shows how to translate AI ideas into action inside real teams.": "这是一本简短而重点突出的指南，展示了如何在实际团队中将人工智能理念转化为行动。",
  "EN:ZH:Products and decisions.": "产品和决定。",
  "EN:ZH:Use it as a field manual while you move through the lessons.": "在学习课程的过程中，将其作为一本实地手册使用。",
  "EN:ZH:Mark it up, try the checklist and bring the questions back to class.": "做上记号，尝试核对表，并将问题带回课堂。",
  "EN:ZH:Our mission is simple and ambitious to help millions of people adapt to the AI revolution with clarity": "我们的使命简单而宏大，就是帮助数百万人清晰地适应人工智能革命",
  "EN:ZH:and confidence.": "和信心。",
  "EN:ZH:Every lecture, worksheet, and example in this course is built with that mission in mind.": "本课程中的每一堂课、每一张作业纸和每一个示例都以这一使命为出发点。",
  "EN:ZH:But the truth is, the best improvements don't happen in my head.": "但事实上，最好的改进并不是在我的脑海中实现的。",
  "EN:ZH:They happen because of your voice.": "因为你的声音，它们才会发生。",
  "EN:ZH:So when you finish this section, please take a minute to leave an honest review on the course page.": "因此，当您学完这部分内容后，请花一分钟在课程页面上留下真实的评论。",
  "EN:ZH:Share one thing that helped you, one thing that could be clearer, and one takeaway you plan to apply": "分享一件对你有帮助的事，一件可以让你更清楚的事，以及一件你计划应用的收获",
  "EN:ZH:this week.": "本周。",
  "EN:ZH:2 or 3 specific sentences are perfect your perspective guides the next updates, inspires new case studies": "2 或 3 个具体句子是完美的，您的观点指导了下一次更新，激发了新的案例研究",
  "EN:ZH:and helps other learners decide if this path fits their goals.": "并帮助其他学习者决定这条道路是否适合他们的目标。",
  "EN:ZH:Thank you for being here and for pushing your skills forward.": "感谢你们来到这里，并不断提高自己的技能。",
  "EN:ZH:Enjoy your copy of AI for business.": "请尽情享受《商业人工智能》。",
  "EN:ZH:Keep experimenting and let me know what you're building.": "继续尝试，让我知道你们在做什么。",
  "EN:ZH:I'm excited to see your ideas take shape in the real world.": "我很高兴看到你们的想法在现实世界中成形。",
  "EN:ZH:Hey guys, welcome to my Udemy interface breakdown.": "大家好，欢迎来到我的 Udemy 界面分解。",
  "EN:ZH:In this video I will be showing you how to navigate through Udemy's interface.": "在本视频中，我将向您演示如何浏览 Udemy 的界面。",
  "EN:ZH:Leave a review, use the Q&A section and more.": "发表评论、使用问答板块等。",
  "EN:ZH:Navigate to the My Learning page and choose a course you want to watch right now.": "导航至 \"我的学习 \"页面，选择您现在要观看的课程。",
  "EN:ZH:On the right side menu, you will be able to see the course section list.": "在右侧菜单中，您可以看到课程部分列表。",
  "EN:ZH:Within each section, there are additional materials that you can download such as useful links, videos,": "在每个部分中，您都可以下载其他资料，如有用的链接和视频、",
  "EN:ZH:checklists that will be relevant to the lesson.": "与本课相关的核对表。",
  "EN:ZH:Now let's move to the Q&A section.": "现在让我们进入问答环节。",
  "EN:ZH:It's normal that you will have questions about the lecture.": "对讲座有疑问是正常的。",
  "EN:ZH:My goal is to always provide the best support possible to all my students.": "我的目标是始终尽可能为所有学生提供最好的支持。",
  "EN:ZH:By going to the Q&A section, you can find answers to some of the common problems that students are": "通过访问 \"问与答 \"部分，您可以找到学生常见问题的答案，包括",
  "EN:ZH:facing.": "面对。",
  "EN:ZH:Or ask your question right.": "或者正确提问。",
  "EN:ZH:After a few first lessons, Udemy will ask for a review.": "上完第一节课后，Udemy 会要求您进行评论。",
  "EN:ZH:We understand that it is just a start of the course.": "我们知道，这只是课程的开始。",
  "EN:ZH:However, if you want to share your opinion on the course, you can do it here.": "不过，如果您想分享您对课程的意见，可以在这里发表。",
  "EN:ZH:You can also leave a review or edit the previous one right after you completed the course.": "完成课程后，您还可以立即留下评论或编辑之前的评论。",
  "EN:ZH:Your feedback is really important to me and I look forward to hearing it.": "你们的反馈意见对我来说非常重要，我期待听到你们的反馈意见。",
  "EN:ZH:To not to miss any new content or important information, please make sure that all the announcements": "为了不错过任何新内容或重要信息，请确保所有公告",
  "EN:ZH:are on for you here.": "在这里为您开启。",
  "EN:ZH:Lastly, you can adjust playback speed and captions.": "最后，您还可以调整播放速度和字幕。",
  "EN:ZH:Playback speed determines how fast the course you are watching will play.": "播放速度决定您正在观看的课程的播放速度。",
  "EN:ZH:If you have limited time or you prefer learning at a faster rate, adjusting playback speed is useful.": "如果您时间有限或喜欢更快的学习速度，调整播放速度很有用。",
  "EN:ZH:Click on the playback rate button and accordingly, you will be able to adjust the playback speed of": "单击播放速度按钮，您就可以相应地调整以下播放速度",
  "EN:ZH:your course.": "你的课程",
  "EN:ZH:Video.": "视频",
  "EN:ZH:Captions can be used to better understand the speaker.": "可以使用字幕来更好地理解发言者。",
  "EN:ZH:To turn captions on, simply click on this icon at the bottom of the video.": "要打开字幕，只需点击视频底部的图标即可。",
  "EN:ZH:Okay guys, now you know how to use Udemy's interface.": "好了，现在你们知道如何使用 Udemy 的界面了吧。",
  "EN:ZH:If you have any further questions, please write to me in the Q&A that we discussed in this video previously.": "如果您有任何其他问题，请在我们之前在本视频中讨论的问答中给我写信。",
  "EN:ZH:In this video, I will explain you how to get the most benefits from Udemy AI features.": "在本视频中，我将向您介绍如何从 Udemy AI 功能中获得最大收益。",
  "EN:ZH:Udemy is leveraging AI a lot, and right now its positioning as AI powered educational platform.": "Udemy 正在大量利用人工智能，目前其定位是人工智能驱动的教育平台。",
  "EN:ZH:The two main features from AI that you can use to make your educational process more effective are AI": "人工智能的两大功能可以让你的教育过程更加有效，它们是人工智能",
  "EN:ZH:assistant and Role play.": "助理和角色扮演。",
  "EN:ZH:I will start from AI system.": "我将从人工智能系统入手。",
  "EN:ZH:You can find it in the right menu.": "您可以在右侧菜单中找到它。",
  "EN:ZH:So you have all your course content and here you have AI assistant.": "因此，你有了所有的课程内容，这里还有人工智能助手。",
  "EN:ZH:Here you can chat with this AI assistant and ask any questions you have about the content.": "在这里，您可以与这个人工智能助手聊天，提出任何有关内容的问题。",
  "EN:ZH:For example, what is my GPT or what is AI engine?": "例如，什么是我的 GPT 或什么是人工智能引擎？",
  "EN:ZH:Or you can ask to explain GPT to your as you was a child.": "或者，你也可以像小时候一样，要求向你解释 GPT。",
  "EN:ZH:So all answers are pretty fast and straightforward.": "因此，所有答案都非常快速、直接。",
  "EN:ZH:You can put here any, uh, messages so you can say that you like this results or you don't like these": "您可以在这里输入任何信息，这样您就可以说您喜欢这个结果，或者您不喜欢这些结果。",
  "EN:ZH:results.": "结果",
  "EN:ZH:And it's pretty easy to leverage in your further activities.": "而且在今后的活动中也很容易加以利用。",
  "EN:ZH:What is important during this implementation you can easily add additional questions if it's needed.": "重要的是，在实施过程中，您可以根据需要轻松添加其他问题。",
  "EN:ZH:You can clarify what is going on, etc. you can find the AI system not just in the right menu.": "您不仅可以在右侧菜单中找到人工智能系统，还可以明确发生了什么。",
  "EN:ZH:You can use it during the Q&A.": "您可以在问答过程中使用它。",
  "EN:ZH:For example, if you have any questions, for example, you want to learn more about AI agents.": "例如，如果您有任何问题，比如您想了解更多有关人工智能代理的信息。",
  "EN:ZH:Uh, you can.": "你可以的",
  "EN:ZH:On the one hand, uh, wait while I'm answering your question and I'm here to help you.": "一方面，呃，等我回答你的问题，我是来帮你的。",
  "EN:ZH:So I'm happy to answer all your questions to assist you during the learning.": "因此，我很乐意回答您的所有问题，为您的学习提供帮助。",
  "EN:ZH:But on the other hand, you can just click get an instant answer.": "但另一方面，您只需点击一下，就能立即得到答案。",
  "EN:ZH:And most of people are not happy to wait.": "而大多数人并不乐于等待。",
  "EN:ZH:So if you have the possibility to ask the question to AI assistant, you here have the possibility to": "因此，如果您可以向人工智能助手提问，您就可以",
  "EN:ZH:get the answer faster.": "更快地得到答案。",
  "EN:ZH:So what is AI agent, how it works, etc. and this gives you possibility to implement it further in": "因此，什么是人工智能代理，它是如何工作的，等等，这些都为您在以下方面进一步实施人工智能代理提供了可能",
  "EN:ZH:your approach.": "你的方法。",
  "EN:ZH:Much more easier and much more faster.": "更方便、更快捷。",
  "EN:ZH:You can test any stuff for.": "您可以测试任何东西。",
  "EN:ZH:You can ask for example what is actual version This.": "例如，您可以询问实际版本是什么。",
  "EN:ZH:Version of ChatGPT.": "ChatGPT 的版本。",
  "EN:ZH:And it will give you the answer based on the data of the course.": "它会根据课程数据给出答案。",
  "EN:ZH:And additionally.": "另外",
  "EN:ZH:So it's going to the data the current version of ChatGPT GPT four.": "因此，它将使用当前版本的 ChatGPT GPT 四层数据。",
  "EN:ZH:You can ask to give some specifications about the model.": "您可以要求提供有关型号的一些规格。",
  "EN:ZH:It will give you the specifications about the model etc..": "它将为您提供型号规格等信息。",
  "EN:ZH:So as you see it's pretty straightforward.": "所以，正如你所看到的，这非常简单。",
  "EN:ZH:It helps you to communicate easier, faster.": "它可以帮助您更轻松、更快速地进行交流。",
  "EN:ZH:It's your personal AI creator.": "这是你个人的人工智能创造者。",
  "EN:ZH:Based on the content you have, you can chat with it.": "根据您的内容，您可以与它聊天。",
  "EN:ZH:You can ask questions, you can ask for support.": "你可以提问，可以寻求支持。",
  "EN:ZH:And definitely I'm here to help you.": "我肯定是来帮你的。",
  "EN:ZH:But AI assistant will be really fast.": "但人工智能助手的速度会非常快。",
  "EN:ZH:It can work even in time zones where I'm not available at the moment.": "即使在我暂时不在的时区，它也能正常工作。",
  "EN:ZH:And this is really amazing feature to make your educational process more smoothly.": "这确实是一项了不起的功能，能让你的教育过程更加顺利。",
  "EN:ZH:Another big feature that I want to share with you is role play.": "我想与大家分享的另一大特色是角色扮演。",
  "EN:ZH:On the courses that are with role play, you can see the role play page on their page, but also in": "在有角色扮演的课程中，您可以在其页面上看到角色扮演页面，也可以在",
  "EN:ZH:the course curriculum.": "课程设置。",
  "EN:ZH:You can see where the role play based.": "你可以看到角色扮演的基础。",
  "EN:ZH:Most of my courses have at least one role play.": "我的大多数课程都至少有一个角色扮演游戏。",
  "EN:ZH:Usually it's or HR manager or interviewer.": "通常是人力资源经理或面试官。",
  "EN:ZH:That helps you to build a career with the knowledge that you have.": "这有助于你利用所学知识开创事业。",
  "EN:ZH:And for example, if you will start to plan with this role play in this course, it's your ambitious": "例如，如果你在本课程中开始规划角色扮演，你就会雄心勃勃地",
  "EN:ZH:setting goals with a fellow marketer.": "与营销同行一起设定目标",
  "EN:ZH:So in this course is about, uh, ChatGPT for marketers and definitely to help you to set up the realistic": "因此，本课程是关于，呃，营销人员的 ChatGPT，肯定是为了帮助您建立现实的",
  "EN:ZH:goals about, uh, your AI, uh, adventure, your AI approach.": "关于你的人工智能目标，呃，冒险，你的人工智能方法。",
  "EN:ZH:It's a good way how to use role play, how to implement role play.": "这是一个很好的方法，可以让我们了解如何使用角色扮演，如何实施角色扮演。",
  "EN:ZH:First of all, you are going here and here.": "首先，你要去这里和这里。",
  "EN:ZH:You need to read the goals.": "你需要阅读目标。",
  "EN:ZH:You are reading the goals.": "您正在阅读的是目标。",
  "EN:ZH:You have the possibility to introduce yourself.": "您可以进行自我介绍。",
  "EN:ZH:Share the challenges with AI, discuss your learning goals for this course, and set a personal intention": "与人工智能分享挑战，讨论本课程的学习目标，并设定个人目标",
  "EN:ZH:for what success looks like at the end of the course.": "课程结束时成功的样子。",
  "EN:ZH:Uh, you see how I've already interacted with it.": "嗯，你看我已经和它互动过了。",
  "EN:ZH:I've completed the first goal, the second goal, but not completed the third and the fourth goal.": "我已经完成了第一个目标和第二个目标，但还没有完成第三个和第四个目标。",
  "EN:ZH:So you have the possibility to double check the uncompleted goals.": "因此，您可以再次检查未完成的目标。",
  "EN:ZH:You see what is going on with the third goals, what are their strengths, what are the areas, what": "你可以看到第三个目标的进展情况，他们的优势是什么，有哪些领域，有哪些方面。",
  "EN:ZH:the actionable steps.": "可操作的步骤。",
  "EN:ZH:And you can double check everything.": "你还可以仔细检查一切。",
  "EN:ZH:What is read before you will, uh, retry the, uh, this, uh, role play one more time and after you": "之前读过的内容，你将再试一次，呃，这个，呃，角色扮演，之后你将",
  "EN:ZH:see that, yes, it works.": "你会发现，是的，它是有效的。",
  "EN:ZH:You can start the role play or retry it.": "您可以开始角色扮演或重试。",
  "EN:ZH:Here you have, uh, your scenario.": "这是你的方案",
  "EN:ZH:What do you need to show?": "你需要展示什么？",
  "EN:ZH:Uh, you've joined an online networking group for digital marketing, learning how to use AI tools.": "你加入了一个数字营销在线网络小组，学习如何使用人工智能工具。",
  "EN:ZH:And we have Jordan Malik.": "还有乔丹-马利克。",
  "EN:ZH:Jordan is practical, friendly and ambitious.": "乔丹务实、友好、雄心勃勃。",
  "EN:ZH:He's worked in small campaigns, and he will help you to leverage your AI approach.": "他曾参与过小型活动，他将帮助您充分利用人工智能方法。",
  "EN:ZH:Sometimes you will see a lot of definition.": "有时你会看到很多定义。",
  "EN:ZH:Sometimes it can be faster.": "有时会更快。",
  "EN:ZH:And see here you see the time that you have for your communication, usually from 5 to 10 minutes.": "在这里，您可以看到您的通信时间，通常为 5 到 10 分钟。",
  "EN:ZH:It's a quick talk.": "这是一个快速谈话。",
  "EN:ZH:So you can talk to Jordan, explain your goals, what is going on, etc. Trump.": "这样你就可以与乔丹交谈，解释你的目标和正在发生的事情等等。特朗普",
  "EN:ZH:If you don't like role play, you can skip it.": "如果不喜欢角色扮演，可以跳过。",
  "EN:ZH:But most of my students really love them.": "但我的大多数学生都非常喜欢它们。",
  "EN:ZH:They leave the positive feedback, etc. so the next stage is to start role play.": "他们会留下积极的反馈意见等，因此下一阶段就是开始角色扮演。",
  "EN:ZH:Here's the Jordan.": "这里是约旦。",
  "EN:ZH:He is connecting.": "他正在连接。",
  "EN:ZH:You are talking with him.": "你在和他说话。",
  "EN:ZH:You see how all your goals are moving from, uh, zero to hero and this is what you need to do.": "你会发现你的所有目标都在从 \"零 \"变成 \"英雄\"，这就是你需要做的。",
  "EN:ZH:Uh, my recommendation please check uh, boss, AI assistant and role play.": "呃，我的建议是，请检查呃，老板、人工智能助理和角色扮演。",
  "EN:ZH:It will help you to make your education much more effective.": "它将帮助您更有效地开展教育。",
  "EN:ZH:You will leverage AI for your educational process, will be more faster, effective, and get you better": "您将在教育过程中利用人工智能，这将更快、更有效，并让您获得更好的效果",
  "EN:ZH:And I'm here to assist you.": "我就是来帮助你的。",
  "EN:ZH:So if you have any questions, feel free to ask it to me.": "因此，如果您有任何问题，请随时向我提出。",
  "EN:ZH:I want to be so fast as AI assistant, but definitely I will help you and answer all your questions.": "我希望自己能像人工智能助理一样快，但我一定会帮助您，回答您的所有问题。",
  "EN:ZH:So see you in the next video if Udemy will ask a review at this moment, uh, feel free to share the": "所以，如果此刻 Udemy 会要求评论，请在下一个视频中与我们见面，嗯，请随时与我们分享。",
  "EN:ZH:review about the course.": "课程回顾",
  "EN:ZH:Uh, we ask about Honest Review because the reviews are something like a rocket funnel, which helps": "呃，我们询问诚实评论，是因为评论就像火箭漏斗，有助于",
  "EN:ZH:our courses to be more popular among our students.": "我们的课程更受学生欢迎。",
  "EN:ZH:See you in the next lecture.": "下次讲座再见。",
  "EN:ZH:Hello dear students, today I'm excited to guide you through exploring video.": "亲爱的同学们，大家好！今天，我很高兴能带领大家一起探索视频。",
  "EN:ZH:Let's dive into the video platform together.": "让我们一起深入了解视频平台。",
  "EN:ZH:Once you've logged in, you'll have access to all the essential features for your customer support needs.": "登录后，您就可以使用所有基本功能，满足您的客户支持需求。",
  "EN:ZH:Let's start from the beginning.": "让我们从头开始。",
  "EN:ZH:Here you'll see a dashboard that offers quick actions like live conversations, live agents, live visitors,": "在这里，您会看到一个仪表板，提供即时对话、即时代理、即时游客等快速操作、",
  "EN:ZH:tickets, and flows.": "门票和流量。",
  "EN:ZH:You can also navigate using the left panel where you'll find your inbox for live conversations.": "您还可以使用左侧面板导航，在那里您可以找到实时对话的收件箱。",
  "EN:ZH:You can activate your conversations and integrate with platforms like WhatsApp, Instagram, Facebook": "您可以激活对话，并与 WhatsApp、Instagram、Facebook 等平台整合。",
  "EN:ZH:Messenger or install a chat widget and email.": "Messenger 或安装聊天 Widget 和电子邮件。",
  "EN:ZH:You'll also find an assistant for messaging and solved issues.": "您还会发现一个用于发送信息和解决问题的助手。",
  "EN:ZH:You'll have a section for tickets with zero agent.": "您将有一个零代理的票区。",
  "EN:ZH:In zero agent, you can access performance metrics, live conversations, emails, and knowledge.": "在零代理中，您可以访问性能指标、实时对话、电子邮件和知识。",
  "EN:ZH:This is where you can add to your knowledge base.": "您可以在这里添加知识库。",
  "EN:ZH:You can manually add your website or import from a CSV file, or even import articles.": "您可以手动添加网站或从 CSV 文件导入，甚至导入文章。",
  "EN:ZH:If you're unable to find the right options, you can contact us and we can help train for you using": "如果您找不到合适的选择，可以联系我们，我们可以通过以下方式帮助您进行培训",
  "EN:ZH:any source.": "任何来源。",
  "EN:ZH:Here you can get some suggestions and manage your data sources effectively.": "在这里，您可以获得一些建议，并有效管理您的数据源。",
  "EN:ZH:Uh, I've added our website skills booster and you can select the product type, whether it's an e-commerce": "呃，我已经添加了我们的网站技能助推器，您可以选择产品类型，无论是电子商务",
  "EN:ZH:online store or a business for customers.": "网上商店或面向客户的业务。",
  "EN:ZH:You can also add products via API and receive suggestions for review.": "您还可以通过 API 添加产品，并接收审查建议。",
  "EN:ZH:The AI agent will automatically answer customer questions or provide suggestions for zero knowledge": "人工智能代理将自动回答客户的问题或提供零知识建议",
  "EN:ZH:to improve resolution rates.": "以提高分辨率。",
  "EN:ZH:There's also a playground feature where you can chat with customers.": "还有一个游乐场功能，您可以与客户聊天。",
  "EN:ZH:You can start with a simple greeting and see how the system provides an answer.": "您可以从简单的问候语开始，看看系统如何提供答案。",
  "EN:ZH:Feel free to enter your questions here.": "欢迎在此提出您的问题。",
  "EN:ZH:As you type, the system will generate a response.": "当您键入时，系统将作出回应。",
  "EN:ZH:You can also create tasks from scratch or explore available templates.": "您还可以从头开始创建任务或探索可用模板。",
  "EN:ZH:It's great for dragging and dropping actions and conditions.": "它非常适合拖放操作和条件。",
  "EN:ZH:The flow activates when a visitor sends a message with phrases similar to those listed using an AI model.": "当访客发送的信息中包含与使用人工智能模型列出的短语相似的短语时，流程就会启动。",
  "EN:ZH:The flow will manage the conversation, saving triggers and creating tickets as needed.": "该流程将管理对话，保存触发器，并根据需要创建票单。",
  "EN:ZH:This functionality works with platforms like WeChat, Facebook Messenger, Instagram and WhatsApp.": "该功能适用于微信、Facebook Messenger、Instagram 和 WhatsApp 等平台。",
  "EN:ZH:You can select your preferred conversation language here.": "您可以在这里选择自己喜欢的对话语言。",
  "EN:ZH:Now let's move on to flows.": "现在，让我们继续讨论流量问题。",
  "EN:ZH:Here is an example of flows.": "下面是一个流量示例。",
  "EN:ZH:They can increase your sales by being more precise.": "它们可以通过更精确的方式提高您的销售额。",
  "EN:ZH:You can add sales flows or explore different strategies including lead generation.": "您可以添加销售流程或探索不同的策略，包括销售线索的生成。",
  "EN:ZH:You can manage new bookings easily, boost lead acquisitions or enhance customer service, instantly": "您可以轻松管理新的预订、提高潜在客户获取率或即时增强客户服务。",
  "EN:ZH:address viewer issues, increase satisfaction or decrease bounce rates by exploring available templates.": "通过探索可用模板，解决观众问题，提高满意度或降低跳出率。",
  "EN:ZH:Automate representative answers.": "代表回答自动化。",
  "EN:ZH:Request photo and video shooting and explore all available templates.": "申请照片和视频拍摄，探索所有可用模板。",
  "EN:ZH:There are sales flows available, such as order boards and spinning wheels for discounts for new visitors.": "这里有销售流程，如订单板和为新游客提供折扣的转盘。",
  "EN:ZH:This is all part of the panel.": "这些都是小组讨论的内容。",
  "EN:ZH:Here you'll find options for upselling, closing deals, winning back, or re-engaging with lead flows": "在这里，您可以找到用于追加销售、达成交易、赢得回购或重新吸引客户流的选项",
  "EN:ZH:and lead magnet subscribers.": "和铅磁铁订阅者。",
  "EN:ZH:There's a lead generation bot news and updates.": "这里有线索生成机器人的新闻和更新。",
  "EN:ZH:Real estate lead generation, appointment booking and other functions.": "房地产线索生成、预约及其他功能。",
  "EN:ZH:We also have support flows enabling you to send PDF user guides and manage advanced running requests.": "我们还提供支持流程，使您能够发送 PDF 用户指南和管理高级运行请求。",
  "EN:ZH:You can utilize a digital menu.": "您可以使用数字菜单。",
  "EN:ZH:Let's see what's next with our customer options.": "让我们看看客户选择的下一步。",
  "EN:ZH:When we start, we can see how everything functions.": "当我们开始时，我们可以看到一切是如何运作的。",
  "EN:ZH:Of course, we have analytics for an overview of interactions and AI engine resolution rates.": "当然，我们也有分析功能，可以全面了解互动情况和人工智能引擎的解决率。",
  "EN:ZH:These are readily accessible.": "这些都是现成的。",
  "EN:ZH:You'll also learn how to install a chat widget on your website.": "您还将学习如何在网站上安装聊天小工具。",
  "EN:ZH:It's important because once installed, you can tailor your welcome message, reduce abandoned carts": "它之所以重要，是因为一旦安装，您就可以定制欢迎信息，减少放弃购物车的数量。",
  "EN:ZH:with flows, or engage live visitors.": "流，或与现场游客互动。",
  "EN:ZH:You can also connect with your mailbox, Instagram, Facebook and WhatsApp and install the mobile and": "您还可以连接邮箱、Instagram、Facebook 和 WhatsApp，安装手机和平板电脑。",
  "EN:ZH:desktop apps.": "桌面应用程序。",
  "EN:ZH:We have numerous integrations available.": "我们有许多可用的集成。",
  "EN:ZH:Integrations include Eagle CRM, Zendesk, Sell, Zapier, Google Analytics, Pipedrive, and Zendesk.": "集成包括 Eagle CRM、Zendesk、Sell、Zapier、Google Analytics、Pipedrive 和 Zendesk。",
  "EN:ZH:You can also adjust settings like background color to your preference.": "您还可以根据自己的喜好调整背景颜色等设置。",
  "EN:ZH:Additionally, action colors can be customized.": "此外，还可以定制动作颜色。",
  "EN:ZH:You can choose your preferred colors, enabling custom branding along with home chat or Pre-chat survey": "您可以选择自己喜欢的颜色，在进行主页聊天或预聊天调查时启用自定义品牌",
  "EN:ZH:options.": "选项。",
  "EN:ZH:You can have agents, collages or upload your logo.": "您可以选择代理、拼贴或上传您的徽标。",
  "EN:ZH:Messages can be uploaded and set as headers or body text.": "可上传信息并将其设置为标题或正文。",
  "EN:ZH:Conversation starters can be personalized as well.": "对话开场白也可以个性化。",
  "EN:ZH:You can select from existing options or add your own.": "您可以从现有选项中进行选择，也可以添加自己的选项。",
  "EN:ZH:Manage your online and offline statuses and send email communications.": "管理在线和离线状态，发送电子邮件。",
  "EN:ZH:You'll have control over visibility and positioning.": "您可以控制可见性和定位。",
  "EN:ZH:Choose whether you prefer desktop or mobile views.": "选择您喜欢桌面还是手机浏览。",
  "EN:ZH:Button positions and sizes are customizable, too.": "按钮的位置和大小也可以自定义。",
  "EN:ZH:We support multiple languages.": "我们支持多种语言。",
  "EN:ZH:You can add additional languages if needed, offering flexibility in your language preferences.": "如有需要，您还可以添加其他语言，从而灵活地选择语言。",
  "EN:ZH:You can edit these options and preview changes.": "您可以编辑这些选项并预览更改。",
  "EN:ZH:This information should be quite useful for you.": "这些信息对您应该非常有用。",
  "EN:ZH:That wraps up our walkthrough of the dashboard.": "至此，我们对仪表盘的学习就结束了。",
  "EN:ZH:It's designed to be user friendly, powerful, and scalable to grow with your business, whether it's": "它的设计用户友好、功能强大、可扩展，可与您的业务一起成长，无论是",
  "EN:ZH:automation, live chat, email support, or analytics.": "自动化、即时聊天、电子邮件支持或分析。",
  "EN:ZH:Everything is just a few clicks away.": "只需轻点几下，一切尽在掌握。",
  "EN:ZH:Thank you for joining me.": "感谢您的参与。",
  "EN:ZH:Hello dear students, today we're going to dive into one of the most important steps in setting up your": "亲爱的同学们，大家好！今天，我们将深入探讨建立自己的",
  "EN:ZH:account installing your first live chat widget.": "账户安装您的第一个即时聊天小工具。",
  "EN:ZH:This is how you create the initial connection point between you and your visitors, where conversations": "这样，您就能在您和访客之间建立起最初的连接点，让对话",
  "EN:ZH:start, questions get answered, and relationships are built.": "开始，问题得到解答，关系得以建立。",
  "EN:ZH:Now, inside the video, you'll notice you need to install your widget.": "现在，在视频中，你会发现需要安装小部件。",
  "EN:ZH:I've already got mine set up, but how can you do it?": "我已经设置好了，但如何设置呢？",
  "EN:ZH:You can have the installation code shipped to you, which you then place just before the closing body": "您可以将安装代码邮寄给您，然后将其放置在关闭正文之前",
  "EN:ZH:tag on your website.": "标签。",
  "EN:ZH:Next, you can copy the code to your clipboard and head over to your website to verify if the chat is": "接下来，您可以将代码复制到剪贴板，然后访问您的网站，验证聊天是否正常。",
  "EN:ZH:active.": "活跃。",
  "EN:ZH:For instance, I have it on my demo website and you can see how it appears here.": "例如，我在我的演示网站上安装了它，你可以在这里看到它是如何显示的。",
  "EN:ZH:Uh, you have to installed, uh, to confirm everything is set up correctly.": "呃，你必须安装，呃，确认一切设置正确。",
  "EN:ZH:You'll want to check that everything appears as it should.": "您需要检查是否一切正常。",
  "EN:ZH:Now you have it.": "现在你有了。",
  "EN:ZH:You will now have your chat panel visible.": "现在就可以看到聊天面板了。",
  "EN:ZH:You can customize the background and notice any new changes you've made.": "您可以自定义背景，并注意到您所做的任何新更改。",
  "EN:ZH:Additionally, you can upload your company logo.": "此外，您还可以上传公司徽标。",
  "EN:ZH:This is also where you should put in your demo or actual website URL, and you can also write a header": "您也应该在此处输入您的演示或实际网站的 URL，还可以编写标题",
  "EN:ZH:for your chat.": "供您聊天。",
  "EN:ZH:I've just added a simple welcome message.": "我刚刚添加了一条简单的欢迎信息。",
  "EN:ZH:It's easy to see how you can customize it and even prompt visitors to ask questions.": "不难看出，您可以对其进行定制，甚至提示访客提问。",
  "EN:ZH:Once you have your chat panel set up opening, it will display your chat bot.": "设置好聊天面板后，它就会显示您的聊天机器人。",
  "EN:ZH:You'll notice it starts with some preset messages that can be customized as needed.": "你会发现，它一开始就预设了一些信息，可以根据需要进行定制。",
  "EN:ZH:Moving forward, ensure to add a meta title and meta description.": "然后，确保添加元标题和元描述。",
  "EN:ZH:This is crucial for improving the visibility of your site.": "这对提高网站知名度至关重要。",
  "EN:ZH:Afterward, you can save your changes.": "之后，您可以保存更改。",
  "EN:ZH:This is also where you can name your chatbot, making it uniquely yours.": "您还可以在这里为聊天机器人命名，使其成为独一无二的聊天机器人。",
  "EN:ZH:It's important to configure options like online or offline messages, introduce yourself, and tailor": "重要的是要配置在线或离线信息、自我介绍等选项，并量身定制",
  "EN:ZH:these messages to fit your needs.": "这些信息，以满足您的需求。",
  "EN:ZH:You can also set up specific messages for when you are unavailable, such as sorry we are not available": "您还可以为您无法提供服务时设置特定的信息，例如：对不起，我们无法提供服务",
  "EN:ZH:at this moment.": "此时此刻",
  "EN:ZH:Please leave us a message.": "请给我们留言。",
  "EN:ZH:Once you've installed and set up everything, you'll see all these features on your website enabling": "安装和设置完成后，您就可以在网站上看到所有这些功能。",
  "EN:ZH:real time conversations with your visitors.": "与访客进行实时对话。",
  "EN:ZH:That's it for today's lesson.": "今天的课程到此结束。",
  "EN:ZH:See you in the next one.": "下一届再见",
  "EN:ZH:Let's begin by exploring how you can connect to emails directly within Tédio.": "让我们先来了解一下如何在 Tédio 中直接连接电子邮件。",
  "EN:ZH:To start, navigate to the settings where you'll find the email panel.": "首先，导航到设置，在那里可以找到电子邮件面板。",
  "EN:ZH:Next, you need to proceed to connect your mailbox.": "接下来，您需要连接邮箱。",
  "EN:ZH:You can click on the Connect Mailbox button or find it to your right.": "您可以单击 \"连接邮箱 \"按钮或在右侧找到它。",
  "EN:ZH:Let's move forward.": "让我们继续前进。",
  "EN:ZH:Here, you should click on email and then select your mailbox provider from the options available.": "在此，您应点击电子邮件，然后从可用选项中选择您的邮箱提供商。",
  "EN:ZH:You can choose from Gmail, Microsoft Outlook, or another provider.": "您可以选择 Gmail、Microsoft Outlook 或其他提供商。",
  "EN:ZH:I'll demonstrate with Gmail.": "我将用 Gmail 来演示。",
  "EN:ZH:Once selected, choose your email.": "选择后，请选择您的电子邮件。",
  "EN:ZH:Afterward, Tédio will prompt you to connect.": "之后，Tédio 会提示您连接。",
  "EN:ZH:You'll see your email displayed here and it will be verified.": "您将看到您的电子邮件显示在这里，并将得到验证。",
  "EN:ZH:If you need to add another email, you can remove the existing one and head back to Connect Mailbox": "如果您需要添加另一封邮件，可以移除现有邮件，然后返回连接邮箱",
  "EN:ZH:to add a different name.": "添加不同的名称。",
  "EN:ZH:This is how it works.": "它是这样工作的。",
  "EN:ZH:You'll also notice the sender address.": "您还会注意到发件人地址。",
  "EN:ZH:Here you can specify your domain if necessary.": "如有必要，您可以在此指定您的域名。",
  "EN:ZH:The user should add his custom domain in the domain section to achieve the best results.": "用户应在 \"域 \"部分添加自定义域，以获得最佳效果。",
  "EN:ZH:If needed, you can block any unwanted email addresses.": "如有需要，您可以屏蔽任何不需要的电子邮件地址。",
  "EN:ZH:This part is crucial.": "这一部分至关重要。",
  "EN:ZH:Once you've connected, you can test the setup by sending emails to ensure everything is working correctly.": "连接后，您可以通过发送电子邮件来测试设置，以确保一切运行正常。",
  "EN:ZH:And that's all.": "仅此而已。",
  "EN:ZH:For this lesson, we've covered the essentials.": "本节课，我们介绍了基本知识。",
  "EN:ZH:I'll catch up with you in the next lesson.": "下节课我再来跟你补课。",
  "EN:ZH:In this lesson, we are going to focus on how to integrate with your existing platforms, specifically": "在本课中，我们将重点介绍如何与现有平台集成，特别是",
  "EN:ZH:Shopify, WordPress, Zendesk, and popular CRM tools.": "Shopify、WordPress、Zendesk 和流行的 CRM 工具。",
  "EN:ZH:Don't.": "不要",
  "EN:ZH:You break my heart.": "你让我心碎",
  "EN:ZH:Break, break break.": "休息，休息，休息。",
  "EN:ZH:Break.": "休息",
  "EN:ZH:Break, break.": "休息，休息",
  "EN:ZH:A bit of introduction about myself.": "自我介绍",
  "EN:ZH:So my name is.": "我的名字是",
  "EN:ZH:I am a safe Practice Consultant and a certified trainer from Scaled Agile Inc, USA.": "我是一名安全实践顾问，也是美国 Scaled Agile Inc 的认证培训师。",
  "EN:ZH:I have 13 years of experience working in various agile product management roles.": "我有 13 年的敏捷产品管理经验。",
  "EN:ZH:For example Product Owner, Product manager, enterprise, agile coach, Scrum master.": "例如，产品负责人、产品经理、企业、敏捷教练、Scrum Master。",
  "EN:ZH:So I've played all these roles for various organizations.": "因此，我在不同的组织中扮演过所有这些角色。",
  "EN:ZH:So this is a little bit about the experience I am having with various clients and consulting firms.": "这就是我与不同客户和咨询公司打交道的一些经历。",
  "EN:ZH:So I have experience of working with the big four consulting firms.": "因此，我有与四大咨询公司合作的经验。",
  "EN:ZH:I've also worked for the prestigious group of clients, which is also known as High Tech or Big Tech.": "我还为著名的客户群工作过，这些客户群也被称为高科技或大科技客户群。",
  "EN:ZH:I've worked for insurance industry clients, some of the largest in the world, for example Royal London": "我曾为保险行业的客户工作过，其中不乏世界上最大的客户，例如皇家伦敦保险集团。",
  "EN:ZH:Group.": "组。",
  "EN:ZH:They have more than 100 billion of assets under management.": "他们管理着超过 1000 亿美元的资产。",
  "EN:ZH:I've worked there and I've worked with Google and Business Consulting, which is again one of the largest": "我在那里工作过，也与谷歌和商业咨询公司合作过，后者也是全球最大的商业咨询公司之一。",
  "EN:ZH:business consulting practice in the world.": "全球商业咨询业务。",
  "EN:ZH:What do they feel as well?": "他们也有什么感觉？",
  "EN:ZH:They are also one of the biggest consulting practice in the world.": "他们也是世界上最大的咨询公司之一。",
  "EN:ZH:So this is a bit about my experience working with various consulting firms.": "以上就是我在不同咨询公司工作的一些经历。",
  "EN:ZH:And I've played various roles for these organizations and client for example product owner, product": "我在这些组织和客户中扮演过各种角色，例如产品负责人、产品",
  "EN:ZH:manager, scrum master, agile coach.": "经理、Scrum Master、敏捷教练。",
  "EN:ZH:This is a snapshot of various certifications and exams passed by me over the last decade.": "这是我在过去十年中通过的各种认证和考试的缩影。",
  "EN:ZH:So it includes certification and exam from Scaled Agile, including Leading Safe, Safe or Architect": "因此，它包括 Scaled Agile 的认证和考试，包括 Leading Safe、Safe 或 Architect",
  "EN:ZH:Agile Software safe for government and are all close to some exams I've done.": "敏捷软件对政府来说是安全的，而且与我参加过的一些考试都很接近。",
  "EN:ZH:I've also earned SPC Program Consultant, which makes me a certified coach or trainer from Scaled Agile": "我还获得了 SPC 项目顾问资格，这使我成为 Scaled Agile 的认证教练或培训师。",
  "EN:ZH:Inc. I've done PSM one SP1 and SP2 as well.": "公司。我也做过 PSM one SP1 和 SP2。",
  "EN:ZH:I've also done an MBA from one of the leading institute.": "我还在一家知名学院获得了工商管理硕士学位。",
  "EN:ZH:I have earned a Bachelor of Engineering degree as well from one of the leading institute with focus": "我还获得了一所顶尖学院的工程学学士学位，重点是",
  "EN:ZH:on computer software and other technologies.": "计算机软件和其他技术。",
  "EN:ZH:So this is a little bit of my credentials.": "这就是我的一点资历。",
  "EN:ZH:Think about how much time and effort go into market research, product strategy definition, product": "想一想，在市场调研、产品战略定义、产品",
  "EN:ZH:development, and product launch.": "开发和产品发布。",
  "EN:ZH:These traditional product management processes often involve extensive time and resources.": "这些传统的产品管理流程往往需要耗费大量的时间和资源。",
  "EN:ZH:Now, imagine having an AI powered assistant like Microsoft Copilot and ChatGPT that streamlines these": "现在，想象一下，如果有一个像微软 Copilot 和 ChatGPT 这样的人工智能助手，就能简化这些工作。",
  "EN:ZH:processes, helping you make decisions faster and more informed than ever before.": "这些流程可帮助您比以往更快、更明智地做出决策。",
  "EN:ZH:These tools are not just optimizing product development, but revolutionizing it.": "这些工具不仅优化了产品开发，而且彻底改变了产品开发。",
  "EN:ZH:In this video, we'll explore how gen AI tools like Microsoft Copilot and ChatGPT can transform the": "在本视频中，我们将探讨微软 Copilot 和 ChatGPT 等基因人工智能工具如何能够改变我们的工作方式。",
  "EN:ZH:entire product management life cycle from initial concept to post-launch analysis.": "从最初概念到发布后分析的整个产品管理生命周期。",
  "EN:ZH:Let's dive in and discover their full potential.": "让我们深入其中，发掘它们的全部潜力。",
  "EN:ZH:The first crucial stage of the life cycle is market research, with powerful tools like ChatGPT, Microsoft": "生命周期的第一个关键阶段是市场调研。",
  "EN:ZH:Copilot, and Google Gemini.": "Copilot 和 Google 双子座。",
  "EN:ZH:Gemini Gennai helps you conduct comprehensive market analysis in record time, providing deep insights": "Gemini Gennai 可帮助您在最短时间内进行全面的市场分析，提供深刻的见解",
  "EN:ZH:into market dynamics.": "市场动态。",
  "EN:ZH:Whether you need a detailed Pestel analysis, a thorough Porter's Five Forces assessment, or in-depth": "无论您需要详细的 Pestel 分析、全面的波特五力评估，还是深入的",
  "EN:ZH:competitor profiling.": "竞争对手特征分析。",
  "EN:ZH:Gen AI tools like Microsoft Copilot and ChatGPT enable you to generate accurate and actionable insights": "Gen AI 工具（如 Microsoft Copilot 和 ChatGPT）可帮助您生成准确、可操作的见解",
  "EN:ZH:faster than ever, cutting down research time significantly.": "比以往更快，大大缩短了研究时间。",
  "EN:ZH:For example, instead of manually gathering and sifting through vast amounts of data, you can use gen": "例如，无需手动收集和筛选海量数据，您可以使用 Gen",
  "EN:ZH:AI tools like Microsoft Copilot and ChatGPT to efficiently profile market segments, identify emerging": "Microsoft Copilot 和 ChatGPT 等人工智能工具，以有效地剖析细分市场，识别新兴市场，并为其提供支持。",
  "EN:ZH:trends, and prioritize opportunities with greater precision.": "趋势，更准确地确定机遇的优先次序。",
  "EN:ZH:This allows for a more strategic approach to market entry and product positioning.": "这样就能以更具战略性的方式进入市场和进行产品定位。",
  "EN:ZH:This comprehensive and accelerated research process sets a strong data driven foundation for all subsequent": "这一全面、快速的研究过程为所有后续工作奠定了坚实的数据驱动基础。",
  "EN:ZH:strategic decisions ensuring your product is built on solid market understanding.": "战略决策，确保您的产品建立在对市场的充分了解之上。",
  "EN:ZH:Next, let's move into defining your product strategy.": "接下来，我们来确定产品战略。",
  "EN:ZH:This is where creativity meets clarity, and gen AI tools like Microsoft Copilot and ChatGPT take center": "这就是创意与清晰度的结合，也是微软 Copilot 和 ChatGPT 等人工智能工具的核心所在。",
  "EN:ZH:stage, helping to articulate your vision with precision.": "舞台，帮助您准确地表达自己的愿景。",
  "EN:ZH:Gen AI tools like Microsoft Copilot and ChatGPT can significantly help you create essential product": "Gen AI 工具（如 Microsoft Copilot 和 ChatGPT）可极大地帮助您创建重要的产品。",
  "EN:ZH:management artifacts such as detailed product vision boards, comprehensive business model canvases,": "管理工具，如详细的产品愿景板、全面的商业模式画布、",
  "EN:ZH:and insightful customer journey maps, all with remarkable speed and accuracy.": "以及富有洞察力的客户旅程地图，所有这些都具有极高的速度和准确性。",
  "EN:ZH:Need to outline your products vision or refine your strategic direction?": "需要勾勒产品愿景或完善战略方向？",
  "EN:ZH:Use tools like ChatGPT or Microsoft Copilot to draft these key product strategy artifacts effortlessly,": "使用 ChatGPT 或 Microsoft Copilot 等工具毫不费力地起草这些关键的产品战略工件、",
  "EN:ZH:ensuring all stakeholders are aligned.": "确保所有利益相关方保持一致。",
  "EN:ZH:You will also learn in later lessons how to effectively use AI tools like Microsoft Copilot and ChatGPT": "在后面的课程中，您还将学习如何有效使用 Microsoft Copilot 和 ChatGPT 等人工智能工具。",
  "EN:ZH:to build a model, helping you prioritize features based on customer satisfaction and impact, ensuring": "建立一个模型，帮助您根据客户满意度和影响确定功能的优先级，确保",
  "EN:ZH:you focus on what truly matters to your users.": "您可以专注于对用户真正重要的事情。",
  "EN:ZH:Moving into product development.": "转向产品开发。",
  "EN:ZH:Gen AI tools like Microsoft Copilot and ChatGPT prove invaluable.": "事实证明，微软 Copilot 和 ChatGPT 等 Gen AI 工具非常有价值。",
  "EN:ZH:You can use it to define clear sprint goals, generate innovative features, and create detailed, actionable": "您可以用它来定义清晰的冲刺目标，生成创新功能，并创建详细、可操作的冲刺计划。",
  "EN:ZH:user stories.": "用户故事。",
  "EN:ZH:Accelerating your development cycles.": "加快开发周期",
  "EN:ZH:For example, you can prompt gen AI tools like Microsoft Copilot and ChatGPT to generate a comprehensive": "例如，您可以促使 Microsoft Copilot 和 ChatGPT 等人工智能工具生成全面的",
  "EN:ZH:list of user stories specifically tailored to your product's features, ensuring all aspects are covered": "专门针对产品功能定制的用户故事列表，确保涵盖所有方面",
  "EN:ZH:and clearly defined for your development team.": "并为开发团队明确定义。",
  "EN:ZH:Then, you can easily refine these generated stories, adding specific details and context, and integrate": "然后，您可以轻松完善这些生成的故事，添加具体细节和上下文，并整合",
  "EN:ZH:them directly into your existing workflow, ensuring a seamless transition from concept to execution": "将它们直接纳入现有工作流程，确保从概念到执行的无缝过渡",
  "EN:ZH:even after development.": "即使在开发之后也是如此。",
  "EN:ZH:Gen AI tools like Microsoft Copilot and ChatGPT continue to add immense value.": "微软 Copilot 和 ChatGPT 等新一代人工智能工具将继续带来巨大价值。",
  "EN:ZH:It can help craft compelling go to market messaging, analyze customer feedback for sentiment, and": "它可以帮助设计有吸引力的市场信息，分析客户反馈的情绪，以及",
  "EN:ZH:identify opportunities for iterative improvements and new feature development by integrating AI tools": "通过整合人工智能工具，确定迭代改进和新功能开发的机会",
  "EN:ZH:like Microsoft Copilot and ChatGPT into the launch and post-launch stages.": "如 Microsoft Copilot 和 ChatGPT，进入发布和发布后阶段。",
  "EN:ZH:You can optimize your product's performance, ensure it consistently meets evolving customer needs,": "您可以优化产品性能，确保产品始终满足不断变化的客户需求、",
  "EN:ZH:and maintain a competitive edge in the market.": "并保持市场竞争优势。",
  "EN:ZH:As you can see, gen AI tools like Microsoft Copilot and ChatGPT aren't just tools.": "正如您所看到的，微软 Copilot 和 ChatGPT 等人工智能工具不仅仅是工具。",
  "EN:ZH:These act as a strategic partner that enhances every single step of the product management lifecycle,": "它们作为战略合作伙伴，可加强产品管理生命周期的每一个步骤、",
  "EN:ZH:from ideation to continuous improvement, driving innovation and efficiency.": "从构思到持续改进，推动创新和提高效率。",
  "EN:ZH:Welcome to this video on introduction to ChatGPT.": "欢迎观看 ChatGPT 介绍视频。",
  "EN:ZH:Llms Foundation models and AI.": "Llms 基础模型和人工智能。",
  "EN:ZH:We are living in a time where AI is not just a concept, but a powerful tool that's transforming industries,": "在我们所处的时代，人工智能已不仅仅是一个概念，而是正在改变各行各业的强大工具、",
  "EN:ZH:enhancing human capabilities, and redefining the way we live and work.": "提高人类的能力，重新定义我们的生活和工作方式。",
  "EN:ZH:But how did we get here?": "但我们是怎么来到这里的呢？",
  "EN:ZH:What's the difference between AI, machine learning, deep learning, and generative AI?": "人工智能、机器学习、深度学习和生成式人工智能之间有什么区别？",
  "EN:ZH:And where do terms like foundation models, large language models, and ChatGPT fit in?": "那么，基础模型、大型语言模型和 ChatGPT 等术语又是如何定义的呢？",
  "EN:ZH:Today we will break it all down.": "今天，我们将对这一切进行分析。",
  "EN:ZH:Artificial intelligence, or AI, is a broad field within computer science dedicated to creating machines": "人工智能（AI）是计算机科学中的一个广泛领域，致力于创造机器",
  "EN:ZH:capable of performing tasks that typically require human intelligence.": "能够执行通常需要人类智能的任务。",
  "EN:ZH:Think about things like recognizing speech, making decisions, or understanding language.": "想想识别语言、做出决定或理解语言等事情。",
  "EN:ZH:Example of AI includes self-driving cars like Tesla Autopilot, virtual assistants like Siri or Google": "人工智能的例子包括特斯拉自动驾驶汽车、Siri 或谷歌等虚拟助手。",
  "EN:ZH:Assistant, and fraud detection systems used by banks.": "助理，以及银行使用的欺诈检测系统。",
  "EN:ZH:The concept of AI has been around for decades, with roots trekking back to the 1950s, when Alan Turing": "人工智能的概念已经存在了几十年，其根源可以追溯到 20 世纪 50 年代，当时艾伦-图灵（Alan Turing）提出了 \"人工智能 \"这一概念。",
  "EN:ZH:invented the Turing Test to determine if a computer could pass for a human.": "发明了 \"图灵测试\"，以确定计算机是否可以冒充人类。",
  "EN:ZH:In writing, linguistic fluency.": "在写作方面，语言流畅。",
  "EN:ZH:But AI is more than just mimicking human behavior.": "但人工智能不仅仅是模仿人类行为。",
  "EN:ZH:It's a vast field encompassing various technologies.": "这是一个涵盖各种技术的广阔领域。",
  "EN:ZH:One of the most significant is machine learning.": "其中最重要的是机器学习。",
  "EN:ZH:Machine learning is a subset of AI that allows machines to learn from existing data and improve over": "机器学习是人工智能的一个子集，它允许机器从现有数据中学习，并不断改进。",
  "EN:ZH:time to make decisions or even predictions.": "作出决定甚至预测的时间。",
  "EN:ZH:Imagine you are training a system to recognize spam emails by feeding it thousands of emails, which": "想象一下，你正在训练一个系统识别垃圾邮件，向它输入成千上万封电子邮件，其中",
  "EN:ZH:are examples of spam and non-spam emails.": "是垃圾邮件和非垃圾邮件的例子。",
  "EN:ZH:The machine learns to identify pattern that distinguish between the two.": "机器通过学习来识别区分两者的模式。",
  "EN:ZH:This is similar to how Netflix recommends shows based on your viewing history, or how predictive maintenance": "这类似于 Netflix 根据你的观看历史推荐节目，或预测性维护。",
  "EN:ZH:in manufacturing prevents equipment failures.": "在生产过程中防止设备故障。",
  "EN:ZH:By analyzing past data, the term machine learning was coined in 1959 by Arthur Samuel at IBM.": "通过分析过去的数据，机器学习一词于 1959 年由 IBM 的 Arthur Samuel 提出。",
  "EN:ZH:The origin of which are rooted in theories or artificial intelligence.": "其根源在于人工智能理论。",
  "EN:ZH:He helped in making a crucial evolution in how we think about AI machines that learn, rather than just": "在他的帮助下，我们对人工智能机器学习的思考方式发生了关键性的演变，而不仅仅是",
  "EN:ZH:follow pre-programmed rules.": "遵循预先设定的规则。",
  "EN:ZH:Taking it a step further, we have deep learning, a more advanced form of machine learning that uses": "更进一步，我们有了深度学习，这是一种更先进的机器学习形式，它利用",
  "EN:ZH:neural networks with many layers, hence the term deep.": "神经网络有很多层，因此被称为深度神经网络。",
  "EN:ZH:This technique is particularly good at processing large amount of unstructured data like images or text,": "这种技术尤其擅长处理大量非结构化数据，如图像或文本、",
  "EN:ZH:and making complex decisions.": "并做出复杂的决定。",
  "EN:ZH:For example, deep learning is behind the facial recognition software on your smartphone.": "例如，智能手机上的面部识别软件背后就是深度学习。",
  "EN:ZH:The image recognition in Google Photos, and speech recognition that powers voice assistants like Amazon": "谷歌照片中的图像识别功能，以及为亚马逊等语音助手提供支持的语音识别功能。",
  "EN:ZH:Alexa.": "亚历克莎",
  "EN:ZH:While the concept of deep learning isn't new, it's gained significant traction in 2006, when Geoffrey": "虽然深度学习的概念并不新鲜，但它在 2006 年获得了显著的发展。",
  "EN:ZH:Hinton from the University of Toronto developed fast learning algorithms.": "多伦多大学的辛顿开发了快速学习算法。",
  "EN:ZH:Unlocking the potential for machines to learn more like humans.": "挖掘机器的潜能，让它像人类一样学习。",
  "EN:ZH:And that brings us to the present day, where generative AI is making waves.": "时至今日，生成式人工智能正在掀起波澜。",
  "EN:ZH:Generative AI goes beyond analyzing or predicting based on existing data it creates, whether it's writing": "生成式人工智能不仅能根据现有数据进行分析或预测，它还能编写",
  "EN:ZH:an article, generating an image, or composing music, generative AI can produce entirely new content.": "无论是撰写文章、生成图像还是创作音乐，生成式人工智能都能产生全新的内容。",
  "EN:ZH:A great example of this is ChatGPT, which has captured the public's imagination by generating human": "ChatGPT 就是一个很好的例子。",
  "EN:ZH:like text responses in conversations.": "比如对话中的文字回复。",
  "EN:ZH:Other examples include deli e, which creates unique images from text prompts and an AI that composes": "其他例子还包括根据文字提示创建独特图像的 deli e，以及能编曲的人工智能。",
  "EN:ZH:music.": "音乐",
  "EN:ZH:But what powers these advanced capabilities?": "但这些先进功能的动力是什么？",
  "EN:ZH:That's where Foundation Model comes in.": "这就是基金会模式的作用所在。",
  "EN:ZH:A foundation model is a large machine language model trained on vast amount of unlabeled data using": "基础模型是在大量无标记数据基础上训练的大型机器语言模型，使用",
  "EN:ZH:a transformer algorithm.": "变压器算法",
  "EN:ZH:The result?": "结果呢？",
  "EN:ZH:A versatile model that can be fine tuned for a wide range of applications.": "该机型用途广泛，可针对各种应用进行微调。",
  "EN:ZH:For instance, Google's Bert, a foundation model, was trained on a massive corpus of text data and": "例如，谷歌的基础模型 \"伯特 \"是在海量文本数据语料库中训练出来的，它可以为用户提供更多的信息。",
  "EN:ZH:can be fine tuned to excel at tasks like sentiment analysis or legal document review.": "可以进行微调，以胜任情感分析或法律文件审查等任务。",
  "EN:ZH:Among foundation models, large language models are particularly noteworthy.": "在基础模型中，大型语言模型尤其值得一提。",
  "EN:ZH:They are specialized foundation models that focus specifically on understanding and generating natural": "它们是专门的基础模型，专门侧重于理解和生成自然",
  "EN:ZH:language.": "语言",
  "EN:ZH:Imagine you are building a virtual assistant, then can not only understand your request, but also": "想象一下，你正在打造一个虚拟助理，它不仅能理解你的要求，还能",
  "EN:ZH:anticipate your needs based on past interactions.": "根据以往的互动预测您的需求。",
  "EN:ZH:That's the power of an LLM.": "这就是法学硕士的力量。",
  "EN:ZH:Example of Llms include GPT four, which powers ChatGPT and Bert, which is used in various natural": "Llms 的例子包括为 ChatGPT 和 Bert 提供动力的 GPT four，后者在各种自然语言中使用。",
  "EN:ZH:language processing tasks.": "语言处理任务。",
  "EN:ZH:One of the most well known application of Llms is ChatGPT, built on top of OpenAI's GPT model, ChatGPT": "最著名的 Llms 应用之一是 ChatGPT，它建立在 OpenAI 的 GPT 模型之上，ChatGPT",
  "EN:ZH:exemplifies how Llms can be fine tuned for conversational tasks.": "这说明 Llms 可以针对会话任务进行微调。",
  "EN:ZH:It can carry on a conversation, provide detailed explanations, and even generate creative content,": "它可以进行对话，提供详细的解释，甚至生成有创意的内容、",
  "EN:ZH:making it a versatile tool for businesses and individuals alike.": "使其成为企业和个人的多功能工具。",
  "EN:ZH:For example, you can ask ChatGPT to create a job description for a business intelligence engineer and": "例如，您可以让 ChatGPT 为商务智能工程师创建一份职位描述，然后",
  "EN:ZH:it will write this for you.": "它会为你写下这些。",
  "EN:ZH:To sum it up, AI is the overarching concept of creating intelligent machines.": "总而言之，人工智能是创造智能机器的总体概念。",
  "EN:ZH:Machine learning allows these machines to learn from data.": "机器学习可以让这些机器从数据中学习。",
  "EN:ZH:Deep learning uses complex neural networks to mimic human thought process.": "深度学习利用复杂的神经网络来模仿人类的思维过程。",
  "EN:ZH:Generative AI takes this further by creating new content.": "生成式人工智能通过创建新内容，进一步实现了这一目标。",
  "EN:ZH:Foundational models provide a base that can be fine tuned for specific tasks, and large language models": "基础模型提供了一个可针对特定任务进行微调的基础，而大型语言模型",
  "EN:ZH:like the one powering ChatGPT specialize in processing and generating human language.": "就像为 ChatGPT 提供动力的软件一样，专门处理和生成人类语言。",
  "EN:ZH:We are at a transformative moment in history where these technologies are not just advancing rapidly,": "我们正处于一个历史性的变革时刻，这些技术不仅在迅速发展，而且还在不断进步、",
  "EN:ZH:but are becoming integral to how we live and work as leaders.": "但作为领导者，它正成为我们生活和工作不可或缺的一部分。",
  "EN:ZH:Understanding these concepts is crucial to harnessing their potential effectively and ethically.": "了解这些概念对于有效和合乎道德地利用其潜力至关重要。",
  "EN:ZH:Let's embrace this future with knowledge and responsibility.": "让我们用知识和责任拥抱未来。",
  "EN:ZH:It demands.": "它要求",
  "EN:ZH:Thanks for watching this video.": "感谢您观看本视频。",
  "EN:ZH:In this topic, we are going to discuss two things.": "在本专题中，我们将讨论两件事。",
  "EN:ZH:Create an account on ChatGPT.": "在 ChatGPT 上创建账户。",
  "EN:ZH:In this section, I'll walk you through how to create your account in ChatGPT.": "在本节中，我将教您如何在 ChatGPT 中创建账户。",
  "EN:ZH:And after that I'll show you how to use an existing account to login into chatbot.": "之后，我会教你如何使用现有账户登录聊天机器人。",
  "EN:ZH:Let's go through these.": "让我们一起来看看。",
  "EN:ZH:These are the various steps which we will go through while creating new ChatGPT account.": "以上就是我们在创建新 ChatGPT 账户时要经历的各个步骤。",
  "EN:ZH:First we will visit the OpenAI ChatGPT website, then click on the sign up button to create a new account.": "首先，我们将访问 OpenAI ChatGPT 网站，然后点击注册按钮创建新账户。",
  "EN:ZH:Then we'll provide email and a password for creating a new account.": "然后，我们会提供创建新账户的电子邮件和密码。",
  "EN:ZH:And then once we have provided these details, then basically ChatGPT will send a verification email": "一旦我们提供了这些详细信息，ChatGPT 就会发送一封验证电子邮件",
  "EN:ZH:to our email account and then we'll verify our email address.": "到我们的电子邮件账户，然后我们将验证我们的电子邮件地址。",
  "EN:ZH:Once this verification is complete, then we'll use the email address which we use for creating this": "完成验证后，我们就可以使用创建此电子邮件时使用的电子邮件地址",
  "EN:ZH:account plus the password.": "账户和密码。",
  "EN:ZH:We'll use the combination of these two to login into this ChatGPT account.": "我们将使用这两者的组合来登录 ChatGPT 账户。",
  "EN:ZH:And then we'll provide our full name and date of birth.": "然后提供我们的全名和出生日期。",
  "EN:ZH:Once we do these steps at that point our account will be successfully created.": "完成这些步骤后，我们的账户就创建成功了。",
  "EN:ZH:Let's do these steps one by one.": "让我们逐一完成这些步骤。",
  "EN:ZH:Let's go to the first step which is going to the website.": "第一步，进入网站。",
  "EN:ZH:To create the account, click on ChatGPT website link, which is ChatGPT Openai.com.": "要创建账户，请点击 ChatGPT 网站链接，即 ChatGPT Openai.com。",
  "EN:ZH:I've clicked on this link to go to this website.": "我点击了这个链接，进入了这个网站。",
  "EN:ZH:You can also type it in a new Chrome or Internet Explorer browser window.": "您也可以在新的 Chrome 浏览器或 Internet Explorer 浏览器窗口中输入。",
  "EN:ZH:Once we have reached this website, then what we are going to do is to click on the sign up button.": "到达该网站后，我们要做的就是点击注册按钮。",
  "EN:ZH:Now it is asking us to provide a new email address.": "现在它要求我们提供一个新的电子邮件地址。",
  "EN:ZH:I'm going to provide an email address to it for this account.": "我将为这个账户提供一个电子邮件地址。",
  "EN:ZH:When we are providing the email address for creating a new account, we have to remember that we should": "在提供电子邮件地址以创建新账户时，我们必须记住以下几点",
  "EN:ZH:have not used this email address before for creating the account.": "以前创建帐户时未使用过此电子邮件地址。",
  "EN:ZH:I'm going to provide a new email address to it.": "我将为它提供一个新的电子邮件地址。",
  "EN:ZH:So I've written a new email address here.": "所以我在这里写了一个新的电子邮件地址。",
  "EN:ZH:And then I'm going to click the continue button.": "然后点击 \"继续 \"按钮。",
  "EN:ZH:And then we have to provide a new password.": "然后，我们必须提供一个新密码。",
  "EN:ZH:At the time of creating this account, the password requirement from ChatGPT is minimum 12 letters.": "在创建此账户时，ChatGPT 对密码的要求是至少 12 个字母。",
  "EN:ZH:I'm going to provide a correct password to it.": "我将提供一个正确的密码。",
  "EN:ZH:Okay.": "好的",
  "EN:ZH:I provided the password and I pressed on the continue button.": "我提供了密码，然后按下了 \"继续 \"按钮。",
  "EN:ZH:Once I pressed on the continue button, it is saying that it has sent a verification email to my email": "当我按下继续按钮时，它显示已经向我的电子邮箱发送了一封验证电子邮件",
  "EN:ZH:account.": "账户",
  "EN:ZH:Now I'm going to check in my email account whether I have received the email or not.": "现在，我要在我的电子邮件账户中查看我是否收到了这封邮件。",
  "EN:ZH:Let's see that I've already opened my email by logging into my email account.": "假设我已经通过登录我的电子邮件账户打开了我的电子邮件。",
  "EN:ZH:And if you see this OpenAI verify your email.": "如果您看到 OpenAI 验证您的电子邮件。",
  "EN:ZH:This email have come through as a new email.": "这封邮件是新邮件。",
  "EN:ZH:It have this verify email address button, I'm going to click it.": "它有一个验证电子邮件地址的按钮，我要点击它。",
  "EN:ZH:That's how the email will look like once it arrives in your email box.": "这就是电子邮件到达您的电子邮箱后的样子。",
  "EN:ZH:I'm going to click this verify email address button.": "我要点击这个验证电子邮件地址按钮。",
  "EN:ZH:And now it takes us to OpenAI website again.": "现在，它又把我们带到了 OpenAI 网站。",
  "EN:ZH:And it is asking us some additional details for creation of account.": "它还要求我们提供创建账户所需的其他详细信息。",
  "EN:ZH:I'm going to provide it a new details like my full name and my date of birth.": "我要向它提供新的详细信息，比如我的全名和出生日期。",
  "EN:ZH:And I will agree to the terms and conditions which are provided by OpenAI.": "我同意 OpenAI 提供的条款和条件。",
  "EN:ZH:So I have agreed to the terms and conditions of OpenAI, and now OpenAI have created my account, and": "因此，我已经同意了 OpenAI 的条款和条件，现在 OpenAI 已经创建了我的账户，并且",
  "EN:ZH:it is giving some tips on how to use the ChatGPT account.": "它提供了一些如何使用 ChatGPT 账户的提示。",
  "EN:ZH:The first tip it is giving is ask away.": "它给出的第一条建议就是询问。",
  "EN:ZH:You can ask any question about something you want to learn or coding or brainstorming.": "您可以就想学的东西、编码或头脑风暴提出任何问题。",
  "EN:ZH:You can ask all those things.": "你可以问所有这些问题。",
  "EN:ZH:It is also suggesting you to not share any sensitive information with that GDP.": "它还建议您不要与该 GDP 共享任何敏感信息。",
  "EN:ZH:Then the last tip it is suggesting is that sometimes ChatGPT information can be accurate.": "最后一个提示是，有时 ChatGPT 信息可能是准确的。",
  "EN:ZH:So when you are using the information which is provided by GDP, it can be inaccurate.": "因此，当你使用 GDP 提供的信息时，它可能是不准确的。",
  "EN:ZH:Just be aware of that.": "请注意这一点。",
  "EN:ZH:I'm just going to click on okay let's go.": "我就点击 \"好的，我们走吧\"。",
  "EN:ZH:This we have successfully created a GTP account.": "至此，我们成功创建了一个 GTP 账户。",
  "EN:ZH:We have successfully logged into it.": "我们已成功登录。",
  "EN:ZH:Welcome back.": "欢迎回来",
  "EN:ZH:Another source of information about open AI chatbot will be to visit the website itself.": "有关开放式人工智能聊天机器人的另一个信息来源是访问网站本身。",
  "EN:ZH:And what you are going to want to do is to go to the area in your search bar and then go to openai.com.": "您需要做的是在搜索栏中搜索该区域，然后访问 openai.com。",
  "EN:ZH:You're then going to want to scroll all the way to the bottom.": "然后一路滚动到底部。",
  "EN:ZH:You're going to see several aspects of the OpenAI company.": "您将看到 OpenAI 公司的多个方面。",
  "EN:ZH:And just as you would do an investigation on information about any other website or company, you are": "就像对其他任何网站或公司的信息进行调查一样，您需要",
  "EN:ZH:going to want to see what OpenAI says about itself, in particular in the About Us section, as well": "你会想看看OpenAI是如何介绍自己的，尤其是在 \"关于我们 \"部分，以及",
  "EN:ZH:as the OpenAI research.": "如 OpenAI 研究。",
  "EN:ZH:If you want to determine more that OpenAI says about itself, you want to visit the publications section.": "如果您想了解 OpenAI 关于自己的更多信息，请访问出版物部分。",
  "EN:ZH:The API and OpenAI chatbot allows you to integrate with the platform.": "应用程序接口和 OpenAI 聊天机器人允许您与平台集成。",
  "EN:ZH:You are going to want to pay attention to the pricing element.": "您需要关注定价因素。",
  "EN:ZH:That means then, that if you are willing to program an application, you can interact with the models": "这就意味着，只要你愿意为应用程序编程，就能与模型进行交互",
  "EN:ZH:within OpenAI to connect to the data, and you will need to pay attention to the pricing.": "在 OpenAI 中连接数据时，您需要注意定价。",
  "EN:ZH:As of the recording of this video, you will see pricing for image interaction.": "在录制本视频时，您将看到图像交互的定价。",
  "EN:ZH:You'll also see pricing for language interaction.": "您还会看到语言互动的定价。",
  "EN:ZH:Before using the API, you are going to want to read the terms and policies of OpenAI.": "在使用 API 之前，您需要阅读 OpenAI 的条款和政策。",
  "EN:ZH:When you click this link, you're going to notice that it says ChatGPT, but it's not going to take": "当您点击这个链接时，您会注意到上面写着 ChatGPT，但它并不会将您带到",
  "EN:ZH:you back to the chatbot.": "您将回到聊天机器人。",
  "EN:ZH:What this is going to do is to take you to a specific page telling you more about the chatbot, and": "这将带您进入一个特定页面，向您介绍更多关于聊天机器人的信息，以及",
  "EN:ZH:this is where you want to read about what open AI chatbot actually does.": "在这里，你可以了解到开放式人工智能聊天机器人的实际功能。",
  "EN:ZH:And you're going to see examples as of the recording of this video of what OpenAI chatbot can do.": "在录制这段视频时，你将看到 OpenAI 聊天机器人能做什么的示例。",
  "EN:ZH:You are also going to learn how open AI chatbot works, how it improves itself, and how it actually": "您还将了解开放式人工智能聊天机器人是如何工作的、它是如何自我改进的，以及它实际上是如何",
  "EN:ZH:uses machine learning.": "使用机器学习。",
  "EN:ZH:Provide the information that it gives you when you do a query.": "在查询时提供所需的信息。",
  "EN:ZH:You are going to want to pay specific attention to the limitations that the chatbot says about itself.": "您要特别注意聊天机器人对自己的限制。",
  "EN:ZH:And we're going to stop the video here, and we're going to pick it up in the next video to discuss": "视频到此结束，我们将在下一个视频中继续讨论以下问题",
  "EN:ZH:the limitations.": "限制。",
  "EN:ZH:So with that, thanks.": "就这样，谢谢。",
  "EN:ZH:And I will see you in another video.": "我们在另一个视频里再见。",
  "EN:ZH:Welcome to our next section.": "欢迎来到下一节。",
  "EN:ZH:In this section we are going to discuss delivery bulk creation framework using what it means is what": "在本节中，我们将讨论使用交付批量创建框架的含义是什么。",
  "EN:ZH:are the steps which are required for creating a deliverable using ChatGPT.": "是使用 ChatGPT 创建交付品所需的步骤。",
  "EN:ZH:For example, if you want to create a user story using ChatGPT, what are the tasks involved in that?": "例如，如果您想使用 ChatGPT 创建一个用户故事，其中涉及哪些任务？",
  "EN:ZH:You can use it for delivering any task through ChatGPT.": "您可以使用它通过 ChatGPT 完成任何任务。",
  "EN:ZH:It doesn't matter what is your role.": "你的角色是什么并不重要。",
  "EN:ZH:For example, you can be a product owner, product manager, tester, business analyst, accountant,": "例如，你可以是产品负责人、产品经理、测试人员、业务分析师、会计师、",
  "EN:ZH:marketer, proposal writer, anyone.": "营销人员、提案撰写人，任何人都可以。",
  "EN:ZH:Whatever is your role or whatever work you are trying to do, this will be the high level approach you": "无论您的角色是什么，无论您要做什么工作，这都将是您的高水平方法",
  "EN:ZH:will be needing to approach your task or deliverable for generating it through ChatGPT.": "您将需要通过 ChatGPT 完成您的任务或交付成果。",
  "EN:ZH:This deliverable creation framework using ChatGPT has four steps in scenario.": "这个使用 ChatGPT 的交付品创建框架有四个场景步骤。",
  "EN:ZH:First step is analyze and understand the task at hand.": "第一步是分析和理解手头的任务。",
  "EN:ZH:What does that mean?": "这是什么意思？",
  "EN:ZH:You go through the problem.": "你去解决问题。",
  "EN:ZH:You understand what is the problem you are trying to solve, what is the task you are trying to do?": "你明白你要解决的问题是什么，你要完成的任务是什么？",
  "EN:ZH:Or what is the name of the deliverable you are trying to create using ChatGPT?": "或者您试图使用 ChatGPT 创建的交付品名称是什么？",
  "EN:ZH:GDP.": "国内生产总值。",
  "EN:ZH:What are the various sections in that deliverable?": "该交付品的各个部分是什么？",
  "EN:ZH:What are the sections which you will require in the response?": "您要求在答复中包含哪些部分？",
  "EN:ZH:Those kind of things you will understand at this step.": "这些事情到了这一步你就会明白了。",
  "EN:ZH:For example, if you are creating a user story, you will.": "例如，如果您正在创建一个用户故事，您将",
  "EN:ZH:First you need to understand that you are going to create a story which is a deliverable.": "首先，你需要明白，你要创作的故事是一个可交付的作品。",
  "EN:ZH:Then these are sections of this user story.": "那么这些就是这个用户故事的部分。",
  "EN:ZH:For example, your story title, description, acceptance criteria and between these sections you want": "例如，您的故事标题、描述、验收标准，在这些部分之间，您希望",
  "EN:ZH:ChatGPT to generate the short title of this user story description and acceptance criteria.": "ChatGPT 生成该用户故事描述和验收标准的简短标题。",
  "EN:ZH:What is context of the product or feature for which you are generating deliverable?": "生成交付品的产品或功能的背景是什么？",
  "EN:ZH:All these things you need to understand in step one or doing step one.": "所有这些都是你在第一步或做第一步时需要了解的。",
  "EN:ZH:After you have understood and analyzed the task at hand, then what you do is based on the understanding": "在理解和分析了手头的任务之后，你所做的一切都要基于对任务的理解",
  "EN:ZH:based on the requirements of this deliverable.": "基于本交付品的要求。",
  "EN:ZH:You draft the GTP prompt, then prompt which you have drafted in step number two, you will use this": "起草 GTP 提示语，然后在第二步中起草提示语，您将使用以下提示语",
  "EN:ZH:draft GTP prompt and run it through GTP to generate an initial response once we generate the initial": "草拟 GTP 提示符，并通过 GTP 运行以生成初始响应。",
  "EN:ZH:response, what you do is you review that response.": "答复，你要做的就是审查该答复。",
  "EN:ZH:And if you think this is a high quality response, this is the direction you were expecting the ChatGPT": "如果您认为这是一个高质量的回复，那么这就是您所期待的 ChatGPT 的方向",
  "EN:ZH:to go for your particular task.": "来完成您的特定任务。",
  "EN:ZH:Then you start contextualizing or refining this response to a better level of quality.": "然后，你开始根据具体情况调整或改进这种回应，使其达到更高的质量水平。",
  "EN:ZH:This was the flow.": "这就是流程。",
  "EN:ZH:Then there are two alternate scenarios where there can be hundreds of other scenarios, but these are": "然后是两种不同的方案，其他方案可能有数百种，但这两种方案是",
  "EN:ZH:the two key scenarios which are likely to happen.": "可能出现的两种主要情况。",
  "EN:ZH:Alternate scenarios.": "备用方案",
  "EN:ZH:The first one is the response, which is generated by ChatGPT initial response or any response generated": "第一个是响应，由 ChatGPT 初始响应或任何响应生成",
  "EN:ZH:by ChatGPT.": "由 ChatGPT 提供。",
  "EN:ZH:It's deviating from medium to 7,080% correction level or confidence level.": "它偏离了中等至 7080% 的修正水平或置信水平。",
  "EN:ZH:So if the confidence level of this response or quality level of response is anywhere between 60 to 80%,": "因此，如果该回复的置信度或回复质量水平在 60% 到 80% 之间、",
  "EN:ZH:in that case, what you do is you will run additional prompts in the same thread of ChatGPT to optimize": "在这种情况下，您需要在 ChatGPT 的同一线程中运行额外的提示，以优化",
  "EN:ZH:the results of that GDP to bring the response to the direction you are taking, the response which is": "通过 GDP 的结果，将反应引向你正在采取的方向，即反应是",
  "EN:ZH:now generated by ChatGPT.": "现在由 ChatGPT 生成。",
  "EN:ZH:We will again review it, and if you are happy with the quality of this new response, then you contextualize": "我们将再次进行审查，如果您对新答复的质量感到满意，那么您就将上下文联系起来",
  "EN:ZH:it.": "它。",
  "EN:ZH:This is scenario number two.": "这是第二种情况。",
  "EN:ZH:Scenario number three is that GDP has generated a response which is of very poor quality or quality": "第三种情况是，GDP 产生了质量很差或质量很低的回应",
  "EN:ZH:level is anywhere between 30 to 50%.": "水平在 30% 到 50% 之间。",
  "EN:ZH:Those kind of scenarios you review the result, figure out what has gone wrong in your prompt, and": "在这种情况下，您要回顾结果，找出提示中的错误，并",
  "EN:ZH:then you rewrite your entire prompt and run this entire prompt from the beginning in ChatGPT.": "然后重写整个提示符，并在 ChatGPT 中从头开始运行整个提示符。",
  "EN:ZH:And then whatever response has come through, review this response.": "然后，无论收到什么回复，都要对回复进行审查。",
  "EN:ZH:If it is of high quality, then you contextualize it.": "如果质量很高，那就将其与上下文联系起来。",
  "EN:ZH:This is the high level deliverable creation framework, or steps, which you will use for creating any": "这是一个高层次的交付品创建框架或步骤，您可以使用它来创建任何交付品。",
  "EN:ZH:deliverable through ChatGPT.": "可通过 ChatGPT 交付。",
  "EN:ZH:This is the end of this section.": "本节到此结束。",
  "EN:ZH:In this section we are going to discuss GTP Prompting Framework.": "本节我们将讨论 GTP 提示框架。",
  "EN:ZH:So within this section we have three objectives which we are going to achieve.": "因此，在本节中，我们要实现三个目标。",
  "EN:ZH:First one is General Chat GTP prompt structure template.": "第一个是一般聊天 GTP 提示结构模板。",
  "EN:ZH:In this one I will discuss a prompting structure template and how to use a standard template to generate": "在本课中，我将讨论提示结构模板，以及如何使用标准模板生成",
  "EN:ZH:prompt for different frameworks and deliverables.": "提示不同的框架和交付成果。",
  "EN:ZH:Then, using this GTP structure template, we will create a simple chat GTP prompt structure.": "然后，使用此 GTP 结构模板，我们将创建一个简单的聊天 GTP 提示结构。",
  "EN:ZH:So we will see how to use this template to create a simple GTP prompt structure.": "因此，我们将了解如何使用该模板创建简单的 GTP 提示结构。",
  "EN:ZH:And then the sample chat GTP prompt structure, which we have created in last step, will use that simple": "然后，我们在上一步创建的聊天 GTP 提示结构示例将使用简单的",
  "EN:ZH:GTP prompt to generate a product vision board using chat GTP.": "GTP 提示使用聊天 GTP 生成产品愿景板。",
  "EN:ZH:So these are the three objectives which we are going to achieve in this section.": "这就是我们要在本节中实现的三个目标。",
  "EN:ZH:Let's move on to the next part.": "让我们进入下一部分。",
  "EN:ZH:In this section, what we are going to discuss is a basic chat GTP prompting framework.": "在本节中，我们将讨论一个基本的聊天 GTP 提示框架。",
  "EN:ZH:So this basic framework is developed by me and it is a proprietary framework, but I am letting people": "因此，这个基本框架是由我开发的，它是一个专有框架，但我允许人们",
  "EN:ZH:use it under Creative Commons 4.0 license.": "在知识共享 4.0 许可下使用。",
  "EN:ZH:So you are free to use it for your own purposes or for commercial purposes.": "因此，您可以将其用于自己的目的或商业用途。",
  "EN:ZH:So let's go through this structure of this framework.": "让我们来看看这个框架的结构。",
  "EN:ZH:So this is the general prompting template I have developed.": "这就是我开发的通用提示模板。",
  "EN:ZH:This is your premium structure for people who are playing product owner, product manager product director": "这是您的高级结构，适用于扮演产品负责人、产品经理、产品总监的人员。",
  "EN:ZH:or management consultant role.": "或管理顾问的角色。",
  "EN:ZH:So if you are working in any of the product management role or product role or product strategy role": "因此，如果您正在从事任何产品管理、产品或产品战略工作",
  "EN:ZH:templates should work fine for you because I optimize it to prepare high quality results from ChatGPT,": "模板对您来说应该没问题，因为我对其进行了优化，以便从 ChatGPT 中准备高质量的结果、",
  "EN:ZH:especially for product management roles.": "尤其是产品管理职位。",
  "EN:ZH:So let's go through the structure of this template.": "让我们来了解一下这个模板的结构。",
  "EN:ZH:In the first step or the first line, I am asking the ChatGPT to assume a particular role.": "在第一步或第一行中，我要求 ChatGPT 承担一个特定的角色。",
  "EN:ZH:So here we are specifying the name or role which we want to follow.": "因此，我们在这里指定了要跟踪的名称或角色。",
  "EN:ZH:For example, if we want the tweet to act as a product owner or product manager.": "例如，如果我们希望推文扮演产品负责人或产品经理的角色。",
  "EN:ZH:So managers will specify that here in the next line, you are telling the GTP about the product or project": "因此，经理们将在下一行中明确指出，您正在向 GTP 介绍产品或项目的情况",
  "EN:ZH:on which we are working on.": "我们正在进行的工作。",
  "EN:ZH:Then in the next step, which is the third step, we are asking GTP to generate the various sections": "下一步，也就是第三步，我们要求 GTP 生成不同的部分",
  "EN:ZH:of a framework.": "的框架。",
  "EN:ZH:So let's say if you are building a product vision boards, you specify sections of which you want GTP": "比方说，如果您要制作一个产品愿景板，您可以指定其中需要 GTP 的部分",
  "EN:ZH:to generate for product vision board for example, vision, target audience, all those sections.": "生成产品愿景板，例如愿景、目标受众等所有部分。",
  "EN:ZH:Then in the next step we are telling the name of the framework to GTP.": "下一步，我们将把框架的名称告诉 GTP。",
  "EN:ZH:For example, if you are doing a product vision board, you tell GTP that product Vision board framework.": "例如，如果您正在制作产品愿景板，您可以告诉 GTP 产品愿景板框架。",
  "EN:ZH:Then in next step, we are telling that GTP who is the author of this framework.": "下一步，我们要告诉 GTP 谁是这个框架的作者。",
  "EN:ZH:For example, for a product vision board it is Roman Pichler.": "例如，产品愿景板是 Roman Pichler。",
  "EN:ZH:And then in the next step you will describe the product and project again.": "下一步，您将再次描述产品和项目。",
  "EN:ZH:So the information captured in this step is same as step two.": "因此，这一步获取的信息与第二步相同。",
  "EN:ZH:It's just a copy paste of step two.": "这只是第二步的复制粘贴。",
  "EN:ZH:Then these last two steps here you capture any additional rules which you want to follow or any additional": "然后，在最后两个步骤中，您可以捕捉想要遵循的任何其他规则或任何其他",
  "EN:ZH:constraint which you want to put on ChatGPT responses, or any additional quality parameters which you": "您希望在 ChatGPT 响应上设置的约束，或您希望在 ChatGPT 响应上设置的任何其他质量参数。",
  "EN:ZH:haven't specified in the earlier of these sections.": "在这些章节的前面部分还没有具体说明。",
  "EN:ZH:So adding additional information other than this section is first section is captured in the last sections.": "因此，在第一节之外添加的其他信息将在最后一节中获取。",
  "EN:ZH:And then this plus dot dot section is.": "然后这个加点部分就是",
  "EN:ZH:If you have any further conditions or additional information then number one and two.": "如果您还有其他条件或补充信息，请填写第一和第二项。",
  "EN:ZH:So you can keep adding those additional conditions as new conditions.": "因此，你可以不断添加这些附加条件作为新条件。",
  "EN:ZH:So that's the high level structure of this prompting template.": "这就是这个提示模板的高级结构。",
  "EN:ZH:Obviously I have tested it for ChatGPT and Googlebot.": "显然，我已经为 ChatGPT 和 Googlebot 测试过了。",
  "EN:ZH:It works fine for them, but I'm assuming it should work on a variety of models, including Germany": "这对它们很有效，但我想它应该对包括德国在内的各种机型都有效。",
  "EN:ZH:and other models.": "和其他型号。",
  "EN:ZH:Let's see an examples which I have done with this model for product vision.": "让我们来看看我用这一模型为产品愿景所做的示例。",
  "EN:ZH:So in this example, what I have done is it is showing an example of if you follow this prompt structure": "因此，在这个例子中，我所做的就是展示一个例子，如果你按照这个提示结构进行操作",
  "EN:ZH:template for building a product vision board, how the sample will look like.": "建立产品愿景板的模板，样本的样子。",
  "EN:ZH:So here what we are saying ChatGPT is exactly following the template.": "因此，我们所说的 ChatGPT 完全是按照模板进行的。",
  "EN:ZH:Assume you are a product owner, so this wording remains same as template.": "假定您是产品负责人，因此措辞与模板相同。",
  "EN:ZH:So if you look here I'm saying assume you are.": "所以，如果你看这里，我就假设你是。",
  "EN:ZH:And here I'm just filling the name of the role or product manager.": "在这里，我只是填写了角色或产品经理的姓名。",
  "EN:ZH:Then in the next step for Amazon style bookselling website.": "然后在下一步中建立亚马逊风格的图书销售网站。",
  "EN:ZH:So here we are describing about the product or project on which we are working.": "因此，我们在这里描述的是我们正在开发的产品或项目。",
  "EN:ZH:So in this case we are working on Amazon bookselling website as a product.": "因此，在这种情况下，我们将亚马逊图书销售网站作为一个产品。",
  "EN:ZH:In the next step I have described the sections which I want to develop for the framework.": "下一步，我将介绍我想为框架开发的部分。",
  "EN:ZH:So I am interested in developing product vision board.": "因此，我对开发产品愿景板很感兴趣。",
  "EN:ZH:That's why I have specified the sections which I want to generate in Product Vision board.": "这就是为什么我在 \"产品愿景板 \"中指定了我想要生成的部分。",
  "EN:ZH:So these sections are vision, target group, need product and goal.": "因此，这些部分包括愿景、目标群体、需求产品和目标。",
  "EN:ZH:And in the next step I'm specifying the framework itself.": "下一步，我将指定框架本身。",
  "EN:ZH:So here if you see I'm asking them to specify the name of framework.": "所以在这里，如果你看到我要求他们指定框架的名称。",
  "EN:ZH:And in this example the framework name is product vision board.": "在这个例子中，框架的名称是产品愿景板。",
  "EN:ZH:And in the next step I'm asking to specify the name of author.": "下一步，我要求指定作者姓名。",
  "EN:ZH:So product Vision board is authored by Roman.": "因此，产品愿景板由 Roman 撰写。",
  "EN:ZH:Then in the next step, I'm again asking to describe the project or the product.": "下一步，我再次要求描述项目或产品。",
  "EN:ZH:So this is just a copy of the step number two and then giving it some additional information context": "因此，这只是第二步的复制，然后给它一些额外的信息上下文",
  "EN:ZH:which is not captured in the main body of template.": "这一点在模板主体中没有体现。",
  "EN:ZH:For example, in this case I want target group need product and goal section to be generated in points.": "例如，在这种情况下，我希望目标群体需要的产品和目标部分以积分形式生成。",
  "EN:ZH:So that's why I'm specifying here.": "这就是我在这里说明的原因。",
  "EN:ZH:Sections should be generated or written in points.": "各节应按点生成或书写。",
  "EN:ZH:And then last additional information or constraint I'm putting here is the vision section should not": "我在这里提出的最后一条补充信息或限制条件是，愿景部分不应",
  "EN:ZH:be more than 40 words.": "超过 40 个字。",
  "EN:ZH:So these are kind of additional constraints or rules or quality rules you can put on chat GBP which": "因此，这些都是您可以在聊天 GBP 上设置的额外约束、规则或质量规则，这些规则包括",
  "EN:ZH:GBP will confine to while generating this information.": "在生成这些信息时，GBP 将局限于此。",
  "EN:ZH:So let's quickly read through how the full example looks like.": "让我们快速阅读一下完整的示例。",
  "EN:ZH:What we are saying to chat GBP is assume that you are a product manager for Amazon style book selling": "我们要和 GBP 聊天的意思是，假设您是亚马逊式图书销售的产品经理",
  "EN:ZH:website assume.": "网站假设。",
  "EN:ZH:We are asking indirectly ChatGPT to play a role of a product manager for Amazon style book selling website.": "我们要求 ChatGPT 间接担任亚马逊式图书销售网站的产品经理。",
  "EN:ZH:And then in the next step we are asking ChatGPT to generate vision, target group, need product and": "下一步，我们将要求 ChatGPT 生成愿景、目标群体、需求产品以及",
  "EN:ZH:goal section for a product vision board which is led by Roman Pichler for this Amazon book selling website.": "由 Roman Pichler 领导的亚马逊图书销售网站产品愿景板的目标部分。",
  "EN:ZH:So in this section, we are telling ChatGPT that these are the sections which we want you to produce": "因此，在本节中，我们要告诉 ChatGPT，这些是我们希望您制作的部分",
  "EN:ZH:for a product vision board.": "产品愿景板。",
  "EN:ZH:And this product vision board framework is authored by Roman Pichler.": "这个产品愿景板框架的作者是 Roman Pichler。",
  "EN:ZH:And we want you to produce this product vision board for this Amazon style website.": "我们希望你为这个亚马逊风格的网站制作这个产品愿景板。",
  "EN:ZH:And then in the next section I'm telling ChatGPT to write target group need product and whole section": "然后在下一部分，我告诉 ChatGPT 写下目标群体需要的产品和整个部分",
  "EN:ZH:in form of point.": "点的形式。",
  "EN:ZH:And in the next section I have asked it to capture the vision section in not more than 40 words.": "在下一部分中，我要求用不超过 40 个字来概括愿景部分。",
  "EN:ZH:So this is an example of prompt for product vision board look like for a zoom style website.": "因此，这是一个变焦风格网站的产品愿景板外观提示示例。",
  "EN:ZH:Let's move on to the next section.": "让我们进入下一节。",
  "EN:ZH:In the next section here you can see a product template.": "在下一部分，您可以看到一个产品模板。",
  "EN:ZH:I suggest you to use this template while actually working on chat GBP.": "我建议您在实际制作聊天 GBP 时使用此模板。",
  "EN:ZH:The idea is this is a hands on course, so if you want to learn how to use chat GBP, you have to actually": "我们的想法是这是一门实践课程，所以如果您想学习如何使用聊天 GBP，就必须实际操作",
  "EN:ZH:make your hand dirty and basically go and actually use it.": "把你的手弄脏，然后去真正使用它。",
  "EN:ZH:So I suggest you to use the prompt which I've shown you in the last section to go and use in chat GBP,": "因此，我建议你使用我在上一节中向你展示的提示，在聊天 GBP 中使用、",
  "EN:ZH:and then actually fill this template.": "然后实际填写这个模板。",
  "EN:ZH:So in this product template we have these following sections vision target Group need, product and": "因此，在这个产品模板中，我们有以下几个部分：愿景 目标群体需求、产品和",
  "EN:ZH:Business Goal.": "业务目标。",
  "EN:ZH:And this product vision board is authored by Roman.": "而这块产品愿景板的作者就是罗曼。",
  "EN:ZH:So let's try to generate this product vision board through chat GBP.": "因此，让我们尝试通过聊天 GBP 生成这个产品愿景板。",
  "EN:ZH:So we have already written a sample prompt in our last section.": "因此，我们在上一节中已经写了一个提示示例。",
  "EN:ZH:So I'm just going to copy that prompt and go to chat GBP.": "因此，我将复制该提示并转到 GBP 聊天室。",
  "EN:ZH:This is my chat GBP interface.": "这是我的 GBP 聊天界面。",
  "EN:ZH:Going to start a new chat.": "我要开始新的聊天。",
  "EN:ZH:By going to this part.": "转到这一部分。",
  "EN:ZH:Click on this and then paste the prompt which I have written earlier.": "点击此处，然后粘贴我之前写的提示。",
  "EN:ZH:So again if you quickly review this, assume you are a product manager for there will be some sentence": "所以，如果你快速浏览一下，假定你是一名产品经理，你会发现有这样一句话",
  "EN:ZH:correction error which we might fix during this step.": "在此步骤中，我们可能会纠正错误。",
  "EN:ZH:I suggest you review the grammar before pushing the prompt to ChatGPT.": "我建议您在向 ChatGPT 推送提示之前先复习语法。",
  "EN:ZH:So assume you are a product manager for an Amazon style book selling website.": "假设你是亚马逊式图书销售网站的产品经理。",
  "EN:ZH:Generate the following sections present, target group, need, product and goal for product vision": "生成产品愿景的以下部分：现在、目标群体、需求、产品和目标",
  "EN:ZH:board by Roman Pichler for this style book selling website.": "由 Roman Pichler 为该风格图书销售网站制作的板书。",
  "EN:ZH:Then in this case writing the additional constraint which strategy we have to apply target group need": "那么，在这种情况下，我们就必须写出目标群体需要采用哪种策略的附加约束条件",
  "EN:ZH:product code sections should be written in points and then vision section should not be more than 40": "产品代码部分应按要点编写，然后视觉部分不应超过 40 点",
  "EN:ZH:words.": "话。",
  "EN:ZH:So we have now reviewed this and then we are going to send this message.": "因此，我们现在已经审查了这一点，然后我们将发送这条信息。",
  "EN:ZH:So I've sent this message ChatGPT started generating the sections.": "所以我发送了这条信息，ChatGPT 就开始生成这些部分了。",
  "EN:ZH:So this is how ChatGPT generated it has generated the vision which it is saying.": "这就是 ChatGPT 如何产生它所说的愿景。",
  "EN:ZH:Our book enthusiasts worldwide with a seamless online platform providing access to an extensive collection": "我们为世界各地的图书爱好者提供了一个无缝的在线平台，让他们可以访问大量藏书",
  "EN:ZH:of diverse and engaging titles for hosting a global library community.": "为全球图书馆社区提供丰富多彩、引人入胜的图书。",
  "EN:ZH:So this vision seems at least at average level to me, then it has given us the target groups for this": "因此，在我看来，这一愿景至少达到了平均水平，那么它就为我们提供了这一愿景的目标群体",
  "EN:ZH:particular vision, which is avid readers, student and academicians, gift shoppers, book club and": "他们是狂热的读者、学生和学者、礼品购物者、书友会和书商。",
  "EN:ZH:communities.": "社区。",
  "EN:ZH:So the target group are the potential customer to which we will be targeting this particular website": "因此，目标群体就是我们将针对这一特定网站的潜在客户",
  "EN:ZH:or product.": "或产品。",
  "EN:ZH:Then the next section needs.": "那么下一节就需要",
  "EN:ZH:That seems also average quality to me at least.": "至少在我看来，质量也很一般。",
  "EN:ZH:Convenient and vast book selection, user friendly personalised browsing experience, secure and efficient": "便捷、丰富的图书选择，用户友好的个性化浏览体验，安全、高效",
  "EN:ZH:purchasing processes, community engagement and implementation.": "采购流程、社区参与和实施。",
  "EN:ZH:So in this section in Roman code, we capture the needs of the potential customers or customers which": "因此，在罗马代码的这一部分中，我们要捕捉潜在客户或顾客的需求，这些需求包括",
  "EN:ZH:our product is going to address.": "我们的产品要解决的问题。",
  "EN:ZH:So this also seems average quality to me which is produced by GDP.": "因此，在我看来，这也是 GDP 带来的平均质量。",
  "EN:ZH:Then let's look at the next one.": "那我们来看看下一个。",
  "EN:ZH:So these are the top few features of the product which we usually mention in product section in Roman.": "因此，这就是我们通常在 Roman 的产品部分提到的产品的几大特点。",
  "EN:ZH:So let's see the quality of this section.": "让我们来看看这部分的质量如何。",
  "EN:ZH:Intuitive book recommendation engine.": "直观的图书推荐引擎。",
  "EN:ZH:So this seems a nice feature to be put in top three list.": "因此，将其列入前三名似乎是一个不错的功能。",
  "EN:ZH:Then a responsive and easy to navigate website.": "然后是一个反应灵敏、易于浏览的网站。",
  "EN:ZH:This also seems a good feature to be captured as top three feature of Amazon style book selling website.": "这似乎也是亚马逊式图书销售网站的三大特色之一。",
  "EN:ZH:Then secure payment gateway integration social feature for community building.": "然后，安全支付网关集成了用于社区建设的社交功能。",
  "EN:ZH:So all of these themes among the top few features which we will want to have in our Amazon website.": "因此，所有这些主题都是我们希望在亚马逊网站中拥有的最重要的几个功能。",
  "EN:ZH:And these are the goals which we want to achieve with this website product.": "这些就是我们希望通过该网站产品实现的目标。",
  "EN:ZH:So expand book catalogue to 1 million titles.": "因此将图书目录扩大到 100 万种。",
  "EN:ZH:Achieve 98% customer success rate.": "客户成功率达到 98%。",
  "EN:ZH:Reduce checkout process time by 20%.": "将结账流程时间缩短 20%。",
  "EN:ZH:Build a robust community with 500 active users.": "建立一个拥有 500 名活跃用户的强大社区。",
  "EN:ZH:So this also seems a nice high quality output from chat.": "因此，这似乎也是聊天的一种很好的高质量输出。",
  "EN:ZH:So let's do the next step.": "那么，让我们进行下一步吧。",
  "EN:ZH:Let's populate all this information in our Product Vision board template.": "让我们在产品愿景板模板中填入所有这些信息。",
  "EN:ZH:Let's do that together.": "让我们一起努力。",
  "EN:ZH:GDP gives this copy feature which looks almost like a book.": "GDP 提供的复制功能看起来就像一本书。",
  "EN:ZH:So I'm going to use that copy it, and then I'll bring all this information in our PowerPoint template": "因此，我将使用它，然后将所有这些信息复制到我们的 PowerPoint 模板中",
  "EN:ZH:which we have built for writing the product vision board.": "我们为撰写产品愿景板而建立的。",
  "EN:ZH:So this is how our product vision board is looking like.": "这就是我们的产品愿景板。",
  "EN:ZH:Obviously it's not the final version.": "显然，这不是最终版本。",
  "EN:ZH:You can use this as a starting point for discussion.": "您可以以此作为讨论的起点。",
  "EN:ZH:Let's say you are working as a product owner or product manager.": "假设您是产品负责人或产品经理。",
  "EN:ZH:You can use this as a draft version for discussions with your team, with your top leaders.": "您可以将其作为与团队和高层领导讨论的草案版本。",
  "EN:ZH:What it does is it provides you a good or a rough starting point to produce your product management": "它的作用是为您提供一个良好的或粗略的起点，来制作您的产品管理",
  "EN:ZH:deliverables.": "可交付成果。",
  "EN:ZH:It's not capable of producing the final versions of the deliverables, but it can be definitely used": "它无法制作交付成果的最终版本，但绝对可以用来",
  "EN:ZH:as a good starting point for a draft version or for a initial version, which can be used for starting": "作为草拟版本或初始版本的良好起点，可用于启动",
  "EN:ZH:discussion.": "讨论。",
  "EN:ZH:That's how it looks like once you have populated all the information from the GTP.": "这就是您从 GTP 中输入所有信息后的结果。",
  "EN:ZH:So if you quickly want to look at it.": "所以，如果你想快点看一下。",
  "EN:ZH:So let's go through it.": "那么，让我们一起来看看吧。",
  "EN:ZH:Our vision for this Amazon style bookstore is we want to Empower the people who are book enthusiastic": "我们对这家亚马逊式书店的愿景是，我们希望为那些热衷于图书的人们提供帮助。",
  "EN:ZH:on a global level with seamless online platform which will provide access to extensive collection of": "通过无缝在线平台，可在全球范围内访问大量的",
  "EN:ZH:diverse and engaging book titles, and it will foster global literary community.": "它还将促进全球文学社区的发展。",
  "EN:ZH:That's the vision which we are trying to achieve from this Amazon style book site, and we'll call this": "这就是我们试图通过亚马逊式图书网站实现的愿景，我们将其称为",
  "EN:ZH:website as book People, and we will be targeting this website to avid readers, students and academicians,": "我们将把这个网站定位为 \"读书人 \"网站，读者群包括热心读者、学生和学者、",
  "EN:ZH:people who want to gift books or people who are interested in book clubs and communities.": "想要赠送书籍的人或对读书俱乐部和社区感兴趣的人。",
  "EN:ZH:And these are the needs which our bookstore will address for the customers we are targeting.": "而这些正是我们的书店要满足的目标客户的需求。",
  "EN:ZH:And what are those needs is convenient and vast book selection, user friendly and personalised browsing": "而这些需求就是便捷、丰富的图书选择、用户友好和个性化的浏览方式",
  "EN:ZH:experience, secure and efficient purchasing process, community engagement and recommendation.": "体验、安全高效的采购流程、社区参与和推荐。",
  "EN:ZH:And then these are the top few features of this product, which is intuitive book recommendation, response": "然后是本产品的几大特点，即直观的图书推荐、响应",
  "EN:ZH:and easy to navigate secure payment gateway social feature for building community.": "易于浏览的安全支付网关 社交功能用于建立社区。",
  "EN:ZH:And these are the goals which we are trying to achieve using this Amazon style book store, which we": "这些都是我们试图通过亚马逊风格的书店来实现的目标。",
  "EN:ZH:want to expand our book offering title to 1 million.": "希望将我们的图书发行量扩大到 100 万册。",
  "EN:ZH:We want to achieve 98% customer satisfaction rate.": "我们希望客户满意度达到 98%。",
  "EN:ZH:We want to reduce the checkout process time by 20%, and we want to build a community of 500 active": "我们希望将结账流程时间缩短 20%，并建立一个由 500 名活跃用户组成的社区。",
  "EN:ZH:users.": "用户。",
  "EN:ZH:So all of this, it's a high quality response produced by ChatGPT.": "因此，所有这些都是 ChatGPT 制作的高质量回复。",
  "EN:ZH:It can definitely be used as a draft version or a good starting point for debating the product vision": "它绝对可以作为一个草案版本或讨论产品愿景的良好起点",
  "EN:ZH:for your particular product, with your team, with your leaders.": "针对您的特定产品、您的团队、您的领导。",
  "EN:ZH:But always keep in mind that whenever you're producing deliverables or using ChatGPT, please review": "但请始终牢记，在制作交付物或使用 ChatGPT 时，请查看",
  "EN:ZH:the response which is generated by ChatGPT and customize and contextualize it based on your own need.": "ChatGPT 生成的响应，并根据自己的需要对其进行定制和上下文化。",
  "EN:ZH:In this particular scenario, ChatGPT has generated a very high quality response which did not need": "在这种特殊情况下，ChatGPT 生成了非常高质量的回复，不需要",
  "EN:ZH:much changing, but in your scenario it might need changing.": "但在你的情况下，可能需要更改。",
  "EN:ZH:So please keep all these things in mind while using.": "因此，请在使用时牢记这些事项。",
  "EN:ZH:Product vision board.": "产品愿景板。",
  "EN:ZH:If you are aspiring to be a Product manager product Director, this will be a key part of your job.": "如果您有志成为产品经理、产品总监，这将是您工作的关键部分。",
  "EN:ZH:This will be one of the key deliverables will be like your bread and butter.": "这将是关键的交付成果之一，就像你的面包和黄油一样。",
  "EN:ZH:This is something which all who are on this pathway should be hands on.": "这是所有在这条道路上前进的人都应该亲身经历的事情。",
  "EN:ZH:That's the key idea about this product vision board.": "这就是这个产品愿景板的关键理念。",
  "EN:ZH:It is created by a management consultant known as Roman Pichler and have five sections.": "它由一位名叫 Roman Pichler 的管理顾问创建，共有五个部分。",
  "EN:ZH:First one is vision.": "首先是愿景。",
  "EN:ZH:Then you have target group needs, products and business goals.": "然后是目标群体的需求、产品和业务目标。",
  "EN:ZH:What is the purpose of vision?": "愿景的目的是什么？",
  "EN:ZH:The product vision should not be a plan to show how to reach your goal.": "产品愿景不应该是一个展示如何实现目标的计划。",
  "EN:ZH:Instead, you should be actually writing where you want the product to be.": "相反，你应该真正写出你希望产品达到的效果。",
  "EN:ZH:The product strategy is pathway towards your goal, which is the vision.": "产品战略是实现目标（即愿景）的途径。",
  "EN:ZH:This enables you to change the strategy while grounded in your vision.": "这样，您就可以根据自己的愿景改变战略。",
  "EN:ZH:And what is the other purpose of having the vision is so that you have a common understanding of the": "制定愿景的另一个目的是为了让大家对 \"我们的未来 \"有一个共同的理解。",
  "EN:ZH:vision of product across the team.": "整个团队的产品愿景。",
  "EN:ZH:Let's say you are building a very complex product, like autonomous car like Tesla, which requires": "比方说，你正在制造一种非常复杂的产品，比如像特斯拉这样的自动驾驶汽车，它需要",
  "EN:ZH:hundreds of people working together on it, and each person will have their own understanding vision": "成百上千的人在一起工作，每个人都会有自己的理解愿景",
  "EN:ZH:about the product.": "关于产品",
  "EN:ZH:If you don't have a single product vision which is shared across the team, everyone will keep going": "如果你没有一个全团队共享的产品愿景，那么每个人都会继续走下去",
  "EN:ZH:in different direction.": "方向不同。",
  "EN:ZH:And to bring everyone on a single boat, on a single train, on a single thread of thought.": "让大家同舟共济、同心协力、同舟共济。",
  "EN:ZH:What you need is a common vision which is shared across the entire team.": "你需要的是整个团队的共同愿景。",
  "EN:ZH:And that's why you need a product vision.": "这就是为什么你需要一个产品愿景。",
  "EN:ZH:What each of these sections states vision states your overarching goal.": "这些部分分别阐述了愿景和总体目标。",
  "EN:ZH:Which vision is usually a long term goal which is overarching for a product?": "哪种愿景通常是产品的长期总体目标？",
  "EN:ZH:Usually it is described for the next 5 to 10 years.": "通常是未来 5 到 10 年。",
  "EN:ZH:This is the ultimate reason why you are creating your product.": "这就是您创造产品的最终原因。",
  "EN:ZH:This is the positive change you want to bring to your customers, to your users, or to the world.": "这就是您希望为客户、用户或世界带来的积极变化。",
  "EN:ZH:If you are making a product like that.": "如果你要制作这样的产品。",
  "EN:ZH:For example, Bill gates started this polio vaccination program, which kind of almost eliminated polio": "例如，比尔-盖茨发起了脊髓灰质炎疫苗接种计划，几乎消灭了脊髓灰质炎",
  "EN:ZH:from the entire world.": "来自全世界。",
  "EN:ZH:That is his goal for his polio program.": "这就是他小儿麻痹症计划的目标。",
  "EN:ZH:And you have to make your vision inspiring for your team member or for your customers.": "你必须让你的愿景激励你的团队成员或客户。",
  "EN:ZH:And you can make it as a brief statement.": "你可以做一个简短的陈述。",
  "EN:ZH:Or it can be in a form of slogan.": "也可以是口号的形式。",
  "EN:ZH:That's the high level idea of vision.": "这就是愿景的高级理念。",
  "EN:ZH:Then what are the target groups?": "那么目标群体是什么呢？",
  "EN:ZH:Target groups, which is the second part of this product vision board.": "目标群体，这是产品愿景板的第二部分。",
  "EN:ZH:What it does is it describes the markets or a market segment you want to address.": "它所做的就是描述你想要面向的市场或细分市场。",
  "EN:ZH:So for to tell you the customer segments or market segment you want to address using your product.": "因此，我们要告诉你，你想用自己的产品来满足哪些客户群或细分市场的需求。",
  "EN:ZH:And when you are describing these market segments or target groups, you have to choose a homogeneous": "在描述这些细分市场或目标群体时，您必须选择一个同质的",
  "EN:ZH:cut and clear target group.": "明确的目标群体。",
  "EN:ZH:Homogeneous means when you are selecting one market segment or customer segment, it should be almost": "同质是指当你选择一个细分市场或客户群时，该细分市场或客户群应几乎",
  "EN:ZH:same across this entire segment.": "整个段落都一样。",
  "EN:ZH:It should be clear cut target group of people.": "应明确目标人群。",
  "EN:ZH:When you are creating a brand new product, then at that time each product segment should be having": "当您创建一个全新的产品时，每个产品细分市场都应具有",
  "EN:ZH:very clear boundaries.": "非常明确的界限。",
  "EN:ZH:Then next section is needs.": "然后是需求。",
  "EN:ZH:What does needs capture?": "什么是需求？",
  "EN:ZH:So needs?": "需要什么？",
  "EN:ZH:Describe the product's value proposition.": "描述产品的价值主张。",
  "EN:ZH:The main problem you are trying to address or the primary benefit your product is going to offer.": "您要解决的主要问题或您的产品要提供的主要益处。",
  "EN:ZH:This section should make clear why people will want your product, or why they will pay for your product,": "这一部分应明确说明人们为什么需要你的产品，或为什么要为你的产品付费、",
  "EN:ZH:or the what problem you are trying to solve.": "或您想解决什么问题。",
  "EN:ZH:Of the customer or what is their needs.": "客户的需求是什么？",
  "EN:ZH:That's the high level idea of this need section.": "这就是本需求部分的高层次理念。",
  "EN:ZH:Fourth section is product.": "第四部分是产品。",
  "EN:ZH:What product does product summarizes the 3 to 5 features that make your product stand out and that are": "产品有哪些功能 产品概括了使您的产品脱颖而出的 3 至 5 个功能，它们是",
  "EN:ZH:critical for its success?": "对其成功至关重要？",
  "EN:ZH:You don't have to create an entire like.": "您不必创建一个完整的 \"喜欢\"。",
  "EN:ZH:It should not have hundreds of features listed here.": "它不应该具备此处列出的数百种功能。",
  "EN:ZH:3 to 5 key features which are the key features of your product which are critical for success of your": "3 至 5 个关键特征，这些特征是产品的关键特征，对产品的成功至关重要。",
  "EN:ZH:product?": "产品？",
  "EN:ZH:Those should be described in this section.": "应在本节中加以说明。",
  "EN:ZH:The next part is Business core business Goal section explains why it is worthwhile for your company": "下一部分是 \"企业核心业务目标 \"部分，说明为什么这对贵公司有价值",
  "EN:ZH:to invest in this product.": "投资该产品。",
  "EN:ZH:It states the desired benefits.": "它说明了预期的效益。",
  "EN:ZH:For instance, you want to increase the revenue of your company.": "例如，您想增加公司的收入。",
  "EN:ZH:You want to penetrate a new market.": "您想打入一个新市场。",
  "EN:ZH:You want to reduce cost.": "你想降低成本。",
  "EN:ZH:Reason is about what positive change the product will bring in life for customers in life of society.": "原因在于产品会给客户的生活和社会生活带来哪些积极变化。",
  "EN:ZH:Vision is what advantage or benefit the product will bring in life of customers.": "愿景是指产品将为客户的生活带来哪些优势或好处。",
  "EN:ZH:That is vision.": "这就是愿景。",
  "EN:ZH:But business goal is.": "但业务目标是",
  "EN:ZH:Let's say you are Apple.": "假设你是苹果公司。",
  "EN:ZH:You are trying to introduce iPhone.": "您正在尝试引入 iPhone。",
  "EN:ZH:What positive change it brings in life of customers or users who are going to use iPhone.": "它给即将使用 iPhone 的客户或用户的生活带来了多么积极的变化。",
  "EN:ZH:But what you will achieve as Apple.": "但作为苹果公司，你将取得怎样的成就？",
  "EN:ZH:For yourself.": "为了你自己",
  "EN:ZH:What Apple will achieve by introducing iPhone is it will be additional revenue stream for them.": "苹果公司推出 iPhone 的目的是增加收入来源。",
  "EN:ZH:It will create a great brand for Apple.": "它将为苹果创造一个伟大的品牌。",
  "EN:ZH:That is the business goal Apple is trying to achieve.": "这就是苹果公司要实现的商业目标。",
  "EN:ZH:It will create almost a monopoly for them in premium mobile segment.": "这将使它们几乎垄断高端手机市场。",
  "EN:ZH:This is what they are trying to achieve through Apple in form of business goals.": "这就是他们试图通过苹果公司实现的商业目标。",
  "EN:ZH:Business goal is what Apple is going to achieve from introducing this product.": "商业目标是苹果公司推出这款产品要达到的目的。",
  "EN:ZH:Vision is what the customers of iPhone, which is the product, are going to achieve in next five years.": "愿景是 iPhone（即产品）的客户在未来五年内要实现的目标。",
  "EN:ZH:What is the benefit they are going to get in next five years?": "未来五年，他们会得到什么好处？",
  "EN:ZH:What is the change in society that will be achieved?": "将给社会带来什么变化？",
  "EN:ZH:What is business model canvas.": "什么是商业模式画布？",
  "EN:ZH:So business model canvas is a strategic management tool to quickly and easily define and communicate": "因此，\"商业模式画布 \"是一种战略管理工具，可用于快速、轻松地定义和交流",
  "EN:ZH:a business idea or concept.": "商业理念或概念。",
  "EN:ZH:It is a one page document that works through the fundamental elements of the business or product, structuring": "这是一份一页纸的文件，其中阐述了企业或产品的基本要素，结构如下",
  "EN:ZH:an idea in a coherent way.": "一个连贯的想法。",
  "EN:ZH:So if you look at the management consultants who are used to, you know, do the business model before": "所以，如果你看看那些习惯于先做商业模式再做管理的咨询师们",
  "EN:ZH:business model came into picture, the same kind of details, uh, will be written in it ten to 15 or": "商业模式出现后，同样的细节将被写入其中 10 到 15 年，甚至更长的时间。",
  "EN:ZH:20 page document, and it will take a lot of time to go through that document.": "该文件长达 20 页，需要花很多时间才能看完。",
  "EN:ZH:And if you want to do a presentation, it used to become very complex to understand what's the actual": "如果你想做一个演示，要了解什么是真正的 \"演示 \"就会变得非常复杂。",
  "EN:ZH:business model and what this business model canvas does is it summarizes all the key elements for success": "商业模式画布的作用是总结成功的所有关键要素",
  "EN:ZH:of of a business owner or a single page.": "的企业主或单一页面。",
  "EN:ZH:And the creator of this business model canvas is Alex Osterwalder.": "这个商业模式画布的创造者就是亚历克斯-奥斯特瓦德。",
  "EN:ZH:Uh, and it has nine, uh, nine sections.": "它有九个部分。",
  "EN:ZH:For example, this key partners are key activities.": "例如，关键合作伙伴就是关键活动。",
  "EN:ZH:So each of this is a section.": "因此，这每一部分都是一个章节。",
  "EN:ZH:And uh, let's go through these sections one by one.": "让我们逐一介绍这些部分。",
  "EN:ZH:The first section is the customer segments.": "第一部分是客户细分。",
  "EN:ZH:Uh, this section I'm going to take from the perspective of product, like you are writing this business": "呃，这一部分我将从产品的角度出发，就像你在撰写这篇商业报告一样",
  "EN:ZH:model canvas for a product.": "产品的模型画布。",
  "EN:ZH:So from that perspective I'm going to describe this.": "因此，我要从这个角度来描述一下。",
  "EN:ZH:So in this customer segment uh section you will capture who are your customers, who are they, what": "因此，在 \"客户细分 \"部分，您将捕捉谁是您的客户、他们是谁以及他们的需求是什么。",
  "EN:ZH:they think, what they, uh what they see, what how they feel and what they actually do.": "他们在想什么，他们看到了什么，他们有什么感觉，他们实际做了什么。",
  "EN:ZH:So that kind of stuff, uh, you will, uh, capture here in, in customer segments.": "因此，您将在客户细分中捕捉到这些信息。",
  "EN:ZH:So these this is helping you identify the target, uh, customers or target customer segments you are": "因此，这可以帮助您确定目标客户或目标客户群。",
  "EN:ZH:going to target as a product.": "产品的目标。",
  "EN:ZH:Uh, then the next one is value proposition.": "下一个是价值主张。",
  "EN:ZH:So value proposition is the second section.": "因此，价值主张是第二部分。",
  "EN:ZH:And what you capture here is what's compelling about your product or proposition.": "在这里，你所捕捉到的就是你的产品或主张中令人信服的地方。",
  "EN:ZH:Why should the customer buy uh or use your product.": "客户为什么要购买或使用你的产品？",
  "EN:ZH:What is the value you are bringing to the life of your customer?": "你能为客户的生活带来什么价值？",
  "EN:ZH:That kind of stuff you are going to capture in value proposition section.": "您要在价值主张部分捕捉这些内容。",
  "EN:ZH:The next section is the channel.": "下一部分是通道。",
  "EN:ZH:So in the channel section you are going to capture how these propositions are promoted sold or delivered.": "因此，在渠道部分，你要抓住这些主张是如何推广、销售或传递的。",
  "EN:ZH:Uh and why and what is it working or not.": "呃，为什么？",
  "EN:ZH:So what are the various channels, uh, which you use for promoting means advertising, uh, your products,": "那么，你们是通过哪些渠道来宣传你们的产品的呢？",
  "EN:ZH:selling your products and delivered.": "销售您的产品并交付。",
  "EN:ZH:Remember that all of these channels can be different for a single product.": "请记住，对于同一种产品，所有这些渠道都可能是不同的。",
  "EN:ZH:You might use one channel for promoting another channel for actually selling it, and then you use another": "您可以使用一种渠道进行宣传，另一种渠道进行实际销售，然后再使用另一种渠道",
  "EN:ZH:channel for delivering it.": "提供渠道。",
  "EN:ZH:So you can have different channel for each of these activity.": "因此，您可以为每项活动设置不同的渠道。",
  "EN:ZH:Or you can have same channel as well based on the product you are designing.": "或者，您也可以根据自己设计的产品采用相同的渠道。",
  "EN:ZH:Then uh, the next section, uh, in this model is the customer relationship.": "这个模型的下一个部分是客户关系。",
  "EN:ZH:In this section you capture how do you interact with your customer throughout their customer journey": "在本节中，您将了解在整个客户旅程中如何与客户互动",
  "EN:ZH:so that that kind of information is captured here.": "以便在此获取此类信息。",
  "EN:ZH:Then the next section is, uh, the revenue streams.": "下一部分是收入流。",
  "EN:ZH:Revenue stream is how does the business earn revenue from the value proposition or the product which": "收入流是指企业如何从价值主张或产品中获得收入，其中",
  "EN:ZH:you are selling?": "你要卖什么？",
  "EN:ZH:So how do you actually, uh, make money, uh, using this product?": "那么，你究竟是如何利用这个产品赚钱的呢？",
  "EN:ZH:What are those value streams then?": "那么，这些价值流是什么？",
  "EN:ZH:Uh, the next one is key activities.": "下一个是关键活动。",
  "EN:ZH:So key activities is what unique, uh, strategic things does the business do to deliver this proposition.": "因此，关键活动是企业为实现这一主张所做的独特战略工作。",
  "EN:ZH:So what is unique, uh, activities within your business model?": "那么，你们的商业模式中有哪些独特的活动？",
  "EN:ZH:Uh, those things you capture in key activities, then, uh, key resources.": "呃，你在关键活动中捕捉到的那些东西，然后，呃，关键资源。",
  "EN:ZH:Key resources are what unique strategic assets must the business have to compete in marketplace with": "关键资源是指企业必须拥有哪些独特的战略资产，才能在市场竞争中与其他企业竞争。",
  "EN:ZH:your competitors for this particular product.": "该产品的竞争对手。",
  "EN:ZH:So those kind of information are captured in key resources then key partnerships.": "因此，关键资源和关键合作伙伴关系中都包含了这些信息。",
  "EN:ZH:So uh, key partnership is of what can the company not do.": "因此，关键的伙伴关系是公司不能做什么。",
  "EN:ZH:So it can focus on key activities.": "因此，它可以把重点放在关键活动上。",
  "EN:ZH:So that are uh, what are the things which you can outsource or can be done by other partners for those": "那么，有哪些工作可以外包或由其他合作伙伴来完成呢？",
  "EN:ZH:activities?": "活动？",
  "EN:ZH:You, uh, find out key partners, and you capture those key partners here.": "你，呃，找出关键合作伙伴，然后在这里捕捉这些关键合作伙伴。",
  "EN:ZH:So as a company, you will not be interested in doing everything which makes up your products or services.": "因此，作为一家公司，你不会有兴趣做构成产品或服务的所有事情。",
  "EN:ZH:You might be interested in focusing only on the things which are your strengths, where you can make": "你可能只想专注于你的强项，在这些方面，你可以做出",
  "EN:ZH:more money, where you need less resources.": "更多的钱，而你需要更少的资源。",
  "EN:ZH:So based on that, all these factors, you take the decisions.": "因此，基于所有这些因素，你做出了决定。",
  "EN:ZH:What will be your key partners for this product?": "该产品的主要合作伙伴是哪些？",
  "EN:ZH:Because you don't want to do everything.": "因为你不想什么都做。",
  "EN:ZH:You will be interested in outsourcing or partnering on things which are strength of other people, not": "您会对外包或合作感兴趣，因为这是别人的强项，而不是您的强项。",
  "EN:ZH:your strength.": "你的力量",
  "EN:ZH:And the next one is cost structure.": "其次是成本结构。",
  "EN:ZH:So in cost structure section you capture what are the major cost drivers and how they are linked to": "因此，在成本结构部分，您需要了解哪些是主要的成本动因，以及它们与以下方面的联系",
  "EN:ZH:revenue.": "收入。",
  "EN:ZH:So what are the things which drive your business from cost angle, those things you capture here and": "那么，从成本的角度来看，是什么推动了您的业务发展？",
  "EN:ZH:how those costs are helping in delivering the revenue.": "这些成本如何帮助实现收入。",
  "EN:ZH:So based on that, you capture the cost structures here.": "因此，在此基础上，你可以捕捉到这里的成本结构。",
  "EN:ZH:Welcome to our next session.": "欢迎来到下一环节。",
  "EN:ZH:In this section we will generate a business model canvas using ChatGPT.": "在本节中，我们将使用 ChatGPT 生成商业模式画布。",
  "EN:ZH:Within this section, we are going to have three subsections or three steps which we are going to do": "在本节中，我们将有三个小节或三个步骤，我们要做的是",
  "EN:ZH:which are.": "其中包括",
  "EN:ZH:The first one is we'll write a ChatGPT prompt for generating a business model canvas.": "首先，我们将编写一个用于生成商业模式画布的 ChatGPT 提示。",
  "EN:ZH:For this, we'll use the standard prompting template which is recommended by me.": "为此，我们将使用我推荐的标准提示模板。",
  "EN:ZH:And then we'll generate a sample business model canvas using ChatGPT.": "然后，我们将使用 ChatGPT 生成一个商业模式画布样本。",
  "EN:ZH:So whatever prompt we generated in step one, we'll use that ChatGPT prompt for Business Model Canvas": "因此，无论我们在第一步中生成了什么提示，我们都将在 \"商业模式画布 \"中使用该 ChatGPT 提示",
  "EN:ZH:to generate a business model canvas using ChatGPT.": "使用 ChatGPT 生成商业模式画布。",
  "EN:ZH:That's what we are going to do in this step two.": "这就是我们要做的第二步。",
  "EN:ZH:And then in step three, what we are going to do is we will review, uh, the Business Model canvas,": "然后在第三步，我们要做的是回顾 \"商业模式画布\"、",
  "EN:ZH:which is generated by ChatGPT against, uh, standard guidelines provided by, uh, the author of Business": "它是由 ChatGPT 根据《商业版》作者提供的标准指南生成的。",
  "EN:ZH:Model Canvas.": "帆布模型。",
  "EN:ZH:And wherever required, we will refine the business model canvas based on the guidelines provided by": "如有需要，我们将根据以下机构提供的指导原则完善商业模式画布",
  "EN:ZH:the author.": "作者",
  "EN:ZH:So these are the three steps we which we are going to follow in this section.": "这就是本节要介绍的三个步骤。",
  "EN:ZH:So let's do this.": "那就这么办吧。",
  "EN:ZH:Steps one by one.": "一步一步来",
  "EN:ZH:So uh, the first step in this step, uh, what we will do is we'll write a ChatGPT prompt for Business": "因此，这一步的第一步，我们要做的就是为 Business",
  "EN:ZH:model canvas.": "帆布模型。",
  "EN:ZH:So, uh, this is the general prompt structure, which I have, uh, discussed in a separate section": "这就是一般的提示结构，我将在另一节中讨论它",
  "EN:ZH:earlier.": "早些时候。",
  "EN:ZH:So just a reminder, what the structure does is in the first step, we'll tell the role or actor name.": "所以提醒一下，这个结构的第一步是告诉角色或演员的名字。",
  "EN:ZH:Then in the next step we we capture the description of the product or the project.": "然后，在下一步中，我们将捕捉产品或项目的描述。",
  "EN:ZH:And then in the next step we capture the names of sections for the framework which we are going to produce.": "然后在下一步中，我们为将要制作的框架获取各部分的名称。",
  "EN:ZH:And then we write, uh, the name of framework.": "然后写上框架的名称。",
  "EN:ZH:Then we write the name of author of the framework.": "然后，我们写下框架作者的姓名。",
  "EN:ZH:Then we describe the product, and in the last two steps we provide any additional constraints or quality": "然后，我们对产品进行描述，并在最后两步中提供任何附加限制或质量要求。",
  "EN:ZH:parameters which GTP should use for generating this framework.": "参数，GTP 应使用这些参数来生成该框架。",
  "EN:ZH:So this is the template structure we are going to follow.": "这就是我们要遵循的模板结构。",
  "EN:ZH:Let's see the example business model corresponding to this.": "让我们来看看与此相对应的商业模式示例。",
  "EN:ZH:So in this case what we are doing is we are following the template for generating a business model canvas": "因此，在这种情况下，我们要做的就是按照模板生成商业模式画布",
  "EN:ZH:for Amazon style website.": "亚马逊风格的网站。",
  "EN:ZH:So so first step is assume you are a product manager.": "所以，第一步就是假设你是一名产品经理。",
  "EN:ZH:So instead of role uh, we are giving the role as product manager.": "因此，我们赋予的角色不是产品经理，而是产品经理。",
  "EN:ZH:Because usually the business model canvas is authored, uh, for a particular product by the product": "因为通常情况下，商业模式画布是由产品经理为某一特定产品撰写的。",
  "EN:ZH:manager.": "经理",
  "EN:ZH:Or sometimes it is authored by product owner, product director.": "有时也由产品负责人、产品总监撰写。",
  "EN:ZH:So these kind of people but, uh, product manager is, uh, more suitable for this kind of role.": "因此，这类人更适合担任产品经理。",
  "EN:ZH:That's why we are using the product manager role.": "这就是我们使用产品经理角色的原因。",
  "EN:ZH:Then the in the next step we are describing about the product for which we are generating this business": "下一步，我们将介绍我们为之创造业务的产品",
  "EN:ZH:So in this case the product is Amazon style book selling website.": "因此，在这种情况下，产品就是亚马逊式的图书销售网站。",
  "EN:ZH:Then in the next step, we are writing the names of the sections which you are generating for this business": "然后，在下一步中，我们将写下您为这项业务生成的各部分名称",
  "EN:ZH:So I have written the nine section names of Business Model Canvas which are customer segment value proposition": "因此，我写下了 \"商业模式画布 \"的九个部分名称，即客户群价值主张",
  "EN:ZH:channels, Customer relationship, revenue stream, key resources, key activities, key partnership": "渠道、客户关系、收入流、关键资源、关键活动、关键伙伴关系",
  "EN:ZH:and cost structure.": "和成本结构。",
  "EN:ZH:And then in the next step, I have written the name of the framework itself.": "下一步，我写下了框架本身的名称。",
  "EN:ZH:In this example, the framework name is Business Model Canvas.": "在本例中，框架名称为 \"业务模型画布\"。",
  "EN:ZH:And in next step I have named the author of this framework, which is Alex Osterwalder.": "下一步，我将介绍这个框架的作者，他就是亚历克斯-奥斯特瓦德。",
  "EN:ZH:Then here what I have captured is a description of the product which we are building.": "在这里，我所捕捉到的是对我们正在制造的产品的描述。",
  "EN:ZH:This is same as the step number two.": "这与第二步相同。",
  "EN:ZH:So this is exactly the copy of the two.": "因此，这正是两者的复制品。",
  "EN:ZH:And then, uh, in the last step, what I have done is I have written an additional rule which I want": "然后，在最后一步，我又写了一条规则，我希望",
  "EN:ZH:to follow, which is all the sections, for example, the customer segment proposition.": "例如，客户细分主张。",
  "EN:ZH:All these sections should be, uh, written in points.": "所有这些部分都应该用 \"点 \"来写。",
  "EN:ZH:So I want to produce, uh, all these sections, um, in point format.": "所以，我想把所有这些部分，嗯，以点的形式制作出来。",
  "EN:ZH:So, uh, just a quick summary of this prompt.": "那么，呃，就简单总结一下这个提示吧。",
  "EN:ZH:So, uh, here what we are doing is we are asking ChatGPT to assume the role of a product manager for": "所以，我们现在要做的是，请 ChatGPT 为我们承担起产品经理的角色。",
  "EN:ZH:a Amazon style book selling website.": "亚马逊式图书销售网站。",
  "EN:ZH:And we want ChatGPT to generate nine sections of, uh, the business model canvas, which are customer": "我们希望 ChatGPT 生成商业模式画布的九个部分，分别是客户",
  "EN:ZH:segments, value proposition channels, customer relationship, revenue stream, key resources, key": "细分市场、价值主张渠道、客户关系、收入流、关键资源、关键",
  "EN:ZH:activities, key partnership and co structure.": "活动、主要伙伴关系和共同结构。",
  "EN:ZH:And these sections are for the Business Model Canvas and Business Model.": "而这些部分是针对 \"商业模式画布 \"和 \"商业模式 \"的。",
  "EN:ZH:Canvas is authored by Alex Osterwalder and this business model canvas we want to generate for Amazon": "Canvas 是由 Alex Osterwalder 撰写的，我们希望为亚马逊生成这一商业模式画布",
  "EN:ZH:style book selling website.": "式图书销售网站。",
  "EN:ZH:And we want all the sections to be written in points.": "我们希望所有章节都用点来写。",
  "EN:ZH:So that's a high level summary of this, this prompt.": "以上就是对这一提示的高度概括。",
  "EN:ZH:Let's move on to the next step.": "让我们进入下一步。",
  "EN:ZH:So this is a sample template for Business Model Canvas.": "这就是 \"商业模式画布 \"的样本模板。",
  "EN:ZH:And this is provided by Alex Osterwalder.": "这是由亚历克斯-奥斯特瓦德提供的。",
  "EN:ZH:And it has these nine sections key partner Key activities Key resources and these other sections.": "其中包括九个部分：主要合作伙伴、主要活动、主要资源和其他部分。",
  "EN:ZH:So this is the template.": "这就是模板。",
  "EN:ZH:Let's move to the next one.": "让我们进入下一个环节。",
  "EN:ZH:So in this next step what we are going to do is we will use uh the ChatGPT prompt which is written by": "在下一步中，我们将使用 ChatGPT 提示，它是由",
  "EN:ZH:us uh, and uh, basically we'll run it in ChatGPT and generate the response from ChatGPT or for this": "基本上，我们将在 ChatGPT 中运行它，并从 ChatGPT 生成响应。",
  "EN:ZH:business model, let's do that.": "商业模式，那就这样做吧。",
  "EN:ZH:So I'm just going to copy this prompt from here.": "所以，我就从这里复制这个提示。",
  "EN:ZH:Now I'm going to go to, uh, an active session of, uh, GTP.": "现在我要进入 GTP 的活动会话。",
  "EN:ZH:So here I have active session of GTP.": "因此，我这里有 GTP 的活动会话。",
  "EN:ZH:In my case, I'm going to reuse the existing thread which we have used before.": "就我而言，我将重复使用我们以前使用过的现有线程。",
  "EN:ZH:The reason for that is because, uh, in the existing thread, I have already generated a product vision": "原因是，呃，在现有的主题中，我已经生成了一个产品愿景",
  "EN:ZH:board for the same product.": "同一产品的电路板。",
  "EN:ZH:If you are producing, uh, uh, product management deliverables from the same product, I'll suggest": "如果您正在生产，呃，呃，来自同一产品的产品管理可交付成果，我建议您",
  "EN:ZH:you to continue using the same thread rather than creating a new chat.": "您可以继续使用同一主题，而不是创建新的聊天。",
  "EN:ZH:But if you are doing a deliverable for a different product, then, uh, use a new chat window.": "但如果您要为不同的产品提供服务，那就使用新的聊天窗口。",
  "EN:ZH:So let's do that.": "那就这么办吧。",
  "EN:ZH:So I'm going to paste the chat GTP prompt, which I have generated before.": "因此，我将粘贴之前生成的聊天 GTP 提示。",
  "EN:ZH:I will just fix some spelling errors or grammar in it.": "我只需修正其中的一些拼写错误或语法错误。",
  "EN:ZH:And uh, I'm going to submit uh, this uh, through send a message to ChatGPT and we'll see what is": "我将向 ChatGPT 发送一条信息，看看会有什么结果。",
  "EN:ZH:the response that GDP is going to produce.": "GDP 将产生的反应。",
  "EN:ZH:So ChatGPT has now produced a response.": "因此，ChatGPT 现在做出了回应。",
  "EN:ZH:If you look at the response quickly, uh, what it is doing is to produce the, the customer segments,": "如果你能快速做出反应，那么它所做的就是产生客户群、",
  "EN:ZH:uh, for example, avid readers, uh, casual readers, scholars and academicians, gift shoppers and": "例如，热心读者、休闲读者、学者和学术界人士、礼品购物者和",
  "EN:ZH:then also, uh, against these headings, what uh, ChatGPT has done is, is given A11 liner description": "然后，针对这些标题，ChatGPT 所做的是，给出 A11 内衬说明",
  "EN:ZH:of it, for example, avid Reader, it has given further description, uh, of avid Reader, which are": "例如，\"avid Reader\"，它对 \"avid Reader \"做了进一步说明，包括",
  "EN:ZH:individuals who read regularly and are looking for a diverse range of books.": "经常阅读并寻求各种书籍的个人。",
  "EN:ZH:Casual readers are people who read occasionally and are open to, uh, to exploring new titles.": "休闲读者是指偶尔阅读、愿意探索新书的人。",
  "EN:ZH:So it has given one one liner against each of the output.": "因此，它对每项产出都提出了一条意见。",
  "EN:ZH:Again, let's have a quick look at value proposition.": "让我们再次快速了解一下价值主张。",
  "EN:ZH:So it is saying extensive book catalog.": "因此，它的图书目录非常丰富。",
  "EN:ZH:And then it's giving a description of it offering a vast and diverse section of books across journeys.": "然后，它又介绍说，它提供了大量不同旅程的书籍。",
  "EN:ZH:So I was only expecting ChatGPT to produce this headlines, not the description, but HTTP have given": "因此，我只期望 ChatGPT 生成这个标题，而不是描述，但 HTTP 已经给出了",
  "EN:ZH:me both headlines as well as description for each of the section.": "我既要写标题，也要写每个部分的说明。",
  "EN:ZH:So what I'm going to do now is I will quickly port the response with ChatGPT has produced for this business": "因此，我现在要做的是，我将快速移植 ChatGPT 为这项业务产生的反应",
  "EN:ZH:model canvas in our PowerPoint.": "我们的 PowerPoint 中的模型画布。",
  "EN:ZH:And then what we'll do is we will have a review it against the guidelines provided by the author of": "然后，我们将根据《世界人权宣言》作者提供的指导方针进行审查。",
  "EN:ZH:Business Model Canvas.": "商业模式画布",
  "EN:ZH:Obviously, uh, one key refinement I'm going to do here is when I'm producing, uh, adding it to my": "显然，我要做的一个关键改进是，在制作时，将其添加到我的",
  "EN:ZH:template, I will not add the descriptions which are produced by, uh, ChatGPT GDP.": "模板，我不会添加由 ChatGPT GDP 制作的说明。",
  "EN:ZH:For each of these headlines, I will only keep the headlines.": "对于每个标题，我只保留标题。",
  "EN:ZH:For example, in customer segment, I will only keep avid readers, casual readers, scholarly and academicians": "例如，在客户群中，我将只保留狂热读者、休闲读者、学者和学术界人士",
  "EN:ZH:and gift shoppers.": "和礼品购物者。",
  "EN:ZH:I will not add the description of each headline to the template.": "我不会在模板中添加每个标题的说明。",
  "EN:ZH:I'll keep them as in the reading notes so that or reference notes, so that we know what of what each": "我将把它们保留在阅读笔记中，以便或参考笔记中，让我们知道每一个",
  "EN:ZH:of these section means, but I will not add it to the actual template.": "的意思，但我不会将其添加到实际模板中。",
  "EN:ZH:So let let me do that.": "那就让我来吧。",
  "EN:ZH:Uh, quickly uh, offline.": "呃，很快，呃，离线。",
  "EN:ZH:And let's review the results, which are uh, produced by ChatGPT.": "让我们回顾一下 ChatGPT 得出的结果。",
  "EN:ZH:In light of the guidelines provided by the author of, uh, Business Model Canvas.": "根据《商业模式画布》作者提供的指南。",
  "EN:ZH:So what I've done is I've just ported the content from ChatGPT to the template of Business Model Canvas,": "因此，我只是将 ChatGPT 中的内容移植到了 Business Model Canvas 的模板中、",
  "EN:ZH:and this template has the guidance as well.": "这个模板也有指导意义。",
  "EN:ZH:Each of these call outs, these are the guidance provided by the author of Business Model Canvas.": "这些提示都是《商业模式画布》作者提供的指导。",
  "EN:ZH:And this.": "还有这个",
  "EN:ZH:The content in red font is the content which is produced by ChatGPT.": "红色字体的内容由 ChatGPT 制作。",
  "EN:ZH:Answer to each section.": "每个部分的答案。",
  "EN:ZH:So let's review this.": "让我们回顾一下。",
  "EN:ZH:Are each of this section in light of the guidelines?": "本节的每一部分是否都符合指导原则？",
  "EN:ZH:So key partners GDP it has produced for key partners publishers.": "因此，关键合作伙伴 GDP 为关键合作伙伴出版商提供了产品。",
  "EN:ZH:So publishers are the people or the companies who publish books are authors are the people who actually": "因此，出版商是指出版书籍的人或公司，而作者则是指真正",
  "EN:ZH:write books and are payment processor are for example, the credit card payment processor, debit card": "",
  "EN:ZH:payment processor, or banks.": "支付处理商或银行。",
  "EN:ZH:All those kind of companies and affiliates, uh, tend to be, uh, used for, uh, say, marketing": "所有这些公司和附属机构，呃，往往用于，呃，比如说，营销",
  "EN:ZH:books.": "书籍",
  "EN:ZH:So all those, uh, these four are, are, uh, key partners.": "因此，所有这些，呃，这四个都是，呃，关键的合作伙伴。",
  "EN:ZH:So without reading the guidelines, they seem fine to me.": "因此，在没有阅读指导原则的情况下，我觉得它们似乎没有问题。",
  "EN:ZH:Let's quickly look at the guideline as well.": "让我们也来快速了解一下该准则。",
  "EN:ZH:Identify external organizations, suppliers or partners that help the company in various aspects of": "确定在以下各方面为公司提供帮助的外部组织、供应商或合作伙伴",
  "EN:ZH:its business operation.": "其业务运营。",
  "EN:ZH:So here we are identifying the external organizations or suppliers or partners who will help the company,": "因此，在这里我们要确定哪些外部组织、供应商或合作伙伴会帮助公司、",
  "EN:ZH:uh, in in selling books.": "卖书",
  "EN:ZH:And if you read the guidelines and look at the output generated by ChatGPT, the output, uh, seems,": "如果你阅读了指南并查看了 ChatGPT 生成的输出结果，那么输出结果，呃，似乎、",
  "EN:ZH:uh, all right to me in light of the guidance provided by the author for this section.": "嗯，根据作者为本节提供的指导，我觉得没问题。",
  "EN:ZH:Let's look at the next section, which is key activities, uh, section.": "让我们看看下一部分，也就是关键活动部分。",
  "EN:ZH:So in key activities, ChatGPT have generated curating, book catalog, algorithm refinement, marketing": "因此，在关键活动中，ChatGPT 产生了策划、图书目录、算法完善、营销",
  "EN:ZH:campaign and user engagement.": "活动和用户参与。",
  "EN:ZH:So, uh, just, uh, reading through these activities or results seems fine to me because curating": "所以，呃，只是阅读这些活动或结果，对我来说似乎没什么问题，因为策划",
  "EN:ZH:books is creating the catalog, talking to these, uh, publishers, authors and getting their catalogue,": "书籍是创建目录，与这些出版商、作者交谈，获取他们的目录、",
  "EN:ZH:which are relevant to the website.": "与网站相关。",
  "EN:ZH:That seems a good key activity to do.": "这似乎是一个很好的关键活动。",
  "EN:ZH:Or it will take a significant amount of resources and time to do.": "否则就会耗费大量的资源和时间。",
  "EN:ZH:And it is one of the key thing which this book people company should be doing.": "这也是这家图书公司应该做的关键事情之一。",
  "EN:ZH:Then algorithm refinement are refining the algorithm, uh, which, uh will help in searching, getting": "然后，算法改进是对算法的细化，呃，这将有助于搜索，获得",
  "EN:ZH:the right search result and all or uh, whenever a person is searching a particular book.": "当一个人在搜索某本书时，就会出现正确的搜索结果和所有或呃。",
  "EN:ZH:So, uh, that kind of algorithm requirement also seems fine, a good activity to me to be included": "所以，呃，这种算法要求似乎也不错，对我来说是一项很好的活动，可以纳入其中",
  "EN:ZH:in key activity then marketing campaign because, um, one of the key aspect of any online business": "在关键活动中开展营销活动，因为任何在线业务的一个关键方面是",
  "EN:ZH:is running successful marketing campaign.": "正在开展成功的营销活动。",
  "EN:ZH:So marketing campaign also seems the correct activity and engaging users who are either potential customers": "因此，营销活动似乎也是一项正确的活动，并能吸引潜在客户用户的参与",
  "EN:ZH:or existing customers that also seems to have the activity.": "或现有客户似乎也有这种活动。",
  "EN:ZH:Let's see the guideline from uh, the author of this framework outline the most important activities": "让我们看看这个框架的作者概述了最重要活动的指导原则",
  "EN:ZH:the company must perform to make its business model work.": "公司必须做到这一点，才能使其商业模式行之有效。",
  "EN:ZH:So here we have activities the company must be doing to make the business model successful.": "因此，要使商业模式取得成功，公司必须开展各种活动。",
  "EN:ZH:We have to capture those activities.": "我们必须抓住这些活动。",
  "EN:ZH:So, uh, in based on reading the guidance and the activities, both in the activities generated by": "因此，呃，在阅读指南和活动的基础上，无论是在由",
  "EN:ZH:ChatGPT seems fine to me.": "我觉得 ChatGPT 还不错。",
  "EN:ZH:Uh, I don't see any problem in the quality of output of GDP in this scenario.": "在这种情况下，我看不出 GDP 的产出质量有什么问题。",
  "EN:ZH:Let's look at the guidance for key resources now.": "现在让我们来看看关键资源的指南。",
  "EN:ZH:So key resources are as per the guidance the list of critical assets infrastructure resources required": "因此，关键资源是根据指导意见列出的所需关键资产基础设施资源",
  "EN:ZH:to deliver the value proposition reach consumers and operate the business.": "以向消费者传递价值主张并经营业务。",
  "EN:ZH:So it is listing the most critical assets without which the business will not exist, uh, including": "因此，它列出了最关键的资产，没有这些资产，企业将无法存在，呃，包括",
  "EN:ZH:the infrastructure or any other resources which are required to deliver the value proposition to the": "向客户提供价值主张所需的基础设施或任何其他资源",
  "EN:ZH:customer.": "顾客",
  "EN:ZH:Uh, so Uh, that's the guidance that is given.": "呃，所以呃，这就是给出的指导。",
  "EN:ZH:Let's see whether we have captured that source or not.": "让我们看看我们是否捕捉到了这个源。",
  "EN:ZH:Extensive book database.": "庞大的图书数据库。",
  "EN:ZH:So if we don't have an extensive book database, that means when the potential customer come to our": "因此，如果我们没有一个庞大的图书数据库，这就意味着当潜在客户来到我们的",
  "EN:ZH:website, they will not have any thing to buy.": "网站，他们就没有东西可买了。",
  "EN:ZH:So extensive catalog seems, uh, a key resource to me for this business model.": "在我看来，广泛的目录是这种商业模式的关键资源。",
  "EN:ZH:Technology infrastructure.": "技术基础设施。",
  "EN:ZH:Having that the website, uh, which is the code of the website or website which is required to run": "网站，呃，也就是运行所需的网站或网站代码",
  "EN:ZH:this business, having the servers which will host the website, having the payment in connection to": "在这一业务中，拥有托管网站的服务器，支付与网站有关的费用。",
  "EN:ZH:the third party payment APIs and, uh, connection to the couriers or the post service, which will": "第三方支付应用程序接口，以及与快递公司或邮政服务的连接，这将",
  "EN:ZH:deliver uh, ship these books.": "运送这些书",
  "EN:ZH:So having all that, uh, technology infrastructure in place seems, uh, a key, right, key activity": "因此，拥有所有这些技术基础设施似乎是一个关键，对吧，关键活动",
  "EN:ZH:to me then recommending an algorithm that also seems a key resource because, uh, uh, based on, uh,": "对我来说，推荐一种算法似乎也是一种关键资源，因为，呃，呃，基于，呃、",
  "EN:ZH:the right, uh, recommendation algorithm.": "正确的推荐算法。",
  "EN:ZH:Right.": "对",
  "EN:ZH:Recommended book will be recommended to potential customer or customers based on the interests of customer,": "推荐书籍将根据客户的兴趣推荐给潜在客户或客户、",
  "EN:ZH:based on their past history of purchases, based on their past browsing history or of our website.": "根据他们过去的购买记录、过去的浏览记录或我们网站的浏览记录。",
  "EN:ZH:Then the marketing team.": "然后是营销团队。",
  "EN:ZH:Because marketing is one of the key activity for a online website.": "因为营销是在线网站的关键活动之一。",
  "EN:ZH:And that's why are having a great marketing team seems to be a right key resource to me.": "这就是为什么在我看来，拥有一支优秀的营销团队是正确的关键资源。",
  "EN:ZH:So the quality of this output also seems fine.": "因此，这种输出的质量似乎也不错。",
  "EN:ZH:I don't think we need to refine anything in this section as well.": "我认为我们也不需要完善这一部分的任何内容。",
  "EN:ZH:Let's look at the cost structure.": "让我们来看看成本结构。",
  "EN:ZH:So the guidance of cost structure is breakdown the cost associated with operating the business.": "因此，成本结构的指导意义在于分解与企业运营相关的成本。",
  "EN:ZH:This include fixed cost, variable cost as well as economies of scale.": "这包括固定成本、可变成本以及规模经济。",
  "EN:ZH:So we have to identify the key cost which will be uh you know put in these three buckets fixed cost,": "因此，我们必须确定关键成本，并将其归入固定成本的三个部分、",
  "EN:ZH:variable cost.": "可变成本。",
  "EN:ZH:And for a online business which is selling books technology Development seems to be the one of the key": "对于销售图书的在线业务来说，技术开发似乎是关键之一。",
  "EN:ZH:variable cost as well as fixed cost.": "可变成本和固定成本。",
  "EN:ZH:To me then marketing and advertising cost again seems to be running the customer support team or department.": "在我看来，营销和广告成本似乎又是客户支持团队或部门的运营成本。",
  "EN:ZH:The expenses associated with it also seems the right category of cost to be captured here, so I don't": "与此相关的开支似乎也属于应在此处记录的成本类别，因此我不",
  "EN:ZH:think this section need any refinement.": "我认为这一部分需要改进。",
  "EN:ZH:So we have reviewed this section successfully.": "至此，我们顺利完成了本节的复习。",
  "EN:ZH:Let's look at value proposition.": "让我们来看看价值主张。",
  "EN:ZH:So the guidance or value proposition is outline the unique value or solution that the company offers": "因此，指导或价值主张就是概述公司提供的独特价值或解决方案",
  "EN:ZH:to its customer.": "客户。",
  "EN:ZH:And what problem does it solve or need it fulfills.": "它能解决什么问题或满足什么需求。",
  "EN:ZH:So here in this section we have to capture the unique value or solution which our company is offering": "因此，在这一部分，我们必须抓住公司提供的独特价值或解决方案",
  "EN:ZH:and what problem we are trying to solve or what need we are trying to fulfill.": "以及我们要解决什么问题或满足什么需求。",
  "EN:ZH:So let's look at Chatgpt's response.": "让我们看看 Chatgpt 的回答。",
  "EN:ZH:Extensive book catalog.": "丰富的图书目录。",
  "EN:ZH:This can be a good unique value proposition because many are businesses which are either offline or": "这可能是一个很好的独特价值主张，因为许多企业要么是离线企业，要么是线下企业。",
  "EN:ZH:online.": "在线",
  "EN:ZH:They tend to have a smaller catalog which are result in.": "它们往往有一个较小的目录。",
  "EN:ZH:Even though if a lot of customer comes to them, they might not have relevant books for them.": "即使有很多客户来找他们，他们也可能没有相关的书籍。",
  "EN:ZH:That's why having extensive book catalog seems, uh.": "这就是为什么拥有大量图书目录的原因",
  "EN:ZH:Uh, point to be captured in value proposition then?": "那么，价值主张中要抓住的一点是什么？",
  "EN:ZH:Personal recommendation also seems to me a good unique value proposition because rather than showing,": "在我看来，个人推荐也是一个很好的独特价值主张，因为它不是展示、",
  "EN:ZH:uh, irrelevant, uh, book recommendations, uh, in which a potential customer might not be interested,": "呃，不相关的，呃，潜在客户可能不感兴趣的书籍推荐、",
  "EN:ZH:giving them, uh, targeted and personalized recommendation based on their interest, based on their": "根据他们的兴趣，为他们提供有针对性的个性化推荐。",
  "EN:ZH:browsing history, based on their purchase history, seems to be a great, unique value proposition": "基于他们的购买历史记录的浏览历史，似乎是一个伟大而独特的价值主张",
  "EN:ZH:to have then seamless shopping experience.": "以获得无缝购物体验。",
  "EN:ZH:Again.": "再来一次",
  "EN:ZH:This also seems, uh, very interesting, unique value proposition to capture.": "这似乎也是非常有趣的，可以捕捉到独特的价值主张。",
  "EN:ZH:It means the customer experience which is being offered is seamless.": "这意味着所提供的客户体验是无缝的。",
  "EN:ZH:It doesn't feel broken at at points.": "在某些时候，它并不会让人感觉破碎。",
  "EN:ZH:It doesn't seem to be, uh, seemed or it doesn't seem to be siloed.": "似乎没有，呃，似乎没有，或者似乎没有被孤立起来。",
  "EN:ZH:So having that great and seamless shopping experience seems to be a good value proposition.": "因此，拥有出色的无缝购物体验似乎是一个很好的价值主张。",
  "EN:ZH:Then community engagement.": "然后是社区参与。",
  "EN:ZH:So connecting various author, uh, book enthusiasts together, which have, uh, common interests.": "这样就把不同的作者，呃，图书爱好者联系在一起，他们有，呃，共同的兴趣爱好。",
  "EN:ZH:So providing those kind of, uh, communities where they can discuss about a particular book or particular": "因此，提供这些社区，让他们可以讨论特定的书籍或特定的",
  "EN:ZH:kind of book, that also seems to be a good value proposition.": "这似乎也是一个很好的价值主张。",
  "EN:ZH:So all these points, they seems fine.": "因此，所有这几点看起来都很好。",
  "EN:ZH:We don't need to do any refinement in this section as well.": "在这一部分，我们也不需要做任何改进。",
  "EN:ZH:Let's look at customer relationship.": "让我们来看看客户关系。",
  "EN:ZH:So customer relationship chat GTP has generated three points.": "因此，客户关系聊天 GTP 产生了三个要点。",
  "EN:ZH:Uh self service community engagement and customer support.": "自助服务社区参与和客户支持。",
  "EN:ZH:So what is the guidance here.": "那么，这里有什么指导意义呢？",
  "EN:ZH:Explain how the company established and maintains relationship with customer.": "解释公司如何与客户建立和保持关系。",
  "EN:ZH:This can include personalized service, self service, automated services, etc. so in this section": "这可以包括个性化服务、自助服务、自动服务等，因此在本节中",
  "EN:ZH:we explain how our company will establish a relationship with our customer or potential customer.": "我们解释公司将如何与客户或潜在客户建立关系。",
  "EN:ZH:So uh, for we, we will make our uh the first point is about self service.": "因此，第一点是关于自助服务。",
  "EN:ZH:The customers will be able to buy the books on on their, their own without human intervention from": "顾客可以在没有人工干预的情况下，自己购买书籍。",
  "EN:ZH:any employee from our side.": "我方任何员工。",
  "EN:ZH:So that also seems to be a good customer relationship.": "因此，这似乎也是一种良好的客户关系。",
  "EN:ZH:Uh, point to be captured then.": "那就等着被抓吧",
  "EN:ZH:Community engagement.": "社区参与。",
  "EN:ZH:So, uh, if they have any questions, uh, related to the book and all they can discuss with the fellow": "因此，如果他们有任何与这本书有关的问题，都可以与同行讨论。",
  "EN:ZH:customer or potential customer.": "客户或潜在客户。",
  "EN:ZH:So that also seems to a good customer relationship point to be captured.": "因此，这似乎也是一个很好的客户关系点。",
  "EN:ZH:Then, uh, we will provide customer support as well.": "然后，我们还将提供客户支持。",
  "EN:ZH:So all these things, uh, seems to be, uh, right point to be captured in customer relationship.": "因此，所有这些似乎都是客户关系中应该把握的要点。",
  "EN:ZH:Then customer segments are define different group of people or organization that the company aims to": "那么，客户细分就是定义公司旨在服务的不同人群或组织。",
  "EN:ZH:reach and serve.": "到达和服务。",
  "EN:ZH:So in this case we have to identify clear segments which we are targeting.": "因此，在这种情况下，我们必须明确我们的目标细分市场。",
  "EN:ZH:So avid readers who are basically the regular readers of book.": "因此，热心读者基本上都是图书的常客。",
  "EN:ZH:They also seem to be right.": "他们似乎也是对的。",
  "EN:ZH:Uh, customer segment convert casual readers, people who occasionally read those people also seem to": "呃，客户群转换休闲读者，那些偶尔阅读的人似乎也",
  "EN:ZH:be the right customer segment scholar, academician, and scholar shoppers.": "成为学者、院士和学者购物者的正确客户群。",
  "EN:ZH:So all of these seems to be, uh, right customer segments, uh, to me for a starting point.": "对我来说，所有这些似乎都是正确的客户细分。",
  "EN:ZH:Then, uh, so in the channel section, uh, it described the ways, uh, the company delivers its value": "然后，呃，在渠道部分，呃，它描述了公司提供价值的方式，呃",
  "EN:ZH:proposition to the customer.": "向客户提出的建议。",
  "EN:ZH:This includes sales and distribution channel.": "这包括销售和分销渠道。",
  "EN:ZH:So, uh, in this section, we capture the company, which are the channel used by the company to deliver": "因此，在本节中，我们将捕捉公司，即公司用于交付的渠道。",
  "EN:ZH:value to this customers.": "客户的价值。",
  "EN:ZH:and this can include sales and distribution channel.": "这可能包括销售和分销渠道。",
  "EN:ZH:So online platform it can.": "因此，在线平台是可以的。",
  "EN:ZH:Ah they have used a generic word.": "啊，他们用了一个通用词。",
  "EN:ZH:Ah but they could have been more specific here.": "啊，但他们本可以说得更具体些。",
  "EN:ZH:For example website mobile for iOS, mobile app for Android.": "例如，iOS 的移动网站、Android 的移动应用程序。",
  "EN:ZH:So they could have been a little bit more specific here then social media.": "因此，他们本可以在社交媒体方面做得更具体一些。",
  "EN:ZH:Uh, again, this is mainly again, uh, this can be used for marketing as well as for servicing.": "同样，这也主要用于营销和服务。",
  "EN:ZH:So this also seems fine to me.": "因此，我觉得这样也很好。",
  "EN:ZH:But we can be more specific here.": "但在这里，我们可以说得更具体一些。",
  "EN:ZH:Like if we it is early days, we might be only interested in, uh, let's say starting with, uh, Facebook": "比如说，如果我们还处于起步阶段，我们可能只对 Facebook 感兴趣。",
  "EN:ZH:or only with, uh, Google for advertising or marketing.": "或只与谷歌合作做广告或营销。",
  "EN:ZH:So we can be more specific here rather than be generic.": "因此，我们在这里可以说得更具体一些，而不是泛泛而谈。",
  "EN:ZH:So that is one refinement point we can include then email marketing.": "因此，这是我们可以将电子邮件营销纳入其中的一个改进点。",
  "EN:ZH:Uh, this seems fine to me.": "我觉得这样挺好。",
  "EN:ZH:Affiliate marketing.": "联盟营销。",
  "EN:ZH:This also seems fine to me because they are specific, uh, in in these aspects here.": "这在我看来也很好，因为他们在这些方面都很具体。",
  "EN:ZH:Let's look at the revenue stream section.": "让我们来看看收入流部分。",
  "EN:ZH:So the guidance in this section is identify the sources of revenue for the company.": "因此，本节的指导思想是确定公司的收入来源。",
  "EN:ZH:How does the company makes money from the from its customers.": "公司如何从客户那里赚钱。",
  "EN:ZH:So here we are identifying the key value streams.": "因此，我们要确定关键价值流。",
  "EN:ZH:So the top key value stream is book sales which seems correct to me.": "因此，最重要的价值流是图书销售，这在我看来是正确的。",
  "EN:ZH:Then subscription services.": "然后是订阅服务。",
  "EN:ZH:So subscription services can be for online book reading.": "因此，订阅服务可以用于在线图书阅读。",
  "EN:ZH:For example, you might offer let's say ten books a month for £10 or let's say in £30 per month.": "例如，您可以每月以 10 英镑或 30 英镑的价格提供十本书。",
  "EN:ZH:You can offer unlimited book reading, unlimited book title.": "您可以提供无限量的图书阅读和无限量的书名。",
  "EN:ZH:So that can be a good, good value stream.": "因此，这可能是一个很好的价值流。",
  "EN:ZH:Then affiliate marketing in the context of revenue stream means even though you are selling books but": "那么在收入流的背景下，联属营销意味着即使你在卖书，但",
  "EN:ZH:certain kind of book which you are not selling certain category of book, you might advertise those": "如果您不销售某类图书，您可以为这些图书做广告。",
  "EN:ZH:kind of books for other people on your website.": "在您的网站上为其他人提供图书。",
  "EN:ZH:So that can be a revenue stream as well.": "因此，这也可以成为一种收入来源。",
  "EN:ZH:But that doesn't seem much relevant to me at this point.": "但现在看来，这与我没有多大关系。",
  "EN:ZH:Again, advertisement from other third parties about some other products.": "再次，来自其他第三方的关于其他产品的广告。",
  "EN:ZH:Uh, these two will generate less result in in the beginning, but, uh, this can be included as,": "呃，这两项在开始时产生的结果会少一些，但是，呃，这也可以包括在内、",
  "EN:ZH:as well.": "也是如此。",
  "EN:ZH:My thinking is they kind of average fit, uh, for this purpose, but, uh, they're not like, a wrong,": "我的想法是，它们平均适合这种用途，但它们并不是错的、",
  "EN:ZH:uh, suggestion by GDP.": "呃，GDP 建议。",
  "EN:ZH:So this is, uh, the business model canvas for, uh, book people, which is Amazon style bookstore.": "这就是亚马逊书店的商业模式。",
  "EN:ZH:I just wanted to show you how the final, uh, business model canvas will look like for the book people,": "我只是想向你们展示一下最终的商业模式画布是怎样的、",
  "EN:ZH:which is Amazon style website, after we have removed the guidance.": "这是亚马逊风格的网站，在我们取消指导之后。",
  "EN:ZH:So if you look at, uh, it now have all the nine sections in it, key partners and the corresponding": "因此，如果你看一下，呃，它现在包含了所有九个部分，主要合作伙伴和相应的",
  "EN:ZH:values of each of these sections generated by by ChatGPT.": "由 ChatGPT 生成的每个部分的值。",
  "EN:ZH:Hi all, welcome to our next session.": "大家好，欢迎来到下一环节。",
  "EN:ZH:So in this section we are going to discuss how to generate a kernel model using chat.": "因此，本节我们将讨论如何使用聊天生成内核模型。",
  "EN:ZH:And within this there are three steps or subsection uh we will be using to generate uh kernel model": "其中有三个步骤或小节，我们将用来生成内核模型",
  "EN:ZH:using chat GTP.": "使用聊天 GTP。",
  "EN:ZH:The first step is we'll learn how to write chat GTP prompt for kernel mode.": "第一步，我们将学习如何为内核模式编写聊天 GTP 提示。",
  "EN:ZH:Then once we have written the chat GTP prompt for kernel model, then we'll generate a sample kernel": "然后，一旦我们编写了内核模型的聊天 GTP 提示，我们就会生成一个样本内核",
  "EN:ZH:model using GTP.": "使用 GTP 的模型。",
  "EN:ZH:And then next step is once we have generated a kernel model using chat GTP, we will review this kernel": "下一步是，一旦我们使用聊天 GTP 生成了内核模型，我们将审查这个内核",
  "EN:ZH:model which is generated by chat chat GTP and refine it if required.": "聊天 GTP 生成的模型，并根据需要对其进行改进。",
  "EN:ZH:So these are the three steps we are going to discuss.": "这就是我们要讨论的三个步骤。",
  "EN:ZH:Let's go through these steps one by one.": "让我们逐一介绍这些步骤。",
  "EN:ZH:So in this slide we will learn how to generate a chat GTP prompt for kernel mode.": "在本幻灯片中，我们将学习如何为内核模式生成聊天 GTP 提示。",
  "EN:ZH:So uh we'll be following our standard prompt generation template for generating ChatGPT prompt for piano": "因此，我们将按照标准提示生成模板为钢琴生成 ChatGPT 提示信息",
  "EN:ZH:model.": "模型",
  "EN:ZH:Let's go through the example modal prompt, which I have generated using the standard prompt generation": "让我们来看看我使用标准提示生成器生成的模态提示示例",
  "EN:ZH:template.": "模板。",
  "EN:ZH:So in the first step, what I'm doing is I'm asking ChatGPT to assume the role of product manager.": "因此，第一步，我要求 ChatGPT 承担起产品经理的角色。",
  "EN:ZH:Why I'm asking that is because Cano model is usually produced by a product manager within a product": "我之所以这么问，是因为 Cano 模型通常是由产品经理在产品内部制作的。",
  "EN:ZH:development team.": "开发团队。",
  "EN:ZH:Then, uh, in the next step, uh, what I'm doing is I'm explaining about the product or project we": "然后，呃，下一步，呃，我要做的是解释我们的产品或项目。",
  "EN:ZH:are doing.": "正在做的事情。",
  "EN:ZH:So we are building a Ryanair style airline.": "因此，我们正在建设一家瑞安式的航空公司。",
  "EN:ZH:That's the description of this product.": "这就是对该产品的描述。",
  "EN:ZH:So, uh, why I am using the word Ryanair style airline.": "所以，呃，为什么我要用瑞安航空式的航空公司这个词。",
  "EN:ZH:So by using just existing example, what I'm doing is I am asking ChatGPT to follow a similar business": "因此，通过使用现有的示例，我所做的就是要求 ChatGPT 遵循类似的商业模式",
  "EN:ZH:model which ran Airlines is doing.": "ran 航空公司正在采用的模式。",
  "EN:ZH:And that's the reason I am using this kind of prompting in in this step.": "这就是我在这个步骤中使用这种提示的原因。",
  "EN:ZH:The idea is by you doing this ChatGPT will look in, will already have a knowledge of Ryanair's business": "这样做的目的是让 ChatGPT 了解瑞安航空的业务。",
  "EN:ZH:model, and it will use that as a base model to give us a result for our airline.": "模型，并以此为基础模型为我们的航空公司提供结果。",
  "EN:ZH:And you can do similar prompting, let's say if you are trying to build a website for selling books,": "比方说，如果你想建立一个卖书的网站，你也可以做类似的提示、",
  "EN:ZH:which will be Amazon style website, so you can talk about Amazon style website if you are doing something,": "这将是亚马逊风格的网站，因此，如果你正在做某件事情，你可以谈论亚马逊风格的网站、",
  "EN:ZH:let's say, uh, which will be a competitor of Uber in in ride hailing, then you can say Uber style": "比方说，呃，它将成为 Uber 在叫车服务方面的竞争对手，那么你可以说 Uber 风格",
  "EN:ZH:ride hailing product.": "叫车产品。",
  "EN:ZH:So you pick, uh, in this uh, line you pick.": "所以，你挑，呃，在这个呃，行你挑。",
  "EN:ZH:Well established competitors of, uh, your product or your industry.": "你的产品或行业的成熟竞争对手。",
  "EN:ZH:That way, that way, chat GTP will refer to their business model as a base model to generate deliverables": "这样，这样，聊天 GTP 就会参考他们的业务模式，将其作为生成交付成果的基础模式",
  "EN:ZH:for you.": "给你",
  "EN:ZH:That way, you don't have to tell a lot of background to chat GTP.": "这样，您就不必在聊天 GTP 时讲述大量背景信息。",
  "EN:ZH:That's the idea of writing prompting like this.": "这就是这种写作提示的理念。",
  "EN:ZH:In this line.": "在这一行中",
  "EN:ZH:And then in the next section, we'll write the sections which we want to generate for the Kano model.": "然后在下一节中，我们将编写我们希望为卡诺模型生成的部分。",
  "EN:ZH:Kano model usually have three sections basic features, excitement features, and performance features.": "卡诺模型通常有三个部分：基本特征、兴奋特征和性能特征。",
  "EN:ZH:So we've listed all the three sections.": "因此，我们列出了所有三个部分。",
  "EN:ZH:In next section we have written the name of framework itself.": "下一节我们将介绍框架本身的名称。",
  "EN:ZH:So which is Kano model in this scenario.": "那么，在这种情况下，哪个是卡诺模式呢？",
  "EN:ZH:And then we have written the name of author of Kano model which is doctor uh, Noori Ki Kano.": "然后，我们写下了卡诺模型作者的名字，他就是诺里-基-卡诺医生（Doctor uh, Noori Ki Kano）。",
  "EN:ZH:And then uh, in the next step, we have again described the product which we described in step two,": "然后，在下一步中，我们再次描述了我们在第二步中描述的产品、",
  "EN:ZH:which is Ryanair style airline.": "这是一家瑞安式的航空公司。",
  "EN:ZH:And then we have written an additional condition that we want all the section to be generated in points.": "然后，我们还写了一个附加条件，即我们希望所有部分都以点为单位生成。",
  "EN:ZH:So it is just what we are doing is we are just populating, uh, the values uh, of uh, these red points": "因此，我们要做的只是填充这些红色点的值。",
  "EN:ZH:which are in parentheses.": "在括号中。",
  "EN:ZH:Uh, uh, in, in, in the sample.": "呃，呃，在，在，在样本里。",
  "EN:ZH:So we are just following the template and populating the values of these red font items in, in the": "因此，我们只需按照模板，将这些红色字体项的值填充到",
  "EN:ZH:So if I'm showing you a quick mapping of each of the lines by doing this.": "因此，如果我这样做，就能快速绘制出每条线路的地图。",
  "EN:ZH:So this this is what, uh, by following these steps we have generated a example for piano model.": "因此，按照这些步骤，我们就生成了钢琴模型的示例。",
  "EN:ZH:Let's, uh, summarize this quickly.": "让我们，呃，快速总结一下。",
  "EN:ZH:So, uh, what we are doing here is we are asking ChatGPT to play the role of a product manager for": "所以，我们现在要做的就是让 ChatGPT 扮演产品经理的角色。",
  "EN:ZH:regional style airline.": "支线航空公司。",
  "EN:ZH:And what we want that GDP is to generate basic feature, excitement, feature and performance feature": "我们希望 GDP 生成基本特征、兴奋点、特征和性能特征",
  "EN:ZH:sections for the Kano model for this style website and the Kano model is authored by Doctor Naruki Kano": "本风格网站的狩野模式部分和狩野模式由博士 Naruki Kano 撰写",
  "EN:ZH:and we want all the sections for this Kano model to be written in points.": "我们希望这个卡诺模型的所有部分都用点来书写。",
  "EN:ZH:So that's the summary.": "这就是总结。",
  "EN:ZH:Now the next step is to actually use uh, this uh prompt to in ChatGPT to generate these sections.": "下一步就是使用 ChatGPT 中的提示来生成这些部分。",
  "EN:ZH:So let's do that together.": "让我们一起努力吧",
  "EN:ZH:So I'm going to just copy the prompt which we have generated for the Kano model.": "因此，我将直接复制我们为卡诺模型生成的提示。",
  "EN:ZH:And we'll just go to ChatGPT and we'll start a new thread or a new chat.": "我们只需进入 ChatGPT，然后开始一个新的主题或新的聊天。",
  "EN:ZH:The reason for that is I'm going to, uh, produce this Kano model for this Ryanair style airline for": "原因是我要为这家瑞安航空公司制作卡诺模型。",
  "EN:ZH:the first time.": "第一次。",
  "EN:ZH:We haven't done any product management deliverable for this product before.": "我们以前没有为这个产品做过任何产品管理交付。",
  "EN:ZH:So that's why I'm going to use a new new chat window here.": "因此，我要在这里使用一个新的聊天窗口。",
  "EN:ZH:Okay, I've just started a new chat window and now I'm going.": "好的，我刚刚开始了一个新的聊天窗口，现在我要走了。",
  "EN:ZH:I pasted a the prompt which we have generated for this website and I'm going to post it to chat GTP.": "我粘贴了我们为本网站生成的提示，并将其发布到聊天 GTP 上。",
  "EN:ZH:GDP has started generating the response for this and what chat GTP has done, if you look carefully,": "如果你仔细观察，GDP 已经开始对此做出回应，而 GTP 也做了很多工作、",
  "EN:ZH:is it have generated the headlines for each of the section.": "是它产生了每个部分的标题。",
  "EN:ZH:For example, for basic feature, it has generated low cost fares as headline, but in addition to that,": "例如，在基本功能方面，它产生了低成本的头条票价，但除此之外、",
  "EN:ZH:it has given description of each of these sections as well.": "它还对每个部分进行了说明。",
  "EN:ZH:So for low cost feature it is saying competitive pricing to attract budget conscious travelers, transparent": "因此，在低成本特色方面，它说的是有竞争力的定价，以吸引有预算意识的游客，透明的",
  "EN:ZH:pricing with minimal hidden fees, point to point connectivity, online booking and check in standard": "隐性费用极低的定价、点到点连接、在线预订和登机手续标准",
  "EN:ZH:seat allocation.": "座位分配。",
  "EN:ZH:And on time performance.": "按时完成任务。",
  "EN:ZH:So it has given us the headlines.": "因此，它给了我们头条新闻。",
  "EN:ZH:Plus it has given some of the descriptions as well with the each of the headline.": "此外，它还对每个标题进行了说明。",
  "EN:ZH:So look at the excitement feature as well.": "所以，也要看看兴奋功能。",
  "EN:ZH:It has given us the headlines, customizable ancillary services, inflight entertainment option, exclusive": "它为我们提供了头条新闻、可定制的辅助服务、机上娱乐选项、专属的",
  "EN:ZH:loyalty programs.": "忠诚度计划。",
  "EN:ZH:Plus it has given the description of each of them same way for performance feature.": "此外，它还以同样的方式对每个性能特征进行了描述。",
  "EN:ZH:So what I'm going to do is I'm going to put all this information to our PowerPoint template.": "因此，我要做的就是把所有这些信息放到我们的 PowerPoint 模板中。",
  "EN:ZH:And while porting this information, what I'm going to do is I have ported this in our Ryanair sorry": "在移植这些信息时，我要做的是，我已将这些信息移植到我们的瑞安抱歉中。",
  "EN:ZH:model template for our new airline.": "我们新航空公司的示范模板。",
  "EN:ZH:But what I'm going to do is I will not, I will discard, I will keep the descriptions detailed description": "但我要做的是，我不会放弃，我会保留详细的描述。",
  "EN:ZH:inside the notes of the pack, and I will only write the names of or headlines of the feature on our": "我只会写上我们的专题名称或标题。",
  "EN:ZH:our slide deck.": "我们的幻灯片。",
  "EN:ZH:So that's what I'm going to do now.": "这就是我现在要做的。",
  "EN:ZH:I'm going to put them one by one.": "我一个一个来。",
  "EN:ZH:Now I have ported the response which is generated by ChatGPT on our Kino modal template.": "现在，我已将 ChatGPT 生成的响应移植到我们的 Kino 模态模板上。",
  "EN:ZH:So what I have done is I've only taken the headlines of each of the feature and discarded the descriptions": "因此，我只摘取了每个专题的标题，而舍弃了说明",
  "EN:ZH:of each of the feature, and then mapped all of the feature to respective, uh, graph lines.": "然后将所有特征映射到相应的图线上。",
  "EN:ZH:So I've mapped all the excitement features to this, uh, green line and all the performance related": "因此，我将所有的兴奋特征都映射到了这条绿线上，并将所有与性能相关的特征都映射到了这条绿线上。",
  "EN:ZH:feature I mapped to this purple line and basic features I've mapped to Blue Line.": "我将特征映射到这条紫色线条上，并将基本特征映射到蓝色线条上。",
  "EN:ZH:Now let's do a quick reminder of the guidance on kernel model for feature.": "现在，让我们快速回顾一下有关特征内核模型的指导。",
  "EN:ZH:And then we, uh, review the features the result generated by ChatGPT against the guidance.": "然后，我们会根据指南审查 ChatGPT 生成的结果特征。",
  "EN:ZH:So the first section is excitement features.": "因此，第一部分是兴奋功能。",
  "EN:ZH:So excitement feature guidance is these are unexpected delights generate high satisfaction.": "因此，激动人心的特色指导是这些意想不到的美味产生的高满意度。",
  "EN:ZH:Absence doesn't cause dis satisfaction.": "缺席不会导致不满意。",
  "EN:ZH:So excitement features are, as the name suggests, they excite the customer.": "因此，兴奋功能顾名思义就是让客户兴奋。",
  "EN:ZH:They're not expected.": "不指望他们。",
  "EN:ZH:In general, they are more like surprise to customer and they result in generation of very high satisfaction.": "一般来说，它们更像是给客户的惊喜，能让客户产生极高的满意度。",
  "EN:ZH:But if these excitement features are not there, then in that case customer will not be dissatisfied.": "但如果没有这些令人兴奋的功能，客户也不会不满意。",
  "EN:ZH:So based on this definition, let's look at are responses generated by chat GTP for excitement feature.": "根据这个定义，我们来看看聊天 GTP 为兴奋功能生成的响应。",
  "EN:ZH:So customizable X ancillary services chat GTP have put in excitement feature which is customizable like": "因此，可定制的 X 辅助服务聊天 GTP 加入了可定制的兴奋功能，如",
  "EN:ZH:similar services are.": "类似的服务有",
  "EN:ZH:They are add on services like meals, baggage priority boarding, personalized packages for unique traveler": "这些都是附加服务，如餐饮、行李优先登机、为独特旅客提供的个性化套餐等。",
  "EN:ZH:of preference.": "的偏好。",
  "EN:ZH:So all those things kind of services, customizable ancillary services.": "因此，所有这些服务都是可定制的辅助服务。",
  "EN:ZH:They are I put them in right bucket.": "我把它们放在右边的桶里。",
  "EN:ZH:They are uh, something which will excite the customer if they are available, but it will not reduce.": "如果有，它们会让顾客感到兴奋，但不会减少。",
  "EN:ZH:The absence of this feature will not satisfy the customers.": "如果没有这项功能，客户就不会满意。",
  "EN:ZH:Then, uh, the next one is in-flight entertainment.": "然后，呃，下一个是机上娱乐。",
  "EN:ZH:So again, this is again a kind of exciting feature.": "因此，这又是一个令人兴奋的功能。",
  "EN:ZH:Uh, it will excite the customer.": "嗯，这会让顾客兴奋。",
  "EN:ZH:But if there is a absence of in-flight entertainment, customer will not be dissatisfied.": "但是，如果机上没有娱乐设施，乘客也不会不满意。",
  "EN:ZH:Exclusive, uh, loyalty program.": "专属的忠诚度计划",
  "EN:ZH:So, again, the presence of this will excite the customer.": "因此，这一点同样会让客户感到兴奋。",
  "EN:ZH:It will increase the customer satisfaction, but the customer will not feel dissatisfied.": "这将提高客户满意度，但客户不会感到不满意。",
  "EN:ZH:If the loyalty programs are not there, then custom upgrades.": "如果没有忠诚度计划，那就定制升级。",
  "EN:ZH:So customer updates are more around, uh, availability of upgrades to premium sitting with extra legroom": "因此，客户更新更多是围绕着，呃，是否可以升级到有额外腿部空间的高级坐席",
  "EN:ZH:for a fee or providing blankets or pillows in flight.": "收费或在飞行中提供毯子或枕头。",
  "EN:ZH:So those kind of amenities or upgrades.": "所以，这些都是设施或升级。",
  "EN:ZH:Again, they will delight the customers if they are available.": "同样，如果有的话，它们也会让客户感到高兴。",
  "EN:ZH:They will generate high satisfaction.": "他们会产生很高的满意度。",
  "EN:ZH:But if these are not present, then it will not cause this satisfaction.": "但如果没有这些，就不会产生这种满足感。",
  "EN:ZH:Then themed travel experiences.": "然后是主题旅游体验。",
  "EN:ZH:So special flights for events, holiday themed experiences, collaboration with local businesses for": "因此，为活动提供特别航班、节日主题体验、与当地企业合作以获得",
  "EN:ZH:unique inflight offerings.": "独特的机上服务。",
  "EN:ZH:So these are the kind of themed travel experiences.": "因此，这些都是主题旅游体验。",
  "EN:ZH:If they are present, they will generate high satisfaction for the customer, but they will not cause": "如果它们存在，就会给客户带来很高的满意度，但它们不会导致",
  "EN:ZH:dissatisfaction.": "不满意。",
  "EN:ZH:So one thing we have to keep in mind is why can a modal exist?": "因此，我们必须牢记的一点是，为什么模态可以存在？",
  "EN:ZH:Why product owners or manager do this kind of modal analysis?": "产品负责人或经理为什么要进行这种模态分析？",
  "EN:ZH:The reason is the kind of modal analysis is done to understand what are the features without which the": "原因在于，进行模态分析是为了了解，如果没有这些特征，那么",
  "EN:ZH:product doesn't exist, and to identify those features, which are the basic features?": "产品不存在，要找出这些特征，哪些是基本特征？",
  "EN:ZH:The basic feature are the features without which the product will not exist.": "基本功能是指没有这些功能，产品就不存在。",
  "EN:ZH:So if you are in initial phase of your product, you are doing MVP of your product.": "因此，如果您正处于产品的初始阶段，那么您就在做产品的 MVP。",
  "EN:ZH:At that point, you will be putting your effort in building the basic feature, because if you don't": "在这一点上，你将把精力放在构建基本功能上，因为如果你不",
  "EN:ZH:have basic feature, then you know the product itself will not exist.": "有基本功能，那么产品本身也就不存在了。",
  "EN:ZH:So you figure out what are the features which are required for building the minimum requirements of": "因此，您需要弄清楚，要满足建立",
  "EN:ZH:the product, which are basic product without which the product doesn't exist.": "它们是产品的基本组成部分，没有它们，产品就不存在。",
  "EN:ZH:Then you figure out what are the performance need which which will enhance the customer satisfaction.": "然后，你要弄清楚哪些绩效需求可以提高客户满意度。",
  "EN:ZH:But if you don't have these performance feature, then customer will be dissatisfied.": "但如果没有这些性能特点，客户就会不满意。",
  "EN:ZH:And then the third category you identify is the excitement features the presence of excitement feature.": "第三类是 \"兴奋特征\"，即 \"兴奋特征的存在\"。",
  "EN:ZH:It delights the customer.": "它让顾客感到愉悦。",
  "EN:ZH:It increases the satisfaction of customers significantly.": "这大大提高了客户的满意度。",
  "EN:ZH:But if excitement features are not there, still it will not create dissatisfaction for the to the customer": "但是，如果没有令人兴奋的功能，也不会引起客户的不满。",
  "EN:ZH:and to categorize the features in these three categories.": "并将特征分为这三个类别。",
  "EN:ZH:Product Owner and manager do this analysis and based on the stages of the product you are in, you will": "产品负责人和经理会进行分析，根据您所处的产品阶段，您将",
  "EN:ZH:be interested in building those features.": "有兴趣建立这些功能。",
  "EN:ZH:For example, if you are in very early days of building the product, you will be interested in concentrating": "例如，如果您正处于开发产品的初期阶段，那么您就有兴趣集中精力",
  "EN:ZH:your effort on basic feature and you will be putting some of the effort in, you know, building performance": "你将把精力放在基本功能上，而把部分精力放在，你知道的，提高性能上。",
  "EN:ZH:feature.": "特点",
  "EN:ZH:But as you move more towards maturity, you keep building performance feature and then excitement features": "但是，当你越来越成熟时，你就会不断建立性能功能，然后是刺激功能",
  "EN:ZH:are more about if you are trying to move into a more premium segment or you are trying to differentiate": "更重要的是，如果你想进入更高端的市场，或者你想与众不同",
  "EN:ZH:from your competitors in those kind of scenario, you, uh, build, uh, these excitement feature.": "在这种情况下，要想从竞争对手中脱颖而出，就必须建立起这些令人兴奋的功能。",
  "EN:ZH:And that's the reason, uh, the product owners or managers do this kind of Canada.": "这也是产品负责人或经理在加拿大工作的原因。",
  "EN:ZH:We have already reviewed excitement feature.": "我们已经回顾了激动人心的功能。",
  "EN:ZH:So let's quickly look at basic feature.": "让我们快速了解一下基本功能。",
  "EN:ZH:So basic feature are the fundamental feature.": "因此，基本特征就是基本特征。",
  "EN:ZH:They are fundamentally expected and these are the feature without which the product will not exist.": "从根本上说，这些都是人们所期望的，没有这些功能，产品就不存在。",
  "EN:ZH:But the presence of these features have minimal impact on customer satisfaction.": "但这些功能的存在对客户满意度的影响微乎其微。",
  "EN:ZH:But the absence will create a lot of problem because if you don't have the basic feature available,": "但如果没有这些基本功能，就会产生很多问题、",
  "EN:ZH:the customer will be significantly unhappy.": "客户就会非常不满意。",
  "EN:ZH:So let's see whether I have categorized them as a right basic feature.": "让我们看看我是否把它们归类为正确的基本功能。",
  "EN:ZH:The first one it has generate low cost fares.": "首先，它产生了低成本票价。",
  "EN:ZH:So low cost fare because we are building a Ryanair style airline.": "因此，我们的票价很低，因为我们正在建设一家瑞安式的航空公司。",
  "EN:ZH:That's why I have categorized low cost fares as a basic feature.": "这就是为什么我把低成本票价归为基本功能的原因。",
  "EN:ZH:Right?": "对不对？",
  "EN:ZH:Because Ryanair is a low cost fare airline, right?": "因为瑞安航空是一家廉价航空公司，对吗？",
  "EN:ZH:And a low cost airline airline like Ryanair will not.": "而像瑞安这样的廉价航空公司则不会。",
  "EN:ZH:The their product itself will not exist without low cost.": "没有低成本，产品本身就不会存在。",
  "EN:ZH:That's the reason that GDP categorized low cost fares as the basic feature.": "这就是 GDP 将低成本票价列为基本特征的原因。",
  "EN:ZH:Then point to point connectivity.": "然后是点对点连接。",
  "EN:ZH:So again, chat GDP have added this as the basic feature.": "因此，聊天 GDP 再次将此添加为基本功能。",
  "EN:ZH:The reason for our particular case, the reason for this is because Ryan Air is having a very strong": "对于我们这个特殊的案例，原因在于瑞安航空公司有一个非常强大的",
  "EN:ZH:connectivity in European region, and it is the key feature of their business model, the basic feature": "欧洲地区的连通性，这也是其商业模式的主要特征，其基本特征是",
  "EN:ZH:of their model that they provide point to point connectivity, direct flights within the European region": "他们的模式是提供点到点的连接、欧洲地区内的直飞航班",
  "EN:ZH:from many cities.": "来自许多城市。",
  "EN:ZH:And that's why they have categorized this point to point connectivity as a basic feature.": "因此，他们将这种点对点连接归类为基本功能。",
  "EN:ZH:So remember one thing that for a airline A and B, depending on what product they are trying to build,": "因此，请记住一点，对于航空公司 A 和航空公司 B 来说，这取决于他们正在努力打造什么样的产品、",
  "EN:ZH:the same feature can be put as basic feature for airline B, and can become a performance or excitement": "同样的功能可作为 B 航空公司的基本功能，并可成为一种表演或兴奋点",
  "EN:ZH:feature for airline B.": "B 航空公司的特点。",
  "EN:ZH:So remember that that thing.": "所以，请记住这一点。",
  "EN:ZH:The next point is online booking and check in.": "其次是在线预订和登记。",
  "EN:ZH:So uh, again, uh, this is uh, because most of the airlines offer this facility now.": "所以，呃，还是那句话，呃，这是呃，因为现在大多数航空公司都提供这种设施。",
  "EN:ZH:That's why it has become a basic feature or basic expectation by the customers.": "因此，它已成为客户的基本功能或基本期望。",
  "EN:ZH:The standard seat allocation.": "标准座位分配。",
  "EN:ZH:So having availability to standard seat again this is a basic feature.": "因此，提供标准座位也是一项基本功能。",
  "EN:ZH:On time performance, starting the flight at right time and reaching the destination airport at right": "准时到达，准时起飞，准时到达目的地机场",
  "EN:ZH:time.": "时间",
  "EN:ZH:Again it's a basic feature.": "这也是一项基本功能。",
  "EN:ZH:So GDP airport all the basic features are based on our particular scenario in the right categorization.": "因此，GDP 机场的所有基本功能都是根据我们的特定场景进行正确分类的。",
  "EN:ZH:Let's see the performance now.": "现在让我们看看它的表现。",
  "EN:ZH:So performance need are directly proportional impact.": "因此，性能需求的影响是成正比的。",
  "EN:ZH:If the presence of them these feature in the product enhances satisfaction.": "如果产品具有这些功能，就会提高满意度。",
  "EN:ZH:But if they are not present then it uh causes this The satisfaction.": "但如果它们不存在，就会导致这种 \"满意\"。",
  "EN:ZH:So fuel efficient fleet.": "因此，车队的燃油效率很高。",
  "EN:ZH:So from a customer perspective, I might not put fuel efficient fleet in performance feature.": "因此，从客户的角度来看，我可能不会把节油车队放在性能功能中。",
  "EN:ZH:I might put it in excitement feature.": "我可能会把它放在 \"兴奋 \"专题中。",
  "EN:ZH:The reason for it is Kano analysis is done from customer perspective, like what customer perceive as": "原因在于卡诺分析是从客户角度出发的，比如客户认为",
  "EN:ZH:performance feature or excitement feature or basic need.": "性能特征、刺激特征或基本需求。",
  "EN:ZH:So fuel efficient I will categorize that excitement need for our scenario.": "因此，在我们的方案中，我将把节油归类为兴奋需求。",
  "EN:ZH:The reason for that is for a Ryanair style airline, the customer will be more interested in paying": "原因在于，对于瑞安式的航空公司来说，客户更愿意支付",
  "EN:ZH:low fares.": "低票价。",
  "EN:ZH:They will be less interested in how much polluting this draft is, right?": "他们会对这一草案的污染程度不那么感兴趣，对吗？",
  "EN:ZH:How much so that pollution kind of aspect should be more of excitement feature uh, in case of uh,": "在这种情况下，污染应该是更令人兴奋的特征、",
  "EN:ZH:Ryanair style airline.": "瑞安式航空公司",
  "EN:ZH:So in this case I will move this to excitement uh feature then reliable customer service.": "因此，在这种情况下，我将把它移到 \"令人兴奋 \"部分，然后是 \"可靠的客户服务 \"部分。",
  "EN:ZH:So having a reliable customer service I will say this is a performance rate.": "因此，拥有可靠的客户服务，我会说这是一个绩效率。",
  "EN:ZH:So I categorize it correctly.": "所以我把它归类得很正确。",
  "EN:ZH:Uh expanded route uh network.": "扩大路线网络",
  "EN:ZH:So expanded route network again is a performance need pending dead route network uh means giving connectivity": "因此，扩大路由网络又是一种性能需求，而死路由网络则意味着提供连通性",
  "EN:ZH:to a larger network by connecting to airports where other airlines serve.": "通过与其他航空公司提供服务的机场连接，形成更大的网络。",
  "EN:ZH:And take you from that, uh, one airport to another.": "把你从一个机场带到另一个机场",
  "EN:ZH:Advanced safety features.": "先进的安全功能。",
  "EN:ZH:So having access to advanced safety feature again is a performance need not necessarily a basic need": "因此，获得先进的安全功能又是一种性能需求，而不一定是基本需求",
  "EN:ZH:and hence cabin conform or comfort.": "从而使机舱更加舒适。",
  "EN:ZH:Giving little bit more legroom is again a performance feature.": "腿部空间更宽敞也是一项性能特点。",
  "EN:ZH:So this all this categorization is correct.": "因此，所有这些分类都是正确的。",
  "EN:ZH:Hi all.": "大家好",
  "EN:ZH:Welcome.": "欢迎光临",
  "EN:ZH:Imagine unlocking a powerful tool that not only simplifies computational analysis, but also accelerates": "想象一下，解锁一个功能强大的工具，不仅能简化计算分析，还能加速",
  "EN:ZH:your decision making process.": "您的决策过程。",
  "EN:ZH:Sounds interesting.": "听起来很有趣。",
  "EN:ZH:Let's dive in.": "让我们深入了解一下。",
  "EN:ZH:In this section, we will uncover how to generate draft market segments effortlessly using ChatGPT.": "在本节中，我们将揭示如何使用 ChatGPT 轻松生成细分市场草案。",
  "EN:ZH:A game changer in strategic Planning.": "改变战略规划中的游戏规则。",
  "EN:ZH:Market segmentation is the cornerstone of effective competitor analysis.": "市场细分是有效分析竞争对手的基石。",
  "EN:ZH:It's all about grouping customers with similar needs and preferences to craft targeted strategies that": "这就是将具有相似需求和偏好的客户进行分组，以制定有针对性的战略，这些战略包括",
  "EN:ZH:resonate.": "共鸣。",
  "EN:ZH:ChatGPT serves as your brainstorming partner, helping you quickly draft initial customer segments.": "ChatGPT 可作为您的头脑风暴合作伙伴，帮助您快速起草初始客户细分。",
  "EN:ZH:But here is the key.": "但关键就在这里。",
  "EN:ZH:While this tool can give you a strong starting point, the real magic happens when you refine and customize": "虽然该工具可以为您提供一个强有力的起点，但真正的神奇之处还在于您对其进行完善和定制。",
  "EN:ZH:these drafts to align with your unique product goals and strategic vision.": "这些草案将与您独特的产品目标和战略愿景保持一致。",
  "EN:ZH:Let's explore how you can harness the power of AI to streamline this process and make smarter, faster": "让我们来探讨一下如何利用人工智能的力量来简化这一流程，并更智能、更快速地进行决策",
  "EN:ZH:decisions.": "决定。",
  "EN:ZH:So the first step is to start with a general prompting template.": "因此，第一步是从一般提示模板开始。",
  "EN:ZH:So you can use this general prompting template to generate any artifact which you are producing.": "因此，您可以使用这个通用提示模板来生成您正在制作的任何工件。",
  "EN:ZH:So you can use this template to produce customer personas, market segments, competitor analysis,": "因此，你可以用这个模板来制作客户角色、市场细分和竞争对手分析、",
  "EN:ZH:any artifact on which you are working.": "您正在处理的任何人工制品。",
  "EN:ZH:So the very first step of this prompt template is to define the role or actor, which you want ChatGPT": "因此，该提示模板的第一步就是定义您想要 ChatGPT 的角色或演员",
  "EN:ZH:to play for defining this artifact, for example product manager, management consultant.": "例如产品经理、管理顾问。",
  "EN:ZH:These are the usual roles which do market segmentation or competitor analysis.": "这些通常是进行市场细分或竞争对手分析的角色。",
  "EN:ZH:Then the next step is to give ChatGPT more context about your company, your product or project.": "然后，下一步就是向 ChatGPT 介绍有关贵公司、产品或项目的更多背景信息。",
  "EN:ZH:For example, you are doing market segmentation, let's say for teams or Cisco WebEx, which is a collaboration": "例如，您正在进行市场细分，比方说为团队或 Cisco WebEx（一种协作工具）进行市场细分。",
  "EN:ZH:and communication tool.": "和交流工具。",
  "EN:ZH:So you provide that context to ChatGPT in this step.": "因此，您需要在这一步中向 ChatGPT 提供上下文。",
  "EN:ZH:Then you provide the key skills or education qualification which are relevant to this artifact, which": "然后提供与该职位相关的关键技能或教育资格，其中包括",
  "EN:ZH:are usually part of profiles of people who do these artifacts for competitor analysis, usually they": "通常情况下，为竞争对手进行分析而制作这些人工制品的人，其个人资料的一部分通常是",
  "EN:ZH:say education is MBA in strategy.": "说教育是战略方面的 MBA。",
  "EN:ZH:So we provide the name of the educational qualification and also the key skills for producing this artifact.": "因此，我们提供了教育资格证书的名称，以及制作这一工艺品的关键技能。",
  "EN:ZH:For example, the key skill for producing this artifact is competitor analysis or a market segmentation": "例如，制作这一工具的关键技能是竞争对手分析或市场细分。",
  "EN:ZH:or whatever skills are relevant to producing this artifact.": "或任何与制作这件艺术品相关的技能。",
  "EN:ZH:You list them here.": "你把它们列在这里。",
  "EN:ZH:Then what you do in the next step is you list the names of sections which you want to produce in this": "下一步要做的是，在这里列出你想要制作的部分的名称。",
  "EN:ZH:particular artifact.": "特定的文物。",
  "EN:ZH:For example, if you are doing market segmentation, then the sections can be the name of the segment,": "例如，如果您正在进行市场细分，那么部分可以是细分市场的名称、",
  "EN:ZH:the needs of customers or problems of customers, the size of segment.": "客户的需求或问题、细分市场的规模。",
  "EN:ZH:All of these are various sections within this artifact which you want to produce.": "所有这些都是您要制作的这件艺术品的各个部分。",
  "EN:ZH:Then in the next step, what you do is you name the artifact or framework itself which you want to produce.": "下一步，你要做的就是为你要制作的工件或框架本身命名。",
  "EN:ZH:For example, if you are doing competitor analysis, you provide competitor analysis as the name.": "例如，如果您要进行竞争对手分析，您可以将竞争对手分析作为名称。",
  "EN:ZH:If you are doing market segmentation, you provide market segmentation as the name.": "如果要进行市场细分，就必须提供市场细分的名称。",
  "EN:ZH:And then in these steps you provide any additional information which is relevant for producing the artifact": "然后，在这些步骤中，您可以提供与制作人工制品相关的任何其他信息",
  "EN:ZH:or framework, or you provide the business rules which you want to follow for producing this artifact.": "或框架，或者您提供了制作该工件时希望遵循的业务规则。",
  "EN:ZH:For example, you want the format of the output to be tabular format.": "例如，您希望输出格式为表格格式。",
  "EN:ZH:Or for example, you want all the content which will produce for this particular artifact to be in points.": "例如，您希望为这一特定人工制品制作的所有内容都以点为单位。",
  "EN:ZH:For example, you may want the tone of artifact to be professional.": "例如，您可能希望人工制品的语气专业一些。",
  "EN:ZH:So all those additional information you cover here.": "所以，你在这里介绍的所有这些额外信息。",
  "EN:ZH:So this is the structure of Journal prompt template which you can use for producing any artifact, not": "这就是期刊提示模板的结构，您可以用它来制作任何人工制品，而不是",
  "EN:ZH:just competitor analysis but anything.": "只是竞争对手分析，而不是任何东西。",
  "EN:ZH:For example, if you want to write a email or you want to write minutes of meeting, so you want to": "例如，如果您要撰写电子邮件或会议记录，那么您要",
  "EN:ZH:do a project plan.": "制定项目计划。",
  "EN:ZH:Any artifact you are producing, you can use this journal prompt template, uh, to use as a starting": "您在制作任何艺术品时，都可以使用这个日记提示模板，呃，作为一个起点。",
  "EN:ZH:point for producing the prompt for that artifact.": "点，用于制作该人工制品的提示。",
  "EN:ZH:So the next step is to use this general prompt template to produce the prompt for the artifact which": "因此，下一步就是使用这个通用提示模板为人工制品生成提示，其中包括",
  "EN:ZH:you are producing.": "您正在生产的产品。",
  "EN:ZH:In this case, we will use this general prompt template to produce the prompt for market segmentation.": "在这种情况下，我们将使用这个通用提示模板来制作市场细分的提示。",
  "EN:ZH:So our artifact which we are trying to produce is market segmentation.": "因此，我们要制作的神器就是市场细分。",
  "EN:ZH:And we use this prompt template to generate that prompt for market segmentation.": "我们使用这个提示模板来生成市场细分的提示。",
  "EN:ZH:So key things to note is the wording which is written in black point you.": "因此，需要注意的关键是用黑色字体书写。",
  "EN:ZH:This will usually remain same across uh prompts.": "这在不同的提示中通常保持不变。",
  "EN:ZH:And the wording which is written in red font.": "以及用红色字体书写的字样。",
  "EN:ZH:That will change based on your product, based on your context, based on the artifact you are producing.": "这将根据你的产品、你的环境和你正在生产的产品而改变。",
  "EN:ZH:So let's, uh, try to generate this prompt for market segmentation using this prompt template.": "因此，让我们尝试使用这个提示模板来生成市场细分的提示。",
  "EN:ZH:So the very first step what we are doing is we are defining the role or actor name for this artifact": "因此，我们要做的第一步就是为这一人工制品定义角色或演员名称",
  "EN:ZH:which we want to play.": "我们想玩的游戏。",
  "EN:ZH:So in this particular case we want to play product manager role.": "因此，在这种特殊情况下，我们希望扮演产品经理的角色。",
  "EN:ZH:Then in the next step what we are doing is we are giving more context about the product, project or": "下一步，我们要做的就是提供有关产品、项目或服务的更多背景信息。",
  "EN:ZH:company for which we are producing this artifact.": "我们为其制作这件艺术品的公司。",
  "EN:ZH:So here we are just telling ChatGPT that this artifact which you are producing, it is for a communication": "因此，我们在这里只是告诉 ChatGPT，你们制作的这件艺术品是用于交流的",
  "EN:ZH:and collaboration tool, which is Cisco WebEx.": "和协作工具，即 Cisco WebEx。",
  "EN:ZH:And then in the next step we are defining is the key skill which we want ChatGPT to have and the education": "下一步，我们将确定我们希望 ChatGPT 掌握的关键技能和教育内容。",
  "EN:ZH:qualification.": "资格。",
  "EN:ZH:So we want ChatGPT to have competitor analysis as its key skill or expertise in.": "因此，我们希望 ChatGPT 将竞争对手分析作为其关键技能或专长。",
  "EN:ZH:And we want ChatGPT to have a MBA in strategy from Harvard University.": "我们希望 ChatGPT 拥有哈佛大学战略学 MBA 学位。",
  "EN:ZH:What we are doing is we are identifying the persona of profiles of people who usually produce this artifact,": "我们正在做的是识别通常制作这种艺术品的人的形象特征、",
  "EN:ZH:which is market segmentation.": "这就是市场细分。",
  "EN:ZH:And usually this kind of artifacts are prepared by people who have expertise in computer analysis and": "通常，这类人工制品都是由具有计算机分析专业知识的人员准备的，而且",
  "EN:ZH:who have done MBA in strategy.": "战略专业工商管理硕士。",
  "EN:ZH:Then in this part, what we are doing is we are defining the names of section which we want ChatGPT": "在这一部分中，我们要做的是定义我们希望 ChatGPT 的部分名称",
  "EN:ZH:to produce for this artifact.": "为这一艺术品制作。",
  "EN:ZH:So the names of the section are segment description, customer characteristics, needs, motivation.": "因此，这些部分的名称分别是细分市场描述、客户特征、需求和动机。",
  "EN:ZH:All the sections we are listing here which we want ChatGPT to produce for this artifact.": "我们在此列出了希望 ChatGPT 为该人工制品生成的所有部分。",
  "EN:ZH:Then we are defining the name of artifact itself, In this case, the name of artifact is the segment": "在本例中，工件的名称是线段",
  "EN:ZH:analysis.": "分析。",
  "EN:ZH:Then we are defining any additional rules which we want to follow for producing this artifact.": "然后，我们要定义制作该人工制品所需的其他规则。",
  "EN:ZH:So for example, the market analysis which we are doing is corresponding to the same market as Cisco": "因此，举例来说，我们所做的市场分析与思科的市场分析是相对应的。",
  "EN:ZH:WebEx.": "WebEx.",
  "EN:ZH:Then the other additional rule which we want to follow is that all the sections should be written in": "然后，我们要遵循的另一条补充规则是，所有章节都应以",
  "EN:ZH:points.": "点。",
  "EN:ZH:Then the next rule we want to follow is that each point within the output should not be more than five": "接下来，我们要遵循的规则是，输出中的每个点都不应超过五个",
  "EN:ZH:Then the next rule we want to follow is we want it to perform the segment analysis for the top two segment": "然后，我们要遵循的下一条规则是，我们希望它对前两个分段进行分段分析",
  "EN:ZH:corresponding to this product product.": "与该产品相对应的产品。",
  "EN:ZH:And then we want the output to be in tabular format.": "然后，我们希望以表格格式输出。",
  "EN:ZH:So what we have done in this case is use the Journal prompt template and use it as a starting point": "因此，我们在本例中使用了日志提示模板，并将其作为起点",
  "EN:ZH:to generate a prompt for market segmentation.": "为市场细分提供提示。",
  "EN:ZH:That's what we have done.": "这就是我们所做的。",
  "EN:ZH:This was the next step.": "这是下一步。",
  "EN:ZH:So after this what we'll do is we'll run the prompt which we have drafted in this tab in ChatGPT.": "之后，我们要做的就是运行我们在 ChatGPT 这个选项卡中起草的提示。",
  "EN:ZH:After this, what we'll do is we'll run the prompt which we have drafted in this tab in ChatGPT.": "之后，我们要做的就是运行我们在 ChatGPT 这个选项卡中起草的提示。",
  "EN:ZH:Obviously, you can also copy this prompt and run it inside GDB to produce your own market segmentation": "当然，您也可以复制这个提示并在 GDB 中运行，以生成自己的市场细分结果",
  "EN:ZH:artifact.": "神器。",
  "EN:ZH:Obviously, you need to contextualize it a little bit for your product, for your context, or for the": "很明显，你需要根据你的产品、你的背景或",
  "EN:ZH:work you are doing.": "你正在做的工作。",
  "EN:ZH:You need to contextualize it, but most of it is reusable for you.": "您需要根据具体情况进行调整，但大部分内容都可以重复使用。",
  "EN:ZH:It will be a good starting point for you, most likely if you are producing a first draft.": "如果您正在撰写初稿，这将是一个很好的起点。",
  "EN:ZH:This prompt will be 80% reusable and you might have to change 10 to 20% of it.": "该提示 80% 可以重复使用，您可能需要修改其中的 10% 到 20%。",
  "EN:ZH:So I'm just going to copy it, and then I'll just go to ChatGPT and run this prompt.": "所以我要复制它，然后进入 ChatGPT 并运行这个提示。",
  "EN:ZH:Now I've gone to ChatGPT started a new thread by clicking on this pencil.": "现在，我已进入 ChatGPT，点击这支铅笔开始了一个新的主题。",
  "EN:ZH:I've clicked this new chat.": "我点击了这个新聊天工具。",
  "EN:ZH:Then I'm going to paste it using Ctrl V, pasted the entire prompt which I have walked you through in": "然后，我将使用 Ctrl V 粘贴它，粘贴整个提示信息，我已在",
  "EN:ZH:the last slide, and I've just clicked on this arrow to send it.": "最后一张幻灯片，我刚刚点击了这个箭头来发送它。",
  "EN:ZH:Now ChatGPT started producing the segment analysis for us.": "现在，ChatGPT 开始为我们制作细分市场分析。",
  "EN:ZH:So the next step is we just copy this segment analysis and paste it in the PowerPoint to see how it": "下一步，我们只需复制这个细分分析，然后粘贴到 PowerPoint 中，看看它是如何进行的",
  "EN:ZH:looks like.": "看起来像",
  "EN:ZH:So we'll quickly do that.": "所以，我们很快就能做到这一点。",
  "EN:ZH:And now what I've done is I've just copy pasted the output from ChatGPT for this market segment analysis": "现在，我复制粘贴了 ChatGPT 对这一细分市场分析的输出结果",
  "EN:ZH:in the PowerPoint in the form of a table.": "以表格的形式出现在 PowerPoint 中。",
  "EN:ZH:And what ChatGPT have done, if you look at it carefully, is it have identified two segments.": "如果你仔细观察，就会发现 ChatGPT 已经确定了两个细分市场。",
  "EN:ZH:First is small and medium businesses.": "首先是中小型企业。",
  "EN:ZH:Then second is enterprise level organizations.": "其次是企业级组织。",
  "EN:ZH:And then what is done is based on the sections which we asked it to produce for all those sections it": "然后，根据我们要求它为所有这些部分编制的章节，它",
  "EN:ZH:has produced, uh, the key pointer, for example, the segment description for small and medium businesses": "例如，中小型企业的分部说明",
  "EN:ZH:is business with, uh, less than 500 employees.": "是雇员少于 500 人的企业。",
  "EN:ZH:And then for enterprise level organization, large organization with global presence.": "然后是企业级组织，即在全球开展业务的大型组织。",
  "EN:ZH:Then key characteristic of small and medium businesses is they are sensitive, they are tech savvy,": "中小型企业的主要特点是敏感、精通技术、",
  "EN:ZH:they are more flexible.": "它们更加灵活。",
  "EN:ZH:Whereas the characteristics of large organization is they are structured compliance focused.": "而大型组织的特点是结构严谨，注重合规性。",
  "EN:ZH:multi-department.": "多部门。",
  "EN:ZH:So if you read through it, you will find that this is a pretty high quality output.": "因此，如果你仔细阅读，就会发现这是一个相当高质量的输出。",
  "EN:ZH:And uh, obviously this is a good fit for a first draft.": "显然，这很适合写初稿。",
  "EN:ZH:And then what you can do is you can read this word by word, refine it, contextualize it based on your": "然后，你就可以逐字逐句地阅读，根据自己的情况对其进行提炼和语境化。",
  "EN:ZH:product, based on your market, based on your situation, and validate it based on research, because": "根据您的市场、您的情况来设计产品，并在研究的基础上进行验证，因为",
  "EN:ZH:ChatGPT can do hallucination and produce wrong outputs.": "ChatGPT 会产生幻觉和错误输出。",
  "EN:ZH:Uh, in this segment, what I've done is I've shown you how a general prompt structure template is structured": "在这一部分，我向大家展示了一般提示结构模板的结构",
  "EN:ZH:and how you can use that general prompt template as a starting point to create a prompt for market segments.": "以及如何以通用提示模板为起点，创建细分市场的提示。",
  "EN:ZH:And then I've shown you how to run this prompt for market segments in ChatGPT.": "然后，我向你展示了如何在 ChatGPT 中运行这个细分市场提示。",
  "EN:ZH:And then bring it in the presentation tool or whatever artifact tool you are using.": "然后将其带入演示工具或你正在使用的任何人工制品工具。",
  "EN:ZH:And then you actually refine it, contextualize it based on your context, your need.": "然后，你再根据自己的背景和需求，对它进行实际的提炼和语境化。",
  "EN:ZH:So in Porter's five force model, we have this bargaining power of suppliers, threat of substitutes": "因此，在波特的五力模型中，我们有供应商的讨价还价能力、替代品的威胁",
  "EN:ZH:or products, bargaining power of buyers, threats of new entrants, rivalry among existing competitors.": "或产品、买方的议价能力、新进入者的威胁、现有竞争者之间的竞争。",
  "EN:ZH:So these are the five forces which we analyze in Porter's Five force model.": "这就是我们在波特五力模型中分析的五种力量。",
  "EN:ZH:And we rate them high medium, low based on our analysis.": "根据我们的分析，我们将它们分为高、中、低三个等级。",
  "EN:ZH:And what it does is helps us in understanding the attractiveness of the industry we are trying to enter": "它的作用是帮助我们了解我们试图进入的行业的吸引力",
  "EN:ZH:with our product.": "我们的产品。",
  "EN:ZH:And moreover, each of these forces, that means this industry is more attractive to enter for us.": "此外，每一种力量都意味着这个行业对我们来说更具吸引力。",
  "EN:ZH:So that means more lower.": "因此，这意味着更低的价格。",
  "EN:ZH:The sum of each of these forces are.": "每种力的总和是",
  "EN:ZH:That means there is high profitability in that particular industry, that particular segment.": "这意味着该行业、该细分市场的利润率很高。",
  "EN:ZH:And our chance of becoming successful in that industry is higher, and our chances of making profit": "我们在该行业取得成功的机会更大，我们获利的机会也更大",
  "EN:ZH:is higher.": "较高。",
  "EN:ZH:So, uh, this is the standard prompt structure template.": "这就是标准的提示结构模板。",
  "EN:ZH:And we will use this template as a starting point and apply the parameters specific to Porter's five": "我们将以这一模板为起点，应用波特五项战略的具体参数",
  "EN:ZH:force model to this template to generate a prompt, which can be used for generating Porter's five force": "力模型生成提示，该提示可用于生成波特的五力模型。",
  "EN:ZH:So I've already written a sample prompt for Porter's Five force model.": "因此，我已经编写了波特五力模型的提示样本。",
  "EN:ZH:Let's, uh, see the structure of it.": "让我们来看看它的结构。",
  "EN:ZH:So what I have done is if you look at the, uh, prompting structure template, I have replaced the": "因此，我所做的是，如果你看一下提示结构模板，我已经替换了",
  "EN:ZH:parameters which are given in parentheses with uh, with Porter's five force model parameters.": "括号中用 uh 表示的参数与波特的五力模型参数一致。",
  "EN:ZH:So let's see this already written prompt.": "那么，让我们看看这个已经写好的提示吧。",
  "EN:ZH:The first step is, uh, to make ChatGPT assume the persona of the the role which ChatGPT is going to": "第一步是，让 ChatGPT 承担 ChatGPT 将要扮演的角色的角色。",
  "EN:ZH:play for generating this, uh, model.": "为生成这个模型做准备。",
  "EN:ZH:And in this particular scenario, we are asking ChatGPT to follow the product manager role.": "在这种特殊情况下，我们要求 ChatGPT 遵循产品经理的角色。",
  "EN:ZH:Then in the next step, what we are doing is we are explaining to ChatGPT for what product we are designing": "下一步，我们要做的是向 ChatGPT 解释我们要设计的产品是什么",
  "EN:ZH:this Porter's Five force model.": "波特五力模型",
  "EN:ZH:So in our particular example, we are designing this Porter's Five force model for Amazon style bookselling": "因此，在我们的具体例子中，我们为亚马逊式的图书销售设计了波特五力模型",
  "EN:ZH:website.": "网站。",
  "EN:ZH:And then in the next step, what we are doing is we are telling ChatGPT what are the section we want": "下一步，我们要做的就是告诉 ChatGPT 哪些部分是我们想要的",
  "EN:ZH:it to generate for our model.": "为我们的模型生成。",
  "EN:ZH:So as you all know that Porter's five force model has five forces.": "大家都知道，波特的五力模型有五种力量。",
  "EN:ZH:So what I have done is in this section I have listed all the five forces.": "因此，我在这一部分列出了所有五种力量。",
  "EN:ZH:So for example bargaining power of suppliers, threat of substitutes.": "例如，供应商的议价能力、替代品的威胁。",
  "EN:ZH:So all the five sections of Porter's five force model.": "因此，波特五力模型的所有五个部分都是如此。",
  "EN:ZH:And then in the next step I have described the name of the model itself or the framework which we are": "下一步，我将描述模型本身或框架的名称。",
  "EN:ZH:trying to generate.": "试图产生。",
  "EN:ZH:In this particular example, it is a Porter's Five force model.": "在这个特殊的例子中，它是波特五力模型。",
  "EN:ZH:And then in the next step, I have described the name of original author of this model.": "下一步，我将介绍该模型原作者的姓名。",
  "EN:ZH:In this particular case it is Michael Porter.": "在这个特殊的案例中，他就是迈克尔-波特。",
  "EN:ZH:And then in the next step, what I have done is again, uh, describe the name of product for which": "然后在下一步，我所做的就是再次，呃，描述该产品的名称。",
  "EN:ZH:we are generating this model.": "我们正在生成这个模型。",
  "EN:ZH:So, uh, if you look at it, this is exactly same as, uh, what we did in step two.": "所以，呃，如果你看一下，这和我们在第二步中所做的完全一样。",
  "EN:ZH:So exactly same information, which is Amazon style bookselling website.": "因此，信息完全相同，这就是亚马逊式的图书销售网站。",
  "EN:ZH:Then in next step, what we are doing is we are adding some additional conditions.": "下一步，我们要做的就是添加一些附加条件。",
  "EN:ZH:What we want is we want ChatGPT to generate all the results for each of these five sections as points.": "我们希望 ChatGPT 将这五个部分中的每个部分作为点生成所有结果。",
  "EN:ZH:So that's what we are explaining here.": "这就是我们要解释的。",
  "EN:ZH:Old section should be written in points.": "旧部分应按要点书写。",
  "EN:ZH:And then uh what.": "然后呢",
  "EN:ZH:There is one more additional condition we are giving to ChatGPT here is that we want each of these forces,": "在这里，我们还要给 ChatGPT 附加一个条件，那就是我们需要这些力量中的每一种力量、",
  "EN:ZH:which is bargaining power of suppliers, threat of substitute to be rated as low, medium or high.": "供应商的讨价还价能力、替代品的威胁被评为低、中或高。",
  "EN:ZH:And then again, what I've done is copied the second step again.": "然后，我又复制了第二步。",
  "EN:ZH:So this is how I have structured, uh, this example prompt.": "这就是我的结构，呃，这个提示示例。",
  "EN:ZH:So if you quickly compare it with uh our standard prompting template, what I've done is most of the": "因此，如果将它与我们的标准提示模板进行快速比较，我所做的就是将大部分的",
  "EN:ZH:parameters are same for this main section.": "本主要部分的参数相同。",
  "EN:ZH:So all of these can be mapped 1 to 1.": "因此，所有这些都可以 1 对 1 地映射。",
  "EN:ZH:Basically the role name is Product manager.": "角色名称基本上是产品经理。",
  "EN:ZH:Then here we have described the product.": "在这里，我们对产品进行了描述。",
  "EN:ZH:Then we have described the sections of the framework.": "然后，我们介绍了该框架的各个部分。",
  "EN:ZH:Then we have written the name of framework or model in this case which is Porter's five force model.": "然后，我们写下了框架或模型的名称，即波特的五力模型。",
  "EN:ZH:Then we have written the name of author of this framework.": "然后，我们写下了该框架的作者姓名。",
  "EN:ZH:And then these are main sections till here are the main sections of the template.": "然后这些是主要部分，直到这里是模板的主要部分。",
  "EN:ZH:Then uh, this is the additional section of the template.": "然后，这是模板的附加部分。",
  "EN:ZH:Here uh we have given x additional constraints.": "在这里，我们给出了 x 个额外的约束条件。",
  "EN:ZH:For example, you know the section should be written in points.": "例如，你知道这一部分应该用点来写。",
  "EN:ZH:And uh, something which is very specific to Porter's five forces.": "还有，波特的五种力量中有一些非常特殊的东西。",
  "EN:ZH:That each section should be rated as low, medium, high.": "每个部分应分为低、中、高三个等级。",
  "EN:ZH:So that is also provided as a uh additional information or additional section.": "因此，这也是作为附加信息或附加部分提供的。",
  "EN:ZH:So just one more point.": "所以，还有一点。",
  "EN:ZH:Uh, so in this example prompt for Porter's five force model, most of the structure of this model is": "因此，在波特五力模型的示例提示中，该模型的大部分结构是",
  "EN:ZH:reusable by you.": "您可以重复使用。",
  "EN:ZH:So for example, when you are preparing this 4 to 5 four prompt for your own work, there are certain": "因此，举例来说，当你为自己的作品准备这四到五条提示时，有一些",
  "EN:ZH:sections which you don't need to change.": "无需更改的部分。",
  "EN:ZH:You can just reuse them the way I have written.": "你可以按照我的写法重复使用它们。",
  "EN:ZH:So I'll highlight those section by green.": "因此，我将用绿色突出显示这些部分。",
  "EN:ZH:So for example the first step you can use as it is you don't need to change anything.": "例如，第一步你可以原封不动地使用，不需要做任何改动。",
  "EN:ZH:Then the second step you need to change based on your own product and your own context.": "第二步，你需要根据自己的产品和环境进行改变。",
  "EN:ZH:But the third step which is the sections, all these part are they will remain same for Porter's five": "但第三步，也就是各部分，所有这些部分都将保持不变，即波特的五个",
  "EN:ZH:force model.": "力模型。",
  "EN:ZH:So all this part you don't need to change.": "因此，所有这部分你都不需要改变。",
  "EN:ZH:And then in this step the name of framework will also remain same.": "在这一步中，框架的名称也将保持不变。",
  "EN:ZH:So you don't need to change this.": "所以，你不需要改变这一点。",
  "EN:ZH:Then the name of the author for this framework will also remain same.": "那么该框架的作者姓名也将保持不变。",
  "EN:ZH:But this section will again change and then this one.": "但是，这一部分会再次改变，然后是这一部分。",
  "EN:ZH:If you are doing a presentation, this section will also remain same.": "如果您要做演示，这一部分也将保持不变。",
  "EN:ZH:But if you are doing a more detailed document where you need to write in each section in 30 to 50 words": "但是，如果您要撰写一份更详细的文件，需要用 30 到 50 个字写完每个部分",
  "EN:ZH:or maybe 100 words, in that case, you might change this a little bit.": "或者可能是 100 个单词，在这种情况下，你可以稍微修改一下。",
  "EN:ZH:Then again, this part, this will also remain same for you as long as you are generating a Porter's": "话又说回来，这一部分，只要你正在创建波特公司，就不会改变。",
  "EN:ZH:Five force model.": "五力模式。",
  "EN:ZH:And then the last part, this will change.": "最后一部分，这将会改变。",
  "EN:ZH:So I'm going to highlight the sections which will change for you in yellow color.": "因此，我会用黄色突出显示将为您更改的部分。",
  "EN:ZH:So based on the product and context, this Amazon style book selling website, this section will change": "因此，根据亚马逊式图书销售网站的产品和背景，这部分内容会有所变化",
  "EN:ZH:for you based on your own product.": "根据您自己的产品为您提供服务。",
  "EN:ZH:Then again, this section which is Amazon style book selling website.": "再有，这部分内容是亚马逊式的图书销售网站。",
  "EN:ZH:This will be changed based on your context, based on your product and then this section again this": "这将根据您的上下文、您的产品和本节再次进行更改。",
  "EN:ZH:will change for you.": "会为你而改变。",
  "EN:ZH:So again, to summarize the sections which are in yellow color, they will be changing based on your": "因此，再次总结一下黄色部分，它们将根据您的以下情况而变化",
  "EN:ZH:own context.": "自己的背景。",
  "EN:ZH:The section which are highlighted in green color.": "以绿色突出显示的部分。",
  "EN:ZH:They will remain same for Porter's five force model for you.": "对于波特的五力模型来说，它们将保持不变。",
  "EN:ZH:So now we have already written the prompt for Porter's Five force model.": "现在，我们已经写好了波特五力模型的提示。",
  "EN:ZH:So what we are going to do is we'll just, uh, use this prompt from for generating the output from": "因此，我们要做的就是，呃，使用这个提示来生成来自",
  "EN:ZH:ChatGPT.": "ChatGPT.",
  "EN:ZH:We'll post this prompt to ChatGPT to generate the output.": "我们将向 ChatGPT 发送此提示，以生成输出。",
  "EN:ZH:So now what we are going to do is we are going to use the the prompt which we generated in this example": "现在，我们要做的就是使用在本例中生成的提示信息",
  "EN:ZH:to actually generate the Porter's five force model from ChatGPT.": "从 ChatGPT 中实际生成波特五力模型。",
  "EN:ZH:So I'm going to quickly copy the prompt which we have written.": "所以，我要快速复制我们写好的提示。",
  "EN:ZH:And I'm going to paste it into ChatGPT.": "我要把它粘贴到 ChatGPT 中。",
  "EN:ZH:What I have done is I'm not going to start a new thread.": "我所做的是，我不会启动一个新的主题。",
  "EN:ZH:I'm going to use existing thread.": "我要用现有的线程。",
  "EN:ZH:The reason is I have for this particular product, Amazon style bookstore.": "原因是我为这一特殊产品建立了亚马逊式的书店。",
  "EN:ZH:What I have done is I've already created a thread where I have generated other models as well, and": "我所做的是，我已经创建了一个线程，在其中也生成了其他模型，并且",
  "EN:ZH:that's why I'm going to use the the same existing thread with the same product where I've done the analysis": "这就是为什么我要使用现有的同一产品的同一主题，我已经在那里做了分析",
  "EN:ZH:before.": "之前。",
  "EN:ZH:I'm going to post that and before posting I'll quickly, uh, you know, fix the grammar, uh, in it.": "我要把它贴出来，在贴出来之前，我会很快地，呃，你知道，修正一下语法，呃，里面的语法。",
  "EN:ZH:So send the prompt to ChatGPT has started generating the response.": "因此，向 ChatGPT 发送的提示已开始生成响应。",
  "EN:ZH:So if I look at it, it has started generating, uh, each section.": "所以，如果我看一下，它已经开始生成，呃，每个部分。",
  "EN:ZH:So if you have a quick look at the output which ChatGPT has generated.": "因此，请快速查看 ChatGPT 生成的输出结果。",
  "EN:ZH:They have generated each of the section or forces for example.": "例如，他们生成了每个部分或每种力量。",
  "EN:ZH:Bargaining power of suppliers.": "供应商的议价能力。",
  "EN:ZH:Threat of substitute products.": "替代产品的威胁。",
  "EN:ZH:So each of these section is generated.": "因此，每个部分都是这样产生的。",
  "EN:ZH:Plus it has given a rating of medium to the first section, medium to second, high to third section.": "此外，它还将第一部分评为中等，第二部分评为中等，第三部分评为高等。",
  "EN:ZH:And also it have given the reasoning why it has given a particular rating for this particular section.": "此外，它还给出了对这一特定部分给予特定评级的理由。",
  "EN:ZH:For example, uh, here uh bargaining power of supplier.": "例如，供应商的议价能力。",
  "EN:ZH:It has given a medium rating and it has given the reasons why it is like that.": "它给出了中等评级，并说明了这样做的原因。",
  "EN:ZH:So ChatGPT has generated this output.": "因此，ChatGPT 生成了这样的输出。",
  "EN:ZH:So what I'm going to do is I'm going to quickly copy this output by using this book button and paste": "因此，我要做的是使用这个书本按钮快速复制输出，然后粘贴",
  "EN:ZH:it in the template, which we have for it.": "在我们为它准备的模板中。",
  "EN:ZH:Now what I have done is I've ported the output of that GDP in our template for Porter's five model.": "现在，我把 GDP 的输出结果移植到波特五模型的模板中。",
  "EN:ZH:So I've ported the ratings, uh, for each of the forces.": "因此，我为每支部队都做了评级。",
  "EN:ZH:And then I've ported the reasoning of why ChatGPT has generated those ratings.": "然后，我把 ChatGPT 获得这些评分的原因移植到了这里。",
  "EN:ZH:Also, I've given some color schemes.": "此外，我还提供了一些配色方案。",
  "EN:ZH:So we have given a red color for high rating and then low color for green and amber for medium.": "因此，我们用红色代表高分，用绿色代表低分，用琥珀色代表中分。",
  "EN:ZH:So I've used the standard color coloring which is red amber green.": "因此，我使用了标准色，即红色、琥珀色和绿色。",
  "EN:ZH:And then I've written the ratings.": "然后我就写了评分。",
  "EN:ZH:So in this section, what we will do is it's a hands on session.": "因此，在本节中，我们要做的就是动手操作。",
  "EN:ZH:So if you are attending my course then you will be, uh, working with me to do this exercise, hands": "所以，如果你参加了我的课程，那么你就会和我一起做这个练习，双手",
  "EN:ZH:on.": "上。",
  "EN:ZH:And for that, that the template uh, which is required for uh, you know, writing this response or": "为此，撰写这份答复或",
  "EN:ZH:prompt are already available uh, in, in, in the course which you are referring to.": "在您提到的课程中已经有提示。",
  "EN:ZH:So please work with me step by step on, on this session.": "所以，请和我一起一步一步地完成这个环节。",
  "EN:ZH:Uh, because that's how you're going to, uh, learn it.": "因为这就是你学习的方法",
  "EN:ZH:So in this section, what we will do is generate a list of your story related to a feature.": "因此，在本节中，我们要做的就是生成与某个功能相关的故事列表。",
  "EN:ZH:So what is this section or this problem we are trying to address is many times, uh, you are a scrum": "那么，我们要解决的这部分或这个问题是什么呢？",
  "EN:ZH:master.": "主人",
  "EN:ZH:You're working as scrum master, product owner, product manager, lead business analyst, and you are": "您现在的职务是总监、产品负责人、产品经理、首席业务分析师，而且您正在",
  "EN:ZH:given one feature.": "给定一个特征。",
  "EN:ZH:And what you have to do is you have to break this feature down into, uh, your, uh, your stories.": "你要做的就是把这个功能分解成，呃，你的，呃，你的故事。",
  "EN:ZH:And instead of doing that manually, what we are doing is we are going to use a chat GTP for delivering": "我们将使用聊天 GTP 来传输数据，而不是手动传输。",
  "EN:ZH:this.": "这。",
  "EN:ZH:So this will have three steps.": "因此，这将有三个步骤。",
  "EN:ZH:step.": "步骤。",
  "EN:ZH:The first step is we'll write the prompt for generating the list of your story.": "第一步，我们将编写生成故事清单的提示。",
  "EN:ZH:For this, we will use our standard prompt generating template, which is available in earlier videos": "为此，我们将使用我们的标准提示生成模板，该模板可在前面的视频中找到",
  "EN:ZH:in this course.": "在本课程中。",
  "EN:ZH:Obviously, if you map it back to the ChatGPT framework, what this step is.": "很明显，如果将其映射回 ChatGPT 框架，这一步就是什么。",
  "EN:ZH:In this step we will analyze and understand the task at hand.": "在这一步中，我们将分析和了解当前的任务。",
  "EN:ZH:In this scenario, the task is to generate a set of news story which based on a feature description,": "在这种情况下，任务是根据特征描述生成一组新闻故事、",
  "EN:ZH:and then we will understand it, analyze it, and then we'll drop the prompt based on our understanding": "然后我们会理解它、分析它，然后根据我们的理解放弃提示",
  "EN:ZH:and requirement for for this particular deliverable.": "以及对这一特定交付品的要求。",
  "EN:ZH:Then the next step is we'll use the ChatGPT prompt, which we generated or drafted in last step to run": "下一步，我们将使用上一步生成或起草的 ChatGPT 提示符运行",
  "EN:ZH:it through ChatGPT.": "通过 ChatGPT。",
  "EN:ZH:And then ChatGPT will create the response which is have the A list of your story which we are expecting": "然后 ChatGPT 将创建回复，其中包含我们期待的您的故事的 A 列表",
  "EN:ZH:corresponding to a feature.": "与特征相对应。",
  "EN:ZH:So yeah, so this is what we are going to do in this step.": "所以，这就是我们这一步要做的。",
  "EN:ZH:And then in next step we'll what we'll do is we'll review the response which is generated by chat GTP.": "下一步，我们将查看聊天 GTP 生成的响应。",
  "EN:ZH:And if it is of high quality, we'll contextualize it based on our product context, based on our feature,": "如果它的质量很高，我们就会根据我们的产品背景和功能对其进行语境化处理、",
  "EN:ZH:based on the task at hand, and populate it in our template.": "并将其填充到我们的模板中。",
  "EN:ZH:So yeah.": "所以是的。",
  "EN:ZH:So this is the high level things which we will achieve in session in this slide.": "因此，这就是我们将在本幻灯片中实现的高层次目标。",
  "EN:ZH:What we are going to do is we will work on writing a prompt for the task at hand, which is will write": "我们要做的就是为手头的任务编写提示语，也就是要写出",
  "EN:ZH:a prompt which will convert a feature into a corresponding your story.": "一个提示，它将把一个功能转换成相应的你的故事。",
  "EN:ZH:That's what we are going to do.": "这就是我们要做的。",
  "EN:ZH:So let's go through step by step.": "让我们一步一步来。",
  "EN:ZH:Obviously we are going to use our journal prompt structure template to write this prompt for this particular": "很显然，我们将使用日记提示结构模板来为这个特定的主题编写提示。",
  "EN:ZH:use case.": "使用案例。",
  "EN:ZH:So in the first step what I've done is I've asked ChatGPT to assume the role of product manager.": "所以第一步，我请 ChatGPT 担任产品经理。",
  "EN:ZH:Because product manager tend to do this kind of work, product manager, product owner that they tend": "因为产品经理倾向于做这样的工作，产品经理、产品负责人他们倾向于",
  "EN:ZH:to write identify what are the user stories within a feature.": "来确定功能中的用户故事。",
  "EN:ZH:Then the next step in the prompt is I'm describing the project or product at hand.": "然后，提示的下一步就是我描述手头的项目或产品。",
  "EN:ZH:In this particular case, what we are doing is we are writing this feature for a Amazon style book selling": "在这种特殊情况下，我们要做的是为亚马逊风格的图书销售编写这一功能。",
  "EN:ZH:Then in the next step, what we are doing is we are generating various sections which we want in the": "在下一步中，我们要做的就是生成我们想要在",
  "EN:ZH:response of our prompt.": "我们及时作出反应。",
  "EN:ZH:So in this particular case, we want a list of stories which we want ChatGPT to generate and also corresponding": "因此，在这种特殊情况下，我们需要一个希望 ChatGPT 生成的故事列表，以及相应的",
  "EN:ZH:estimate for each user story.": "每个用户故事的估算。",
  "EN:ZH:And all these stories should be corresponding to the feature which is the book search.": "所有这些故事都应与图书搜索功能相对应。",
  "EN:ZH:So the key idea here is what we want is ChatGPT to generate a list of all the user stories corresponding": "因此，我们希望 ChatGPT 能生成一个与所有用户故事相对应的列表。",
  "EN:ZH:to the book search feature, and we want it to give estimate for each story within this.": "到图书搜索功能，我们希望它能对其中的每个故事进行估算。",
  "EN:ZH:Uh, also, we are telling that this feature is corresponding to the Amazon style book selling website.": "此外，我们还告诉大家，这一功能与亚马逊式的图书销售网站相对应。",
  "EN:ZH:So this is again giving some additional context to the product.": "因此，这再次为产品提供了一些额外的背景信息。",
  "EN:ZH:Then we are not writing the name of uh, framework author.": "那么，我们写的就不是呃，框架作者的名字。",
  "EN:ZH:We are skipping this step.": "我们跳过这一步。",
  "EN:ZH:And then obviously this step we have already done that.": "显然，这一步我们已经完成了。",
  "EN:ZH:We have given the additional context to the product or project.": "我们为产品或项目提供了更多的背景信息。",
  "EN:ZH:And then uh, these are some additional parameters which we are introducing quality parameters or additional": "然后，这些是我们引入的质量参数或附加参数。",
  "EN:ZH:information?": "信息？",
  "EN:ZH:For example, we want each of the user story to follow in principle so that the each of these stories": "例如，我们希望每个用户故事都遵循这样的原则，即每个故事",
  "EN:ZH:are testable, independent of each other.": "是可以检验的，彼此独立。",
  "EN:ZH:And we want the estimates which ChatGPT is going to generate to be in story point.": "我们希望 ChatGPT 生成的估算值以故事点为单位。",
  "EN:ZH:And each story point should be equal to one day.": "每个故事点应相当于一天。",
  "EN:ZH:Also, one additional parameter we have specified is we don't want any of the story to be more than": "此外，我们还指定了一个额外的参数，那就是我们不希望任何故事超过",
  "EN:ZH:seven story point.": "七个故事点。",
  "EN:ZH:The reason for doing that is we want to follow that principle that each story should fit in, fit within": "这样做的原因是，我们希望遵循这样一个原则，即每个故事都应适合，适合于",
  "EN:ZH:a sprint, and assuming if it is a two week sprint, then the maximum size of my thumb rule which we": "如果是两周的冲刺，那么我的拇指规则的最大尺寸是",
  "EN:ZH:can take in sprint is seven story points.": "在冲刺阶段可以获得七个故事点。",
  "EN:ZH:So that's how we have constructed our prompt for this particular use case.": "因此，我们就是这样为这个特殊用例构建提示的。",
  "EN:ZH:The blue font content is the content which you will be contextualizing based on your product and project.": "蓝色字体的内容是您将根据产品和项目进行上下文关联的内容。",
  "EN:ZH:Rest of the content, whether it is in black font or red font, if you are generating a list of your": "其余的内容，不管是黑色字体还是红色字体，如果您正在生成您的",
  "EN:ZH:story corresponding to feature, rest of the steps will most likely remain.": "故事与功能相对应，其余步骤很可能会保留。",
  "EN:ZH:Rest of the prompt will most likely remain same for you.": "其余的提示对您来说很可能保持不变。",
  "EN:ZH:So in this blue font in this one, what you will do is you will explain the context of your project": "因此，在这个蓝色字体中，你要做的就是解释你的项目背景",
  "EN:ZH:or product and or task.": "或产品和或任务。",
  "EN:ZH:And in this one you will name the title of the feature you want ChatGPT to generate stories for.": "在这一项中，您要为希望 ChatGPT 生成故事的功能命名。",
  "EN:ZH:And then you give some additional context of the product here.": "然后你再介绍一下产品的背景。",
  "EN:ZH:And this this step, if you map it back to our framework ChatGPT framework, which we discussed earlier,": "而这一步，如果将其映射回我们之前讨论过的 ChatGPT 框架，就可以实现、",
  "EN:ZH:this step is around like we have analyzed and understood the problem at hand, which is the task here": "这一步就好像我们已经分析并理解了当前的问题，而这正是我们的任务所在",
  "EN:ZH:is to generate a list of your story from a feature title.": "就是根据专题标题生成一个故事列表。",
  "EN:ZH:And then what we have done is we have crafted a ChatGPT prompt for this task.": "然后，我们为这项任务设计了一个 ChatGPT 提示。",
  "EN:ZH:So after this the next step is run this prompt which we have written here in in ChatGPT.": "之后，下一步就是运行我们在 ChatGPT 中编写的提示。",
  "EN:ZH:So what I'm doing is I'm just copying this prompt, going to ChatGPT.": "因此，我要做的就是复制这个提示，转到 ChatGPT。",
  "EN:ZH:And I'm going to start a new chat and pasted this prompt here, and I'm going to run it here.": "我要开始一个新的聊天，并在这里粘贴这个提示，然后在这里运行它。",
  "EN:ZH:So ChatGPT has now generated a new story.": "因此，ChatGPT 现在又产生了一个新的故事。",
  "EN:ZH:So what we are going to do is we'll quickly put these stories to the templates, to the template which": "因此，我们要做的就是快速地将这些故事放到模板中，模板是",
  "EN:ZH:we have already provided.": "我们已经提供。",
  "EN:ZH:Imagine a world where AI not only enhances our capabilities, but also upholds our highest ethical standards": "想象一下，在这个世界上，人工智能不仅能增强我们的能力，还能维护我们的最高道德标准",
  "EN:ZH:as leaders in this transformative era.": "作为这个变革时代的领导者。",
  "EN:ZH:It's our responsibility to ensure that AI systems we deploy are both powerful and principled.": "我们有责任确保我们部署的人工智能系统既强大又有原则。",
  "EN:ZH:Today, we are diving into the core principles of responsible AI guidelines that every leader must understand": "今天，我们将深入探讨每位领导者都必须了解的负责任人工智能指导方针的核心原则",
  "EN:ZH:to navigate this rapidly evolving landscape.": "以驾驭这一快速演变的格局。",
  "EN:ZH:AI has the potential to revolutionize the way we make decisions, solve problems, and innovate.": "人工智能有可能彻底改变我们决策、解决问题和创新的方式。",
  "EN:ZH:But with greater power comes great responsibility.": "但权力越大，责任也越大。",
  "EN:ZH:Without careful consideration, AI can inevitably produce biased, unsafe, or even harmful outcomes.": "如果不经过深思熟虑，人工智能不可避免地会产生有偏见、不安全甚至有害的结果。",
  "EN:ZH:That's why principles of responsible AI are essential.": "因此，负责任的人工智能原则至关重要。",
  "EN:ZH:Let's start with fairness.": "让我们从公平开始。",
  "EN:ZH:AI systems must treat all people equitably without discrimination.": "人工智能系统必须一视同仁地平等对待所有人。",
  "EN:ZH:For instance, imagine a loan approval system trained primarily on data from individuals over 30 years": "例如，设想一个贷款审批系统主要根据 30 年以上的个人数据进行培训",
  "EN:ZH:old if that bias isn't corrected.": "如果不纠正这种偏差，就会变得很老。",
  "EN:ZH:Younger applicants might be unfairly denied loans simply because the AI hasn't been trained on a representative": "年轻的申请者可能会被不公平地拒绝贷款，原因很简单，人工智能还没有经过有代表性的训练",
  "EN:ZH:dataset.": "数据集。",
  "EN:ZH:Ensuring fairness means scrutinizing your data and algorithms to prevent such biases.": "确保公平意味着要仔细检查数据和算法，防止出现此类偏差。",
  "EN:ZH:Promoting equity in every AI driven decision.": "在每个人工智能驱动的决策中促进公平。",
  "EN:ZH:Next is reliability and safety.": "其次是可靠性和安全性。",
  "EN:ZH:AI systems should perform consistently and safely, especially in high stakes scenarios.": "人工智能系统应始终如一地安全运行，尤其是在高风险场景中。",
  "EN:ZH:Take autonomous vehicles, for example.": "以自动驾驶汽车为例。",
  "EN:ZH:If an AI system fails to make a safe decision in a split second, the consequence can be dire and even": "如果人工智能系统未能在一瞬间做出安全决策，后果将不堪设想，甚至是",
  "EN:ZH:fatal.": "致命。",
  "EN:ZH:Thorough testing and continuous monitoring are crucial to ensure these systems operate safely in all": "彻底的测试和持续的监控对于确保这些系统在所有情况下安全运行至关重要。",
  "EN:ZH:conditions.": "条件",
  "EN:ZH:Privacy and security is another crucial principle.": "隐私和安全是另一项重要原则。",
  "EN:ZH:AI systems often rely on vast amounts of data and much of it personal and sensitive.": "人工智能系统通常依赖于大量数据，其中大部分是个人敏感数据。",
  "EN:ZH:It's imperative that this data is not only secured against breaches, but also used in a way that respect": "当务之急是，不仅要确保这些数据的安全，防止数据外泄，而且在使用这些数据时要尊重以下原则",
  "EN:ZH:individuals privacy.": "个人隐私。",
  "EN:ZH:Consider an AI healthcare application that processes patient data.": "考虑一款处理患者数据的人工智能医疗应用。",
  "EN:ZH:If privacy safeguards are not in place, sensitive information could be exposed, leading to serious": "如果隐私保护措施不到位，敏感信息可能会被暴露，导致严重的以下后果",
  "EN:ZH:ethical and legal repercussions.": "伦理和法律影响。",
  "EN:ZH:Inclusiveness is about ensuring AI powers everyone, including those with disabilities or from underrepresented": "包容性是指确保人工智能为每个人提供动力，包括残疾人士或代表人数不足的群体。",
  "EN:ZH:groups.": "团体",
  "EN:ZH:For example, a voice recognition system that only understands certain accents would exclude many users.": "例如，只能听懂某些口音的语音识别系统会将许多用户排除在外。",
  "EN:ZH:Building inclusive AI means designing systems that are accessible and beneficial to a diverse population,": "建立包容性人工智能意味着设计出让不同人群都能使用并从中受益的系统、",
  "EN:ZH:reflecting the true diversity of society.": "反映社会的真正多样性。",
  "EN:ZH:Now let's talk about transparency.": "现在我们来谈谈透明度。",
  "EN:ZH:At any point, users should be able to understand how an AI system arrived at a particular decision.": "在任何时候，用户都应该能够理解人工智能系统是如何做出特定决定的。",
  "EN:ZH:Imagine being denied a loan by an AI driven system, and when you ask why, the process is completely": "想象一下，当你被人工智能驱动的系统拒绝贷款时，当你询问原因时，整个过程却完全是 \"无稽之谈\"。",
  "EN:ZH:opaque.": "不透明。",
  "EN:ZH:This lack of transparency erodes trust.": "这种缺乏透明度的情况削弱了信任。",
  "EN:ZH:Instead, AI systems should provide clear, understandable explanations for their decisions, allowing": "相反，人工智能系统应为其决策提供清晰、易懂的解释，从而使",
  "EN:ZH:users to see the logic behind the outcomes.": "用户可以看到结果背后的逻辑。",
  "EN:ZH:And finally, accountability.": "最后是问责制。",
  "EN:ZH:Whether an AI system makes a good decision or a bad one, there must be a clear accountability.": "无论人工智能系统做出的决定是好是坏，都必须有明确的责任。",
  "EN:ZH:Organization must take responsibility for their AI systems and the outcomes they produce.": "组织必须对其人工智能系统及其产生的结果负责。",
  "EN:ZH:If an AI driven hiring tool leads to discriminatory hiring practices, it's the organization, not the": "如果人工智能驱动的招聘工具导致了歧视性的招聘行为，那是组织的问题，而不是员工的问题。",
  "EN:ZH:AI, that must be held accountable and take corrective action.": "人工智能，必须承担责任并采取纠正措施。",
  "EN:ZH:Incorporating these responsible AI principles fairness, reliability, safety, privacy and security.": "这些负责任的人工智能原则包括公平性、可靠性、安全性、隐私性和安全性。",
  "EN:ZH:Inclusiveness, transparency and accountability into your leadership strategy.": "将包容性、透明度和问责制纳入领导力战略。",
  "EN:ZH:Isn't that about ethical compliance?": "这不就是遵守道德规范吗？",
  "EN:ZH:It's about building AI systems that truly serve and uplift humanity.": "这就是要建立真正服务和提升人类的人工智能系统。",
  "EN:ZH:As leaders, we have the power to guide AI development in a direction that benefits everyone.": "作为领导者，我们有能力引导人工智能朝着有利于每个人的方向发展。",
  "EN:ZH:Let's commit to these principles and lead the way towards a future where AI is a force for good.": "让我们恪守这些原则，引领人工智能走向美好未来。",
  "EN:ZH:Thanks for watching this video on responsible AI principles.": "感谢您观看这段有关负责任的人工智能原则的视频。",
  "EN:ZH:So this is a sample product vision board.": "这就是产品愿景板的样本。",
  "EN:ZH:I have done so.": "我已经这样做了。",
  "EN:ZH:What is this sample vision board about?": "这块愿景板的内容是什么？",
  "EN:ZH:I'm running this product management classes right.": "我正在开办这个产品管理班。",
  "EN:ZH:And uh this is the product which I am selling.": "这就是我要销售的产品。",
  "EN:ZH:And what I have tried to write a product vision board around this product or service offering.": "我曾尝试围绕这一产品或服务撰写产品愿景板。",
  "EN:ZH:So it becomes easy for all of us to understand what I'm trying to do.": "这样大家就很容易理解我的意图了。",
  "EN:ZH:So the vision of this product or service offering, which I'm offering, is help aspiring product owners": "因此，我所提供的产品或服务的愿景是帮助有抱负的产品所有者",
  "EN:ZH:and managers learn and practice product management.": "和管理人员学习和实践产品管理。",
  "EN:ZH:Most people who are actually offering these services, they are just helping in learning it.": "实际上，大多数提供这些服务的人只是在帮助学习。",
  "EN:ZH:But what is the differentiator of my product is I am helping them actually practice product management.": "但我的产品与众不同之处在于，我帮助他们真正实践产品管理。",
  "EN:ZH:So this is where I want to reach, uh, in next let's say two year, five year.": "这就是我想在未来两年或五年内达到的目标。",
  "EN:ZH:That's the vision of this work which I am doing.": "这就是我正在做的这项工作的愿景。",
  "EN:ZH:Who are the target group for this product or service?": "该产品或服务的目标群体是谁？",
  "EN:ZH:first is a product owners product managers, but I will consider aspiring plus early to mid mid level": "首先是产品所有者产品经理，但我也会考虑有抱负的加早期到中期的中层人员",
  "EN:ZH:because it's not like the work we are doing is not just for people who want to be there, who are already": "因为我们所做的工作并不只是为了那些想在那里工作的人，那些已经",
  "EN:ZH:there, but they want to deepen their understanding knowledge.": "但他们希望加深对知识的理解。",
  "EN:ZH:We are catering to those guys as well.": "我们也在迎合这些人的需求。",
  "EN:ZH:So what I'm doing in this target group is I'm clearly identifying who are going to be my target audience,": "因此，我在目标群体中要做的就是明确谁将是我的目标受众、",
  "EN:ZH:who are going to be my target customers, and I'm going to target them only people who are already expert": "谁将是我的目标客户，我将只针对那些已经是专家的人",
  "EN:ZH:in product management.": "在产品管理方面。",
  "EN:ZH:They might not be interested in what I'm I am doing right, because they might be having access to,": "他们可能对我所做的事情不感兴趣，因为他们可能有机会接触到、",
  "EN:ZH:let's say, 30, £50,000, uh, worth of training budget and they can go to high end classes.": "比方说，3、5 万英镑的培训预算，他们可以去上高端课程。",
  "EN:ZH:So our target audience is people who don't have a lot of money, who are already working in some other": "因此，我们的目标受众是那些没有很多钱、已经在其他行业工作的人。",
  "EN:ZH:role, who are studying something else, but they want to move to product ownership or management,": "他们正在学习其他专业，但希望转而从事产品所有权或管理工作、",
  "EN:ZH:which is aspiring.": "这是一种渴望。",
  "EN:ZH:But on the other hand, people who are already product owners or manager, they are early in their career": "但另一方面，那些已经是产品负责人或经理的人，他们在职业生涯初期",
  "EN:ZH:stage or they're in middle of their career stage.": "阶段或正处于职业生涯中期。",
  "EN:ZH:They will also benefit from it because many of these things are are not, are always practiced, even": "他们也会从中获益，因为其中许多事情并不存在，而且一直在实践，甚至",
  "EN:ZH:in big organizations.": "在大组织中。",
  "EN:ZH:So we're trying to align them to the standard product management toolkit.": "因此，我们正试图将它们与标准的产品管理工具包统一起来。",
  "EN:ZH:So this is about target group needs.": "因此，这与目标群体的需求有关。",
  "EN:ZH:Let's see what are the needs.": "让我们看看有哪些需求。",
  "EN:ZH:Learn and practice product management toolkit from an experienced and certified agile coach.": "向经验丰富的认证敏捷教练学习和实践产品管理工具包。",
  "EN:ZH:So what is the need I'm trying to address here?": "那么，我想满足的需求是什么呢？",
  "EN:ZH:Or what is the problem which are my target audience or customers are facing?": "或者，我的目标受众或客户面临的问题是什么？",
  "EN:ZH:So I have not written it as a problem statement.": "所以我没有把它写成问题陈述。",
  "EN:ZH:I've written as a answer to that problem.": "我写这篇文章就是为了解决这个问题。",
  "EN:ZH:The problem we can write in multiple ways.": "我们可以用多种方法来写这个问题。",
  "EN:ZH:One is write the problem.": "一是写出问题。",
  "EN:ZH:Like when we are writing the need, we can write it as a problem if we have to write it as a problem.": "比如我们在写需求时，如果非要把它写成问题，我们可以把它写成问题。",
  "EN:ZH:This needs action.": "这需要行动。",
  "EN:ZH:How will you write that?": "你打算怎么写？",
  "EN:ZH:This is the benefit I'm trying to deliver.": "这就是我要提供的好处。",
  "EN:ZH:Learn and practice product management toolkit from an experienced certified Enterprise Agile Coach.": "向经验丰富的认证企业敏捷教练学习和实践产品管理工具包。",
  "EN:ZH:So just remember each of the words I have written here.": "所以，请记住我在这里写下的每一句话。",
  "EN:ZH:It is for a reason.": "这是有原因的。",
  "EN:ZH:It is there.": "它就在那里。",
  "EN:ZH:I have carefully chosen my words while writing this.": "在写这篇文章时，我仔细斟酌了我的用词。",
  "EN:ZH:See, our needs are.": "看，我们的需求是",
  "EN:ZH:What?": "什么？",
  "EN:ZH:What is the benefit this product is going to provide to the customer or target group?": "该产品将为客户或目标群体带来什么好处？",
  "EN:ZH:That's what we write.": "这就是我们的写作。",
  "EN:ZH:So one way is writing the needs in the form of benefit.": "因此，一种方法是以利益的形式写出需求。",
  "EN:ZH:I have written it already in the form of benefit.": "我已经以福利的形式写了出来。",
  "EN:ZH:One way to write this section is writing in form of benefit, which the customer is going to get.": "撰写这一部分的一种方法是以客户将获得的好处的形式来撰写。",
  "EN:ZH:Another way is write it as a problem, like what is the problem customer is facing?": "另一种方法是把它写成一个问题，比如客户面临的问题是什么？",
  "EN:ZH:If you have to write it as a problem, how to write it?": "如果你必须把它写成一个问题，该怎么写呢？",
  "EN:ZH:I'll, I'll, I'll, I'll explain it with my example.": "我，我，我，我用我的例子来解释一下。",
  "EN:ZH:So one thing is if you look at internet, there is no single place where you can learn product management": "因此，从互联网上看，没有一个地方可以让你学习产品管理。",
  "EN:ZH:or even if you can learn it, is hosting thousands and thousands of pounds.": "即使你能学会，也要花上几千几万英镑。",
  "EN:ZH:So this is one problem I'm trying to solve.": "这就是我想解决的一个问题。",
  "EN:ZH:Another is even if you can learn the theory, there is no a structured way of learning how to practice": "另一个问题是，即使你能学会理论，也没有系统的学习实践方法。",
  "EN:ZH:it with your own hands.": "用自己的双手",
  "EN:ZH:That kind of offering is not available where somebody works with you to actually produce your own product": "在有人与你合作实际生产你自己的产品时，这种服务是不存在的",
  "EN:ZH:management deliverables.": "管理可交付成果。",
  "EN:ZH:And then let's say, even if those kind of stuff are available, people who are teaching this stuff,": "再比方说，即使有了这些东西，教这些东西的人也是如此、",
  "EN:ZH:they have never done product management or they have never worked as agile coach themselves.": "他们从未做过产品管理，或者他们自己从未担任过敏捷教练。",
  "EN:ZH:What they are doing is they are read some material and started talking about it.": "他们所做的就是阅读一些材料，然后开始讨论。",
  "EN:ZH:That is another kind of problem.": "这是另一种问题。",
  "EN:ZH:Then the fourth problem is even if they know the stuff, they are not certified.": "第四个问题是，即使他们知道这些东西，他们也没有经过认证。",
  "EN:ZH:So this is various kind of problems I am trying to address using this benefit.": "这就是我想利用这项福利解决的各种问题。",
  "EN:ZH:So this is the way I have written this section is I've written the benefit.": "因此，我是这样写这一部分的，我写的是好处。",
  "EN:ZH:But other way of writing it is you write what the problems your customers are facing.": "但另一种写法是，你要写出客户面临的问题。",
  "EN:ZH:What are the those gaps in the market.": "市场上有哪些空白点？",
  "EN:ZH:And you write those gaps as needs.": "你把这些差距写成需求。",
  "EN:ZH:So this is another example.": "这是另一个例子。",
  "EN:ZH:Let's go to the product section.": "让我们转到产品部分。",
  "EN:ZH:So what the product section does is.": "因此，产品部分的作用是",
  "EN:ZH:What is the product list.": "产品清单是什么？",
  "EN:ZH:The 3 to 5 key features of the product.": "产品的 3 至 5 个主要特点。",
  "EN:ZH:So one of the key feature for the product we are offering is virtual live hands on session.": "因此，我们提供的产品的一个主要特点就是虚拟现场实践课程。",
  "EN:ZH:So this is one of the key feature.": "因此，这也是其中一个主要特点。",
  "EN:ZH:Then I have this.": "然后是这个。",
  "EN:ZH:Communities are on WhatsApp telegram and I have a YouTube channel.": "我在 WhatsApp 电报和 YouTube 频道上建立了社区。",
  "EN:ZH:So this is another key feature which my product is offering.": "因此，这也是我的产品提供的另一个关键功能。",
  "EN:ZH:Then the fourth feature is I provide guidance as well as templates for product management.": "第四个特点是，我为产品管理提供指导和模板。",
  "EN:ZH:So these are the three key features I am offering using this service.": "这就是我使用这项服务的三个主要特点。",
  "EN:ZH:Then what are the business goal I am trying to achieve?": "那么，我要实现的业务目标是什么？",
  "EN:ZH:Uh first one is develop our brands.": "首先是发展我们的品牌。",
  "EN:ZH:Again, this business goal are from the perspective of the organization or the person who is who is": "同样，这一业务目标也是从组织或个人的角度出发的。",
  "EN:ZH:developed this product offering.": "开发了这一产品。",
  "EN:ZH:So develop our brand and open a new revenue stream.": "因此，发展我们的品牌，开辟新的收入来源。",
  "EN:ZH:So these are the two business goal I am trying to achieve.": "这就是我要实现的两个商业目标。",
  "EN:ZH:So this is a sample of how to do a product vision board.": "这就是如何制作产品愿景板的示例。",
  "EN:ZH:So what I have done is I have created a business model canvas for Airbnb.": "因此，我为 Airbnb 创建了一个商业模式画布。",
  "EN:ZH:Let's go through the sections by sequence.": "让我们按顺序介绍一下各部分。",
  "EN:ZH:So the first section, who are your customers?": "那么第一部分，谁是你的客户？",
  "EN:ZH:So in this section for Airbnb I have identified two segments of customers travelers within travelers.": "因此，在本节中，我为 Airbnb 确定了两类客户，即旅行者中的旅行者。",
  "EN:ZH:Uh, there are two sub segments tourists and business travelers.": "游客和商务旅客是两个细分市场。",
  "EN:ZH:Then there are hosts who are the property owners or people who host their property on Airbnb.": "然后是房东，即房产所有者或在 Airbnb 上托管其房产的人。",
  "EN:ZH:So that the guests can, uh, use those properties.": "这样，客人就可以使用这些财产了。",
  "EN:ZH:So let's move on to the next one.": "那我们继续下一个。",
  "EN:ZH:So value proposition in value proposition.": "因此，价值主张中的价值主张。",
  "EN:ZH:What is Airbnb?": "Airbnb 是什么？",
  "EN:ZH:It's a startup.": "这是一家初创公司。",
  "EN:ZH:What they do is they match people who are looking for, uh, short term accommodation with the people": "他们所做的就是为寻找短期住宿的人牵线搭桥。",
  "EN:ZH:who have their rooms, uh, available for short term.": "他们的房间可以短期使用。",
  "EN:ZH:So they match these two, two kind of people.": "因此，他们将这两种人匹配起来。",
  "EN:ZH:So the people who are interested in renting the rooms with hosts, and that I own a digital platform.": "因此，有兴趣与房东一起租房的人，就会知道我拥有一个数字平台。",
  "EN:ZH:That's their main, uh, main business.": "这就是他们的主要业务。",
  "EN:ZH:They are very, very popular in India, Europe, uh, us.": "它们在印度、欧洲和我们这里都非常非常受欢迎。",
  "EN:ZH:And their market capitalization is more than the biggest, uh, hotel, uh, chain in the world.": "他们的市值超过了世界上最大的连锁酒店。",
  "EN:ZH:I think Marriott is the biggest hotel chain in the world.": "我认为万豪是世界上最大的连锁酒店。",
  "EN:ZH:And if you look at Marriott hotel chain, their market capitalization is less than Airbnb.": "如果你看看万豪连锁酒店，他们的市值还不如 Airbnb。",
  "EN:ZH:And the interesting thing is about Airbnb's, they don't own any property.": "有趣的是，Airbnb 并不拥有任何房产。",
  "EN:ZH:So any of the property which you rent on Airbnb is not owned by Airbnb themselves.": "因此，您在 Airbnb 上租用的任何房产都不归 Airbnb 所有。",
  "EN:ZH:They are owned by the host.": "它们归主机所有。",
  "EN:ZH:So due to this special characteristic, they are as uh light asset model.": "因此，由于这种特殊性，它们被称为轻资产模型。",
  "EN:ZH:Light asset model means they don't either don't own any physical asset or very light or very little": "轻资产模式是指他们不拥有任何实物资产，或拥有的实物资产很少或很轻",
  "EN:ZH:physical assets, because if you compare Airbnb with their physical brick and mortar kind of competitor,": "因为如果把 Airbnb 与他们的实体竞争者进行比较的话、",
  "EN:ZH:it is.": "就是这样。",
  "EN:ZH:Marriott Hotels and Marriott Hotels own thousands of hotels across the world.": "万豪酒店集团和万豪酒店在全球拥有数千家酒店。",
  "EN:ZH:And another key characteristic of Airbnb is a two sided marketplace.": "Airbnb 的另一个主要特点是双面市场。",
  "EN:ZH:So why it is called two sides?": "那么，为什么叫两面呢？",
  "EN:ZH:Because one side they have these, uh, travelers, uh, which are tourists or business travelers who": "因为一边是游客，一边是商务旅行者。",
  "EN:ZH:are looking for, uh, renting property on the other side, Airbnb, other customers of Airbnb are people": "在另一边，Airbnb 的其他客户也在寻找租房服务。",
  "EN:ZH:who want to rent their properties on Airbnb platform.": "他们希望在 Airbnb 平台上出租自己的房产。",
  "EN:ZH:So both of them are, uh, their customers.": "所以这两个人都是他们的客户。",
  "EN:ZH:And that's why it's called two sided marketplace.": "这就是它被称为双面市场的原因。",
  "EN:ZH:Let's, uh, dive into value proposition.": "让我们来谈谈价值主张。",
  "EN:ZH:So what is the value you deliver to your customer?": "那么，您为客户提供的价值是什么？",
  "EN:ZH:That's what we capture here.": "这就是我们在这里捕捉到的。",
  "EN:ZH:What is the customer need that your value proposition address.": "您的价值主张要满足的客户需求是什么？",
  "EN:ZH:So these are four key needs which Airbnb is addressing unique accommodation options.": "以上就是 Airbnb 解决独特住宿选择的四个关键需求。",
  "EN:ZH:So the kind of accommodation you will get on Airbnb, you will not get them from hotel chains like Marriott": "因此，你在 Airbnb 上获得的住宿，不是万豪等连锁酒店能提供的。",
  "EN:ZH:or other competitors of their.": "或他们的其他竞争对手。",
  "EN:ZH:For example, let's say you want to experience a tree house or you want to, uh, stay on in a tent": "比如说，您想体验树屋，或者想住在帐篷里",
  "EN:ZH:near the beach, or you want to go and stay in in a jungle or hut or outhouse for for a week or two.": "或者您想在海滩附近的丛林、小屋或外屋住上一两个星期。",
  "EN:ZH:So that kind of experience are very, very unique to Airbnb.": "因此，这种体验对于 Airbnb 来说是非常、非常独特的。",
  "EN:ZH:They are not offered by other competitors of Airbnb.": "Airbnb 的其他竞争对手不提供这些服务。",
  "EN:ZH:Then, uh, cost effective lodging.": "然后，呃，经济实惠的住宿。",
  "EN:ZH:So because the properties which are rented on Airbnb, most of them are serviced by the owners themselves": "因此，在 Airbnb 上出租的房产，大部分都由房主自己提供服务",
  "EN:ZH:and they don't tend to have any employee.": "而且他们往往没有雇员。",
  "EN:ZH:And many times these properties are empty rooms.": "而这些房产很多时候都是空房。",
  "EN:ZH:So let's say someone is a couple who are living in a three bedroom house and they don't use, most of": "比方说，有一对夫妇住在一套三居室的房子里，他们大部分时间都不用",
  "EN:ZH:the time, one of their room in this three bedroom house.": "当时，他们住在这栋三居室房子里的一个房间里。",
  "EN:ZH:So they they rent 1 or 2 room of theirs when they actually don't need it on Airbnb platform, due to": "因此，他们在 Airbnb 平台上租下了自己的 1 或 2 个房间，而实际上他们并不需要这些房间，原因是",
  "EN:ZH:which, in usual circumstances, this room would have been empty.": "而在通常情况下，这个房间是空的。",
  "EN:ZH:So due to which the cost ah which is incurred by many of these hosts for creating this, uh, available": "因此，许多主机为创建这种可用性而产生的成本啊",
  "EN:ZH:rooms is very, very low.": "房间数量非常非常少。",
  "EN:ZH:That's why it is cost effective lodging.": "这也是住宿成本低的原因。",
  "EN:ZH:This is another proposition they offer then the trust and safety.": "这是他们提供的信任和安全的另一个主张。",
  "EN:ZH:So how they achieve this trust and safety is by allocating various ratings to the tourists as well as": "因此，他们是如何实现这种信任和安全的，就是通过为游客分配各种评级以及",
  "EN:ZH:the host.": "主机。",
  "EN:ZH:So using this five star rating method they help in building that trust.": "因此，使用这种五星评级方法有助于建立信任。",
  "EN:ZH:Uh, in in in the community.": "在社区里",
  "EN:ZH:So this is value proposition then.": "这就是价值主张。",
  "EN:ZH:Uh, let's go to the third, uh, the channels which, uh, Airbnb used uh, for reaching their customer.": "第三，Airbnb 用来接触客户的渠道。",
  "EN:ZH:Ah, they have their own website, which is web 2.0.": "啊，他们有自己的网站，这是 web 2.0。",
  "EN:ZH:They have their own mobile app on iOS Us and on Android they use social media for for promoting their": "他们在 iOS Us 和 Android 上都有自己的移动应用程序，并利用社交媒体来推广自己的产品。",
  "EN:ZH:advertisement and all that.": "广告什么的。",
  "EN:ZH:They use social media, for example.": "例如，他们使用社交媒体。",
  "EN:ZH:They promote themselves on Facebook, YouTube, all these platforms, and they also promote themselves": "他们在 Facebook、YouTube 等平台上宣传自己，同时也宣传自己",
  "EN:ZH:on partner websites.": "在合作伙伴网站上。",
  "EN:ZH:So these are the various channels they use.": "这些就是他们使用的各种渠道。",
  "EN:ZH:The first two they use for almost everything, whether it is advertising, sales and delivery and the": "前两者几乎用于所有方面，无论是广告、销售还是送货，而后两者则用于所有方面。",
  "EN:ZH:last two one, they are using more for generating leads or advertisements.": "最后两个是，他们更多地将其用于产生线索或广告。",
  "EN:ZH:So this is about channels.": "这就是渠道的问题。",
  "EN:ZH:Uh, let's go to the fourth section which is customer relationship.": "第四部分是客户关系。",
  "EN:ZH:So what relationship does each customer segment expect to establish and maintain.": "那么，每个客户群期望建立和维护怎样的关系呢？",
  "EN:ZH:So what are the various relationship they maintain with various customers.": "那么，他们与不同客户之间保持着怎样的关系呢？",
  "EN:ZH:They use these online bookings.": "他们使用这些在线预订。",
  "EN:ZH:They use reviews and ratings.": "他们使用评论和评级。",
  "EN:ZH:Uh they use customer support and host.": "呃，他们使用客户支持和主机。",
  "EN:ZH:And they have this uh communication between host and guest.": "他们在主人和客人之间进行这种沟通。",
  "EN:ZH:So they have some in-app messaging, which can be used between host and guest for communicating between": "因此，他们有一些应用程序内的消息，可用于主人和客人之间的交流。",
  "EN:ZH:each other.": "彼此。",
  "EN:ZH:So these are the four key customer relationship they are managing.": "这就是他们管理的四种主要客户关系。",
  "EN:ZH:Reviews and ratings.": "评论和评分。",
  "EN:ZH:Both host as well as the traveler can provide reviews and ratings to each other, right?": "东道主和旅行者都可以互相提供评论和评分，不是吗？",
  "EN:ZH:Based on the experience of host and traveler with each other, they provide rating to each other.": "根据东道主和旅行者彼此的经验，他们为对方提供评级。",
  "EN:ZH:Customer support is available to both parties, including the host as well as the travelers, and then": "双方（包括东道主和旅行者）都可获得客户支持，然后",
  "EN:ZH:the online bookings which the travelers can do.": "旅客可以进行在线预订。",
  "EN:ZH:So these are the four relationship channels then revenue streams.": "这就是四种关系渠道和收入流。",
  "EN:ZH:So these are the key revenue streams of Airbnb on how their customer reward them.": "以上就是 Airbnb 如何回报客户的主要收入来源。",
  "EN:ZH:The first is service fees.": "首先是服务费。",
  "EN:ZH:So one of the method is they charge service fees to both host and from guest for for host they charge": "因此，其中一种方法是他们同时向房东和客人收取服务费。",
  "EN:ZH:service fees for this are for successful bookings and to guest they charge a service fee in the form": "服务费是针对成功预订的客人收取的，他们向客人收取服务费的形式是",
  "EN:ZH:of cleaning fees or booking fees or different different kind of fees.": "清洁费、预订费或各种不同的费用。",
  "EN:ZH:Then, uh, they charge some host commission fee as well, which tend to be a percentage of the room": "然后，呃，他们还会收取一些房东佣金，通常是房间的一定比例",
  "EN:ZH:rent.": "租。",
  "EN:ZH:Then, uh, advertising and promotion, they, they charge the hosts for advertising and promoting their": "然后，呃，广告和推广，他们，他们向主持人收取广告和推广他们的",
  "EN:ZH:rooms if they want to promote in special categories.": "房间，如果他们想在特殊类别中进行推广。",
  "EN:ZH:So these are the key revenue streams.": "因此，这些都是主要的收入来源。",
  "EN:ZH:Then let's go to the sixth, uh, section key resources.": "然后让我们来看第六部分，呃，关键资源。",
  "EN:ZH:So what are the key resources needed by Airbnb to deliver their value proposition so that this first": "那么，Airbnb 需要哪些关键资源来实现他们的价值主张，从而使这第一家",
  "EN:ZH:one is the technology platform?": "一个是技术平台？",
  "EN:ZH:One key point to remember here is they are using the word technology platform here.": "需要记住的一个要点是，他们在这里使用了技术平台一词。",
  "EN:ZH:They're not using the word iOS app or Android app.": "他们没有使用 iOS 应用程序或 Android 应用程序这个词。",
  "EN:ZH:Why?": "为什么？",
  "EN:ZH:Because all the technological components together is considered as technology platform, which includes": "因为所有技术组件都被视为技术平台，其中包括",
  "EN:ZH:their iOS app or Android app.": "他们的 iOS 应用程序或安卓应用程序。",
  "EN:ZH:Their website, all the technology assets which are backing this Airbnb experience, all of them together": "他们的网站、支持 Airbnb 体验的所有技术资产，所有这些加在一起",
  "EN:ZH:are considered as technology platform.": "被视为技术平台。",
  "EN:ZH:Then the second key resource they have, uh, is the hosted properties.": "他们拥有的第二个关键资源是托管财产。",
  "EN:ZH:The properties which are hosted by the host on their platform.": "主机在其平台上托管的属性。",
  "EN:ZH:Then the user data, how the users are using their apps, how uh, they are, which kind of rooms they": "然后是用户数据，用户如何使用他们的应用程序，他们是如何使用的，他们使用哪种房间",
  "EN:ZH:are booking, what are the various areas which are hotspots for booking in various areas?": "在预订时，哪些方面是各地区的预订热点？",
  "EN:ZH:How much rent the customer is ready to pay.": "客户准备支付多少租金。",
  "EN:ZH:All that kind of data is, uh, is is the asset or key resource for Airbnb because it helps them in": "所有这些数据都是 Airbnb 的资产或关键资源，因为这些数据有助于他们",
  "EN:ZH:optimizing the prices for a particular property, for a particular area, for a particular city.": "优化特定房产、特定区域和特定城市的价格。",
  "EN:ZH:Then the next key resource, uh, important resource for them is the brand and the reputation.": "然后，他们的下一个关键资源，呃，重要资源就是品牌和声誉。",
  "EN:ZH:Section seven is key activities.": "第七部分是关键活动。",
  "EN:ZH:What are the key activities they perform every day to deliver value through their proposition to their": "他们每天都在开展哪些关键活动，通过他们的主张为客户创造价值？",
  "EN:ZH:What are those?": "那些是什么？",
  "EN:ZH:Perform development and maintenance.": "进行开发和维护。",
  "EN:ZH:So this perform development and maintenance is about our development maintenance of their technology": "因此，这种性能开发和维护是关于我们对其技术的开发维护。",
  "EN:ZH:platform.": "平台。",
  "EN:ZH:So they keep adding new new features to their existing technology platform.": "因此，他们不断在现有技术平台上增加新的功能。",
  "EN:ZH:They if there is some problem in existing features they do the maintenance of those.": "如果现有功能出现问题，他们会进行维护。",
  "EN:ZH:Then uh, marketing and user acquisition.": "然后是营销和用户获取。",
  "EN:ZH:So they keep doing, uh, marketing to lure more customers.": "因此，他们不断进行营销，以吸引更多顾客。",
  "EN:ZH:So remember in case of Airbnb, they have two kind of customers because they are two sided marketplace.": "因此，请记住，就 Airbnb 而言，他们有两种客户，因为他们是双面市场。",
  "EN:ZH:So they have to continue to lure the travelers who are going to do the bookings.": "因此，他们必须继续吸引旅客进行预订。",
  "EN:ZH:On the other side, they have to continue to lure the hosts who are going to host their properties on": "另一方面，他们还必须继续吸引主机商在以下网站上托管他们的物业",
  "EN:ZH:their platform.": "他们的平台。",
  "EN:ZH:So this user acquisition or marketing is for both kind of, uh, customers, both for travelers as well": "因此，这种用户获取或市场营销既针对客户，也针对旅行者。",
  "EN:ZH:as host, then quality assurance and trust building.": "然后是质量保证和建立信任。",
  "EN:ZH:What is quality assurance?": "什么是质量保证？",
  "EN:ZH:So in case any hosts who are not properly maintaining their properties and renting on Airbnb, they": "因此，如果有房东没有妥善维护自己的房产并在 Airbnb 上出租，他们",
  "EN:ZH:have their own mechanism to remind them that improve your standards of your property.": "有自己的机制来提醒他们，提高您的物业标准。",
  "EN:ZH:Otherwise it will be removed.": "否则将被删除。",
  "EN:ZH:They also use this rating mechanism review mechanism from host side and traveler side to improve those": "他们还利用这种评级机制，从东道方和旅行方的角度进行审查，以改进那些",
  "EN:ZH:quality, uh, to give feedback to both sides of parties.": "质量，嗯，给双方的反馈。",
  "EN:ZH:That way they improve the quality of, uh, the experience which the traveler is going to get.": "这样，他们就能提高旅行者的体验质量。",
  "EN:ZH:Also, they help, uh, the host in improving the quality of experience is going to have with the customer": "此外，它们还能帮助主机提高客户体验的质量。",
  "EN:ZH:and the help building the trust as well, because when the product which the traveler is going to use,": "这也有助于建立信任，因为当旅行者要使用产品时、",
  "EN:ZH:it is actually going to be what is advertised.": "它实际上会和广告上说的一样。",
  "EN:ZH:Then there will be more trust in the in the community.": "这样，社区就会更加信任我们。",
  "EN:ZH:And the next key activity is the customer support.": "下一个关键活动是客户支持。",
  "EN:ZH:So these are the key activities which Airbnb perform.": "以上就是 Airbnb 开展的主要活动。",
  "EN:ZH:So this was section seven key partners.": "因此，这是七个主要合作伙伴的部分。",
  "EN:ZH:How who are the key partners.": "主要合作伙伴是谁。",
  "EN:ZH:What we how we decide what are the key partners.": "我们如何决定哪些是关键合作伙伴。",
  "EN:ZH:Why we can't do all of these things ourselves.": "为什么我们不能自己做这些事？",
  "EN:ZH:The reason is as a business, we should be concentrating on our strength.": "原因在于，作为一家企业，我们应该集中精力发展自己的优势。",
  "EN:ZH:What is my strength?": "我的力量是什么？",
  "EN:ZH:Uh, so that I can make more money by putting less effort, by creating less headache, less problem": "呃，这样我就可以通过减少努力、减少头痛、减少问题来赚更多的钱了",
  "EN:ZH:for me.": "对我来说",
  "EN:ZH:Based on that principle, you decide who are going to be your key partners.": "根据这一原则，你要决定谁是你的主要合作伙伴。",
  "EN:ZH:So, uh, the first key partner for Airbnb is host.": "因此，Airbnb 的第一个关键合作伙伴是房东。",
  "EN:ZH:Who are the property owners?": "业主是谁？",
  "EN:ZH:So just think if instead of Airbnb, if you were doing this business model canvas for Marriott hotel,": "所以，试想一下，如果你不是在做 Airbnb，而是在做万豪酒店的商业模式画布、",
  "EN:ZH:right.": "对",
  "EN:ZH:Marriott hotels are also doing the same business but in a different way.": "万豪酒店也在做同样的生意，但方式不同。",
  "EN:ZH:What will happen in case of merit?": "如果有功，会发生什么情况？",
  "EN:ZH:Uh, hotels.": "酒店",
  "EN:ZH:This host will not be key partners, right?": "这位主人不会是关键合作伙伴吧？",
  "EN:ZH:Property owners.": "业主",
  "EN:ZH:These will not be key partners because most of the property they have in Marriott hotels, they are": "他们不会成为主要合作伙伴，因为他们在万豪酒店拥有的大部分财产都是",
  "EN:ZH:owned by themselves.": "自己拥有。",
  "EN:ZH:And also their customer segment will not be hosts.": "他们的客户群也不会是主机。",
  "EN:ZH:Because most of the properties are owned by them.": "因为大部分房产都归他们所有。",
  "EN:ZH:The next one is the India.": "下一个是印度。",
  "EN:ZH:You have the UPI and the Google pay all those.": "你有 UPI 和 Google 支付所有这些。",
  "EN:ZH:Then tourism and travel agencies they need to get in some countries and places they need to get licenses": "然后是旅游和旅行社，他们需要在一些国家和地方获得许可证",
  "EN:ZH:from them.": "从他们那里。",
  "EN:ZH:Then the government authorities who provide the regulatory compliance.": "然后是提供监管合规性的政府部门。",
  "EN:ZH:The next point, uh, ninth section is the cost structure.": "下一点，呃，第九部分是成本结构。",
  "EN:ZH:So what are the important cost which you incur to deliver your value proposition?": "那么，要实现自己的价值主张，有哪些重要的成本呢？",
  "EN:ZH:So in case of Airbnb they are technology infrastructure marketing, advertising, customer support,": "因此，就 Airbnb 而言，它们是技术基础设施、市场营销、广告和客户支持、",
  "EN:ZH:legal and regulatory compliance and employee salary.": "遵守法律法规和员工工资。",
  "EN:ZH:So these are the key costs which uh Airbnb in a.": "这些就是 Airbnb 的主要成本。",
  "EN:ZH:Hello and welcome to this video on creating a ChatGPT prompt template for crafting PowerPoint outlines.": "大家好，欢迎观看本视频，了解如何创建用于制作 PowerPoint 大纲的 ChatGPT 提示模板。",
  "EN:ZH:In this session, I will walk you through a versatile prompt template designed to help you generate": "在本课中，我将向您介绍一个多功能提示模板，旨在帮助您生成",
  "EN:ZH:comprehensive outlines for your PowerPoint presentations.": "为您的 PowerPoint 演示文稿提供全面的大纲。",
  "EN:ZH:Whether you're a project manager, management consultant, marketer, or any other professional, this": "无论您是项目经理、管理顾问、营销人员还是其他任何专业人士，这本",
  "EN:ZH:prompt template can be tailored to your specific role and domain.": "提示模板可根据您的特定角色和领域进行定制。",
  "EN:ZH:Additionally, it can be configured to address a specific topic of your presentation, be it banking,": "此外，它还可以针对演讲的特定主题进行配置，如银行业、",
  "EN:ZH:insurance, or any other industry.": "保险或任何其他行业。",
  "EN:ZH:Now let's dive in into how this template is structured.": "现在，让我们深入了解一下该模板的结构。",
  "EN:ZH:Two key points to note here.": "这里有两个要点需要注意。",
  "EN:ZH:First, the text in black font is generic and will remain consistent across most presentations.": "首先，黑色字体的文本是通用的，在大多数演示文稿中都会保持一致。",
  "EN:ZH:Second, the text in red font called within the brackets is where you will make specific changes depending": "其次，括号内红色字体的文本是您要做具体更改的地方，具体取决于",
  "EN:ZH:on your presentation, topic, and audience.": "取决于您的演讲、主题和听众。",
  "EN:ZH:In the first part of the prompt, we start by defining the role or actor name of the presenter, where": "在提示的第一部分，我们首先要定义主持人的角色或演员名称，其中",
  "EN:ZH:we instruct ChatGPT to assume the perspective of the person who is presenting the presentation.": "我们指示 ChatGPT 假设演示者的视角。",
  "EN:ZH:For example, if you are a project manager, management consultant or a senior executive like a CEO": "例如，如果您是项目经理、管理顾问或首席执行官等高级管理人员",
  "EN:ZH:or CFO, you will satisfy that role here.": "或首席财务官，您在这里就能胜任这一角色。",
  "EN:ZH:In the next step, we will provide the context about the company, product or project for which you": "下一步，我们将为您提供有关公司、产品或项目的背景信息。",
  "EN:ZH:are preparing this presentation.": "正在准备本介绍。",
  "EN:ZH:This helps better understand the background and the context of this presentation.": "这有助于更好地了解本介绍的背景和来龙去脉。",
  "EN:ZH:Following this will inform ChatGPT that it is an expert in creating PowerPoint presentations.": "这样，ChatGPT 就会知道自己是制作 PowerPoint 演示文稿的专家。",
  "EN:ZH:This is a crucial step as it activates ChatGPT specialized expertise in structuring effective presentation": "这是至关重要的一步，因为它激活了 ChatGPT 在构建有效演示方面的专业知识",
  "EN:ZH:outlines.": "概述。",
  "EN:ZH:Next, we'll ask GDP to generate the outline based on a specific topic.": "接下来，我们将要求 GDP 根据特定主题生成大纲。",
  "EN:ZH:For instance, if your presentation is on the use of AI in insurance industry, you would replace the": "例如，如果您要介绍人工智能在保险业中的应用，您可以将 \"人工智能 \"替换为 \"保险\"。",
  "EN:ZH:placeholder text with the actual topic name.": "占位符文本与实际主题名称。",
  "EN:ZH:Then we focus on the intended goal of this presentation.": "然后，我们重点讨论本次演讲的预期目标。",
  "EN:ZH:Here we are defining the intent in code.": "在这里，我们用代码来定义意图。",
  "EN:ZH:What is the purpose of this presentation and what outcomes are we trying to achieve by delivering this": "本演示文稿的目的是什么？",
  "EN:ZH:presentation to continue with the example of AI in insurance.": "继续以保险业的人工智能为例进行介绍。",
  "EN:ZH:You might be delivering this presentation to help senior leaders or managers within an insurance company": "您可以通过本演示文稿帮助保险公司的高级领导或管理人员",
  "EN:ZH:to understand how AI can be implemented in their operations.": "以了解如何在其运营中实施人工智能。",
  "EN:ZH:This context ensures that GDP generates an outline that aligns with your presentation's objective.": "这种上下文确保 GDP 生成的大纲与您的演示目标相一致。",
  "EN:ZH:Next, we specify the target audience for this presentation.": "接下来，我们要明确本演示文稿的目标受众。",
  "EN:ZH:Is it senior management or middle managers or junior team members?": "是高层管理人员、中层管理人员还是基层团队成员？",
  "EN:ZH:All that audience is captured here and define the audience ensures that outline is tailored to their": "所有受众都在这里被捕获，定义受众可确保大纲是为他们量身定制的。",
  "EN:ZH:level of understanding and interest.": "理解程度和兴趣。",
  "EN:ZH:After identifying the audience, we instruct that GDP on the number of slides we want in the presentation.": "在确定受众之后，我们向 GDP 说明我们希望在演示中使用的幻灯片数量。",
  "EN:ZH:This can vary based on the depth of the topic, the audience we are presenting to, or the ask of our": "这可能会根据主题的深度、我们的演讲对象或我们的要求而有所不同。",
  "EN:ZH:managers who have asked us to present this presentation.": "请我们作此介绍的管理人员。",
  "EN:ZH:For example, you might ask for a five slide, ten slide, or 15 slide presentation depending on your": "例如，您可以要求制作 5 张幻灯片、10 张幻灯片或 15 张幻灯片的演示文稿，具体取决于您的",
  "EN:ZH:needs.": "需要。",
  "EN:ZH:We also define the tone of the presentation.": "我们还确定了演示文稿的基调。",
  "EN:ZH:Should it be formal or informal?": "是正式还是非正式？",
  "EN:ZH:Professional or perhaps humorous setting, the tone is essential for delivering a presentation that": "在专业或幽默的环境中，基调对演讲至关重要，因为它能让人感受到",
  "EN:ZH:resonates with your audience.": "与受众产生共鸣。",
  "EN:ZH:Then we instruct ChatGPT to create one slide per section of the presentation, with each slide capturing": "然后，我们指示 ChatGPT 为演示文稿的每个部分创建一张幻灯片，每张幻灯片捕捉以下内容",
  "EN:ZH:the key points relevant to that section.": "与该部分相关的要点。",
  "EN:ZH:Next, we highlight any specific points or topics that must be covered.": "接下来，我们会强调必须涵盖的具体要点或主题。",
  "EN:ZH:For instance, in an AI presentation, you might want to emphasize ethical considerations or key use": "例如，在人工智能演示中，您可能要强调伦理方面的考虑或关键用途",
  "EN:ZH:cases.": "案件",
  "EN:ZH:These instructions ensure that the outline includes the critical elements you want to cover.": "这些说明可确保提纲包含您希望涵盖的关键要素。",
  "EN:ZH:Finally, we include a section for additional information or rules that GDP should follow when generating": "最后，我们还加入了一个部分，以提供更多信息或规则，供 GDP 在生成数据时遵循。",
  "EN:ZH:the outline of the presentation.": "发言提纲。",
  "EN:ZH:This allows for any final customization needed to suit your unique requirements.": "这样就可以根据您的独特要求进行最终定制。",
  "EN:ZH:To summarize, the red font sections are customizable based on your needs, while the backbone serves": "总之，红色字体部分可根据您的需求进行定制，而骨干部分则用于",
  "EN:ZH:as the foundation for any presentation outline you create using this prompt.": "作为您使用此提示创建演示大纲的基础。",
  "EN:ZH:Thank you for watching this video and I hope you found this walkthrough helpful.": "感谢您观看本视频，希望本攻略对您有所帮助。",
  "EN:ZH:I look forward to seeing you in my next video.": "我期待着在下一个视频中看到你。",
  "EN:ZH:Hello and welcome to this video.": "大家好，欢迎收看本视频。",
  "EN:ZH:In this video, we'll learn how to write a ChatGPT prompt specifically for drafting an outline for a": "在本视频中，我们将学习如何撰写 ChatGPT 提示，专门用于起草一份",
  "EN:ZH:presentation.": "介绍。",
  "EN:ZH:We will build on existing template that we have developed for creating PowerPoint outlines, and apply": "我们将以现有的用于创建 PowerPoint 大纲的模板为基础，应用",
  "EN:ZH:it to a real world presentation scenario.": "将其应用到现实世界的演示场景中。",
  "EN:ZH:The goal here is to help you understand how to craft a prompt that guides ChatGPT in generating a structured": "这里的目标是帮助您了解如何制作提示，引导 ChatGPT 生成结构化的",
  "EN:ZH:outline for your presentation.": "发言提纲。",
  "EN:ZH:In this example, we will be focusing on a presentation about exploring opportunities for AI in the": "在本示例中，我们将重点介绍在以下领域探索人工智能机遇的演示文稿",
  "EN:ZH:insurance sector.": "保险业。",
  "EN:ZH:I'll walk you through the process of using this existing prompt template to craft an outline for this": "我将教你如何使用这个现有的提示模板来为这篇文章拟定提纲。",
  "EN:ZH:In this scenario, imagine I am a management consultant advising an insurance company.": "在这种情况下，假设我是一名管理顾问，为一家保险公司提供咨询。",
  "EN:ZH:My client has requested a presentation that explains how AI can be leveraged in the insurance industry.": "我的客户要求我介绍如何在保险业利用人工智能。",
  "EN:ZH:The presentation will be aimed at senior management and junior staff members to help them understand": "讲座将面向高级管理层和初级工作人员，帮助他们了解",
  "EN:ZH:AI potential in their day to day operations.": "人工智能在日常运营中的潜力。",
  "EN:ZH:With that context in mind, the aim of this video is to demonstrate how to write a ChatGPT prompt for": "有鉴于此，本视频旨在演示如何为以下内容编写 ChatGPT 提示语",
  "EN:ZH:defining the outline for presentation for this specific use case.": "为这一特定用例确定演示大纲。",
  "EN:ZH:Let's dive in to this process.": "让我们深入了解这一过程。",
  "EN:ZH:On the left hand side of your screen, you will see a basic prompt template for generating presentation": "在屏幕左侧，您将看到一个用于生成演示文稿的基本提示模板",
  "EN:ZH:This is a general template that can be used for a wide range of presentations.": "这是一个通用模板，可用于各种演示。",
  "EN:ZH:Our task is to modify this template so that it fits the specific topic of AI in insurance sector, while": "我们的任务是修改该模板，使其适合保险业人工智能这一特定主题，同时",
  "EN:ZH:also tailoring it to our audience.": "同时也为我们的受众量身定做。",
  "EN:ZH:Let's break down how to use this template.": "让我们来分析一下如何使用这个模板。",
  "EN:ZH:The first step is to instruct ChatGPT to take on the role of presenter.": "第一步是指示 ChatGPT 扮演主持人的角色。",
  "EN:ZH:In this case, the presenter is a management consultant who is preparing to deliver the presentation.": "在本例中，主讲人是一名管理顾问，正在准备发表演讲。",
  "EN:ZH:This ensures that ChatGPT creates content from the point of view of that role, using its knowledge": "这可以确保 ChatGPT 从角色的角度出发，利用其知识创建内容",
  "EN:ZH:about this role as well as expertise.": "关于这一角色的专业知识。",
  "EN:ZH:Next, we need to provide a description of the company or industry for which the presentation is being": "接下来，我们需要提供一份关于公司或行业的介绍。",
  "EN:ZH:prepared.": "准备好了",
  "EN:ZH:In our example, the presentation is for an insurance company.": "在我们的例子中，演示对象是一家保险公司。",
  "EN:ZH:So we specify that here.": "因此，我们在此具体说明。",
  "EN:ZH:This step adds important context for ChatGPT to work with.": "这一步骤为 ChatGPT 添加了重要的工作背景。",
  "EN:ZH:The next two lines in the template remains unchanged.": "模板中接下来的两行保持不变。",
  "EN:ZH:They inform ChatGPT that it is an expert in creating PowerPoint presentations.": "他们告诉 ChatGPT，它是制作 PowerPoint 演示文稿的专家。",
  "EN:ZH:This reinforces its ability to structure an effective outline.": "这就加强了其构建有效提纲的能力。",
  "EN:ZH:Following that, we ask ChatGPT to generate an outline for the presentation.": "然后，我们请 ChatGPT 生成演讲提纲。",
  "EN:ZH:In the next step, we clearly state the topic that is exploring opportunities for AI in the insurance": "下一步，我们将明确提出在保险业探索人工智能机遇的主题",
  "EN:ZH:sector.": "部门。",
  "EN:ZH:This gives the AI a concrete focus for generating the structure of the presentation.": "这就为人工智能提供了生成演示结构的具体重点。",
  "EN:ZH:Next, we define the presentations goal or purpose.": "接下来，我们要确定演示文稿的目标或宗旨。",
  "EN:ZH:In this case, our goal is to introduce the audience to the current AI landscape and explain how AI": "在这种情况下，我们的目标是向听众介绍当前的人工智能形势，并解释人工智能如何",
  "EN:ZH:can be applied within the insurance industry.": "可应用于保险业。",
  "EN:ZH:The desired outcome is to help the audience, both senior managers and junior staff, understand how": "预期成果是帮助受众（包括高级管理人员和基层员工）了解如何",
  "EN:ZH:AI can be integrated into their daily work processes.": "人工智能可以融入他们的日常工作流程。",
  "EN:ZH:We then define the target audience, which in our example consists of middle management and junior staff": "然后，我们确定目标受众，在我们的例子中，目标受众包括中层管理人员和基层员工",
  "EN:ZH:in the insurance company.": "保险公司。",
  "EN:ZH:By identifying the audience that GDP can create a presentation that is appropriate for their level of": "通过确定受众，GDP 可以设计出适合他们水平的演示文稿。",
  "EN:ZH:expertise.": "专业知识。",
  "EN:ZH:Next, we specify the number of slides needed in this presentation.": "接下来，我们指定该演示文稿所需的幻灯片数量。",
  "EN:ZH:For example, we will instruct HTTP to generate ten slides, but this number can be adjusted based on": "例如，我们将指示 HTTP 生成十张幻灯片，但这一数字可以根据以下情况进行调整",
  "EN:ZH:your needs.": "您的需求。",
  "EN:ZH:Since this is a corporate presentation, we have chosen a formal tone which is typical for business": "由于这是一次企业演讲，我们选择了商务演讲中常用的正式语调。",
  "EN:ZH:environments.": "环境。",
  "EN:ZH:However, depending on your needs, you could choose a more informal or conversational tone.": "不过，您也可以根据自己的需要，选择更加非正式或对话式的语气。",
  "EN:ZH:The next part of the template remains unchanged.": "模板的下一部分保持不变。",
  "EN:ZH:Here we ask ChatGPT to create one slide per section, ensuring each slide covers the key point of that": "在此，我们要求 ChatGPT 为每个部分制作一张幻灯片，确保每张幻灯片都能涵盖该部分的关键点。",
  "EN:ZH:section.": "节。",
  "EN:ZH:Then we specify the points we want to cover.": "然后，我们指定要覆盖的点。",
  "EN:ZH:For instance, in this example, we may want to address ethical use of AI in insurance, AI use cases,": "例如，在这个例子中，我们可能想讨论人工智能在保险业中的伦理应用、人工智能用例、",
  "EN:ZH:and potential benefits AI can offer to the insurance industry.": "以及人工智能为保险业带来的潜在好处。",
  "EN:ZH:This ensures that the generated outline includes all the crucial points for the presentation.": "这可确保生成的大纲包含演示文稿的所有关键要点。",
  "EN:ZH:Finally, we can provide additional instructions.": "最后，我们还可以提供其他说明。",
  "EN:ZH:For example, we might ask ChatGPT to add any other relevant points specific to AI's roles in the insurance": "例如，我们可能会要求 ChatGPT 添加与人工智能在保险中的作用有关的任何其他相关要点",
  "EN:ZH:This allows for flexibility and ensures that the presentation outline is comprehensive.": "这样做既有灵活性，又能确保演示大纲的全面性。",
  "EN:ZH:That's the final step in structuring our ChatGPT prompt for creating a presentation outline.": "这就是我们构建 ChatGPT 提示创建演示大纲的最后一步。",
  "EN:ZH:After we have crafted the prompt, we can run it through ChatGPT and see the results.": "制作好提示符后，我们就可以通过 ChatGPT 运行它并查看结果了。",
  "EN:ZH:What we expect to receive is an outline that organizes the content into sections, each with its own": "我们期望收到的是一份大纲，它将内容分为若干部分，每部分都有自己的",
  "EN:ZH:slides and each slide having the key points included in it.": "幻灯片，每张幻灯片都包含要点。",
  "EN:ZH:And that's how you can use ChatGPT to generate a presentation outline.": "这就是如何使用 ChatGPT 生成演示大纲。",
  "EN:ZH:I hope this tutorial has been helpful.": "希望本教程对你有所帮助。",
  "EN:ZH:Thank you for watching.": "感谢您的收看。",
  "EN:ZH:I will see you in the next video.": "我们下期视频再见。",
  "EN:ZH:Welcome to this video.": "欢迎观看本视频。",
  "EN:ZH:In this video we are going to generate a presentation outline using ChatGPT.": "在本视频中，我们将使用 ChatGPT 生成演示大纲。",
  "EN:ZH:And for that what we are going to do is in the last video we generated a prompt for generating this": "为此，我们要做的是在上一个视频中生成一个提示，用于生成以下内容",
  "EN:ZH:presentation outline using GTP.": "使用 GTP 编写演示大纲。",
  "EN:ZH:We are going to use that prompt and run it in ChatGPT to generate a PowerPoint outline using ChatGPT.": "我们将使用该提示并在 ChatGPT 中运行它，以使用 ChatGPT 生成 PowerPoint 大纲。",
  "EN:ZH:So the first step for doing that is you open a browser window and go to that GTP.": "因此，第一步就是打开浏览器窗口，进入 GTP。",
  "EN:ZH:So you go to ChatGPT by typing ChatGPT Openai.com.": "输入 ChatGPT Openai.com，即可访问 ChatGPT。",
  "EN:ZH:Obviously you need a account for logging into ChatGPT.": "显然，您需要一个账户来登录 ChatGPT。",
  "EN:ZH:I am assuming you already have a ChatGPT account if you don't have it.": "如果您还没有 ChatGPT 帐户，我想您已经有了。",
  "EN:ZH:Uh, I have another video on how to create account and login, so I'm skipping all that step for now.": "关于如何创建账户和登录，我有另一个视频，所以暂时跳过这一步。",
  "EN:ZH:And now we have reached, uh, the state GDP.": "现在我们已经达到了，呃，国家的 GDP。",
  "EN:ZH:And what we are going to do is we are going to start this new chat window and it will open this new": "我们要做的就是启动这个新的聊天窗口，然后打开这个新的",
  "EN:ZH:chat for us, and we'll go to this message section, uh, of GDP.": "我们将转到 GDP 的留言区。",
  "EN:ZH:And we'll just, uh, paste the prompt which we created in our uh, last lecture for generating, uh,": "我们只需粘贴我们在上次讲座中创建的生成提示、",
  "EN:ZH:this PowerPoint outline.": "本 PowerPoint 大纲。",
  "EN:ZH:So this is the prompt which we wrote in our last lecture.": "这就是我们在上次讲座中写的提示。",
  "EN:ZH:We are going to copy this prompt.": "我们要复制这个提示。",
  "EN:ZH:And paste it in this chat window and uh run it in chat GDP.": "然后粘贴到这个聊天窗口，并在聊天 GDP 中运行。",
  "EN:ZH:And let's see what GDP does with it.": "让我们看看 GDP 会怎么做。",
  "EN:ZH:Chat GDP has Https started, uh, defining the outline for this prompt, and it has generated the title": "聊天 GDP 已开始 Https，呃，为这一提示定义大纲，并生成了标题",
  "EN:ZH:slide.": "幻灯片",
  "EN:ZH:It is saying title is Exploring opportunities for AI in the insurance Sector, generated a subtitle": "标题是《探索保险业的人工智能机遇》，副标题是",
  "EN:ZH:which is understanding How AI can Transform Your Work.": "这就是了解人工智能如何改变你的工作。",
  "EN:ZH:Then, uh, it has generated a slide number two, which is introduction to AI in insurance.": "然后，呃，它生成了第二张幻灯片，介绍保险中的人工智能。",
  "EN:ZH:And slide number three, the AI landscape in insurance.": "第三张幻灯片是人工智能在保险业的应用。",
  "EN:ZH:And it has added points in each of these slides.": "在每张幻灯片中，它都增加了一些要点。",
  "EN:ZH:For example in this one it has added definition of artificial intelligence and its components including": "例如，在这本书中，它增加了人工智能的定义及其组成部分，包括",
  "EN:ZH:machine learning language natural language processing etc. and dusty.": "机器学习语言自然语言处理等。",
  "EN:ZH:Overview.": "概述。",
  "EN:ZH:Then it has created the next slide key use cases in insurance.": "然后，它创建了下一张幻灯片中的关键保险用例。",
  "EN:ZH:Then it has created the next slide AI in underwriting and risk management.": "然后，它在承保和风险管理方面创造了下一个人工智能幻灯片。",
  "EN:ZH:Then the next slide is AI in customer service and experience.": "下一张幻灯片是人工智能在客户服务和体验方面的应用。",
  "EN:ZH:Ethical consideration of AI in insurance.": "保险业人工智能的伦理考量。",
  "EN:ZH:Challenges and limitations of AI in In insurance, which are data quality, availability issues, integration": "人工智能在保险业中的挑战和局限性，包括数据质量、可用性问题、整合",
  "EN:ZH:challenges with legacy system, then future trends and opportunities.": "然后是未来的趋势和机遇。",
  "EN:ZH:Conclusion and call to action.": "结论和行动呼吁。",
  "EN:ZH:And in that, it is showing us a recap of AI's potential to transform insurance operations, encouraging": "在此过程中，它向我们展示了人工智能改变保险业务的潜力，鼓励我们",
  "EN:ZH:staff to identify opportunities where AI can be applied.": "工作人员确定可以应用人工智能的机会。",
  "EN:ZH:Next steps and Q&A.": "接下来的步骤和问答。",
  "EN:ZH:So all this outline and the key points within outlines looks good to me.": "因此，在我看来，所有这些提纲和提纲中的要点都很好。",
  "EN:ZH:Uh, I think what one point is missing is it hasn't added any case studies to the outline.": "呃，我觉得有一点没有说清楚，那就是大纲中没有增加任何案例研究。",
  "EN:ZH:So I'm just going to go ahead and ask it to, uh, write some case studies for us.": "所以，我打算请它为我们写一些案例研究。",
  "EN:ZH:So I've already written a prompt for that.": "因此，我已经为此写好了提示。",
  "EN:ZH:Uh, let me add you add that prompt here.": "让我在这里加上提示。",
  "EN:ZH:Also, one thing I've noticed is the quality of the content which is generated by, uh, Our GDP for": "此外，我还注意到一点，那就是我们的 GDP 所生成的内容的质量。",
  "EN:ZH:this presentation outline is really good.": "这份演示提纲非常好。",
  "EN:ZH:Uh, but when you are doing your work, what you are going to do is you are going to review all these": "呃，但是当你做你的工作时，你要做的就是审查所有这些",
  "EN:ZH:points and change the points, uh, based on your needs, based on, uh, if you have designed some": "根据你的需要，改变点数，如果你设计了一些",
  "EN:ZH:point wrongly due to hallucination, you fix all those points while reviewing it.": "由于幻觉而错误的点，你在复习时会修正所有这些点。",
  "EN:ZH:So I'm going to ask ChatGPT that this is great.": "所以我要问 ChatGPT，这很棒。",
  "EN:ZH:Why I'm doing that is basically I'm telling it that ChatGPT you are going in the right direction.": "我这样做的目的基本上是告诉它，ChatGPT 你的方向是正确的。",
  "EN:ZH:Uh, so that it understands that it has to continue going in the same direction.": "嗯，这样它就会明白，它必须继续朝着同一个方向前进。",
  "EN:ZH:That's why I'm saying it is great.": "这就是我说它很棒的原因。",
  "EN:ZH:And further, I'm asking it to add, uh, two case studies in the above outline.": "此外，我还要求在上述大纲中增加两个案例研究。",
  "EN:ZH:And, uh, I'm also asking that each case study should be added per slide.": "而且，我还要求每张幻灯片都要添加案例研究。",
  "EN:ZH:So what I'm hoping by this point is it will add two more slides and each slide will have its own case": "因此，我希望此时能增加两个幻灯片，每个幻灯片都有自己的外壳",
  "EN:ZH:study.": "研究。",
  "EN:ZH:So if you look at here, what I started doing is it has started rewriting the outline again and seems": "所以，如果你看看这里，我开始做的事情就是再次重写大纲，而且似乎",
  "EN:ZH:to have added two uh, case studies, uh, to it.": "增加了两个案例研究。",
  "EN:ZH:So let's see again.": "让我们再来看看。",
  "EN:ZH:So in slide number five it has added a case study AI in claims processing at Lemonade Insurance.": "因此，在第五张幻灯片中，它添加了一个柠檬水保险公司的人工智能理赔案例。",
  "EN:ZH:Then in slide number seven it has added case study two AI in fraud detection at risk insurance.": "然后在第七张幻灯片中添加了案例研究二：人工智能在风险保险欺诈检测中的应用。",
  "EN:ZH:So all this, uh, looks nicer to me.": "所以这一切，呃，在我看来更美好。",
  "EN:ZH:Uh, so in this video, what I want you to do is ask ChatGPT to generate a outline for us.": "在本视频中，我要你做的就是让 ChatGPT 为我们生成一个大纲。",
  "EN:ZH:So that's great.": "所以这很好。",
  "EN:ZH:Um, so thanks for watching this video and see you in the next video.": "感谢您观看本视频，下期视频再见。",
  "EN:ZH:In this video I'm going to show you how to, uh, uh, port, uh, the outline which is generated by": "在本视频中，我将向您展示如何移植由",
  "EN:ZH:chat GTP into, uh, PowerPoint using VBA.": "使用 VBA 在 PowerPoint 中聊天 GTP。",
  "EN:ZH:So let's see the steps for that.": "让我们来看看具体步骤。",
  "EN:ZH:So I already have already made a prompt for it.": "因此，我已经为它做了一个提示。",
  "EN:ZH:Uh, I'll add that prompt and ask that GTP to generate the VBA code for it.": "我会添加该提示，并要求 GTP 为其生成 VBA 代码。",
  "EN:ZH:So don't worry about it.": "所以不用担心。",
  "EN:ZH:For this, you don't need to know the VBA.": "为此，您不需要了解 VBA。",
  "EN:ZH:What you need to know is the prompt which I'm going to write, and that will be available to you through": "您需要知道的是我要写的提示，您可以通过以下方式获得该提示",
  "EN:ZH:this video.": "此视频。",
  "EN:ZH:Also, what you need to know is the steps on how to, uh, use that, uh, VBA code to, uh, add the": "此外，您还需要知道如何使用 VBA 代码添加\"...... \"的步骤。",
  "EN:ZH:content, um, in the PowerPoint.": "内容，嗯，在 PowerPoint 中。",
  "EN:ZH:So I have a existing written, uh, prompt, which is write VBA code to turn the outline above into": "因此，我有一个现有的书面提示，即编写 VBA 代码，将上面的大纲转化为",
  "EN:ZH:PowerPoint slides include code for each slide.": "PowerPoint 幻灯片包括每张幻灯片的代码。",
  "EN:ZH:Do not add a command to save the presentation, and do not add a command to close the presentation.": "不要添加保存演示文稿的命令，也不要添加关闭演示文稿的命令。",
  "EN:ZH:Why we have written this prompt like this is because once we have generated the VBA code, uh.": "为什么我们要这样写这个提示，因为一旦我们生成了 VBA 代码，呃。",
  "EN:ZH:Uh, and we have added the uh, content to the PowerPoint, we might want to, uh, tweak certain things": "我们已将内容添加到 PowerPoint 中，可能需要对某些内容进行调整",
  "EN:ZH:in the PowerPoint before, uh, saving it.": "在保存 PowerPoint 之前。",
  "EN:ZH:That's why I've written the prompt like this.": "这就是我这样写提示的原因。",
  "EN:ZH:So let's run this.": "那么，让我们运行这个。",
  "EN:ZH:If you see here ChatGPT has started writing the VBA code for the entire PowerPoint outline.": "在这里，您可以看到 ChatGPT 已经开始为整个 PowerPoint 大纲编写 VBA 代码。",
  "EN:ZH:It will take some time for ChatGPT to generate the entire VBA code.": "ChatGPT 生成整个 VBA 代码需要一些时间。",
  "EN:ZH:It continued to generate that.": "它继续产生这种效果。",
  "EN:ZH:So now we have the VBA code.": "现在我们有了 VBA 代码。",
  "EN:ZH:What we are going to do is we are going to do copy code from here.": "我们要做的是从这里复制代码。",
  "EN:ZH:And we are going to open our desktop PowerPoint app and basically add it there.": "我们将打开桌面 PowerPoint 应用程序，并在其中添加它。",
  "EN:ZH:So the next step here is we go to our desktop PowerPoint app.": "因此，下一步就是进入桌面 PowerPoint 应用程序。",
  "EN:ZH:And we start that PowerPoint app.": "然后启动 PowerPoint 应用程序。",
  "EN:ZH:And what we need is in the PowerPoint app we need the developer tab for uh starting this.": "在 PowerPoint 应用程序中，我们需要 \"开发者 \"选项卡来启动这个程序。",
  "EN:ZH:And for the developer tab to be present.": "开发人员选项卡也要存在。",
  "EN:ZH:Uh, we need an additional developer tab here for uh, adding the VBA in this case.": "在这里，我们需要一个额外的开发人员选项卡来添加 VBA。",
  "EN:ZH:So for that what we need to do is we need to add it.": "因此，我们需要做的就是添加它。",
  "EN:ZH:So for that first step is to go to files.": "因此，第一步就是查阅档案。",
  "EN:ZH:Then within that go to options.": "然后进入选项。",
  "EN:ZH:Then within that we have to navigate to Customize Ribbon.": "然后，我们必须导航到 \"自定义功能区\"。",
  "EN:ZH:And then from Customize Ribbon you have to go to developer and then check the developer section from": "然后从 \"自定义功能区 \"转到 \"开发人员\"，再从 \"开发人员 \"部分选中 \"开发人员\"。",
  "EN:ZH:here.": "这里。",
  "EN:ZH:And then click on okay.": "然后点击 \"好的\"。",
  "EN:ZH:So by doing that what you see is a new developer tab is added here.": "这样，你会看到这里添加了一个新的开发人员选项卡。",
  "EN:ZH:So now we go to this developer tab.": "现在，我们进入 \"开发者 \"选项卡。",
  "EN:ZH:Then we click on this Visual Basic.": "然后点击 Visual Basic。",
  "EN:ZH:The uh the first one within Visual Basic uh we go to this uh insert module.": "在 Visual Basic 中的第一个模块是插入模块。",
  "EN:ZH:And within that you have this downside arrow.": "在这个箭头中，还有一个向下的箭头。",
  "EN:ZH:We click on down arrow and click on module.": "我们点击向下箭头，然后点击模块。",
  "EN:ZH:So we started a new module.": "因此，我们启动了一个新模块。",
  "EN:ZH:And here we are going to place the VBA code which we uh had in our uh GDP.": "在这里，我们将放置我们在 GDP 中的 VBA 代码。",
  "EN:ZH:Uh so this is the VBA code we generated in GDP.": "这是我们在 GDP 中生成的 VBA 代码。",
  "EN:ZH:We copy this VBA code and then we paste it here in the module section.": "我们复制这段 VBA 代码，然后粘贴到模块部分。",
  "EN:ZH:And once we have pasted it there is a this run sub button.": "粘贴完成后，会出现一个运行子按钮。",
  "EN:ZH:We run that.": "我们运行它。",
  "EN:ZH:Once you run it you are seeing that, uh, converted our, um, uh, VBA code into a presentation.": "运行后，你就会看到我们将 VBA 代码转换成了演示文稿。",
  "EN:ZH:So in this what we did is we first generated the outline, uh, using ChatGPT, and then we use ChatGPT": "在这里，我们首先使用 ChatGPT 生成大纲，然后使用 ChatGPT",
  "EN:ZH:to, uh, convert the presentation outline to VBA code.": "将演示大纲转换为 VBA 代码。",
  "EN:ZH:And then we, uh, put the VBA code in developer section in a new module in PowerPoint and convert it": "然后，我们将 VBA 代码放入 PowerPoint 中一个新模块的开发人员部分，并将其转换为",
  "EN:ZH:into a PPT.": "制作成 PPT。",
  "EN:ZH:So you can see, uh, this is now available.": "所以，你可以看到，呃，这个现在可以用了。",
  "EN:ZH:And let's see, uh, how, uh, it is looking like.": "让我们看看，呃，它看起来怎么样。",
  "EN:ZH:So this is the title section.": "这就是标题部分。",
  "EN:ZH:It is looking okay to me.": "我觉得还不错。",
  "EN:ZH:Uh, here uh, there is one additional thing which has happened is it has added this additional bullets.": "呃，这里呃，还发生了一件事，就是它又增加了这颗子弹。",
  "EN:ZH:So let's see if there is any way of replacing these additional bullets.": "因此，让我们看看是否有办法替换这些额外的子弹。",
  "EN:ZH:So one way is that you can, uh, do, uh, control uh, f where you go to the find and then uh, click": "因此，一种方法是，你可以，呃，做，呃，控制呃，F，你去查找，然后呃，单击",
  "EN:ZH:on this replace.": "在此替换。",
  "EN:ZH:When you are doing find what you just copy paste this uh bullet with this additional space here.": "查找时，只需复制粘贴这颗子弹，并在此处留出空白。",
  "EN:ZH:So I've already copied it using Ctrl C from there.": "因此，我已经用 Ctrl C 从那里复制了它。",
  "EN:ZH:And I'm pasting it here and replace it with blank.": "我把它粘贴在这里，用空白代替。",
  "EN:ZH:So let's see if it recognizes it.": "让我们看看它是否能识别。",
  "EN:ZH:So it has started recognizing this.": "因此，它已经开始认识到这一点。",
  "EN:ZH:And what we are going to do is we are going to replace it in blank.": "我们要做的就是将其替换为空白。",
  "EN:ZH:And we replace it in the entire pack one by one.": "然后，我们将其逐一替换到整个包装中。",
  "EN:ZH:So let's try to replace it.": "所以，让我们试着替换它。",
  "EN:ZH:So it started replacing it.": "于是，它开始替换它。",
  "EN:ZH:So you just replace it in the entire pack to fix this problem.": "因此，只需更换整个包装就能解决这个问题。",
  "EN:ZH:So uh and this one.": "还有这个",
  "EN:ZH:So we have fixed this problem now.": "现在我们已经解决了这个问题。",
  "EN:ZH:So our next step is to do some, uh, beautification.": "所以我们下一步要做的就是美化工作。",
  "EN:ZH:Uh.": "呃......",
  "EN:ZH:Hi all, welcome to this session on Move Content from ChatGPT to PowerPoint using Ms. Word and PowerPoint": "大家好，欢迎参加关于使用 Word 和 PowerPoint 将内容从 ChatGPT 移至 PowerPoint 的会议",
  "EN:ZH:This is the second method for moving content to PowerPoint.": "这是第二种将内容移动到 PowerPoint 的方法。",
  "EN:ZH:We have already discussed another method of moving content from ChatGPT to PowerPoint using VBA.": "我们已经讨论过使用 VBA 将内容从 ChatGPT 移至 PowerPoint 的另一种方法。",
  "EN:ZH:So let's dive into it.": "那就让我们深入了解一下吧。",
  "EN:ZH:So for doing this method, what we have to do is we have to go back to the same thread of the OpenAI": "因此，要使用这种方法，我们必须回到 OpenAI 的同一线程",
  "EN:ZH:where we created the presentation outline.": "我们在这里创建了演示大纲。",
  "EN:ZH:So if you remember we created our presentation outline, uh, here uh in this particular thread.": "所以，如果你还记得，我们创建了我们的演示大纲，呃，在这里呃在这个特定的线程。",
  "EN:ZH:So we will go here and we will, uh, write a prompt to ask ChatGPT to remove these, uh, slide numbers.": "因此，我们将在这里编写一个提示，要求 ChatGPT 删除这些幻灯片编号。",
  "EN:ZH:Why I'm removing the slide number is because it can be hard to remove them, uh, manually.": "我之所以要删除幻灯片编号，是因为手动删除幻灯片编号可能比较困难。",
  "EN:ZH:So I will use a prompt to, uh, remove the slide numbers, uh, from the presentation outline.": "因此，我将使用提示符来删除演示大纲中的幻灯片编号。",
  "EN:ZH:So what I will do here is I'll just write this prompt, which is please remove, uh, slide number one,": "所以，我要做的就是写下这个提示，即请删除一号幻灯片、",
  "EN:ZH:colon, cell number two three, etc. from the presentation outline.": "冒号、单元格号 2 3 等。",
  "EN:ZH:And let's see what it says.": "让我们看看它是怎么说的。",
  "EN:ZH:So if you look here it has started writing uh, the presentation outline without those uh, uh, slide": "所以，如果你看这里，它已经开始撰写呃，演示大纲，而没有那些呃，呃，幻灯片",
  "EN:ZH:numbers.": "数字",
  "EN:ZH:And it looks much cleaner now.": "现在看起来干净多了。",
  "EN:ZH:So what we'll do now is just copy, uh, this content, uh, like this, uh, the presentation outline,": "所以，我们现在要做的就是复制，呃，这些内容，呃，像这样，呃，演示大纲、",
  "EN:ZH:uh, by selecting the relevant sections.": "选择相关章节。",
  "EN:ZH:It will copy all of this and then we will go to Office online.": "它将复制所有这些内容，然后我们将进入在线办公。",
  "EN:ZH:So office online, uh, it's a free tool available to all of us.": "因此，在线办公是我们所有人都可以使用的免费工具。",
  "EN:ZH:You can create a free account where you can actually use, uh, um, Microsoft Word, Microsoft PowerPoint,": "你可以创建一个免费账户，在这里你可以使用 Microsoft Word、Microsoft PowerPoint、",
  "EN:ZH:all of that free, of course.": "当然，这一切都是免费的。",
  "EN:ZH:So now we'll go to the online version of office.": "现在，我们将进入在线版 Office。",
  "EN:ZH:And the steps which I'm showing you now are only possible on online version of office.": "我现在向你展示的步骤只能在在线版 Office 中实现。",
  "EN:ZH:So we'll just create, uh, new uh, word document by clicking on this.": "因此，我们只需点击这里，创建一个新的 word 文档。",
  "EN:ZH:So now Microsoft Word have created the online document.": "因此，现在 Microsoft Word 创建了在线文档。",
  "EN:ZH:So we'll just paste the content which we, uh, copy it from, uh, GDP using control V.": "因此，我们只需粘贴从 GDP 复制的内容，使用控制 V。",
  "EN:ZH:So we have pasted that content now in the Microsoft Word.": "因此，我们将这些内容粘贴到 Microsoft Word 中。",
  "EN:ZH:If you see here, uh, all the outline and the key points are pasted.": "如果你看到这里，呃，所有的大纲和要点都是粘贴上去的。",
  "EN:ZH:The next step from here is you go to file and then export and then export to PowerPoint.": "下一步是转到文件，然后导出，再导出到 PowerPoint。",
  "EN:ZH:You click on that.": "点击它。",
  "EN:ZH:And what it will do is it will open a wizard for exporting it to PowerPoint.": "它将打开一个向导，将其导出到 PowerPoint。",
  "EN:ZH:Obviously you can select one of the pre uh designed theme by PowerPoint for applying the theme as well.": "显然，您也可以选择 PowerPoint 预先设计好的主题之一来应用该主题。",
  "EN:ZH:But for the purpose of this demo I'm not going to do that.": "但为了演示的目的，我不会这么做。",
  "EN:ZH:I'll just select a blank theme without any design into it and I'll push export.": "我会选择一个没有任何设计的空白主题，然后点击导出。",
  "EN:ZH:So now it is preparing the slide and summarizing the content.": "因此，现在是准备幻灯片和总结内容。",
  "EN:ZH:And now, uh, it has created a presentation which is ready for us.": "现在，它已经为我们准备好了演示文稿。",
  "EN:ZH:So we'll just click on Open Presentation from here.": "因此，我们只需点击这里的 \"打开演示文稿\"。",
  "EN:ZH:Uh, Microsoft uh, Office Online have now exported our word content into PowerPoint.": "Microsoft Office Online 已将我们的 Word 内容导出到 PowerPoint 中。",
  "EN:ZH:And this is available here.": "在这里可以找到。",
  "EN:ZH:Obviously what it has done is it has only created this, uh, first slide, uh, by the title of the": "很明显，它所做的只是创建了这张幻灯片，呃，第一张幻灯片，呃，标题是：\"......\"。",
  "EN:ZH:document.": "文件",
  "EN:ZH:So what we'll do is we'll just delete this particular slide.": "因此，我们要做的就是删除这张幻灯片。",
  "EN:ZH:Uh, okay.": "好吧",
  "EN:ZH:So what we'll do is if you see here that it has started showing you the design ideas, you can also": "因此，我们要做的是，如果你看到这里已经开始向你展示设计理念，你也可以",
  "EN:ZH:apply the design ideas here itself.": "在这里应用设计理念。",
  "EN:ZH:But I'll not, uh, do that in this step.": "但我不会，呃，在这个步骤中这样做。",
  "EN:ZH:They are seeing the first slide as uh, a normal slide.": "他们将第一张幻灯片视为普通幻灯片。",
  "EN:ZH:Uh, what I'll do is I'll just change it to, uh, title slide.": "我会把它改成标题幻灯片。",
  "EN:ZH:This one title slide.": "这一张标题幻灯片。",
  "EN:ZH:Uh, so that Microsoft starts seeing this as a title slide rather than a normal content slide.": "这样，微软就会将其视为标题幻灯片，而不是普通的内容幻灯片。",
  "EN:ZH:So now it has applied, uh, this title slide layout.": "现在，它已经应用了这个标题幻灯片布局。",
  "EN:ZH:And in the rest of the slides, uh, it is already seeing it as, uh, title and content.": "而在其他幻灯片中，它已经将其视为标题和内容。",
  "EN:ZH:Uh, uh, slide.": "呃，呃，滑动。",
  "EN:ZH:So these are fine.": "所以这些都很好。",
  "EN:ZH:So we have applied that.": "因此，我们采用了这一方法。",
  "EN:ZH:And uh, what we will do is just quickly, uh, open, uh, uh, the presentation which we have created,": "我们要做的就是快速打开我们制作的演示文稿、",
  "EN:ZH:uh, in, uh, uh, Microsoft PowerPoint desktop.": "在 Microsoft PowerPoint 桌面上。",
  "EN:ZH:The reason for doing that is because Microsoft, uh, PowerPoint desktop is much more powerful.": "这样做的原因是，微软的 PowerPoint 桌面功能要强大得多。",
  "EN:ZH:It gives us much more options to, uh, play around with.": "这让我们有了更多的选择，可以随意发挥。",
  "EN:ZH:So if you see here they opened this back, uh, in Microsoft PowerPoint desktop.": "所以，如果你看到这里，他们在 Microsoft PowerPoint 桌面上打开了这个文件。",
  "EN:ZH:And what we are going to do is we'll, uh, quickly save this back.": "我们要做的就是，呃，迅速把它保存起来。",
  "EN:ZH:We'll save a copy of this back at the place we want.": "我们将在想要的地方保存一份副本。",
  "EN:ZH:Now, let's say on the desktop, uh, with, uh, this name, let's call it version 0.1.": "现在，假设在桌面上，呃，这个名字，我们称之为 0.1 版。",
  "EN:ZH:Okay, so we have saved it at our, uh, our convenient location.": "好了，我们已经把它保存在我们方便的地方了。",
  "EN:ZH:And if you start up opening the designer, you will see that the PowerPoint is showing you design ideas.": "如果你打开设计器，就会看到 PowerPoint 正在向你展示设计理念。",
  "EN:ZH:You can apply all that.": "你可以应用所有这些。",
  "EN:ZH:So I've already created another video which shows how to apply, uh, the designs to all of these slides": "因此，我已经制作了另一个视频，展示如何将设计应用于所有这些幻灯片",
  "EN:ZH:using Microsoft PowerPoint.": "使用 Microsoft PowerPoint。",
  "EN:ZH:So you can refer to the other video where I'm showing all that, uh, for beautifying, uh, uh, this": "所以，你可以参考另一个视频，在那里我展示了所有这些，呃，用于美化，呃，呃，这个",
  "EN:ZH:presentation from here.": "从这里开始介绍。",
  "EN:ZH:Thanks for watching this video, and I'll see you in the next video.": "感谢观看本视频，我们下期视频再见。",
  "EN:ZH:Our next step is to do our beautification in this pack.": "我们下一步要做的就是美化这个背包。",
  "EN:ZH:So let's do some beautification.": "所以，让我们来美化一下吧。",
  "EN:ZH:One way of doing the beautification is using the inbuilt designer.": "美化的一种方法是使用内置设计器。",
  "EN:ZH:So you click go on the right hand side top corner and click on this designer.": "点击右上角的设计器。",
  "EN:ZH:And if you see that from here we have started showing some design ideas to us.": "如果你从这里看到，我们已经开始向我们展示一些设计理念。",
  "EN:ZH:So we can choose let's say one of this design ID maybe this one.": "因此，我们可以从这个设计 ID 中选择一个，也许是这个。",
  "EN:ZH:This looks okay to me.": "我觉得还不错。",
  "EN:ZH:Let's see what designer is proposing in this one.": "让我们来看看设计者在其中提出了什么建议。",
  "EN:ZH:Maybe we select this one Okay then next one a landscape and insurance.": "也许我们先选这个，然后再选下一个景观和保险。",
  "EN:ZH:Let's try this one.": "让我们试试这个。",
  "EN:ZH:Or.": "或者",
  "EN:ZH:Yeah.": "是啊",
  "EN:ZH:This one is also looking okay.": "这个看起来也不错。",
  "EN:ZH:Maybe let's keep this one for the timing.": "也许让我们留着这个，以备不时之需。",
  "EN:ZH:Key use cases of AI.": "人工智能的主要应用案例。",
  "EN:ZH:Let's apply this one okay.": "让我们来应用这一个好了。",
  "EN:ZH:Case study.": "案例研究。",
  "EN:ZH:Can try either this.": "可以试试这个。",
  "EN:ZH:Or maybe this one.": "或者是这个。",
  "EN:ZH:What is it?": "是什么？",
  "EN:ZH:Maybe we.": "也许我们",
  "EN:ZH:Let's keep this one.": "让我们留着这个。",
  "EN:ZH:Okay, then.": "那好吧",
  "EN:ZH:AI in underwriting and risk management.": "人工智能在承保和风险管理中的应用。",
  "EN:ZH:Uh, maybe let's go with this one.": "呃，也许我们还是选这个吧。",
  "EN:ZH:Then case study two.": "然后是案例研究二。",
  "EN:ZH:Okay, let's apply this one.": "好吧，让我们来应用这个。",
  "EN:ZH:Ethical considerations.": "伦理方面的考虑。",
  "EN:ZH:Let's say these right.": "就说这些吧。",
  "EN:ZH:Ethical considerations challenges.": "伦理方面的挑战。",
  "EN:ZH:Future trends and opportunities.": "未来的趋势和机遇。",
  "EN:ZH:Let's keep this one for the time being.": "这个暂时先放着。",
  "EN:ZH:And then conclusion and action.": "然后是结论和行动。",
  "EN:ZH:This one.": "这个",
  "EN:ZH:We just remove this additional slide.": "我们只是去掉了这个额外的幻灯片。",
  "EN:ZH:And now let's quickly have a look at how our presentation is looking.": "现在，让我们快速浏览一下我们的演示文稿。",
  "EN:ZH:And now if you look here what it's doing is started giving more design options based is now considering": "现在，它开始提供更多的设计选项，并正在考虑",
  "EN:ZH:this as base design started giving more design options in this one.": "在此基础上，开始提供更多的设计选择。",
  "EN:ZH:So what I'm going to do is I'm just going to create a duplicate of this slide first and see some different": "因此，我要做的是，先复制这张幻灯片，然后看看有什么不同。",
  "EN:ZH:options here.": "在此选择。",
  "EN:ZH:Maybe let's keep this.": "也许我们可以保留这个。",
  "EN:ZH:Let's keep this one okay.": "让我们保持这个好。",
  "EN:ZH:Maybe let's keep the first slide okay okay.": "也许我们还是保留第一张幻灯片好了。",
  "EN:ZH:We are going to keep it this one as like this only then okay.": "我们要把它保持成这样，只有这样才行。",
  "EN:ZH:So we got this version now which is looking much, much better than where we started.": "因此，我们现在得到的这个版本要比我们开始时的版本好很多很多。",
  "EN:ZH:And this is our first slide exploring opportunities, which is basically the title slide.": "这是我们探索机遇的第一张幻灯片，基本上就是标题幻灯片。",
  "EN:ZH:This is the introduction to AI in uh, insurance.": "这就是人工智能在保险领域的应用。",
  "EN:ZH:Uh, it is kind of dividing the pack into various sections.": "呃，这是把背包分成不同的部分。",
  "EN:ZH:Then it is showing us the AI landscape in insurance, then key use cases in insurance.": "然后，它向我们展示了人工智能在保险领域的应用，接着是保险领域的主要应用案例。",
  "EN:ZH:Then it has shown one case study to us.": "然后，它向我们展示了一个案例研究。",
  "EN:ZH:Then it is showing AI in underwriting and risk management.": "然后是在承保和风险管理方面展示人工智能。",
  "EN:ZH:Then it is showing case study two.": "然后是案例研究二。",
  "EN:ZH:Then it is showing us uh ethical consideration of AI in insurance.": "然后，它向我们展示了人工智能在保险方面的伦理考虑。",
  "EN:ZH:Then it is showing challenges and limitations of AI in insurance.": "然后是人工智能在保险领域的挑战和局限性。",
  "EN:ZH:Then it is showing future trends and opportunities and then conclusion.": "然后是未来趋势和机遇，最后是结论。",
  "EN:ZH:So this pack is really looking nice from where we started.": "从一开始，这个背包就非常漂亮。",
  "EN:ZH:And within a matter of minutes we created basically a very nice looking pack.": "几分钟之内，我们就制作出了一个非常漂亮的包装。",
  "EN:ZH:So let's uh, try to save this pack as this one, let's say this.": "所以，让我们试着把这个数据包保存为这个，比方说这个。",
  "EN:ZH:Save as.": "另存为",
  "EN:ZH:Browse.": "浏览。",
  "EN:ZH:Let's save it on the desktop.": "让我们把它保存到桌面上。",
  "EN:ZH:It has already picked this name.": "它已经取了这个名字。",
  "EN:ZH:And let's call it, uh.": "就叫它",
  "EN:ZH:And we just save it.": "我们只是把它保存起来。",
  "EN:ZH:So what we have done is we have created a exploring opportunities for AI in insurance sector presentation": "因此，我们所做的就是为人工智能在保险领域的应用创造机会。",
  "EN:ZH:within a matter of minutes.": "顷刻之间。",
  "EN:ZH:Obviously, this is a draft presentation.": "显然，这是一份演示文稿。",
  "EN:ZH:You can, uh, review the content.": "您可以查看内容。",
  "EN:ZH:You can change the color scheme, play around it, make it more interesting, make it more appealing,": "你可以改变配色方案，随意发挥，让它更有趣，更吸引人、",
  "EN:ZH:make it more consistent.": "使其更加一致。",
  "EN:ZH:You do all those things to make it more better.": "你所做的一切，都是为了让它变得更好。",
  "EN:ZH:Thanks for joining me in this, uh, session.": "感谢您参加本次会议。",
  "EN:ZH:Hi all, welcome to this video on generating a new presentation starting from a blank presentation.": "大家好，欢迎观看关于从空白演示文稿生成新演示文稿的视频。",
  "EN:ZH:In this video, what we will do is we'll start from a blank presentation and we'll use a title of a": "在本视频中，我们将从一个空白的演示文稿开始，并使用一个",
  "EN:ZH:presentation, which we want to generate the entire pack using Microsoft Copilot.": "演示文稿，我们希望使用 Microsoft Copilot 生成整个软件包。",
  "EN:ZH:So let's start with it.": "那我们就从它开始吧。",
  "EN:ZH:So the first step is to start your Microsoft PowerPoint.": "因此，第一步就是启动 Microsoft PowerPoint。",
  "EN:ZH:So you go to the search section within your Microsoft Windows.": "因此，您可以进入 Microsoft Windows 的搜索部分。",
  "EN:ZH:And you can see the PowerPoint app here you start the PowerPoint app.": "你可以在这里看到 PowerPoint 应用程序，启动 PowerPoint 应用程序。",
  "EN:ZH:So uh, one of the prerequisite for creating this presentation is you need Uh, Microsoft Copilot activity": "因此，创建此演示文稿的前提之一是你需要 Microsoft Copilot 活动。",
  "EN:ZH:on your machine.": "在你的机器上。",
  "EN:ZH:So the next step is to start with a blank presentation.": "因此，下一步就是从空白演示开始。",
  "EN:ZH:And then once you do that, you will see this copilot button appearing on the top right hand corner": "完成操作后，您会看到右上角出现这个副驾驶按钮",
  "EN:ZH:within your PowerPoint.": "在您的 PowerPoint 中。",
  "EN:ZH:So we'll use, uh use that.": "所以我们就用这个。",
  "EN:ZH:And this is copilot symbol.": "这是副驾驶员的标志。",
  "EN:ZH:And from here, uh, within few seconds, the options, uh, within copilot will start appearing.": "从这里开始，呃，几秒钟内，副驾驶内的选项就会开始出现。",
  "EN:ZH:So these are some of the pre-built prompts available from copilot.": "以上就是 copilot 提供的一些预置提示。",
  "EN:ZH:So this is a pre-built prompt available from Microsoft Copilot, which is used in scenarios where you": "因此，这是微软 Copilot 提供的预置提示，可用于以下场景",
  "EN:ZH:want to create a totally new presentation about a particular title.": "想就某个标题创建一个全新的演示文稿。",
  "EN:ZH:So we'll use this pre-built, uh, prompt, which is about creating a presentation.": "因此，我们将使用这个预置的提示，它是关于创建演示文稿的。",
  "EN:ZH:So use this.": "那就用这个吧。",
  "EN:ZH:Once you click on it, uh, it will pre-populate some part of this prompt, which is create a presentation": "一旦你点击了它，呃，它就会预先填充提示的某些部分，即创建演示文稿",
  "EN:ZH:about.": "关于",
  "EN:ZH:And after this, what we have to do is we have to write the name of topic on which we are creating this": "之后，我们要做的就是写下要创建的主题名称",
  "EN:ZH:So let's generate a presentation on exploring opportunities for AI in banking sector.": "因此，让我们就探索银行业的人工智能机遇进行一次介绍。",
  "EN:ZH:So I'm going to have typed this thing which is exploring opportunities for AI in banking sector after": "因此，我将在之后打出这篇探索银行业人工智能机遇的文章。",
  "EN:ZH:And then once you are happy with the title you send it using this, uh, message button.": "一旦你对标题满意，就可以用这个 \"信息 \"按钮发送。",
  "EN:ZH:Um, Microsoft Copilot is working on creating your presentation.": "Microsoft Copilot 正在为您制作演示文稿。",
  "EN:ZH:If you see here it is saying almost there.": "如果你看到这里，就说明快到了。",
  "EN:ZH:If you want to stop in between you can click on Stop Generating as well.": "如果想中途停止，也可以点击 \"停止生成\"。",
  "EN:ZH:Then it will stop the process of generating.": "然后就会停止生成过程。",
  "EN:ZH:So if you see it has started creating a presentation in front of you and it is saying, okay, here": "所以，如果你看到它已经开始在你面前创建演示文稿，并说，好的，这里",
  "EN:ZH:you go.": "你去。",
  "EN:ZH:A presentation about exploring opportunities for AI banking sector has been created.": "我们制作了一份关于探索人工智能银行业机遇的演示文稿。",
  "EN:ZH:And if you want, you can use designer to change the layout options.": "如果你愿意，还可以使用设计器更改布局选项。",
  "EN:ZH:So if you look at, uh, this presentation which is generated by Microsoft Copilot, it has been generated": "因此，如果你看一下，呃，这个由 Microsoft Copilot 生成的演示文稿，它是这样生成的",
  "EN:ZH:So this is the title slide with the title with the image background image with subtitle.": "因此，这是标题幻灯片，带有标题、图像背景和副标题。",
  "EN:ZH:Also it have put the speaker notes within the speaker notes section which you can use for uh presenting": "此外，它还将发言者注释放在了发言者注释部分，您可以使用这些注释进行发言。",
  "EN:ZH:this presentation.": "本演示文稿。",
  "EN:ZH:Uh, also it has given you this warning which is AI generated content may be incorrect.": "此外，它还给出了这样的警告：人工智能生成的内容可能不正确。",
  "EN:ZH:So what it means is whenever you are using this presentation to review it, you need to make sure,": "因此，这意味着无论何时使用此演示文稿进行复习，都需要确保这一点、",
  "EN:ZH:uh, whatever things are not correct, you you just fix those things.": "呃，不管有什么不对的地方，你都要改正过来。",
  "EN:ZH:So look at this slide for example.": "请看这张幻灯片。",
  "EN:ZH:It have uh added the title to the slide.": "在幻灯片上添加了标题。",
  "EN:ZH:It had added a image to the slide.": "它在幻灯片上添加了一个图像。",
  "EN:ZH:It have added the various text in the body of the slide, and it has also given you the speaker note": "它已在幻灯片正文中添加了各种文本，还为您提供了发言者注释",
  "EN:ZH:which you can use for speaking about this slide.": "您可以用它来讲述这张幻灯片。",
  "EN:ZH:Then similarly for the next one, uh, it have added a image, a title, and all of the text, plus": "然后类似地为下一个添加图片、标题和所有文本，再加上",
  "EN:ZH:the, uh, the content of the slide.": "幻灯片的内容。",
  "EN:ZH:So if you look in total, uh, copilot have created, uh, 14 slides in total and which has a conclusion": "所以，如果你看一下，呃，副驾驶总共制作了 14 张幻灯片，其中有一个结论",
  "EN:ZH:section as well.": "部分也是如此。",
  "EN:ZH:So this is what I wanted to show you that using Microsoft Copilot, you can create a presentation from": "这就是我想向你展示的，使用 Microsoft Copilot，你可以从以下内容创建演示文稿",
  "EN:ZH:a blank presentation just using the title of the presentation.": "空白演示文稿，只需使用演示文稿的标题。",
  "EN:ZH:And it will populate the entire presentation, including various slides, uh, the, uh, the headings,": "它将填充整个演示文稿，包括各种幻灯片、标题、",
  "EN:ZH:the, uh, content and the images and also the speaker notes.": "内容、图片以及发言人的说明。",
  "EN:ZH:See you in the next video.": "下期视频再见。",
  "EN:ZH:Welcome to this video on generate a presentation from a file.": "欢迎观看关于从文件生成演示文稿的视频。",
  "EN:ZH:In this video, we will learn how to use Microsoft Copilot in PowerPoint to generate a presentation": "在本视频中，我们将学习如何在 PowerPoint 中使用 Microsoft Copilot 生成演示文稿",
  "EN:ZH:from existing Microsoft Document.": "从现有的 Microsoft 文档。",
  "EN:ZH:So let's dive in.": "那我们就开始吧。",
  "EN:ZH:So we'll start with a new presentation.": "因此，我们将从一个新的演示开始。",
  "EN:ZH:Then we'll go to copilot.": "然后我们去找副驾驶。",
  "EN:ZH:Then we'll select this.": "然后我们选择这个。",
  "EN:ZH:Create a presentation from File Prompt.": "从文件提示符创建演示文稿",
  "EN:ZH:And then here we will add the link to the file.": "然后，我们将在这里添加文件链接。",
  "EN:ZH:So there are two prerequisite here.": "因此，这里有两个先决条件。",
  "EN:ZH:One is that the file which we are using is the source file here should be in Microsoft Word format.": "首先，我们使用的源文件应该是 Microsoft Word 格式。",
  "EN:ZH:And second prerequisite here is it should be present either in your SharePoint or in Your Microsoft": "第二个先决条件是，它应该存在于 SharePoint 或 Microsoft",
  "EN:ZH:Drive.": "开车",
  "EN:ZH:So let's get the link of our Microsoft Drive here and add it.": "因此，让我们在这里获取 Microsoft Drive 的链接并添加它。",
  "EN:ZH:This is my Microsoft Drive.": "这是我的 Microsoft Drive。",
  "EN:ZH:So I have a existing scrum guide in word format.": "因此，我有一份 word 格式的现有 Scrum 指南。",
  "EN:ZH:So I'm just going to click on it.": "所以我要点击它。",
  "EN:ZH:And when you click on it this uh arrow share with other people appears.": "点击后，就会出现 \"与他人分享 \"的箭头。",
  "EN:ZH:We click on it again.": "我们再次点击。",
  "EN:ZH:And then from here we copy this link, anyone with the link.": "然后从这里复制这个链接，任何人都可以使用这个链接。",
  "EN:ZH:And then it has copied the link.": "然后它就复制了链接。",
  "EN:ZH:And we just go back to the file from where we started.": "然后我们就回到开始的文件。",
  "EN:ZH:And we just paste the link here after the prompt and we run it.": "我们只需在提示后粘贴链接，然后运行即可。",
  "EN:ZH:So Microsoft Copilot has uh located the file and started drafting the outline of the presentation.": "于是，Microsoft Copilot 找到了文件，并开始起草演示大纲。",
  "EN:ZH:So this is the outline of the presentation.": "这就是演讲提纲。",
  "EN:ZH:It is drafting.": "这是起草工作。",
  "EN:ZH:Now it has started drafting the slide.": "现在，它已经开始起草滑梯。",
  "EN:ZH:Now it has started generating the slide.": "现在，它已经开始产生幻灯片了。",
  "EN:ZH:Also you have the option to stop generating if you want to.": "如果您愿意，还可以选择停止生成。",
  "EN:ZH:And it started adding the speaker notes to each of the slide.": "然后，它开始在每张幻灯片上添加演讲者注释。",
  "EN:ZH:It has finally drafted the pack for you.": "它终于为你起草了背包。",
  "EN:ZH:The pack has 46 slide.": "该背包有 46 张幻灯片。",
  "EN:ZH:You can see that, uh, in the first slide it is giving you a warning that, uh, uh, the content generated": "你可以看到，呃，在第一张幻灯片中，它会给你一个警告，呃，呃，生成的内容",
  "EN:ZH:by AI may be correct.": "人工智能可能是正确的。",
  "EN:ZH:What it means is you have to basically review the content and basically fix it.": "这意味着您必须对内容进行基本审查和基本修复。",
  "EN:ZH:It has also generated a agenda slide for this pack and also generated the speaker notes, uh, for the": "它还为本资料包生成了一张议程幻灯片，并为会议生成了发言者说明。",
  "EN:ZH:slide, uh, then it has generated uh, authors and publication date purpose of this guide, then scrum": "幻灯片，呃，然后它产生了呃，作者和出版日期本指南的目的，然后Scrum",
  "EN:ZH:master and environment simplicity and flexibility of scrum.": "Scrum的主人和环境简单而灵活。",
  "EN:ZH:Then what is scrum.": "那么什么是 scrum？",
  "EN:ZH:And it has added pictures as well.": "它还添加了图片。",
  "EN:ZH:It has added titles content and it has also added the uh speaker notes.": "它增加了标题内容，还增加了发言者注释。",
  "EN:ZH:So this is a speaker note in this particular scenario.": "因此，在这种特殊情况下，这是一个扬声器说明。",
  "EN:ZH:And then based on what content it has prepared.": "然后再根据它准备的内容。",
  "EN:ZH:This pack the original content that is also added in the speaker note.": "这部分内容也是发言稿中添加的原始内容。",
  "EN:ZH:So all this is available you can quickly skim through the pack.": "因此，您可以快速浏览所有这些内容。",
  "EN:ZH:So some of the images are really good, but in the scenarios where we don't have images, we can add": "因此，有些图像确实很好，但在没有图像的情况下，我们可以添加",
  "EN:ZH:them using the designer.": "他们使用设计器。",
  "EN:ZH:I'll show you in some examples using that.": "我会用一些例子向你展示。",
  "EN:ZH:So you look at the pack and you will see that the pack is, uh, really, uh, looking very nice.": "你看看背包，就会发现背包真的非常漂亮。",
  "EN:ZH:Uh, they have used good pictures.": "呃，他们用了很好的照片。",
  "EN:ZH:They have, uh, created the headings, the content, the speaker note across, uh, the pack.": "他们制作了标题、内容、发言稿，以及整套资料。",
  "EN:ZH:So this is the entire pack they have created.": "这就是他们创建的整个软件包。",
  "EN:ZH:Let's try to add some image, uh, to make it look better.": "让我们试着添加一些图像，嗯，让它看起来更好。",
  "EN:ZH:We might just add this agenda or this one.": "我们可能会增加这个议程或这个议程。",
  "EN:ZH:Maybe this one.": "也许是这个。",
  "EN:ZH:To make make it more beautiful than, uh, in this one.": "让它比这个更美。",
  "EN:ZH:Maybe we can add this one.": "也许我们可以加上这一条。",
  "EN:ZH:So quickly we can make it look, uh, much, much better using the designer options, selecting the,": "因此，我们可以使用设计器选项，选择\"..、",
  "EN:ZH:uh, the right, uh, design for, uh, basically this back.": "呃，正确的，呃，设计，呃，基本上是这个背面。",
  "EN:ZH:So once you apply the design across the back, you just go and save this file.": "因此，一旦你在背面应用了设计，就可以保存这个文件了。",
  "EN:ZH:Save as you find the right place where you want to save this and save it.": "另存为，找到要保存的正确位置并保存。",
  "EN:ZH:So that's how we create a pack or from an existing word document using Microsoft Copilot, available": "这就是我们如何使用 Microsoft Copilot 从现有 Word 文档创建数据包的方法。",
  "EN:ZH:in PowerPoint.": "在 PowerPoint 中。",
  "EN:ZH:In this video, we'll learn how to add a new slide to existing PowerPoint presentation using Microsoft": "在本视频中，我们将学习如何使用 Microsoft Excel 在现有 PowerPoint 演示文稿中添加新幻灯片。",
  "EN:ZH:Copilot.": "副驾驶员",
  "EN:ZH:I want to add a new slide on Agile overview.": "我想添加一张关于敏捷概述的新幻灯片。",
  "EN:ZH:So I will go to the space where I want to add.": "因此，我将转到要添加的空间。",
  "EN:ZH:So I want to add this slide between slide two and three I'll click here.": "我想在第二和第三张幻灯片之间添加这张幻灯片，请点击这里。",
  "EN:ZH:And then after that I'll go to the prompt window where we write the prompts.": "之后，我将转到提示窗口，在那里写下提示。",
  "EN:ZH:And then within that prompt window we can go to this star which is saying view prompts.": "然后在提示窗口中，我们可以转到 \"查看提示 \"这颗星。",
  "EN:ZH:Within that we go to the create section.": "在此页面内，我们进入创建部分。",
  "EN:ZH:And from the create section we select the prompt which is saying add a slide about.": "在创建部分，我们选择 \"添加有关幻灯片 \"的提示。",
  "EN:ZH:So you click on this one and then you write the name of the topic.": "所以，你要点击这个，然后写下主题名称。",
  "EN:ZH:So I want to add a slide on Agile overview.": "因此，我想添加一张关于敏捷概述的幻灯片。",
  "EN:ZH:So I've added it.": "所以我把它加了进去。",
  "EN:ZH:And after that I'll click this send button.": "之后，我会点击发送按钮。",
  "EN:ZH:Okay let's see how PowerPoint is going to generate it.": "好吧，让我们看看 PowerPoint 将如何生成它。",
  "EN:ZH:So if you look here it has added this slide on agile overview.": "因此，如果你看这里，就会发现它添加了这张关于敏捷概述的幻灯片。",
  "EN:ZH:The heading looks right.": "标题看起来没错。",
  "EN:ZH:Then it has added these bullet points.": "然后又加上了这些要点。",
  "EN:ZH:Then it has added a good image.": "然后，它又增添了一个良好的形象。",
  "EN:ZH:And it has also given you speaker note.": "它还为您提供了扬声器说明。",
  "EN:ZH:So this is what I wanted to show you in this video.": "这就是我想在视频中向大家展示的内容。",
  "EN:ZH:So we are going to cover now waterfall versus agile and how to build MVP.": "因此，我们将讨论瀑布式与敏捷式的对比，以及如何构建 MVP。",
  "EN:ZH:Let's go in detail of this.": "让我们来详细了解一下。",
  "EN:ZH:So in this slide I'm going to give a difference between waterfall and agile incremental delivery.": "在这张幻灯片中，我将介绍瀑布式交付和敏捷式增量交付的区别。",
  "EN:ZH:What used to happen in waterfall method is if you want to build a product, it will take at least six": "以前的瀑布式方法是，如果你想制作一个产品，至少需要六周的时间。",
  "EN:ZH:months to deliver the first release.": "个月的时间发布第一版。",
  "EN:ZH:So what it means is that the customer will only be able to see the actual product by the end of six": "因此，这意味着客户只能在 6 月底才能看到实际产品。",
  "EN:ZH:months.": "个月。",
  "EN:ZH:So let's assume from here to here the time period is six months, and for the first version of product": "因此，我们假设从这里到这里的时间段为六个月，对于第一版产品来说",
  "EN:ZH:to be shipped to the customer, it will take six months.": "要运送到客户手中，需要 6 个月的时间。",
  "EN:ZH:And what we will do in that six months is first, we'll spend one and a half month in gathering the": "在这六个月里，我们将首先用一个半月的时间来收集",
  "EN:ZH:requirements, like what are the various features and capabilities which we need in this product.": "要求，比如我们需要该产品的哪些功能和性能。",
  "EN:ZH:So we'll gather those requirements from various stakeholders and will create requirement documents.": "因此，我们将从不同的利益相关者那里收集这些需求，并创建需求文档。",
  "EN:ZH:The output of this phase will be requirement document, and this phase itself will take almost around": "这一阶段的产出将是需求文档，而这一阶段本身大约需要",
  "EN:ZH:one and a half months.": "一个半月",
  "EN:ZH:And then these requirement documents will be become input for design phase and design phase.": "然后，这些需求文件将成为设计阶段和设计阶段的输入。",
  "EN:ZH:What the architects will do is they'll read through these requirement documents and convert them into": "建筑师们要做的就是通读这些需求文件，并将其转换为",
  "EN:ZH:high level architecture or design, or medium level and low level design.": "高级架构或设计，或中级和低级设计。",
  "EN:ZH:And again, the output of this phase will be again another set of documents which will be known as Design": "同样，这一阶段的成果也将是另一套文件，被称为 \"设计\"。",
  "EN:ZH:Document.": "文件",
  "EN:ZH:It can be architecture document, medium level design document or low level design document.": "它可以是架构文件、中层设计文件或低层设计文件。",
  "EN:ZH:So those will be the output of this design phase.": "因此，这些将是这一设计阶段的成果。",
  "EN:ZH:And it will again take one and a half month.": "这又需要一个半月的时间。",
  "EN:ZH:So we lost one and a half month from here to here.": "从这里到这里，我们损失了一个半月。",
  "EN:ZH:Then again we spent another one and a half month to do the design documents.": "然后，我们又花了一个半月的时间来做设计文件。",
  "EN:ZH:And then these design documents will become input to the next phase, which is implementation phase": "然后，这些设计文件将成为下一阶段（即实施阶段）的参考资料",
  "EN:ZH:in common software development terminology.": "常用的软件开发术语。",
  "EN:ZH:You can call this implementation phase as coding phase as well where the developers will refer to this": "您也可以将这一实施阶段称为编码阶段，开发人员会将其称为",
  "EN:ZH:design documents and they will code the actual system.": "设计文件，他们将对实际系统进行编码。",
  "EN:ZH:And what will get by the end of this implementation phase is the unverified system or unverified system": "而在实施阶段结束时，将得到的是未经验证的系统或未经验证的系统",
  "EN:ZH:is a system which is already coded, but it has never been tested or verified.": "是一个已经编码的系统，但从未经过测试或验证。",
  "EN:ZH:These are the quality assurance principles are not yet applied.": "这些都是尚未应用的质量保证原则。",
  "EN:ZH:So by this time we have spent another one and a half month.": "所以，到这个时候，我们又花了一个半月的时间。",
  "EN:ZH:So now by this time, if you look at here from here to here, we have already spent four and a half": "所以，现在这个时候，如果你看看从这里到这里，我们已经花了四个半月的时间",
  "EN:ZH:month and by the end of four and a half month, what we have got is an unverified system which is never": "而在四个半月结束时，我们得到的是一个未经验证的系统，它永远不会",
  "EN:ZH:been tested for quality purposes.": "已经过质量检测。",
  "EN:ZH:The next phase is this unverified system will go through verification.": "下一阶段，这个未经验证的系统将通过验证。",
  "EN:ZH:So the testers will start testing this unverified system.": "因此，测试人员将开始测试这个未经验证的系统。",
  "EN:ZH:And then it will take another one and a half month.": "然后还需要一个半月的时间。",
  "EN:ZH:And by the end of this validation phase, we'll release a product to the customer.": "验证阶段结束后，我们将向客户发布产品。",
  "EN:ZH:So it will take around six months for one single cycle to requirement to actually delivering a verified": "因此，从一个周期的要求到实际交付经过验证的产品，大约需要 6 个月的时间。",
  "EN:ZH:system.": "系统",
  "EN:ZH:It will take six months before the customer actually sees what is actually developed and before actually": "在客户真正看到实际开发的产品之前需要 6 个月的时间，而在客户看到实际开发的产品之前也需要 6 个月的时间。",
  "EN:ZH:the product reaches the customer.": "产品到达客户手中。",
  "EN:ZH:So that's what used to happen in waterfall, but in agile.": "这就是过去瀑布式工作中的情况，但在敏捷工作中也是如此。",
  "EN:ZH:So what happens is all these four phases requirement, design, implementation, verification, all": "因此，所有这四个阶段的要求、设计、实施、验证都是",
  "EN:ZH:these are done in a shorter cycle which is usually one month or less.": "这些工作的周期较短，通常为一个月或更短。",
  "EN:ZH:So for sake of this example this is a one month cycle.": "因此，在这个例子中，周期为一个月。",
  "EN:ZH:So within one month all these four steps will be done.": "因此，这四个步骤将在一个月内全部完成。",
  "EN:ZH:So we'll do requirement design implementation verification all of this in a one month or less cycle.": "因此，我们将在一个月或更短的周期内完成需求设计、实施验证等所有工作。",
  "EN:ZH:And by the end of this cycle you will have a small product which we can deliver to the customer.": "这个周期结束后，我们就可以向客户交付一个小产品。",
  "EN:ZH:And customer can actually use it and provide feedback to us.": "客户可以实际使用它，并向我们提供反馈。",
  "EN:ZH:So that's the key difference.": "这就是关键的区别。",
  "EN:ZH:Now each of this let's say this one is cycle number one.": "比方说，每一个循环都是一号循环。",
  "EN:ZH:This is two three.": "这是两个 3。",
  "EN:ZH:So after you have done this cycle, immediately you start the second cycle.": "因此，在完成这个循环后，你就会立即开始第二个循环。",
  "EN:ZH:And whatever you have learned from here, whether it's from customer feedback or the process you are": "无论您从这里学到了什么，无论是从客户反馈中还是从您的流程中",
  "EN:ZH:using, while you use that process, you would have learned that these are some of the wrong practices": "在使用该程序的同时，您会了解到以下一些错误做法",
  "EN:ZH:you are following.": "您正在关注的是",
  "EN:ZH:Let's fix these practices.": "让我们来纠正这些做法。",
  "EN:ZH:So you take that feedback and implement that along with new features in second cycle.": "因此，你要采纳这些反馈意见，并在第二个周期中与新功能一起实施。",
  "EN:ZH:And again in the second cycle you will do these four steps requirement design, implementation, verification.": "同样，在第二个周期中，你将完成需求设计、实施、验证这四个步骤。",
  "EN:ZH:All these four in the second cycle again.": "所有这四项都在第二个周期。",
  "EN:ZH:And then by the end of second cycle which is by the end of two months here the two months will end.": "然后在第二个周期结束时，也就是在这里的两个月结束时，这两个月也将结束。",
  "EN:ZH:You will have another increment of the product.": "您将获得该产品的另一个增量。",
  "EN:ZH:So now you have a bigger product.": "现在你有了更大的产品。",
  "EN:ZH:So this is how the product looks after the first iteration was over.": "这就是第一次迭代结束后的产品外观。",
  "EN:ZH:This is how the product looks after second iteration.": "这是第二次迭代后的产品外观。",
  "EN:ZH:Now I have a question by the end of let's say this is four and a half months, how many product increment": "现在我有一个问题，假设四个半月结束，有多少产品增量？",
  "EN:ZH:we would have delivered in waterfall and how many would have delivered in agile that by the end of four": "我们在瀑布式项目中会交付多少项目，在敏捷式项目中会交付多少项目？",
  "EN:ZH:and a half months, from here to here.": "一个半月，从这里到这里。",
  "EN:ZH:How many product increment we would have delivered and how many in waterfall.": "我们会交付多少增量产品，以及在瀑布式流程中交付多少增量产品。",
  "EN:ZH:So in if you look at it by this point we have delivered 12344 product increment in agile.": "因此，到目前为止，我们已经在敏捷领域交付了 12344 个产品增量。",
  "EN:ZH:But in waterfall what we have delivered is documents after documents and then unverified systems.": "但在瀑布式系统中，我们交付的是一个又一个文件，然后是未经验证的系统。",
  "EN:ZH:So we have delivered something which is not usable to customer.": "因此，我们交付给客户的东西是无法使用的。",
  "EN:ZH:So customer have never seen our product.": "因此，客户从未见过我们的产品。",
  "EN:ZH:My next question is how many feedback cycle has gone through?": "我的下一个问题是，已经经历了多少个反馈周期？",
  "EN:ZH:I end of four and a half month in waterfall and in agile.": "我结束了四个半月的瀑布式和敏捷式工作。",
  "EN:ZH:So we have delivered this requirement document by end of this.": "因此，我们已在今年年底前提交了这份需求文件。",
  "EN:ZH:Is this not a feedback cycle?": "这难道不是一个反馈循环吗？",
  "EN:ZH:So when we are talking about feedback we are talking about feedback from the customer.": "因此，当我们谈论反馈时，我们谈论的是来自客户的反馈。",
  "EN:ZH:So by the end of four and a half month in waterfall, the customer have never seen the product.": "因此，在瀑布式流程的四个半月结束时，客户还从未见过产品。",
  "EN:ZH:And because their customer have never seen or used the product, so they have never provided us any": "而且，由于他们的客户从未见过或使用过该产品，因此他们从未向我们提供过任何",
  "EN:ZH:feedback.": "反馈。",
  "EN:ZH:But whereas if you look at incremental delivery, by the end of first month, we have delivered one": "但是，如果从增量交付的角度来看，在第一个月结束时，我们已经交付了一个",
  "EN:ZH:incremental customer, and the customer have now seen the product use the product, and now they would": "增量客户，而客户现在已经看到了产品，使用了产品，现在他们会",
  "EN:ZH:have provided us a feedback which we can use to apply to our next iteration so we can make the product": "为我们提供了反馈意见，我们可以将其应用到下一次迭代中，从而使产品",
  "EN:ZH:better.": "更好。",
  "EN:ZH:Let's say you are building a skateboard and you deliver the skateboard here.": "比方说，你正在制作一个滑板，然后把滑板送到这里。",
  "EN:ZH:And after that, the skateboard color was, let's say, red, and the customer started using it.": "之后，滑板的颜色变成了红色，顾客开始使用它。",
  "EN:ZH:And then they are telling that we don't like the the product.": "然后他们又说我们不喜欢这个产品。",
  "EN:ZH:And when you ask them why, they tell you that the color is red.": "当你问他们为什么时，他们会告诉你颜色是红色的。",
  "EN:ZH:So then you say that if you don't like red, what?": "所以你说，如果你不喜欢红色，那又怎样？",
  "EN:ZH:What color do you like?": "你喜欢什么颜色？",
  "EN:ZH:They tell you blue.": "他们告诉你蓝色。",
  "EN:ZH:So now that the customer want blue color, so you fix that in your next iteration.": "现在客户想要蓝色，所以你要在下一次迭代中解决这个问题。",
  "EN:ZH:So you change the color of your product to blue in in the next iteration.": "于是，在下一次迭代中，你将产品的颜色改为蓝色。",
  "EN:ZH:Also you add other features as well.": "此外，您还可以添加其他功能。",
  "EN:ZH:So that way we are going through four feedback cycle in four and a half month in case of agile, because": "因此，在敏捷的情况下，我们要在四个半月内完成四个反馈周期，因为",
  "EN:ZH:this is one cycle, this is second, this third, fourth.": "这是一个周期，这是第二个周期，这是第三个周期，第四个周期。",
  "EN:ZH:And what it does is it reduces the amount of risk we are going through significantly, because in waterfall": "它的作用是大大降低了我们的风险。",
  "EN:ZH:we are blindsided.": "我们被打懵了。",
  "EN:ZH:We don't know whatever we are building.": "我们不知道自己在建造什么。",
  "EN:ZH:Is it really required by the customer or this is our fancy.": "这是客户的要求，还是我们的幻想？",
  "EN:ZH:We being product managers or product director, we might think that this is what actually going to be": "我们身为产品经理或产品总监，可能会认为这才是真正要做的事情。",
  "EN:ZH:used by the customer.": "客户使用。",
  "EN:ZH:But what if whatever you are thinking, you are investing millions and millions of pound and six months,": "但是，如果无论你在想什么，你都在投资数百万、数千万英镑和六个月的时间呢？",
  "EN:ZH:eight months of your time?": "八个月的时间？",
  "EN:ZH:By the time you actually deliver that product to a market customer, don't like it at all because you": "当你真正把产品交付给市场客户时，却发现自己根本不喜欢它，因为你",
  "EN:ZH:made a wrong hypothesis that customer are going to like this particular product.": "错误地认为客户会喜欢这种产品。",
  "EN:ZH:But that risk is reduced significantly in agile because you can deliver MVP by the end of one month,": "但在敏捷项目中，这种风险会大大降低，因为您可以在一个月内交付 MVP、",
  "EN:ZH:and you can have multiple feedback cycles through which you can learn what is actually going to work": "你可以有多个反馈周期，通过这些周期，你可以了解什么是真正有效的",
  "EN:ZH:and not work.": "而不是工作。",
  "EN:ZH:What is the minimum viable product?": "什么是最小可行产品？",
  "EN:ZH:It is product or service that has enough feature to effectively deploy it to a set of customers and": "它是一种产品或服务，具有足够的功能，可以有效地将其部署到客户群中。",
  "EN:ZH:early adopters who can give direct and valuable feedback while it is still early and inexpensive to": "早期采用者，他们可以在早期提供直接和有价值的反馈意见，而且成本低廉。",
  "EN:ZH:make changes.": "进行更改。",
  "EN:ZH:You are not spending crazy amount of money to develop MVP, but you are building something which is": "开发 MVP 不需要花费巨额资金，但您要开发的东西是",
  "EN:ZH:still usable by the customer, and they will be able to provide feedback on it to you so that you can": "客户仍然可以使用，而且他们可以向您提供反馈，以便您可以",
  "EN:ZH:use that feedback to improvise your product.": "利用反馈意见改进产品。",
  "EN:ZH:So here they are taking an example.": "因此，他们在这里做出了榜样。",
  "EN:ZH:Let's say you want to go from Delhi to Bombay.": "假设您想从德里前往孟买。",
  "EN:ZH:And for going there what you need is a car.": "要去那里，你需要一辆车。",
  "EN:ZH:At least that's what is assumed by us as product manager that we need a car for going from Delhi to": "至少作为产品经理的我们是这么认为的，我们需要一辆车从德里到",
  "EN:ZH:Bombay.": "孟买",
  "EN:ZH:So in agile MVP methodology, instead of building the car from the beginning.": "因此，在敏捷 MVP 方法中，不是从一开始就制造汽车。",
  "EN:ZH:What you do is you do incremental iterative approach where you build a skirting board, which is step": "你要做的就是采用渐进迭代的方法，在此过程中，你要建立一个踢脚板，这一步是",
  "EN:ZH:number one, which let's say one way is to go from Delhi to Bombay by walking, which is the slowest": "第一，假设有一种方法是从德里步行到孟买，这是最缓慢的方法",
  "EN:ZH:way for that.": "的方式。",
  "EN:ZH:The customer doesn't need any product from you.": "客户不需要你提供任何产品。",
  "EN:ZH:But then instead of walking from Delhi to Bombay, what you are doing is you're giving the customer": "但是，与其从德里走到孟买，你现在要做的是让客户",
  "EN:ZH:a skirting board, and you might take a month or so to build this skirting board, and it will not give": "一块踢脚板，你可能要花费一个月左右的时间来制作这块踢脚板，而且它不会给",
  "EN:ZH:the customer the speed or pace of car or the comfort of car, but it will still help the customer in": "汽车的速度、节奏或舒适度，但它仍会在以下方面为客户提供帮助",
  "EN:ZH:improving their velocity so they can move towards Bombay in a more, faster way.": "提高他们的速度，以便以更快、更大的速度向孟买移动。",
  "EN:ZH:So what you do is you build a skirting board which is still usable to the customer because it is helping": "因此，你要做的就是制作一块对客户来说仍然可用的踢脚板，因为它可以帮助",
  "EN:ZH:the customer to move towards their goal.": "让客户朝着自己的目标前进。",
  "EN:ZH:So because they want to move from Delhi to Bombay, they can use this board to move towards there.": "因此，如果他们想从德里前往孟买，就可以利用这块木板前往那里。",
  "EN:ZH:So that's why in this particular example this is MVP.": "因此，在这个特殊的例子中，这就是 MVP 的原因。",
  "EN:ZH:Then what you do in next iteration is you add some more value, which makes the life of customer better": "在下一次迭代中，你要做的就是增加更多价值，让客户的生活更美好。",
  "EN:ZH:in terms of the product usability.": "在产品可用性方面。",
  "EN:ZH:So in this particular example, what they have shown is they have added a handle.": "因此，在这个特殊的例子中，他们所展示的是他们添加了一个句柄。",
  "EN:ZH:So what this handle does is on the board it helps you to have control on the direction of the skating": "因此，这个把手的作用是在滑板上帮助你控制滑行方向。",
  "EN:ZH:board.": "董事会。",
  "EN:ZH:More so now you are able to control with your hands where you want to go.": "现在你更能用双手控制你想去的地方。",
  "EN:ZH:And also it helps you to stand on the board more stably.": "它还能帮助你更稳定地站在木板上。",
  "EN:ZH:And the next step is to convert this board into cycle by adding this chain mechanism and other parts.": "下一步是通过添加链条装置和其他部件，将这块电路板转换成循环装置。",
  "EN:ZH:And now once you move from here to here, what it means is you are adding more stability, more life": "现在，一旦你从这里移动到这里，就意味着你增加了更多的稳定性、更多的生命力",
  "EN:ZH:to the product.": "产品。",
  "EN:ZH:Customer is now able to move more faster towards his or her destination.": "客户现在可以更快地到达目的地。",
  "EN:ZH:And from third to fourth, what you are doing is you are adding a engine to this cycle, and what it": "从第三到第四，你要做的是在这个循环中增加一个引擎，它的作用是",
  "EN:ZH:does is it helps the customer to much faster pace towards their goal.": "这样做的目的是帮助客户以更快的速度实现他们的目标。",
  "EN:ZH:And then the next step is to convert this motorbike to a car, which will significantly add to the comfort.": "下一步就是把这辆摩托车改装成汽车，这样就会大大增加舒适度。",
  "EN:ZH:It will increase the pace of the journey.": "这将加快旅途的步伐。",
  "EN:ZH:It will also help in reducing the number of accidents you could have had when you were using other means.": "它还有助于减少您在使用其他方式时可能发生的事故数量。",
  "EN:ZH:So this is how agile works.": "这就是敏捷的工作原理。",
  "EN:ZH:Whereas a lot of people, even though they are using agile, they are following something like this.": "而很多人，即使在使用敏捷，也是在遵循类似这样的方法。",
  "EN:ZH:If they are trying to build a car, what they do is by the end of first iteration, they will build": "如果他们要制造一辆汽车，那么在第一次迭代结束时，他们会制造出",
  "EN:ZH:one wheel of the car that says that the front wheel.": "一个车轮上写着 \"前轮\"。",
  "EN:ZH:But by the end of first iteration, this wheel is of no use to a customer because customer who is interested": "但是，在第一次迭代结束时，这个轮子对客户来说已经没有用处了，因为客户感兴趣的是",
  "EN:ZH:in travelling, they are not interested in will.": "在旅行中，他们对意志不感兴趣。",
  "EN:ZH:They are interested in something usable to them, which is either one of these like skating board or": "他们感兴趣的是一些对他们有用的东西，比如滑板或",
  "EN:ZH:this motorcycle?": "这辆摩托车？",
  "EN:ZH:Something like that, not a wheel.": "类似的东西，不是轮子。",
  "EN:ZH:This is of no use to them in this second iteration, when people who have misunderstood this agile methodology,": "在第二次迭代中，当人们对这种敏捷方法产生误解时，这对他们毫无用处、",
  "EN:ZH:what they tend to do is they will build the base chassis of the car which is having these wheels connected": "他们的做法是建造汽车的基础底盘，将这些车轮连接起来",
  "EN:ZH:using these chassis.": "使用这些机箱。",
  "EN:ZH:And again, whatever you are delivering by the end of this second cycle, that is also not usable to": "再说一遍，无论你们在第二个周期结束时交付了什么，也不能用于",
  "EN:ZH:the customer Because what will the customer do with this?": "因为客户会用它来做什么？",
  "EN:ZH:It is not a full featured traveling vehicle.": "它不是一辆功能齐全的旅行车。",
  "EN:ZH:Then again, the next step what they do in the same journey is they will build the body of the car.": "同样，下一步他们要做的就是制造车身。",
  "EN:ZH:It doesn't have a engine, nothing, but it looks like a car, but it is not usable at all.": "它没有发动机，什么都没有，但看起来像一辆汽车，但根本不能用。",
  "EN:ZH:And in fourth iteration they build a car.": "在第四次迭代中，他们造出了一辆汽车。",
  "EN:ZH:So in this cycle, let's assume just for the sake of argument, assume it takes six months to go from": "因此，在这个周期中，为了便于论证，让我们假设需要六个月的时间才能从",
  "EN:ZH:here to here.": "从这里到这里",
  "EN:ZH:In this six months, at the end of any of these cycles, the customer is not getting any usable product.": "在这六个月中，任何一个周期结束时，客户都得不到任何可用的产品。",
  "EN:ZH:Only the end of this cycle.": "只是这个周期的结束。",
  "EN:ZH:They get a usable product, which is car.": "他们得到的是可用的产品，也就是汽车。",
  "EN:ZH:And also in this period they have never seen how your product is looking like.": "在此期间，他们也从未见过你的产品是什么样子。",
  "EN:ZH:So this is the problem in the traditional approach of building product, and how this traditional approach": "这就是传统产品制造方法的问题所在，以及这种传统方法如何",
  "EN:ZH:of building product is addressed by agile is explained in this section.": "本节将解释敏捷如何解决建筑产品的质量问题。",
  "EN:ZH:Agile Manifesto.": "敏捷宣言",
  "EN:ZH:So within this section we'll discuss the overview of agile.": "因此，在本节中，我们将讨论敏捷的概述。",
  "EN:ZH:So let's go into it.": "那我们就开始吧。",
  "EN:ZH:So what is agile?": "那么什么是敏捷呢？",
  "EN:ZH:Agile is a mindset contrary to how it is perceived in minds of a lot of people.": "敏捷是一种思维方式，这与很多人对它的看法恰恰相反。",
  "EN:ZH:What they think is if you have four meetings daily stand up, sprint planning meeting, sprint retrospective,": "他们的想法是，如果你每天召开四次会议，分别是立项会议、冲刺计划会议、冲刺回顾会议、",
  "EN:ZH:and people come in those meetings and answer those questions and do the planning, they think that is": "人们参加这些会议，回答这些问题并进行规划，他们认为这是",
  "EN:ZH:agile, but you are just doing some mechanical ceremonies.": "敏捷，但你只是在做一些机械的仪式。",
  "EN:ZH:That's not agile.": "这不是敏捷。",
  "EN:ZH:First thing about agile is a mindset.": "敏捷的第一件事就是心态。",
  "EN:ZH:People who are practicing agile, they have to have that agile mindset.": "实践敏捷的人必须具备敏捷思维。",
  "EN:ZH:And what is this mindset based on?": "这种心态是基于什么呢？",
  "EN:ZH:This mindset is based on four values which you are going to discuss in the next slide.": "这种思维方式基于四种价值观，下一张幻灯片将讨论这四种价值观。",
  "EN:ZH:So what this basically the people who are playing leadership role or working in these agile teams,": "因此，这基本上就是在这些敏捷团队中扮演领导角色或工作的人、",
  "EN:ZH:they have to have this agile mindset which is guided by these four values, and these values are described": "他们必须具备以这四种价值观为指导的敏捷思维，这四种价值观分别是",
  "EN:ZH:and backed by 12 agile principles, which we are going to discuss in the next slide.": "我们将在下一张幻灯片中讨论这些原则。",
  "EN:ZH:And these principles are applied through various agile practices for example scrum, self-organizing": "这些原则通过各种敏捷实践得以应用，例如 Scrum、自组织",
  "EN:ZH:team definition of done, cadence, timebox and retrospective.": "团队对 \"已完成\"、\"进度\"、\"时限 \"和 \"回顾 \"的定义。",
  "EN:ZH:And then it is supported by various frameworks and tools, for example design thinking, XP, scrum": "然后，它得到各种框架和工具的支持，例如设计思维、XP、Scrum",
  "EN:ZH:and safe.": "和安全。",
  "EN:ZH:So what are these for?": "那么，这些是做什么用的呢？",
  "EN:ZH:Scrum is one of the agile frameworks.": "Scrum 是敏捷框架之一。",
  "EN:ZH:Well it is the most popular one, but that doesn't mean there are not other agile frameworks.": "它是最流行的敏捷框架，但这并不意味着没有其他敏捷框架。",
  "EN:ZH:So remember that there are so many other agile framework and scrum is the most popular one.": "因此，请记住还有很多其他的敏捷框架，Scrum 是最流行的一种。",
  "EN:ZH:But there are others like design thinking XP.": "不过，还有其他一些方法，比如设计思维 XP。",
  "EN:ZH:So that's the core idea of agile.": "这就是敏捷的核心理念。",
  "EN:ZH:Let's go inside these values, principles and scrum one by one in coming slides.": "让我们在接下来的幻灯片中逐一了解这些价值观、原则和 scrum。",
  "EN:ZH:Have you ever felt frustrated by rigid processes and excessive documentation that slows down software": "您是否曾因僵化的流程和过多的文档而感到沮丧，因为它们拖慢了软件的运行速度？",
  "EN:ZH:development?": "发展？",
  "EN:ZH:What if there was a better way, one that prioritizes teamwork and real progress over bureaucracy?": "如果有一种更好的方式，一种将团队合作和真正的进步置于官僚主义之上的方式呢？",
  "EN:ZH:That's exactly what agile values offer.": "这正是敏捷价值观所能提供的。",
  "EN:ZH:In this video, we'll dive into first two agile values that revolutionized software development.": "在本视频中，我们将深入探讨彻底改变软件开发的前两个敏捷价值观。",
  "EN:ZH:First, individuals and interactions over process and tools.": "首先，个人和互动重于过程和工具。",
  "EN:ZH:Second, working software over comprehensive documentation.": "其次，工作软件比全面的文档更重要。",
  "EN:ZH:Understanding these values will help you shift your mindset towards collaboration and efficiency, making": "了解这些价值观将帮助您转变观念，提高协作和效率，使",
  "EN:ZH:your team more productive and adaptive.": "提高团队的工作效率和适应能力。",
  "EN:ZH:Agile is backed by agile values.": "敏捷以敏捷价值观为支撑。",
  "EN:ZH:How you create that agile mindset by having these four agile values.": "如何通过这四种敏捷价值观来创建敏捷思维。",
  "EN:ZH:In 2001, there was a group of 17 software developers and they all gathered in a place which is known": "2001 年，有一个由 17 名软件开发人员组成的小组，他们聚集在一个被称为",
  "EN:ZH:as UBT In a ski resort, and together they were all frustrated with the old ways of developing software,": "他们都对软件开发的旧方法感到沮丧、",
  "EN:ZH:and they found so many problems with the existing ways of developing software at that time.": "他们发现当时现有的软件开发方法存在很多问题。",
  "EN:ZH:At that time, the most popular method of developing software products or waterfall.": "当时，最流行的软件产品开发方法还是瀑布法。",
  "EN:ZH:So they found problems with that method.": "因此，他们发现这种方法存在问题。",
  "EN:ZH:And what they have done is to address those problems.": "他们所做的就是解决这些问题。",
  "EN:ZH:They came up with these agile values and principles.": "他们提出了这些敏捷价值观和原则。",
  "EN:ZH:If you have worked in waterfall, you would see that these are the things on the right hand side.": "如果你曾在瀑布式系统中工作过，你就会发现这些东西都在右侧。",
  "EN:ZH:They are common problems in the waterfall method.": "它们是瀑布法中的常见问题。",
  "EN:ZH:And what they are trying to do is whatever was happening in waterfall, they have come up with opposite": "他们所要做的是，无论瀑布式系统中发生了什么，他们都会想出与之相反的方法。",
  "EN:ZH:of that and build them as value in agile so that those waterfall related problems can be solved.": "并在敏捷中将其作为价值来构建，这样就能解决与瀑布式瀑布相关的问题。",
  "EN:ZH:So let's go through those things.": "那么，让我们来回顾一下这些事情。",
  "EN:ZH:What are the individuals and interactions over processes and tools?": "相对于流程和工具而言，个人和互动是什么？",
  "EN:ZH:What it means is values interactions between individuals, individuals and people who are working in": "它的含义是重视个人之间、个人与在以下领域工作的人之间的互动",
  "EN:ZH:agile team or the stakeholder.": "敏捷团队或利益相关者。",
  "EN:ZH:Stakeholder can be the business people who provide a requirement, or the sponsors who provide us money": "利益相关者可以是提供需求的企业人员，也可以是为我们提供资金的赞助商",
  "EN:ZH:to build this product.": "来制造这个产品。",
  "EN:ZH:So agile prefer interactions with discussion.": "因此，敏捷更喜欢通过讨论进行互动。",
  "EN:ZH:It can be face to face voice call being in the same place, so interactions between various stakeholders": "它可以是面对面的语音通话，也可以是在同一地点的语音通话，因此各利益攸关方之间可以进行互动",
  "EN:ZH:and agile team members rather than following process and tools.": "和敏捷团队成员，而不是遵循流程和工具。",
  "EN:ZH:So they are not saying there is no value in following process and tools, but they give much more value": "因此，他们并不是说遵循流程和工具没有价值，而是他们赋予了更多的价值",
  "EN:ZH:to interactions between individuals.": "个人之间的互动。",
  "EN:ZH:Why they are doing this is because in the old regime, which is waterfall regime, what used to happen": "他们这样做的原因是，在旧制度（即瀑布制度）中，曾经发生的情况是",
  "EN:ZH:is the people used to give the requirements.": "是用来提出要求的人。",
  "EN:ZH:They used to sit in a different office, they will be in a different team.": "他们过去坐在不同的办公室，现在将在不同的团队。",
  "EN:ZH:And the people who used to actually develop the software or product, they used to sit in different": "而那些真正开发软件或产品的人，他们曾经坐在不同的岗位上",
  "EN:ZH:teams.": "队伍",
  "EN:ZH:And these people who are developing the software, they used to follow very heavyweight processes to": "而这些开发软件的人，以前都是按照非常繁琐的流程来进行的",
  "EN:ZH:develop these softwares.": "开发这些软件。",
  "EN:ZH:And a lot of that software development team time will go in just following these processes or getting": "而软件开发团队的大量时间将用于遵循这些流程或获取",
  "EN:ZH:acquainted with tools, and it will make their life difficult.": "熟悉工具会给他们的生活带来困难。",
  "EN:ZH:So to solve that problem, they have come up with this solution that they prefer to have more interaction": "因此，为了解决这个问题，他们提出了这样一个解决方案，即他们更希望有更多的互动",
  "EN:ZH:between the business stakeholders and the development team.": "业务利益相关者和开发团队之间的联系。",
  "EN:ZH:That's the idea being conveyed here.": "这就是这里要表达的意思。",
  "EN:ZH:The second one is working software over comprehensive documentation.": "第二种是工作软件，而不是全面的文档。",
  "EN:ZH:If you have worked in waterfall, you will remember that we used to write very, very detailed requirement": "如果你曾在瀑布式系统中工作过，你就会记得我们曾经写过非常非常详细的需求。",
  "EN:ZH:documents.": "文件",
  "EN:ZH:And sometimes it used to say three months, six months in just gathering and documenting the requirements.": "有时，仅收集和记录需求就需要三个月或六个月的时间。",
  "EN:ZH:And we'll do very, very detailed design documents like the medium level design, low level design.": "我们会做非常非常详细的设计文件，比如中层设计和低层设计。",
  "EN:ZH:So we used to do a lot of design documents.": "因此，我们曾经做过很多设计文档。",
  "EN:ZH:Most of the time of people who are working or developing these software products will go into just writing": "开发这些软件产品的人的大部分时间都花在了写作上。",
  "EN:ZH:these documentation, and they will have very little or no time to actually code the system or build": "这些文档，而且他们几乎没有时间来实际编写系统代码或构建系统。",
  "EN:ZH:the system.": "系统。",
  "EN:ZH:And many times what used to happen is 8,090% of program budget will get burned in just writing the documentation,": "很多时候，光是编写文档就会耗费 8090% 的项目预算、",
  "EN:ZH:and only 510% money is left for actually building the product, because by the time you do all the requirements": "只剩下 510% 的资金用于实际开发产品，因为当你满足所有要求时",
  "EN:ZH:and design, all the program budget has been already burned.": "和设计，所有的计划预算都已烧完。",
  "EN:ZH:That used to be a common sight in waterfall project to address that problem.": "这曾经是瀑布式项目中常见的解决该问题的方法。",
  "EN:ZH:They have come up with this value where they are saying that they give more value to working software,": "他们提出了这样一种价值观，即他们赋予工作软件更多的价值、",
  "EN:ZH:which is what actually customers want.": "这才是客户真正想要的。",
  "EN:ZH:It's going back to the same idea which I was conveying in my this slide, that if you just write documentation": "这又回到了我在这张幻灯片中表达的同一个观点，即如果你只是编写文档",
  "EN:ZH:and documentation that is of no value to the customer.": "以及对客户没有价值的文件。",
  "EN:ZH:Customer is interested in a working software or working product.": "客户对可运行的软件或产品感兴趣。",
  "EN:ZH:What they will do with the requirement and design document.": "他们将如何处理需求和设计文件。",
  "EN:ZH:The customer doesn't care how good the requirement and design document you have written, and that's": "客户并不在乎你写的需求和设计文档有多好，这就是",
  "EN:ZH:what it's being conveyed here that the Agile Manifesto gives more value to the working software as compared": "这里所要表达的意思是，相比之下，敏捷宣言赋予了工作软件更多的价值。",
  "EN:ZH:to comprehensive documentation.": "全面的文件。",
  "EN:ZH:In summary, agile empowers team by emphasizing people over processes and working solutions over paperwork.": "总之，敏捷通过强调人而不是流程，强调工作解决方案而不是文书工作来增强团队的能力。",
  "EN:ZH:These values help eliminate bottlenecks, foster collaboration, and keep team focused on delivering": "这些价值观有助于消除瓶颈、促进协作，并使团队专注于交付成果",
  "EN:ZH:real value.": "真正的价值。",
  "EN:ZH:Stay tuned for part two where we will explore the remaining agile values.": "敬请期待第二部分，我们将探讨其余的敏捷价值观。",
  "EN:ZH:What happens when teams and customers don't communicate effectively, or when a strict plan becomes": "当团队和客户不能有效沟通时，或者当严格的计划变得",
  "EN:ZH:outdated before the project is even halfway done?": "项目还没完成一半就过时了？",
  "EN:ZH:Agile values provide a solution by emphasizing flexibility and collaboration over rigid contracts and": "敏捷价值观提供了一种解决方案，它强调灵活性和协作，而不是僵化的合同和",
  "EN:ZH:fixed plans.": "固定计划。",
  "EN:ZH:In this video, we will explore the remaining agile values that drive adaptability and customer satisfaction.": "在本视频中，我们将探讨推动适应性和客户满意度的其余敏捷价值观。",
  "EN:ZH:First, customer collaboration over contract negotiation.": "首先，客户合作重于合同谈判。",
  "EN:ZH:Second, responding to change over following a plan.": "第二，应对变化胜于按计划行事。",
  "EN:ZH:By understanding these values, you will learn how agile teams build the right product by working closely": "通过了解这些价值观，您将学习敏捷团队如何通过紧密合作打造正确的产品",
  "EN:ZH:with customers and embracing change rather than resisting it.": "与客户合作，拥抱变化而不是抵制变化。",
  "EN:ZH:Customer collaboration over contract negotiation.": "客户合作重于合同谈判。",
  "EN:ZH:So what used to happen in waterfall is the business people who will give us the requirement and the": "因此，在瀑布式流程中，业务人员会向我们提供需求和",
  "EN:ZH:developers.": "开发人员",
  "EN:ZH:They used to sit in a different building and by times business people are in us and the developers are": "他们过去坐在另一栋楼里，而现在商务人士在我们这里，开发商在我们这里。",
  "EN:ZH:in India.": "在印度。",
  "EN:ZH:There is not much collaboration or discussions between them and the business.": "他们与企业之间的合作或讨论并不多。",
  "EN:ZH:People will write requirements in the form of document, and they will share those documents with the": "人们会以文档的形式编写需求，并将这些文档分享给",
  "EN:ZH:developers, and the developers will read through these requirement documents and develop software.": "开发人员将阅读这些需求文档并开发软件。",
  "EN:ZH:And what was the problem in that kind of process was that there was a lot of miscommunication.": "在这个过程中，问题在于沟通不畅。",
  "EN:ZH:The business people, let's say, want to develop a chair, but actually the developer end up developing": "比方说，商界人士想开发一把椅子，但实际上开发商最终开发的是",
  "EN:ZH:a table because they haven't fully understood what are the requirements, because requirements were": "因为他们还没有完全理解需求是什么，因为需求是",
  "EN:ZH:conveyed in form of documents, and there was not much interaction or collaboration between business": "以文件形式传达，业务部门之间没有太多的互动或合作。",
  "EN:ZH:people and developers.": "人和开发人员。",
  "EN:ZH:So to solve that problem, they have come up with this value customer collaboration.": "因此，为了解决这个问题，他们提出了 \"客户合作价值\"。",
  "EN:ZH:What it means is there is collaboration between the scrum team, people who are actually going to develop": "这意味着，Scrum 团队、实际开发人员和项目管理人员之间要相互协作。",
  "EN:ZH:the product and the business people who are going to give us money or who are giving us requirement.": "产品，以及要给我们钱或给我们要求的商人。",
  "EN:ZH:So they have to work together, they have to collaborate with each other.": "因此，他们必须共同努力，相互协作。",
  "EN:ZH:And rather than spending a lot of time in contract negotiation.": "而不是在合同谈判上花费大量时间。",
  "EN:ZH:So what used to happen in waterfall is there will be lot of time in writing down the contract between": "因此，在瀑布式流程中，需要花费大量的时间来编写合同。",
  "EN:ZH:various parties who are going to develop the product.": "开发产品的各方。",
  "EN:ZH:Or for example, you are a big customer, let's say Apple, and you want to build a product and you": "或者举个例子，你是苹果公司的大客户，你想开发一款产品，而你",
  "EN:ZH:want to get it built, let's say.": "比方说，想把它建起来。",
  "EN:ZH:So what will happen is a lot of contract negotiation will happen, and a lot of time will go wasted": "因此，将会发生大量的合同谈判，浪费大量的时间",
  "EN:ZH:in just agreeing the contract rather than actually building the product.": "只是同意签订合同，而不是实际制造产品。",
  "EN:ZH:So what they are saying is that in Agile Manifesto, they give more value to customer collaboration": "因此，他们的意思是，在《敏捷宣言》中，他们赋予了客户协作更多的价值",
  "EN:ZH:rather than contract negotiation.": "而不是合同谈判。",
  "EN:ZH:Next one is responding to change over following a plan.": "其次是应对变化，而不是按计划行事。",
  "EN:ZH:So those of you who have worked in waterfall, there used to be a lot of upfront planning in waterfall.": "因此，在瀑布式系统中工作过的人都知道，在瀑布式系统中需要进行大量的前期规划。",
  "EN:ZH:Let's say you are working on a project and the project will go for, let's say, three years.": "比方说，你正在做一个项目，这个项目将持续三年。",
  "EN:ZH:So what the project manager will do in waterfall is they will build a upfront, very, very detailed": "因此，在瀑布式项目中，项目经理要做的就是建立一个前期的、非常详细的",
  "EN:ZH:plan up to the fifth level of activity for action items in advance for the entire three years.": "提前为整个三年的行动项目制定最高达第五级的活动计划。",
  "EN:ZH:And everyone has to just follow that plan word by word.": "每个人都必须一字不差地按照计划行事。",
  "EN:ZH:That's what used to happen in waterfall.": "这就是过去瀑布式的情况。",
  "EN:ZH:Whereas in agile they are suggesting to responding to change why?": "而在敏捷中，他们建议应对变化，为什么？",
  "EN:ZH:They are suggesting to responding to changes, because when you have done a lot of upfront planning.": "他们建议应对变化，因为当你做了大量的前期规划时。",
  "EN:ZH:Let's say you are trying to launch a autonomous car and you build a very detailed plan for three years.": "比方说，你正试图推出一款自动驾驶汽车，你制定了一个非常详细的三年计划。",
  "EN:ZH:What if something change in the regulatory environment?": "如果监管环境发生变化怎么办？",
  "EN:ZH:What if the regulators who are regulating the autonomous car space, they say if you are launching autonomous": "如果管理自动驾驶汽车领域的监管机构说，如果你要推出自动驾驶汽车，你会怎么做？",
  "EN:ZH:car, it can't go beyond 50km/h.": "汽车，时速不能超过 50 公里。",
  "EN:ZH:If they come up with that kind of regulation, how you are going to handle in waterfall, because you": "如果他们制定了这样的规定，你将如何在瀑布式管理中进行处理，因为你",
  "EN:ZH:have already built a plan for three years.": "已经制定了三年计划。",
  "EN:ZH:If you can't, you can't change your plan.": "如果做不到，就不能改变计划。",
  "EN:ZH:There is very little scope or very limited scope to change it.": "改变的余地很小，或者说非常有限。",
  "EN:ZH:And there can be other things, like your competitor can launch a totally different kind of product,": "还可能有其他情况，比如你的竞争对手可能会推出一种完全不同的产品、",
  "EN:ZH:which suddenly start getting a lot of attention from the marketplace.": "突然开始受到市场的广泛关注。",
  "EN:ZH:Look at what has happened with Google and OpenAI launched their chat GTP.": "看看谷歌和 OpenAI 推出的聊天工具 GTP 都发生了什么。",
  "EN:ZH:Google lost close to 100 billion US dollar in their market capital.": "谷歌损失了近 1000 亿美元的市场资本。",
  "EN:ZH:What it meant is they have to suddenly throw all their plans and roadmap in the back burner and come": "这意味着他们必须突然把所有的计划和路线图都抛到脑后，然后来",
  "EN:ZH:up with totally new roadmaps for all their products, because now they have a existential threat in": "为他们的所有产品制定全新的路线图，因为现在他们面临的生存威胁是",
  "EN:ZH:the marketplace, because if they don't change their product roadmap to align with what the kind of": "因为如果他们不改变自己的产品路线图，使之与市场上的",
  "EN:ZH:capabilities of ChatGPT, they will become insignificant or irrelevant.": "它们将变得无足轻重或无关紧要。",
  "EN:ZH:So to address that, what you need is you should follow a framework which allows you to change your": "因此，要解决这个问题，你需要遵循一个框架，让你能够改变你的",
  "EN:ZH:roadmap, change your requirements, which allows you to respond to the changing situation in marketplace,": "这使您能够应对不断变化的市场形势、",
  "EN:ZH:changing needs of customer.": "不断变化的客户需求。",
  "EN:ZH:And that's what they are explaining here.": "这就是他们在这里要解释的。",
  "EN:ZH:Responding to change the agile framework you are using, it should allow you to respond to change rather": "应对变化 你所使用的敏捷框架应允许你应对变化，而不是",
  "EN:ZH:than following a strict plan.": "而不是遵循严格的计划。",
  "EN:ZH:Obviously there is value in following a plan, but this responding to change is more valuable.": "显然，按计划行事有其价值，但这种顺应变化的做法更有价值。",
  "EN:ZH:In summary, agile values help teams stay aligned with customer needs and remain flexible in a fast": "总之，敏捷价值观有助于团队与客户需求保持一致，并在快速发展中保持灵活性。",
  "EN:ZH:changing world.": "不断变化的世界。",
  "EN:ZH:By prioritizing collaboration and adaptability, agile ensures that products are built for real users,": "通过优先考虑协作和适应性，敏捷确保了产品是为真正的用户打造的、",
  "EN:ZH:not just for a contract or a plan.": "而不仅仅是合同或计划。",
  "EN:ZH:Thanks for watching and keep embracing agility in your teams.": "感谢您的收看，请继续在您的团队中拥抱敏捷。",
  "EN:ZH:In this slide we are going to cover the Agile Manifesto, the 12 principles.": "在这张幻灯片中，我们将介绍《敏捷宣言》的 12 项原则。",
  "EN:ZH:So let's go through these principles one by one.": "下面，我们就来逐一讨论这些原则。",
  "EN:ZH:The first principle is our highest priority is to satisfy customer through early and continuous delivery": "我们的首要原则是通过早期和持续交付来满足客户需求。",
  "EN:ZH:of valuable software.": "有价值的软件。",
  "EN:ZH:What this first principle is saying is the highest priority of a scrum team is to satisfy the end customer,": "这第一条原则的意思是，Scrum 团队的首要任务是满足最终客户的需求、",
  "EN:ZH:to understand what the customer wants and or needs, and deliver that to the customer early.": "了解客户的愿望和需求，并尽早将其传递给客户。",
  "EN:ZH:So if you remember in waterfall, we used to deliver the first product version of product by six months.": "因此，如果你还记得在瀑布法中，我们曾经在六个月前交付第一个产品版本。",
  "EN:ZH:But here in agile we deliver in every four weeks, which is month or less than a month.": "但在敏捷项目中，我们每四周交付一次，也就是一个月或不到一个月的时间。",
  "EN:ZH:So the key idea here is deliver early to customer and continuously.": "因此，这里的关键在于尽早并持续地向客户交付产品。",
  "EN:ZH:So keep delivering early like which is like at least once a month or twice a month or and keep continuously": "因此，要继续尽早交货，比如至少每月一次或每月两次，或者持续不断地交货",
  "EN:ZH:deliver valuable software to them continuously means sprint after sprint, iteration after iteration,": "向他们持续交付有价值的软件意味着一次又一次的冲刺，一次又一次的迭代、",
  "EN:ZH:like one month, then second month, third month.": "比如一个月，然后是第二个月、第三个月。",
  "EN:ZH:So this is what they are trying to say.": "这就是他们想说的。",
  "EN:ZH:That is our highest priority, to deliver the value to a customer early and deliver this value to them": "我们的首要任务是尽早为客户创造价值，并将价值传递给他们。",
  "EN:ZH:continuously, iteration after iteration.": "不断地，一次又一次地迭代。",
  "EN:ZH:Then the second one welcome changing requirements even late in development.": "其次是欢迎不断变化的需求，即使是在开发后期。",
  "EN:ZH:Agile processes harness change for the customer.": "敏捷流程为客户带来变革。",
  "EN:ZH:Competitive advantage.": "竞争优势。",
  "EN:ZH:This mean is, even though we are in the late in the cycle, agile frameworks should allow, uh, changing": "这意味着，即使我们处于周期的后期，敏捷框架也应允许，呃，改变",
  "EN:ZH:requirements.": "要求。",
  "EN:ZH:This very simple.": "这很简单。",
  "EN:ZH:The example related to this I have already given you.": "与此相关的例子我已经举过了。",
  "EN:ZH:For example, recently what happened is with the launch of chat GTP lot of companies which are in uh,": "例如，最近，随着聊天 GTP 的推出，很多公司都在呃、",
  "EN:ZH:with uh, which are, which were playing in similar space.": "与呃，这是，这是在类似的空间发挥。",
  "EN:ZH:They have to continuously trash their existing roadmaps, because what they have to do is they have": "他们必须不断破坏现有的路线图，因为他们必须做的是",
  "EN:ZH:to align to what chat GTP is, capable or otherwise, they will not be relevant to the marketplace in": "无论它们是否有能力与聊天 GTP 保持一致，它们在以下情况下都与市场无关",
  "EN:ZH:coming years, right?": "未来几年，对吗？",
  "EN:ZH:So that's what they are telling us here, that the agile frameworks we are following should be open": "这就是他们要告诉我们的，我们遵循的敏捷框架应该是开放的。",
  "EN:ZH:to changes in requirement changes, and why they should be open is because it will help the customer": "为什么它们应该是开放的，因为这将有助于客户",
  "EN:ZH:to remain competitive in the marketplace.": "以保持市场竞争力。",
  "EN:ZH:That's the core idea being conveyed here.": "这就是这里传达的核心思想。",
  "EN:ZH:Third one deliver working software frequently from a couple of weeks to a couple of months with the": "第三，经常在几周到几个月内交付工作软件。",
  "EN:ZH:preference of shorter time scale.": "偏好较短的时间尺度。",
  "EN:ZH:So here they are saying that, uh, we should be delivering the working software.": "所以，他们说，我们应该交付工作软件。",
  "EN:ZH:So they have knowingly used the word working software.": "因此，他们故意使用了工作软件一词。",
  "EN:ZH:So we are not delivering a software which is not going to work.": "因此，我们不会交付一个无法运行的软件。",
  "EN:ZH:We are delivering here the software which the end customer will be able to use or the relevant customer": "我们在这里交付的是最终客户能够使用的软件或相关客户",
  "EN:ZH:is able to use.": "能够使用。",
  "EN:ZH:And we we want to deliver it uh, every month.": "我们希望每个月都能提供。",
  "EN:ZH:So we should be delivering at least every month.": "因此，我们至少每个月都要送货。",
  "EN:ZH:And the preference is if possible, we should be delivering every two weeks, so they have a preference": "如果可能的话，我们应该每两周运送一次，这样他们就有了优先选择",
  "EN:ZH:of delivering the working software to customer in shorter timescale.": "在更短的时间内向客户交付工作软件。",
  "EN:ZH:Business people and developers must work together daily throughout the project.": "在整个项目中，业务人员和开发人员必须每天一起工作。",
  "EN:ZH:So what is this principle?": "那么，这个原则是什么呢？",
  "EN:ZH:So what used to happen in waterfall is that the people who are giving us money are sponsors, or the": "因此，在瀑布项目中，给我们提供资金的人是赞助商，或者是",
  "EN:ZH:people who tell us the requirements of the product.": "告诉我们产品要求的人。",
  "EN:ZH:They used to sit in a different team and the people who are actually developing the system, you can": "他们曾经在不同的团队中工作，而真正开发系统的人，你可以",
  "EN:ZH:call them software developer or testers.": "称他们为软件开发人员或测试人员。",
  "EN:ZH:They used to be in different teams.": "他们曾经在不同的团队。",
  "EN:ZH:Many times.": "很多次",
  "EN:ZH:They used to be in different locations, and they were little collaboration between these two teams.": "过去，这两个团队在不同的地点工作，合作很少。",
  "EN:ZH:Uh, there were less communication, and even if there was communication, the communication was through": "交流较少，即使有交流，也是通过以下渠道进行的",
  "EN:ZH:documentation and all that.": "文件等。",
  "EN:ZH:And what problem was arising because of this structure was that, uh, let's say the, the business.": "这种结构带来的问题是，比方说，业务。",
  "EN:ZH:Want to build a chair?": "想做一把椅子吗？",
  "EN:ZH:That's what the sponsor want.": "这就是赞助商想要的。",
  "EN:ZH:But the developers will not be able to fully understand the requirements of what the business want.": "但开发人员无法完全理解企业的要求。",
  "EN:ZH:And they end up building a table because they haven't fully understood what the customer want.": "由于没有充分了解客户的需求，他们最终只能造出一张桌子。",
  "EN:ZH:And because of this communication gap, there are a lot of delays.": "由于沟通不畅，延误的情况时有发生。",
  "EN:ZH:There were a lot of quality problems and all that.": "有很多质量问题，诸如此类。",
  "EN:ZH:And to solve this problem, this agile principle is embedded, which is business people, which are": "为了解决这个问题，我们植入了敏捷原则，即业务人员，也就是",
  "EN:ZH:people who who are giving us requirement or who are giving us money.": "向我们提出要求或给我们钱的人。",
  "EN:ZH:They work hand in hand with the developers or people who are actually going to develop the product,": "他们与开发人员或实际开发产品的人员携手合作、",
  "EN:ZH:and they work together every day, not just once in a while.": "他们每天都在一起工作，而不是偶尔一次。",
  "EN:ZH:So they they and if possible, they sit in the same physical space so that the, the developers have": "因此，如果可能的话，他们可以坐在同一个物理空间里，这样开发人员就可以",
  "EN:ZH:full access to the product people.": "充分接触产品人员。",
  "EN:ZH:Build projects around motivated individuals.": "围绕积极进取的个人开展项目。",
  "EN:ZH:Give them environment support they need and trust them to get the job done.": "为他们提供所需的环境支持，相信他们能完成工作。",
  "EN:ZH:So what this principle is about.": "那么这个原则是什么呢？",
  "EN:ZH:So agile methodology, it is used.": "因此，我们采用了敏捷方法论。",
  "EN:ZH:Uh, it is not necessarily suitable for all kind of product projects.": "不过，它并不一定适合所有类型的产品项目。",
  "EN:ZH:For example, if you are building a house which have similar houses have been built before so many times.": "例如，如果你正在建造一栋房子，而这栋房子以前已经建过很多次了。",
  "EN:ZH:So in something which where the outcome is predictable, the success is almost so short and which is": "因此，在结果可以预测的情况下，成功的时间几乎很短，而且",
  "EN:ZH:repetitive kind of stuff.": "重复性的东西。",
  "EN:ZH:In those scenarios, we can still use waterfall because waterfall is good for it.": "在这些情况下，我们仍然可以使用瀑布式方法，因为瀑布式方法很好用。",
  "EN:ZH:For example, you are building a house that is a kind of repetitive process because you have built it": "例如，你正在建造一座房子，这是一种重复过程，因为你已经建造了它",
  "EN:ZH:so many times.": "好多次了",
  "EN:ZH:So the detailed plan, line by line, activity by activity.": "因此，详细的计划要逐条逐项进行。",
  "EN:ZH:But scrum is usually used for building.": "但是，Scrum 通常用于构建。",
  "EN:ZH:Our agile is usually used for building complex products.": "我们的敏捷通常用于构建复杂的产品。",
  "EN:ZH:Many times these products have never been built by anyone in the world.": "很多时候，世界上从未有人制造过这些产品。",
  "EN:ZH:For example, you are building an autonomous car most likely when you are trying to build this autonomous": "例如，您正在制造一辆自动驾驶汽车，当您试图制造这辆自动驾驶汽车时，最有可能的情况是",
  "EN:ZH:car.": "汽车",
  "EN:ZH:It has never been built before or it has, even though it might be built before, but it is you as a": "它以前从未被建造过，或者已经被建造过，尽管它以前可能被建造过，但它是你作为一个",
  "EN:ZH:company or you as a team.": "公司或你们作为一个团队。",
  "EN:ZH:You have never built this thing before so you are new to this.": "你以前从未建造过这东西，所以你是新手。",
  "EN:ZH:So in agile is used for building something very complex.": "因此，敏捷用于构建非常复杂的东西。",
  "EN:ZH:And if you are trying to build something very complex or difficult, what you need is motivated individuals,": "如果你要建造非常复杂或困难的东西，你需要的是积极进取的个人、",
  "EN:ZH:right, who are interested in working on complex problems.": "对解决复杂问题感兴趣的人。",
  "EN:ZH:So that's why you they are suggesting to build these projects around motivated people who are motivated": "这就是为什么你们建议围绕那些积极进取的人开展这些项目的原因。",
  "EN:ZH:enough to build these products, and you have to give them a right environment and support they need,": "你必须为他们提供所需的环境和支持、",
  "EN:ZH:and you have to trust them.": "你必须相信他们。",
  "EN:ZH:So what does that that mean is you should not be doing micromanagement of these people, and you have": "所以，这意味着你不应该对这些人进行微观管理，你必须",
  "EN:ZH:enough trust to own them that these people are capable enough to develop this complex product.": "足够的信任，让他们相信这些人有足够的能力开发这种复杂的产品。",
  "EN:ZH:So you have to trust them enough at that level.": "因此，在这个层面上，你必须足够信任他们。",
  "EN:ZH:Otherwise they will not be able to build this capability if you keep micromanaging it, because this": "否则，如果你继续进行微观管理，他们将无法建立这种能力，因为这",
  "EN:ZH:is a complex product development.": "是一种复杂的产品开发。",
  "EN:ZH:So that's the idea being conveyed here And what used to happen in waterfall is there used to be project": "这就是我们要表达的意思。",
  "EN:ZH:managers who who tend to micromanage the people who are working in, uh, in software development.": "那些倾向于对软件开发人员进行微观管理的经理。",
  "EN:ZH:And what was happening is because they were trying to solve complex problem.": "之所以出现这种情况，是因为他们试图解决复杂的问题。",
  "EN:ZH:They were not having enough time or space to try things in a different way.": "他们没有足够的时间和空间去尝试不同的方式。",
  "EN:ZH:So they have to follow exactly what the project manager is telling.": "因此，他们必须完全按照项目经理的要求去做。",
  "EN:ZH:And that might not be the right way for that particular complex problem.": "而这可能并不是解决这一复杂问题的正确方法。",
  "EN:ZH:And to address that problem, they have come up with this principle.": "为了解决这个问题，他们提出了这个原则。",
  "EN:ZH:Number five, principle number six, the most efficient and effective method of conveying information": "第五，第六项原则，最有效率、最有效果的信息传递方法",
  "EN:ZH:to, to and within the team is face to face conversation.": "在团队中，面对面的交流是最重要的。",
  "EN:ZH:So this principle six is about telling.": "因此，第六项原则就是要 \"说\"。",
  "EN:ZH:The best way to convey information within a team is face to face conversation.": "团队内部传递信息的最佳方式是面对面交谈。",
  "EN:ZH:Because when we are doing face to face conversation, uh, the the communication is much, much more": "因为当我们面对面交谈时，沟通会更顺畅。",
  "EN:ZH:better because we are we are talking not just by words.": "更好，因为我们在交谈，而不仅仅是用语言。",
  "EN:ZH:We are talking with our body language, with our hand movements, with our eyes, and we have an opportunity": "我们用肢体语言、手部动作和眼神交谈，我们有机会",
  "EN:ZH:to, uh, change, uh, uh, respond to uh, situation which is presented by the other persons so we": "改变，呃，呃，呃，对其他人提出的情况做出回应，所以我们",
  "EN:ZH:can iterate our thoughts more frequently while we are talking face to face.": "当我们面对面交谈时，可以更频繁地重复我们的想法。",
  "EN:ZH:So and what it does is when we talk face to face, the chances of miscommunications are significantly": "因此，当我们面对面交谈时，沟通不畅的几率会大大降低。",
  "EN:ZH:reduced.": "减少。",
  "EN:ZH:Also, when you are talking face to face with people, it helps in taking decisions quicker.": "此外，当你与人面对面交谈时，有助于更快地做出决定。",
  "EN:ZH:So it helps in taking speedier decision.": "因此，它有助于更快地做出决定。",
  "EN:ZH:So these are the key reasons why they have uh embedded principle number six.": "因此，这些就是他们嵌入第六项原则的关键原因。",
  "EN:ZH:Uh so this slide is having again another six principles for agile and why we are discussing these values": "这张幻灯片再次展示了敏捷的六大原则，以及我们为什么要讨论这些价值观。",
  "EN:ZH:and principles.": "和原则。",
  "EN:ZH:Uh, we have to understand that point as well.": "我们也必须明白这一点。",
  "EN:ZH:So these principles and values, they are the guide for building a agile framework.": "因此，这些原则和价值观就是构建敏捷框架的指南。",
  "EN:ZH:So if you look at scrum.": "所以，如果你看看Scrum。",
  "EN:ZH:What it does is it embeds all these agile values and principles in itself, and it creates events and": "它所做的就是将所有这些敏捷价值观和原则嵌入自身，并创建活动和",
  "EN:ZH:artifacts and rules so that all these agile practices can be implemented in real life.": "工件和规则，以便在现实生活中实施所有这些敏捷实践。",
  "EN:ZH:That's what they do.": "这就是他们的工作。",
  "EN:ZH:So all these principles of agile and value, they work as guides and are all the agile frameworks are": "因此，所有这些敏捷和价值原则都是指导性的，也是所有敏捷框架的指导性原则。",
  "EN:ZH:built in light of these.": "根据这些情况建造。",
  "EN:ZH:That's that's the logic why we need to know these values and principles.": "这就是我们需要了解这些价值观和原则的原因。",
  "EN:ZH:Another reason we why we need to know this is because we have to align our mindset to these values and": "我们需要了解这一点的另一个原因是，我们必须使自己的心态与这些价值观保持一致，并且",
  "EN:ZH:principles, because ultimately, it is the people who are going to do the work.": "原则，因为归根结底，是人要去做工作。",
  "EN:ZH:It's not like if you just have the events, let's say scrum events.": "这不像仅仅有活动，比方说 scrum 活动。",
  "EN:ZH:It's not that scrum events, having those scrum events will automatically implement scrum no.": "并不是有了 scrum 活动，就能自动实施 scrum no。",
  "EN:ZH:The main thing is these principles should be in our mind and we have to build that mindset, agile mindset": "最重要的是，这些原则应牢记于心，我们必须建立这种思维模式，敏捷思维模式",
  "EN:ZH:around these principles and whatever we are doing while we are building these products, that should": "围绕这些原则，无论我们在制造这些产品时做什么，都应",
  "EN:ZH:be guided by these agile values and principles.": "以这些敏捷价值观和原则为指导。",
  "EN:ZH:That's why these knowing these principles and values is important.": "因此，了解这些原则和价值观非常重要。",
  "EN:ZH:Next six principle one by one.": "接下来的六项原则逐一介绍。",
  "EN:ZH:Now.": "现在",
  "EN:ZH:So this is principle number seven.": "这就是第七条原则。",
  "EN:ZH:Working software is primary measure of success.": "工作软件是衡量成功的主要标准。",
  "EN:ZH:So why they have come up with this.": "那么，他们为什么要这样做呢？",
  "EN:ZH:Because in waterfall what used to happen a lot of time was spent in other activities.": "因为在瀑布式系统中，很多时间都花在了其他活动上。",
  "EN:ZH:For example they there were a lot of time in contract spent in contract negotiation, in writing detailed": "例如，他们在合同中花费了大量时间进行合同谈判和撰写详细的合同条款。",
  "EN:ZH:requirement documentation, detailed design documentation, and by the end of by that time, by the": "需求文档、详细设计文档，并在年底前完成",
  "EN:ZH:end of 6 or 7 months, you most of the project budget is burned in just writing the documentation.": "6 个月或 7 个月后，项目的大部分预算就会被用于编写文档。",
  "EN:ZH:So to address those kind of product failures, which were happening continuously again and again.": "因此，为了解决这种不断发生的产品故障。",
  "EN:ZH:They have come up with this principle, which is saying working software is primary measure.": "他们提出了这一原则，即工作软件是首要衡量标准。",
  "EN:ZH:So what it means is whatever work we are doing, we have to make sure that by the end of a sprint or": "因此，这意味着无论我们正在做什么工作，我们都必须确保在冲刺结束或",
  "EN:ZH:iteration or a cycle, which is usually one month or less, we should deliver working software.": "迭代或一个周期，通常是一个月或更短的时间，我们就应该交付可运行的软件。",
  "EN:ZH:And that's what entire team will be measured against.": "这也是衡量整个团队的标准。",
  "EN:ZH:Like their success will be measured against working software.": "就像他们的成功将以工作软件来衡量一样。",
  "EN:ZH:And principle number eight agile processes promote sustainable development.": "原则八：敏捷流程促进可持续发展。",
  "EN:ZH:Uh, the sponsor, developers and users should be able to maintain a constant pace indefinitely.": "呃，赞助商、开发商和用户应该能够无限期地保持稳定的步伐。",
  "EN:ZH:This means that what, uh, agile doesn't mean that you are going.": "这意味着，敏捷并不意味着你要去做什么。",
  "EN:ZH:I mean, instead of eight hours a day, you are going to work ten hours, 12 hours, 15 hours a day.": "我的意思是，你每天要工作 10 个小时、12 个小时、15 个小时，而不是 8 个小时。",
  "EN:ZH:It means is they are saying that you continue agile wants you to deliver the sustainable value to customer": "这意味着，他们希望你继续敏捷地为客户提供可持续的价值。",
  "EN:ZH:sprint.": "冲刺。",
  "EN:ZH:After sprint, they want you to.": "冲刺之后，他们希望你",
  "EN:ZH:Let's say your sprint is for a week or a month.": "比方说，你的冲刺时间是一周或一个月。",
  "EN:ZH:You are delivering this value to the customer at a constant pace month after month, and you can only": "您要月复一月、持续不断地向客户提供这种价值，而您只能",
  "EN:ZH:do it if you are not getting burnt out right?": "如果你不觉得累，就去做，对吗？",
  "EN:ZH:If you are, every day you are working 14 hours, 16 hour, 18 hour a day.": "如果是这样，你每天工作 14 小时、16 小时、18 小时。",
  "EN:ZH:You can't maintain that pace forever.": "你不可能永远保持这种速度。",
  "EN:ZH:You might be able to do that for six months, a year or two year, but you can't do it for 20 years,": "你也许可以这样做六个月、一年或两年，但你不可能这样做 20 年、",
  "EN:ZH:30 years.": "30 年。",
  "EN:ZH:And that's why they have come up with this principle that agile processes are promoting sustainable": "因此，他们提出了 \"敏捷流程促进可持续发展 \"这一原则。",
  "EN:ZH:development.": "发展。",
  "EN:ZH:Because if you are working 20 hours a day, that is not sustainable and they want you to maintain a": "因为如果你每天工作 20 个小时，那是不可持续的，他们希望你保持",
  "EN:ZH:constant pace indefinitely, indefinitely means forever.": "无限期地保持恒定速度，无限期意味着永远。",
  "EN:ZH:And that is only possible if your team members don't get burnt out.": "而这只有在团队成员不感到疲惫的情况下才有可能实现。",
  "EN:ZH:So if you are playing a role of Scrum Master and if your team is working like so many hours every day.": "因此，如果你扮演的是 Scrum Master 的角色，如果你的团队每天都要工作很长时间。",
  "EN:ZH:So you have to make sure that they don't get burned out, find ways where they can still work for you,": "因此，你必须确保他们不会疲惫不堪，找到他们仍能为你工作的方法、",
  "EN:ZH:and still deliver the value which is expected by customers.": "同时还能提供客户所期望的价值。",
  "EN:ZH:Continuous attention to technical excellence and good design enhances agility.": "对卓越技术和良好设计的持续关注可提高灵活性。",
  "EN:ZH:So the, uh, what it means is two things.": "因此，这意味着两件事。",
  "EN:ZH:One, in agile we don't do the architecture upfront, like in waterfall.": "其一，在敏捷中，我们不会像瀑布式那样在前期就完成架构设计。",
  "EN:ZH:What we used to do is we will do the design of the architecture upfront in there will be a design phase": "我们过去的做法是，在设计阶段，我们会预先进行架构设计。",
  "EN:ZH:initially in the beginning itself, and we'll design the whole architecture, how it is going to look": "一开始，我们会设计整个架构，设计它的外观",
  "EN:ZH:like.": "喜欢。",
  "EN:ZH:Whereas in agile what they it's a different way of looking, doing architecture.": "而在敏捷中，他们是以一种不同的方式来看待、来做架构。",
  "EN:ZH:What they are doing is they are suggesting to do the technical architecture or excellence continuously": "他们正在做的是，他们正在建议不断进行技术架构或优化",
  "EN:ZH:throughout each cycle.": "在每个周期内。",
  "EN:ZH:Like you continue to work on good designs and technical excellence from the beginning, and you continue": "就像你从一开始就继续致力于优秀的设计和卓越的技术，你继续",
  "EN:ZH:to do it forever.": "永远做下去。",
  "EN:ZH:It's like you are not doing the entire architecture upfront.": "这就好像你没有在前期完成整个架构。",
  "EN:ZH:Uh, rather than that you keep doing it.": "呃，而不是你继续这样做。",
  "EN:ZH:You keep doing enough technical design and architecture, which is enough for next few sprints.": "你继续做足够多的技术设计和架构，这足够接下来的几个冲刺阶段使用。",
  "EN:ZH:You don't do it more than that, because when you are building complex products, you don't know what": "你不会做得更多，因为当你构建复杂的产品时，你不知道什么是 \"复杂\"。",
  "EN:ZH:design you need.": "您需要的设计。",
  "EN:ZH:You will only know it after you have already built certain part of products at after.": "只有在您已经制造出部分产品之后，您才会知道这一点。",
  "EN:ZH:Because it will take time to discover what is the right architecture and that right architecture evolve": "因为需要时间来发现什么是正确的架构，而正确的架构也需要时间来发展。",
  "EN:ZH:over time.": "随着时间的推移。",
  "EN:ZH:You can't know it in upfront and that's what they are trying to implement in this principle.": "你不可能事先知道，而这正是他们试图在这一原则中实现的。",
  "EN:ZH:Number nine.": "九号",
  "EN:ZH:Simplicity.": "简单。",
  "EN:ZH:The art of maximizing the amount of work not done.": "将未完成的工作量最大化的艺术。",
  "EN:ZH:So they are using the word not done is essential.": "因此，他们使用 \"未完成 \"一词是至关重要的。",
  "EN:ZH:So what this principle means let's say you have a product backlog.": "这个原则的意思是，假设你有一个产品积压。",
  "EN:ZH:You go to customer, you survey them and you do their interview and they are telling you millions of": "你去找客户，对他们进行调查和访谈，他们会告诉你数以百万计的信息。",
  "EN:ZH:things they want to do.": "他们想做的事情。",
  "EN:ZH:If you go to customer, they'll they'll tell you, I want to do a, B, C, d like you go to million": "如果你去找客户，他们会告诉你，我想做 A、B、C、D，就像你去找百万富翁一样",
  "EN:ZH:can come up with millions of things, but you're not going to develop millions of things or features": "你可以想出数百万种东西，但你不可能开发出数百万种东西或功能",
  "EN:ZH:in your product.": "在您的产品中。",
  "EN:ZH:What you're going to develop is something which is most valuable to your customer.": "你要开发的是对客户最有价值的东西。",
  "EN:ZH:And the rest of the thing is fluff.": "其余的都是浮云。",
  "EN:ZH:It is waste.": "这是浪费。",
  "EN:ZH:So what is this principle saying is that you have to maximize the amount of work not done.": "所以，这个原则的意思是，你必须最大限度地增加未完成的工作量。",
  "EN:ZH:Amount of work not done is what fluff waste which the features or capabilities which are not adding,": "未完成的工作量是指没有增加的功能或能力所造成的浪费、",
  "EN:ZH:which are not going to add much value to the life of customer.": "这不会给客户的生活带来多少价值。",
  "EN:ZH:Those capabilities we have to maximize, we have to figure out what are those capabilities and never": "我们必须最大限度地发挥这些能力，我们必须弄清楚这些能力是什么，并且永远不要",
  "EN:ZH:build them.": "建造它们。",
  "EN:ZH:And more we maximize that.": "我们要最大限度地利用这一点。",
  "EN:ZH:That means we are going to deliver more value to the customer.": "这意味着我们将为客户提供更多价值。",
  "EN:ZH:That's what this principle number ten is saying in scrum this is known as backlog management.": "这就是第十条原则在 Scrum 中所说的积压管理。",
  "EN:ZH:Product backlog management.": "产品积压管理。",
  "EN:ZH:There are techniques for doing that.": "这是有技巧的。",
  "EN:ZH:The best architecture and requirement and design emerging from self-organizing team.": "最佳架构、需求和设计来自自组织团队。",
  "EN:ZH:So what does that mean?": "这意味着什么？",
  "EN:ZH:So first we have to understand what is self-organizing team.": "因此，我们首先要了解什么是自组织团队。",
  "EN:ZH:Self-Organizing teams means team which are not micromanaged like there is no manager who is managing": "自我组织团队指的是没有微观管理的团队，就像没有管理者一样",
  "EN:ZH:them.": "他们",
  "EN:ZH:These people are managing themselves.": "这些人是在自我管理。",
  "EN:ZH:So you have people who are working scrum team and they are managing their time on their own.": "因此，你的团队里有一些人是 Scrum 团队的成员，他们自己管理自己的时间。",
  "EN:ZH:Nobody is telling them what to do.": "没有人告诉他们该怎么做。",
  "EN:ZH:They themselves decide what to do.": "他们自己决定做什么。",
  "EN:ZH:Nobody goes inside the like a detail of every minute what you did in this minute, what you did in this": "没有人会详细记录每一分钟你做了什么，这一分钟你做了什么。",
  "EN:ZH:hour.": "小时",
  "EN:ZH:No, like that kind of thing is not practiced.": "不，这种事是不会发生的。",
  "EN:ZH:Micromanagement.": "微观管理。",
  "EN:ZH:And when you give that autonomy to your people, they that autonomy or that self organization help these": "当你赋予员工这种自主权时，他们的自主权或自我组织能力就会帮助这些人",
  "EN:ZH:people build best architecture, best equipment and best designs.": "人们建造最好的建筑、最好的设备和最好的设计。",
  "EN:ZH:So because they will have that scope to come up with these things and obviously just remember one thing,": "所以，因为他们会有这样的范围来想出这些东西，而且显然只需记住一件事、",
  "EN:ZH:this is a lot of misconception in the market.": "这在市场上是一个很大的误区。",
  "EN:ZH:People think that our architecture requirement design come on its own when they are using the word emerges.": "人们在使用 \"出现 \"这个词时，会认为我们的建筑要求设计是自己产生的。",
  "EN:ZH:That doesn't mean that it comes on its own.": "这并不意味着它自己就会出现。",
  "EN:ZH:People do this work like people who are working in the team.": "人们像在团队中工作的人一样完成这项工作。",
  "EN:ZH:They come up with architecture and requirements, uh, over a period of time.": "他们会在一段时间内提出架构和要求。",
  "EN:ZH:So when when they are saying emerges, that actually means people who are working in these teams, they": "因此，当他们说 \"出现 \"时，实际上是指在这些团队中工作的人，他们",
  "EN:ZH:come up with these things or, or, uh, over a period of time.": "或者，或者，呃，在一段时间内想出这些东西。",
  "EN:ZH:That's the meaning.": "就是这个意思。",
  "EN:ZH:It doesn't come on its own, but obviously in waterfall, all these things are done upfront in the beginning": "但显然，在瀑布式设计中，所有这些事情都是在一开始就预先完成的。",
  "EN:ZH:of project, but in, uh, uh, in agile, we keep on doing, doing all these things sprint after sprint.": "但在敏捷项目中，我们会一个冲刺接一个冲刺地做这些事情。",
  "EN:ZH:That's that's the meaning.": "就是这个意思。",
  "EN:ZH:Okay, let's move on to the principle number 12.": "好了，让我们继续讨论第 12 项原则。",
  "EN:ZH:At regular intervals, the team reflects on how to become more effective tuned results and adjust its": "每隔一段时间，团队都会反思如何更有效地调整结果，并调整其",
  "EN:ZH:behavior accordingly.": "行为。",
  "EN:ZH:So this the meaning of this is basically at various intervals a regular interval.": "因此，这其中的含义基本上是在不同的时间间隔内定期进行。",
  "EN:ZH:The team who is working on this agile product, what they are working on building agile product, they": "开发敏捷产品的团队，他们在开发敏捷产品的过程中，他们",
  "EN:ZH:look back in terms of what they have from two angle.": "从两个角度回顾他们所拥有的一切。",
  "EN:ZH:One, they look at the product which they have built or product increment which they have built, and": "其一，他们关注自己打造的产品或产品增量，以及",
  "EN:ZH:they also look at the process they are using to build this product.": "他们还研究了制造该产品的过程。",
  "EN:ZH:And the if a introspect in terms of what did not went well with the product, obviously for this, they": "如果反思一下产品的不足之处，很显然，对于这一点，他们",
  "EN:ZH:get feedback from the customer and they use the customer feedback to figure out what the customer liked": "从客户那里获得反馈，并通过客户反馈找出客户喜欢什么",
  "EN:ZH:and not like.": "而不是喜欢。",
  "EN:ZH:And they implement this or they adapt this new version of the product according to customer feedback.": "他们会根据客户的反馈来实施或调整新版本的产品。",
  "EN:ZH:Second part is the process they are using.": "第二部分是他们正在使用的程序。",
  "EN:ZH:For example, they might be having n number of meetings between themselves.": "例如，他们之间可能会举行 n 次会议。",
  "EN:ZH:They might be preparing some kind of documentation, might be using, let's say this Google meet for": "他们可能正在准备某种文件，可能正在使用，比方说，这个谷歌会议，用于",
  "EN:ZH:meeting each other.": "互相见面。",
  "EN:ZH:So the ways of working the process they are using.": "因此，他们正在使用的工作方法和流程。",
  "EN:ZH:So they look at that as well at a regular interval and figure out what is not working in the process": "因此，他们也会定期检查，找出流程中的不足之处",
  "EN:ZH:or ways of working.": "或工作方式。",
  "EN:ZH:And they adapt their ways of working according to what they have learned and, and fix that those problems": "他们根据所学知识调整工作方式，并解决这些问题",
  "EN:ZH:in the next iteration.": "在下一次迭代中。",
  "EN:ZH:That's the meaning of this 12th principle that the team look back at, at the product they have built": "这就是第 12 项原则的含义，即团队回过头来看，他们所打造的产品",
  "EN:ZH:and the process they are using for building this product, and figure out the the problems with it and": "以及他们在制造该产品时使用的流程，并找出其中存在的问题和",
  "EN:ZH:fix them in upcoming iteration, or adapt the product and process in upcoming iteration based on the": "在即将到来的迭代中修正它们，或者在即将到来的迭代中根据以下内容调整产品和流程",
  "EN:ZH:feedback and learnings.": "反馈和学习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hello world": "你好，世界",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Welcome to our next session.": "欢迎来到我们的下一节课。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In this section we will generate a business model canvas using ChatGPT.": "在本节中，我们将使用 ChatGPT 生成商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Within this section, we are going to have three subsections or three steps which we are going to do": "在本节中，我们将执行三个子部分或三个步骤，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which are.": "分别是：",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first one is we'll write a ChatGPT prompt for generating a business model canvas.": "第一步是编写用于生成商业模式画布的 ChatGPT 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For this, we'll use the standard prompting template which is recommended by me.": "为此，我们将使用我推荐的标准提示词模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we'll generate a sample business model canvas using ChatGPT.": "然后，我们将使用 ChatGPT 生成一个示例商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So whatever prompt we generated in step one, we'll use that ChatGPT prompt for Business Model Canvas": "因此，无论我们在第一步中生成了什么提示词，我们都将使用该商业模式画布的 ChatGPT 提示词",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to generate a business model canvas using ChatGPT.": "来使用 ChatGPT 生成商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what we are going to do in this step two.": "这就是我们在第二步中要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then in step three, what we are going to do is we will review, uh, the Business Model canvas,": "然后在第三步中，我们要做的就是审查，呃，商业模式画布，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is generated by ChatGPT against, uh, standard guidelines provided by, uh, the author of Business": "即由 ChatGPT 生成的画布，对照，呃，由商业模式画布作者提供的，呃，标准指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Model Canvas.": "Model Canvas。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And wherever required, we will refine the business model canvas based on the guidelines provided by": "并在必要时，我们将根据作者提供的指南",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the author.": "对商业模式画布进行完善。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these are the three steps we which we are going to follow in this section.": "以上就是我们在本节中将要遵循的三个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's do this.": "那么，让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Steps one by one.": "逐步进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So uh, the first step in this step, uh, what we will do is we'll write a ChatGPT prompt for Business": "那么，呃，这一步的第一步，呃，我们要做的就是编写一个商业模式画布的 ChatGPT 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:model canvas.": "model canvas。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, this is the general prompt structure, which I have, uh, discussed in a separate section": "那么，呃，这是通用的提示词结构，我之前在另一个单独的章节中，呃，讨论过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:earlier.": "earlier。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just a reminder, what the structure does is in the first step, we'll tell the role or actor name.": "提醒一下，这个结构的作用是，在第一步中，我们会告知角色或执行者名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then in the next step we we capture the description of the product or the project.": "然后在下一步中，我们获取产品或项目的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then in the next step we capture the names of sections for the framework which we are going to produce.": "接着在下一步中，我们获取我们要生成的框架的各个板块名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we write, uh, the name of framework.": "然后我们写下，呃，框架的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we write the name of author of the framework.": "然后我们写下该框架作者的姓名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we describe the product, and in the last two steps we provide any additional constraints or quality": "然后我们描述产品，在最后两步中，我们提供 ChatGPT 在生成此框架时应使用的任何额外约束或质量",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:parameters which GTP should use for generating this framework.": "参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the template structure we are going to follow.": "这就是我们将要遵循的模板结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see the example business model corresponding to this.": "让我们看看与之对应的示例商业模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this case what we are doing is we are following the template for generating a business model canvas": "在这个案例中，我们正在遵循模板来生成一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for Amazon style website.": "亚马逊风格网站的商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So so first step is assume you are a product manager.": "所以，第一步是假设你是一名产品经理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So instead of role uh, we are giving the role as product manager.": "所以我们没有只说角色，呃，而是将角色设定为产品经理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because usually the business model canvas is authored, uh, for a particular product by the product": "因为通常商业模式画布是由产品经理，呃，为特定产品编写的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:manager.": "manager。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or sometimes it is authored by product owner, product director.": "或者有时是由产品负责人、产品总监编写的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these kind of people but, uh, product manager is, uh, more suitable for this kind of role.": "诸如此类的人，但是，呃，产品经理，呃，更适合这种角色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's why we are using the product manager role.": "这就是为什么我们使用产品经理这个角色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the in the next step we are describing about the product for which we are generating this business": "然后在下一步中，我们描述正在为其生成此商业模式画布的产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this case the product is Amazon style book selling website.": "在这个案例中，产品是一个亚马逊风格的图书销售网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then in the next step, we are writing the names of the sections which you are generating for this business": "然后在下一步中，我们写下你为此商业模式画布生成的各个板块的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I have written the nine section names of Business Model Canvas which are customer segment value proposition": "所以我写下了商业模式画布的九个板块名称，分别是客户细分、价值主张、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:channels, Customer relationship, revenue stream, key resources, key activities, key partnership": "渠道、客户关系、收入来源、核心资源、关键业务、重要合作",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and cost structure.": "和成本结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then in the next step, I have written the name of the framework itself.": "然后在下一步中，我写下了框架本身的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In this example, the framework name is Business Model Canvas.": "在这个例子中，框架名称是商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in next step I have named the author of this framework, which is Alex Osterwalder.": "在下一步中，我指出了该框架的作者，即 Alex Osterwalder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then here what I have captured is a description of the product which we are building.": "然后在这里，我获取的是我们正在构建的产品的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is same as the step number two.": "这与第二步相同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is exactly the copy of the two.": "所以这完全是第二步的副本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then, uh, in the last step, what I have done is I have written an additional rule which I want": "然后，呃，在最后一步中，我写了一条我想要遵循的额外规则，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to follow, which is all the sections, for example, the customer segment proposition.": "即所有板块，例如客户细分、价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All these sections should be, uh, written in points.": "所有这些板块都应该，呃，以要点的形式编写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to produce, uh, all these sections, um, in point format.": "所以我想以，嗯，要点格式生成，呃，所有这些板块。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, just a quick summary of this prompt.": "那么，呃，对这个提示词做一个简要总结。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, here what we are doing is we are asking ChatGPT to assume the role of a product manager for": "那么，呃，在这里我们要做的是，让 ChatGPT 担任一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a Amazon style book selling website.": "亚马逊风格图书销售网站的产品经理角色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want ChatGPT to generate nine sections of, uh, the business model canvas, which are customer": "我们希望 ChatGPT 生成商业模式画布的九个板块，呃，即客户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:segments, value proposition channels, customer relationship, revenue stream, key resources, key": "细分群体、价值主张渠道、客户关系、收入流、关键资源、关键",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:activities, key partnership and co structure.": "活动、关键合作伙伴和成本结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And these sections are for the Business Model Canvas and Business Model.": "这些部分是用于商业模式画布和商业模式的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Canvas is authored by Alex Osterwalder and this business model canvas we want to generate for Amazon": "画布由 Alex Osterwalder 编写，我们想为亚马逊风格的图书销售网站生成这个商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:style book selling website.": "风格的图书销售网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want all the sections to be written in points.": "我们希望所有部分都以要点的形式编写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's a high level summary of this, this prompt.": "这就是这个提示词的高层级总结。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's move on to the next step.": "让我们继续下一步。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a sample template for Business Model Canvas.": "这是商业模式画布的一个示例模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is provided by Alex Osterwalder.": "这是由 Alex Osterwalder 提供的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it has these nine sections key partner Key activities Key resources and these other sections.": "它包含这九个部分：关键合作伙伴、关键活动、关键资源以及其他部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the template.": "这就是模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's move to the next one.": "让我们看下一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this next step what we are going to do is we will use uh the ChatGPT prompt which is written by": "在接下来的这一步中，我们将使用我们编写的 ChatGPT 提示词，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:us uh, and uh, basically we'll run it in ChatGPT and generate the response from ChatGPT or for this": "基本上我们会在 ChatGPT 中运行它，并让 ChatGPT 为这个商业模式生成响应，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:business model, let's do that.": "让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm just going to copy this prompt from here.": "我正准备从这里复制这个提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I'm going to go to, uh, an active session of, uh, GTP.": "现在我要去一个活跃的 GPT 会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here I have active session of GTP.": "这里我有一个活跃的 GPT 会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In my case, I'm going to reuse the existing thread which we have used before.": "在我的例子中，我将重用我们之前使用过的现有线程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The reason for that is because, uh, in the existing thread, I have already generated a product vision": "原因是，在现有的线程中，我已经为同一个产品生成了一个产品愿景板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:board for the same product.": "为同一个产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you are producing, uh, uh, product management deliverables from the same product, I'll suggest": "如果你正在为同一个产品制作产品管理交付物，我建议",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you to continue using the same thread rather than creating a new chat.": "你继续使用同一个线程，而不是创建一个新的聊天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if you are doing a deliverable for a different product, then, uh, use a new chat window.": "但如果你是在为不同的产品制作交付物，那么请使用新的聊天窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's do that.": "让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to paste the chat GTP prompt, which I have generated before.": "我将粘贴我之前生成的 Chat GPT 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will just fix some spelling errors or grammar in it.": "我会修正其中的一些拼写错误或语法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And uh, I'm going to submit uh, this uh, through send a message to ChatGPT and we'll see what is": "然后我将通过向 ChatGPT 发送消息来提交这个，我们将看看",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the response that GDP is going to produce.": "GPT 会产生什么样的响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So ChatGPT has now produced a response.": "ChatGPT 现在已经生成了响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you look at the response quickly, uh, what it is doing is to produce the, the customer segments,": "如果快速浏览一下响应，它正在生成客户细分，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:uh, for example, avid readers, uh, casual readers, scholars and academicians, gift shoppers and": "例如，资深读者、普通读者、学者和研究人员、礼品购物者，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then also, uh, against these headings, what uh, ChatGPT has done is, is given A11 liner description": "然后在这些标题下，ChatGPT 还给出了一行简短的描述，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of it, for example, avid Reader, it has given further description, uh, of avid Reader, which are": "例如，对于资深读者，它给出了进一步的描述，即",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:individuals who read regularly and are looking for a diverse range of books.": "经常阅读并寻找各种书籍的个人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Casual readers are people who read occasionally and are open to, uh, to exploring new titles.": "普通读者是偶尔阅读并愿意探索新书的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it has given one one liner against each of the output.": "所以它在每个输出项下都给出了一行描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again, let's have a quick look at value proposition.": "再次，让我们快速看一下价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it is saying extensive book catalog.": "它提到的是广泛的图书目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's giving a description of it offering a vast and diverse section of books across journeys.": "然后给出了描述，即提供跨越不同类别的庞大且多样化的书籍选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I was only expecting ChatGPT to produce this headlines, not the description, but HTTP have given": "我原本只期望 ChatGPT 生成这些标题，而不是描述，但 GPT 给了我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:me both headlines as well as description for each of the section.": "每个部分的标题和描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I'm going to do now is I will quickly port the response with ChatGPT has produced for this business": "所以我现在要做的就是快速将 ChatGPT 为这个商业模式画布生成的响应",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:model canvas in our PowerPoint.": "移植到我们的 PowerPoint 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then what we'll do is we will have a review it against the guidelines provided by the author of": "然后我们要做的就是根据《商业模式画布》作者提供的指南",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Business Model Canvas.": "对其进行审查。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Obviously, uh, one key refinement I'm going to do here is when I'm producing, uh, adding it to my": "显然，我在这里要做的一个关键改进是，当我生成并将其添加到我的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:template, I will not add the descriptions which are produced by, uh, ChatGPT GDP.": "模板中时，我不会添加由 ChatGPT 生成的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For each of these headlines, I will only keep the headlines.": "对于这些标题中的每一个，我将只保留标题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, in customer segment, I will only keep avid readers, casual readers, scholarly and academicians": "例如，在客户细分中，我将只保留资深读者、普通读者、学者和学术界人士",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and gift shoppers.": "以及礼品购买者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will not add the description of each headline to the template.": "我不会将每个标题的描述添加到模板中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll keep them as in the reading notes so that or reference notes, so that we know what of what each": "我会把它们保留在阅读笔记或参考笔记中，这样我们就知道",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of these section means, but I will not add it to the actual template.": "每个部分的意思，但我不会把它们添加到实际的模板中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let let me do that.": "那么让我来处理一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, quickly uh, offline.": "呃，很快在后台处理一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's review the results, which are uh, produced by ChatGPT.": "让我们来看看 ChatGPT 生成的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In light of the guidelines provided by the author of, uh, Business Model Canvas.": "根据《商业模式画布》作者提供的指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I've done is I've just ported the content from ChatGPT to the template of Business Model Canvas,": "所以我所做的就是把 ChatGPT 的内容移植到《商业模式画布》的模板中，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and this template has the guidance as well.": "而且这个模板也有指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Each of these call outs, these are the guidance provided by the author of Business Model Canvas.": "每一个标注，这些都是《商业模式画布》作者提供的指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this.": "还有这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The content in red font is the content which is produced by ChatGPT.": "红色字体的内容是 ChatGPT 生成的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Answer to each section.": "每个部分的答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's review this.": "那么让我们来审查一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Are each of this section in light of the guidelines?": "每个部分是否符合指南的要求？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So key partners GDP it has produced for key partners publishers.": "那么关键合作伙伴，GPT 为关键合作伙伴生成了出版商。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So publishers are the people or the companies who publish books are authors are the people who actually": "出版商是出版书籍的人或公司，作者是实际",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:write books and are payment processor are for example, the credit card payment processor, debit card": "写书的人，支付处理器例如信用卡支付处理器、借记卡",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:payment processor, or banks.": "支付处理器或银行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All those kind of companies and affiliates, uh, tend to be, uh, used for, uh, say, marketing": "所有这些类型的公司和联盟营销商，呃，往往被用于，呃，比如说，营销",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:books.": "书籍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all those, uh, these four are, are, uh, key partners.": "所以所有这些，呃，这四个都是，呃，关键合作伙伴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So without reading the guidelines, they seem fine to me.": "所以在不看指南的情况下，我觉得它们没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's quickly look at the guideline as well.": "让我们也快速看一下指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Identify external organizations, suppliers or partners that help the company in various aspects of": "识别在业务运营的各个方面帮助公司的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:its business operation.": "外部组织、供应商或合作伙伴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we are identifying the external organizations or suppliers or partners who will help the company,": "在这里，我们正在识别将帮助公司的外部组织、供应商或合作伙伴，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:uh, in in selling books.": "呃，在销售书籍方面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you read the guidelines and look at the output generated by ChatGPT, the output, uh, seems,": "如果你阅读指南并查看 ChatGPT 生成的输出，输出，呃，似乎，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:uh, all right to me in light of the guidance provided by the author for this section.": "呃，在我看来是没问题的，符合作者为本部分提供的指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at the next section, which is key activities, uh, section.": "让我们看看下一部分，即关键活动，呃，部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in key activities, ChatGPT have generated curating, book catalog, algorithm refinement, marketing": "在关键活动中，ChatGPT 生成了策划、图书目录、算法优化、营销",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:campaign and user engagement.": "活动和用户参与。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, just, uh, reading through these activities or results seems fine to me because curating": "所以，呃，只是，呃，通读这些活动或结果，我觉得没问题，因为策划",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:books is creating the catalog, talking to these, uh, publishers, authors and getting their catalogue,": "书籍就是创建目录，与这些，呃，出版商、作者交谈并获取他们的目录，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which are relevant to the website.": "这些目录与网站相关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That seems a good key activity to do.": "这似乎是一个很好的关键活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or it will take a significant amount of resources and time to do.": "而且这会耗费大量的资源和时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it is one of the key thing which this book people company should be doing.": "这是这家图书公司应该做的关键事情之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then algorithm refinement are refining the algorithm, uh, which, uh will help in searching, getting": "然后算法优化就是改进算法，呃，这，呃，将有助于搜索，获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the right search result and all or uh, whenever a person is searching a particular book.": "正确的搜索结果等等，或者呃，每当有人搜索一本特定的书时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, that kind of algorithm requirement also seems fine, a good activity to me to be included": "所以，呃，那种算法需求看起来也没问题，对我来说是一个很好的活动，可以包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in key activity then marketing campaign because, um, one of the key aspect of any online business": "在关键活动中，然后是营销活动，因为，嗯，任何在线业务的关键方面之一",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is running successful marketing campaign.": "就是开展成功的营销活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So marketing campaign also seems the correct activity and engaging users who are either potential customers": "所以营销活动似乎也是正确的活动，并且吸引那些潜在客户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or existing customers that also seems to have the activity.": "或现有客户，这似乎也属于该活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see the guideline from uh, the author of this framework outline the most important activities": "让我们看看呃，这个框架作者的指南，概述了最重要的活动",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the company must perform to make its business model work.": "公司必须执行这些活动才能使其商业模式运作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have activities the company must be doing to make the business model successful.": "所以这里我们有公司为了使商业模式成功而必须做的活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have to capture those activities.": "我们必须捕捉这些活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, in based on reading the guidance and the activities, both in the activities generated by": "所以，呃，基于阅读指南和活动，ChatGPT 生成的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ChatGPT seems fine to me.": "活动对我来说似乎都没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, I don't see any problem in the quality of output of GDP in this scenario.": "呃，在这种情况下，我没看到 GDP 输出质量有任何问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at the guidance for key resources now.": "现在让我们看看关键资源的指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So key resources are as per the guidance the list of critical assets infrastructure resources required": "所以根据指南，关键资源是所需的关键资产、基础设施资源列表",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to deliver the value proposition reach consumers and operate the business.": "用于交付价值主张、接触消费者并运营业务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it is listing the most critical assets without which the business will not exist, uh, including": "所以它列出了最关键的资产，没有这些资产业务将无法存在，呃，包括",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the infrastructure or any other resources which are required to deliver the value proposition to the": "基础设施或向客户交付价值主张所需的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:customer.": "任何其他资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so Uh, that's the guidance that is given.": "呃，所以呃，这就是给出的指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see whether we have captured that source or not.": "让我们看看我们是否捕捉到了那个资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Extensive book database.": "广泛的图书数据库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we don't have an extensive book database, that means when the potential customer come to our": "所以如果我们没有广泛的图书数据库，那就意味着当潜在客户来到我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:website, they will not have any thing to buy.": "网站时，他们将没有任何东西可买。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So extensive catalog seems, uh, a key resource to me for this business model.": "所以对我来说，广泛的目录似乎是这个商业模式的一个关键资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Technology infrastructure.": "技术基础设施。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Having that the website, uh, which is the code of the website or website which is required to run": "拥有网站，呃，也就是网站的代码，或者是运行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this business, having the servers which will host the website, having the payment in connection to": "这项业务所需的网站，拥有托管网站的服务器，拥有与",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the third party payment APIs and, uh, connection to the couriers or the post service, which will": "第三方支付 API 连接的支付方式，以及呃，与快递或邮政服务的连接，这些服务将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:deliver uh, ship these books.": "交付、运输这些书籍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So having all that, uh, technology infrastructure in place seems, uh, a key, right, key activity": "所以，拥有所有这些呃，技术基础设施到位，对我来说似乎是一个关键的，对，关键活动",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to me then recommending an algorithm that also seems a key resource because, uh, uh, based on, uh,": "然后是推荐算法，这似乎也是一个关键资源，因为，呃，呃，基于呃，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the right, uh, recommendation algorithm.": "正确的，呃，推荐算法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right.": "是正确的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Recommended book will be recommended to potential customer or customers based on the interests of customer,": "推荐的书籍将根据客户的兴趣推荐给潜在客户或现有客户，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:based on their past history of purchases, based on their past browsing history or of our website.": "基于他们过去的购买历史，基于他们过去在我们网站上的浏览历史。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the marketing team.": "然后是营销团队。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because marketing is one of the key activity for a online website.": "因为营销是在线网站的关键活动之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's why are having a great marketing team seems to be a right key resource to me.": "这就是为什么对我来说，拥有一个优秀的营销团队似乎是一个正确的关键资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the quality of this output also seems fine.": "所以这个输出的质量看起来也没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't think we need to refine anything in this section as well.": "我认为我们也不需要对这一部分进行任何改进。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at the cost structure.": "让我们看看成本结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the guidance of cost structure is breakdown the cost associated with operating the business.": "成本结构的指导原则是分解与业务运营相关的成本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This include fixed cost, variable cost as well as economies of scale.": "这包括固定成本、可变成本以及规模经济。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have to identify the key cost which will be uh you know put in these three buckets fixed cost,": "因此，我们必须确定关键成本，也就是将其放入这三个类别中：固定成本、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:variable cost.": "可变成本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for a online business which is selling books technology Development seems to be the one of the key": "对于一家销售图书的在线业务来说，技术开发似乎是关键的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:variable cost as well as fixed cost.": "可变成本以及固定成本之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To me then marketing and advertising cost again seems to be running the customer support team or department.": "对我来说，营销和广告成本，以及运营客户支持团队或部门的成本，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The expenses associated with it also seems the right category of cost to be captured here, so I don't": "与之相关的费用似乎也属于这里应该涵盖的正确成本类别，所以我并不",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:think this section need any refinement.": "认为这一部分需要任何改进。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have reviewed this section successfully.": "那么，我们已经成功审查了这一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at value proposition.": "让我们来看看价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the guidance or value proposition is outline the unique value or solution that the company offers": "价值主张的指导原则是概述公司向其客户提供的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to its customer.": "独特价值或解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what problem does it solve or need it fulfills.": "以及它解决了什么问题或满足了什么需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here in this section we have to capture the unique value or solution which our company is offering": "因此，在这一部分中，我们必须捕捉我们公司正在提供的独特价值或解决方案，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and what problem we are trying to solve or what need we are trying to fulfill.": "以及我们试图解决什么问题或试图满足什么需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's look at Chatgpt's response.": "那么，让我们来看看 ChatGPT 的回答。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Extensive book catalog.": "丰富的图书目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This can be a good unique value proposition because many are businesses which are either offline or": "这可以是一个很好的独特价值主张，因为许多业务无论是线下的还是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:online.": "线上的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They tend to have a smaller catalog which are result in.": "它们的目录往往较小，这导致了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even though if a lot of customer comes to them, they might not have relevant books for them.": "即使有很多客户找上门，它们也可能没有适合他们的书。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's why having extensive book catalog seems, uh.": "这就是为什么拥有丰富的图书目录似乎，呃。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, point to be captured in value proposition then?": "呃，那么这是价值主张中需要捕捉的一点吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Personal recommendation also seems to me a good unique value proposition because rather than showing,": "个性化推荐对我来说似乎也是一个很好的独特价值主张，因为与其显示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:uh, irrelevant, uh, book recommendations, uh, in which a potential customer might not be interested,": "呃，不相关的、呃、潜在客户可能不感兴趣的图书推荐，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:giving them, uh, targeted and personalized recommendation based on their interest, based on their": "根据他们的兴趣、根据他们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:browsing history, based on their purchase history, seems to be a great, unique value proposition": "浏览历史、根据他们的购买历史，为他们提供有针对性的个性化推荐，似乎是一个极好的独特价值主张，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to have then seamless shopping experience.": "其次是无缝的购物体验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again.": "同样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This also seems, uh, very interesting, unique value proposition to capture.": "这似乎也是一个非常有趣的、值得捕捉的独特价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It means the customer experience which is being offered is seamless.": "这意味着所提供的客户体验是无缝的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't feel broken at at points.": "它在任何环节都不会让人感到断层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't seem to be, uh, seemed or it doesn't seem to be siloed.": "它看起来不会，呃，显得或者说它看起来不会是孤立的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So having that great and seamless shopping experience seems to be a good value proposition.": "因此，拥有那种极佳且无缝的购物体验似乎是一个很好的价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then community engagement.": "然后是社区参与。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So connecting various author, uh, book enthusiasts together, which have, uh, common interests.": "也就是将具有共同兴趣的各种作者、呃、图书爱好者联系在一起。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So providing those kind of, uh, communities where they can discuss about a particular book or particular": "因此，提供这类社区，让他们可以讨论某本特定的书或某类",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:kind of book, that also seems to be a good value proposition.": "特定的书，这似乎也是一个很好的价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all these points, they seems fine.": "所以所有这些点，它们看起来都很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't need to do any refinement in this section as well.": "我们在这一部分也不需要做任何改进。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at customer relationship.": "让我们来看看客户关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So customer relationship chat GTP has generated three points.": "关于客户关系，ChatGPT 生成了三点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh self service community engagement and customer support.": "呃，自助服务、社区参与和客户支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what is the guidance here.": "那么这里的指导原则是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Explain how the company established and maintains relationship with customer.": "解释公司如何建立并维护与客户的关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This can include personalized service, self service, automated services, etc. so in this section": "这可以包括个性化服务、自助服务、自动化服务等，因此在本节中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we explain how our company will establish a relationship with our customer or potential customer.": "我们将解释我们公司将如何与客户或潜在客户建立关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So uh, for we, we will make our uh the first point is about self service.": "那么，呃，对于我们，我们将制定我们的，呃，第一点是关于自助服务的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The customers will be able to buy the books on on their, their own without human intervention from": "客户将能够自行购买书籍，无需来自",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:any employee from our side.": "我们公司任何员工的人为干预。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that also seems to be a good customer relationship.": "所以这似乎也是一种良好的客户关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, point to be captured then.": "呃，这是需要记录的一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Community engagement.": "社区参与。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, if they have any questions, uh, related to the book and all they can discuss with the fellow": "所以，呃，如果他们有任何关于书的问题，他们可以与其他",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:customer or potential customer.": "客户或潜在客户进行讨论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that also seems to a good customer relationship point to be captured.": "所以这似乎也是一个需要记录的良好客户关系点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then, uh, we will provide customer support as well.": "然后，呃，我们也会提供客户支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all these things, uh, seems to be, uh, right point to be captured in customer relationship.": "所以所有这些，呃，似乎都是在客户关系中需要记录的正确点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then customer segments are define different group of people or organization that the company aims to": "然后，客户细分定义了公司旨在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:reach and serve.": "触达和服务的人群或组织。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this case we have to identify clear segments which we are targeting.": "所以在这种情况下，我们必须确定我们针对的明确细分市场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So avid readers who are basically the regular readers of book.": "比如资深读者，他们基本上是书籍的常客。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They also seem to be right.": "他们似乎也是正确的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, customer segment convert casual readers, people who occasionally read those people also seem to": "呃，客户细分转化了休闲读者，那些偶尔阅读的人似乎也",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:be the right customer segment scholar, academician, and scholar shoppers.": "是正确的客户细分，还有学者、院士和学术购物者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all of these seems to be, uh, right customer segments, uh, to me for a starting point.": "所以对我来说，作为起点，所有这些似乎都是正确的客户细分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then, uh, so in the channel section, uh, it described the ways, uh, the company delivers its value": "然后，呃，在渠道部分，呃，它描述了公司向客户交付其价值",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:proposition to the customer.": "主张的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This includes sales and distribution channel.": "这包括销售和分销渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, uh, in this section, we capture the company, which are the channel used by the company to deliver": "所以，呃，在本节中，我们记录了公司，即公司用来向这些客户交付",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:value to this customers.": "价值的渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and this can include sales and distribution channel.": "这可以包括销售和分销渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So online platform it can.": "那么在线平台是可以的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ah they have used a generic word.": "啊，他们使用了一个通用的词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ah but they could have been more specific here.": "啊，但他们在这里本可以更具体一些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example website mobile for iOS, mobile app for Android.": "例如，网站、iOS 移动端、Android 移动应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they could have been a little bit more specific here then social media.": "所以他们在这里本可以更具体一点，然后是社交媒体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, again, this is mainly again, uh, this can be used for marketing as well as for servicing.": "呃，同样，这主要还是，呃，这既可以用于营销，也可以用于服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this also seems fine to me.": "所以这对我来说似乎也很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can be more specific here.": "但我们在这里可以更具体一些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like if we it is early days, we might be only interested in, uh, let's say starting with, uh, Facebook": "比如，如果是早期阶段，我们可能只对，呃，比如说从 Facebook 开始",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or only with, uh, Google for advertising or marketing.": "或者只在 Google 上进行广告或营销感兴趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can be more specific here rather than be generic.": "所以我们可以更具体一些，而不是泛泛而谈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that is one refinement point we can include then email marketing.": "所以这是我们可以包含的一个改进点，然后是电子邮件营销。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, this seems fine to me.": "呃，这对我来说似乎很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Affiliate marketing.": "联盟营销。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This also seems fine to me because they are specific, uh, in in these aspects here.": "这对我来说似乎也很好，因为他们在这些方面很具体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's look at the revenue stream section.": "让我们看看收入流部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the guidance in this section is identify the sources of revenue for the company.": "所以本节的指导是确定公司的收入来源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How does the company makes money from the from its customers.": "公司如何从其客户那里赚钱。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we are identifying the key value streams.": "所以在这里我们要确定关键的价值流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the top key value stream is book sales which seems correct to me.": "所以最关键的价值流是图书销售，这在我看来是正确的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then subscription services.": "然后是订阅服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So subscription services can be for online book reading.": "所以订阅服务可以是针对在线阅读书籍的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, you might offer let's say ten books a month for £10 or let's say in £30 per month.": "例如，你可能会提供，比方说，每月 10 英镑读 10 本书，或者每月 30 英镑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can offer unlimited book reading, unlimited book title.": "你可以提供无限量阅读，无限量的书目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that can be a good, good value stream.": "所以这可以是一个非常好的价值流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then affiliate marketing in the context of revenue stream means even though you are selling books but": "然后，在收入流的背景下，联盟营销意味着即使你正在卖书，但是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:certain kind of book which you are not selling certain category of book, you might advertise those": "某些你没有在卖的特定种类的书，或者特定类别的书，你可能会为他人",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:kind of books for other people on your website.": "在你的网站上给这些书打广告。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that can be a revenue stream as well.": "所以这也可以成为一种收入流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But that doesn't seem much relevant to me at this point.": "但在目前看来，这对我来说似乎不太相关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again, advertisement from other third parties about some other products.": "同样，还有来自其他第三方的关于其他产品的广告。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, these two will generate less result in in the beginning, but, uh, this can be included as,": "呃，这两项在开始时产生的结果较少，但是，呃，这也可以被包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:as well.": "进来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My thinking is they kind of average fit, uh, for this purpose, but, uh, they're not like, a wrong,": "我的想法是，它们对于这个目的来说算是中等契合，呃，但它们并不像是错误的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:uh, suggestion by GDP.": "呃，GPT 的建议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is, uh, the business model canvas for, uh, book people, which is Amazon style bookstore.": "所以这就是，呃，Book People 的商业模式画布，它是一个亚马逊风格的书店。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I just wanted to show you how the final, uh, business model canvas will look like for the book people,": "我只是想向你们展示，Book People 最终的，呃，商业模式画布会是什么样子，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is Amazon style website, after we have removed the guidance.": "也就是那个亚马逊风格的网站，在我们移除引导说明之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you look at, uh, it now have all the nine sections in it, key partners and the corresponding": "所以如果你看，呃，它现在包含了所有的九个板块，关键合作伙伴以及对应的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:values of each of these sections generated by by ChatGPT.": "由 ChatGPT 生成的每个板块的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is business model canvas.": "什么是商业模式画布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So business model canvas is a strategic management tool to quickly and easily define and communicate": "商业模式画布是一种战略管理工具，可以快速、轻松地定义和传达",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a business idea or concept.": "商业想法或概念。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is a one page document that works through the fundamental elements of the business or product, structuring": "它是一份单页文档，涵盖了业务或产品的基本要素，并以连贯的方式",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an idea in a coherent way.": "构建一个想法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you look at the management consultants who are used to, you know, do the business model before": "如果你看一下那些在商业模式画布出现之前习惯于制定商业模式的管理顾问，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:business model came into picture, the same kind of details, uh, will be written in it ten to 15 or": "同样的细节会被写在 10 到 15 页或",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:20 page document, and it will take a lot of time to go through that document.": "20 页的文档中，阅读该文档需要花费大量时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want to do a presentation, it used to become very complex to understand what's the actual": "如果你想做演示，要理解实际的商业模式往往会变得非常复杂，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:business model and what this business model canvas does is it summarizes all the key elements for success": "而商业模式画布的作用就是将成功的所有关键要素",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of of a business owner or a single page.": "总结在单页纸上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the creator of this business model canvas is Alex Osterwalder.": "商业模式画布的创始人是亚历山大·奥斯特瓦德 (Alex Osterwalder)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and it has nine, uh, nine sections.": "呃，它有九个，呃，九个部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, this key partners are key activities.": "例如，这些关键合作伙伴或关键活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So each of this is a section.": "每一个都是一个部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And uh, let's go through these sections one by one.": "那么，让我们逐一了解这些部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first section is the customer segments.": "第一部分是客户细分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, this section I'm going to take from the perspective of product, like you are writing this business": "呃，这一部分我将从产品的角度来讲解，就像你在为某个产品编写",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:model canvas for a product.": "商业模式画布一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So from that perspective I'm going to describe this.": "所以我将从那个角度来描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this customer segment uh section you will capture who are your customers, who are they, what": "在客户细分部分，你将记录谁是你的客户，他们是谁，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:they think, what they, uh what they see, what how they feel and what they actually do.": "他们在想什么，他们看到了什么，他们的感受以及他们实际在做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that kind of stuff, uh, you will, uh, capture here in, in customer segments.": "诸如此类的内容，你将在客户细分中进行记录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these this is helping you identify the target, uh, customers or target customer segments you are": "这有助于你确定作为产品",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to target as a product.": "打算针对的目标客户或目标客户细分群体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, then the next one is value proposition.": "呃，接下来是价值主张。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So value proposition is the second section.": "价值主张是第二部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what you capture here is what's compelling about your product or proposition.": "你在这里记录的是你的产品或主张中引人注目的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why should the customer buy uh or use your product.": "客户为什么要购买或使用你的产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the value you are bringing to the life of your customer?": "你为客户的生活带来了什么价值？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That kind of stuff you are going to capture in value proposition section.": "你将在价值主张部分记录这些内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The next section is the channel.": "下一部分是渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the channel section you are going to capture how these propositions are promoted sold or delivered.": "在渠道部分，你将记录这些主张是如何被推广、销售或交付的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh and why and what is it working or not.": "呃，以及为什么，以及它是否奏效。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what are the various channels, uh, which you use for promoting means advertising, uh, your products,": "那么，你用于推广（即广告宣传）产品、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:selling your products and delivered.": "销售产品和交付产品的各种渠道有哪些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remember that all of these channels can be different for a single product.": "请记住，对于单一产品，所有这些渠道都可能各不相同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You might use one channel for promoting another channel for actually selling it, and then you use another": "你可能会使用一个渠道进行推广，另一个渠道进行实际销售，然后再使用另一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:channel for delivering it.": "渠道进行交付。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can have different channel for each of these activity.": "因此，你可以为每一项活动设置不同的渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or you can have same channel as well based on the product you are designing.": "或者，根据你设计的产品，你也可以使用相同的渠道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then uh, the next section, uh, in this model is the customer relationship.": "那么，这个模型中的下一个部分是客户关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In this section you capture how do you interact with your customer throughout their customer journey": "在这一部分中，你需要记录在整个客户旅程中你如何与客户互动，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so that that kind of information is captured here.": "这样这类信息就会被记录在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the next section is, uh, the revenue streams.": "接下来的一节是收入来源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Revenue stream is how does the business earn revenue from the value proposition or the product which": "收入来源是指企业如何从价值主张或你销售的产品中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you are selling?": "赚取收入？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So how do you actually, uh, make money, uh, using this product?": "那么，你实际上是如何利用这个产品赚钱的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What are those value streams then?": "那么，这些价值流是什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, the next one is key activities.": "下一个是关键业务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So key activities is what unique, uh, strategic things does the business do to deliver this proposition.": "关键业务是指企业为了交付这一主张而进行的哪些独特的战略性工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what is unique, uh, activities within your business model?": "那么，你的商业模式中有哪些独特的活动呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, those things you capture in key activities, then, uh, key resources.": "你在关键业务中记录这些内容，然后是核心资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Key resources are what unique strategic assets must the business have to compete in marketplace with": "核心资源是指企业为了在市场上与竞争对手竞争该特定产品而",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:your competitors for this particular product.": "必须拥有的独特战略资产。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those kind of information are captured in key resources then key partnerships.": "因此，这类信息被记录在核心资源中，然后是关键合作伙伴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So uh, key partnership is of what can the company not do.": "关键合作伙伴关系是指公司不能做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can focus on key activities.": "这样它就可以专注于关键业务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that are uh, what are the things which you can outsource or can be done by other partners for those": "也就是说，对于这些活动，有哪些事情是可以外包的，或者可以由其他合作伙伴来完成的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:activities?": "呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You, uh, find out key partners, and you capture those key partners here.": "你找出关键合作伙伴，并在这里记录这些关键合作伙伴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as a company, you will not be interested in doing everything which makes up your products or services.": "作为一个公司，你不会有兴趣去做构成你的产品或服务的所有事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You might be interested in focusing only on the things which are your strengths, where you can make": "你可能只想专注于你的优势所在、能赚",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:more money, where you need less resources.": "更多钱、需要更少资源的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So based on that, all these factors, you take the decisions.": "因此，基于所有这些因素，你做出决定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What will be your key partners for this product?": "这个产品的关键合作伙伴将是谁？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because you don't want to do everything.": "因为你不想包揽一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You will be interested in outsourcing or partnering on things which are strength of other people, not": "你会倾向于将那些属于别人的优势而非",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:your strength.": "你的优势的事情进行外包或合作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the next one is cost structure.": "下一个是成本结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in cost structure section you capture what are the major cost drivers and how they are linked to": "在成本结构部分，你需要记录主要的成本驱动因素以及它们如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:revenue.": "与收入挂钩。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what are the things which drive your business from cost angle, those things you capture here and": "也就是说，从成本角度驱动你业务的因素有哪些，你在这里记录这些内容，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:how those costs are helping in delivering the revenue.": "这些成本如何帮助实现收入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So based on that, you capture the cost structures here.": "因此，基于此，你在这里记录成本结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I've shown you a couple of arenas as we've gone through this adventure together.": "在我们共同经历这段冒险的过程中，我已经向你们展示了几个竞技场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The ones that I've made, The Outsmart and the Connect Four.": "我制作的那些，比如 The Outsmart 和 Connect Four。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But there are in fact, proper arenas.": "但事实上，还有一些正规的竞技场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or at least there's one really proper arena, very well known.": "或者至少有一个非常正规、非常有名的竞技场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It used to be called Lambesis.": "它以前叫 Lambesis。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These days it is called LM arena.": "现在它被称为 LM arena。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The LM arena language model arena.": "LM arena，即语言模型竞技场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Incredible place to go.": "这是一个非常值得去的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a place where you can chat with two different models anonymously.": "在这里，你可以匿名地与两个不同的模型聊天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It could be frontier.": "它们可能是前沿模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They could be open source.": "也可能是开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You compare them, you don't know which one is which.": "你对它们进行比较，但你不知道哪个是哪个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You vote.": "然后你进行投票。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a like blind human evaluations.": "所以这就像是一种盲测的人工评估。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the results are shown with what's called an ELO style rating, which for people that play chess,": "然后结果会以所谓的 ELO 风格评分显示，对于下象棋的人来说，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you know it well, but it's a kind of rating that is that works when you have a head to head competition": "你们很熟悉它，但这是一种在进行正面交锋竞争时起作用的评分方式，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and you can show the performance of different, different models compared to the ones that came before": "你可以展示不同模型与之前的模型相比的性能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it.": "表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there's it's a it's great fun to participate in this arena to to go through the process yourself": "参与这个竞技场非常有意思，你可以亲自体验",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of weighing up models and voting.": "权衡模型并投票的过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a benefit, you are adding to the community because you are helping everyone to know which which": "作为一个额外的好处，你也在为社区做贡献，因为你在帮助大家了解哪个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is the best model in this, in this very, you know, forget all the benchmarks.": "是这个领域中最好的模型，你知道的，抛开所有基准测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is just at the end of the day, the people's decision on which model is stronger.": "归根结底，这只是人们对哪个模型更强大的决定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so there's something about it that is the sort of the final say in all leaderboards.": "所以在某种程度上，它在所有排行榜中拥有最终发言权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I've explained it.": "我已经解释过了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It might sound a bit abstract to you.": "对你来说，这听起来可能有点抽象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's one way to make it be less abstract that's to go and try it out.": "有一个方法可以让它不那么抽象，那就是去亲自尝试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and do that.": "让我们去试试吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so here we are at la Marina, the place of the famous chatbot arena.": "好了，我们现在来到了 LM Arena，也就是著名的聊天机器人竞技场所在地。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to ask a question not to one model but to two models.": "我们将向两个模型（而不是一个）提出一个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to say tell a joke for a room full of AI engineers.": "我们会说，给满屋子的 AI 工程师讲个笑话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That would be you.": "那就是你们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's see.": "好了，让我们看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it goes to two different assistants assistant A and assistant B.": "问题发给了两个不同的助手：助手 A 和助手 B。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Assistant A says why do the neural network go to therapy.": "助手 A 说，为什么神经网络要去接受心理治疗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because it had too many unresolved layers.": "因为它有太多未解决的层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well it's not bad.": "嗯，还不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:An assistant be sure.": "助手 B 说，没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here's one tailored for AI engineers.": "这是一个为 AI 工程师量身定制的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why did the neural network break up with the decision tree?": "为什么神经网络要和决策树分手？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because it couldn't handle the branching commitment.": "因为它无法处理分支承诺。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yeah.": "是的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um.": "嗯。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ha.": "哈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, I, uh, I think, um, uh, between the two of them, I think a is shorter and sweeter, but I'm": "嗯，我，呃，我觉得，嗯，呃，在这两个之间，我觉得 A 更简短精炼，但我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:torn a bit.": "有点纠结。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I'm gonna go with assistant A, you might feel differently, but that's too bad, because it's not": "但我打算选助手 A，你可能有不同的感受，但那太遗憾了，因为这不是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:your choice.": "你的选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's my choice.": "这是我的选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's the great thing about this site.": "这就是这个网站最棒的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I get to choose.": "我可以做选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you hover over these, you can see it highlights which one I'm going to go left is better.": "如果你将鼠标悬停在这些上面，你可以看到它高亮显示了我将选择哪一个，左边那个更好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that is my vote.": "所以这就是我的投票。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The vote is in.": "投票已提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can go and look at the results.": "现在我们可以去查看结果了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we click here on the leaderboard section.": "于是我们点击这里的排行榜部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see there's actually a bunch of different leaderboards depending on what kind of question you'd": "你可以看到，根据你提出的问题类型，实际上有很多不同的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:asked.": "提问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll stick with the text one because that's where it all began.": "我们将继续查看文本排行榜，因为那是这一切开始的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's probably the most popular one.": "这可能也是最受欢迎的一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see.": "你可以看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It said 50,000 votes here and in pole position is Gemini two five Pro as the model that people most": "这里显示有 50,000 张选票，排在首位的是 Gemini 2.5 Pro，它是人们最",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like to chat with.": "喜欢与之聊天的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, uh, so that that comes first.": "呃，所以它排在第一位。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But sorry, no equal equal.": "但是抱歉，不，是并列。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The score is slightly below, but it's considered I guess a tie is Claude opus 41 and Claude Sonnet": "分数略低，但我猜它被认为是并列的，是 Claude Opus 4.1 和 Claude Sonnet",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:45.": "4.5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So really they are all tied.": "所以实际上它们都并列了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then GPT strangely ChatGPT for zero, which was a version GPT four are particularly optimized for": "然后是 GPT，奇怪的是 ChatGPT 4o，这是一个专门为聊天优化的 GPT-4 版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:chat.": "聊天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe not strangely.": "也许并不奇怪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe that's what you'd expect.": "也许这正是你所期望的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That comes in second place.": "它排在第二位。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's considered a tie with these other models, which includes GPT four five preview, which was": "它被认为与这些其他模型并列，其中包括 GPT-4.5 Preview，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:only released for for a short period of time.": "仅发布了很短一段时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, which is tied one point higher than GPT five high itself.": "嗯，它的分数比 GPT-5 High 本身还高出一分，处于并列位置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so it's interesting and it's good to see Gemini two five Pro and in first place like that.": "嗯，所以这很有趣，很高兴看到 Gemini 2.5 Pro 像这样排在第一位。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see the other leaderboards here.": "你可以在这里看到其他的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again, the thing that makes this most satisfying is that there's no this isn't based on some as": "同样，最令人满意的一点是，这并不是基于某些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a judge or some other criteria or a multi multiple choice selection.": "评委或其他标准，或者是多项选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is based on actual people like you and me voting for the model we prefer with without knowing which": "这是基于像你我这样的真实用户，在不知道哪个模型是哪个的情况下，投票选出我们更喜欢的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:one is which, which means it's super legit.": "这意味着它非常具有公信力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So go on in there, make your vote.": "所以去那里投下你的一票吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Contribute uh to to to the votes and see what what what can happen.": "为投票做出贡献，看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:See how you can change the leaderboard and bring your favorite model to the front.": "看看你如何改变排行榜，并将你最喜欢的模型推向最前面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And learn a little bit about the different capabilities of models while you are at it.": "顺便了解一下模型不同的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as a quick extra topic, I know everyone wants to get to coding.": "作为一个快速的额外话题，我知道大家都想开始写代码了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Fed up with all of these, uh, commercial type topics.": "受够了所有这些，呃，商业类型的话题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But just to wrap up, I want to talk about the different use cases commercially of applying LMS to solve": "但作为总结，我想谈谈在商业上应用大语言模型（LLM）来解决",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:business problems.": "业务问题的不同用例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I often describe it as, as you can think of using LMS and generally applying AI, uh, along this,": "我经常这样描述它，你可以认为使用大语言模型和广泛应用人工智能，呃，是沿着这条，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this continuum of the amount of business value that you're offering.": "这条关于你所提供的业务价值量的连续谱进行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Initially, everyone was thinking about automation.": "最初，每个人都在考虑自动化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You were using AI to automate tasks that were intensely manual and error prone and were easy to automate.": "你使用人工智能来自动化那些高度依赖人工、容易出错且易于自动化的任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Automating repetitive tasks was the domain of of AI originally.": "自动化重复性任务最初是人工智能的领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it moved from automation to augmentation, which is about being a co-pilot, to a human working": "然后它从自动化转向了增强（augmentation），也就是作为人类的副驾驶，与人类",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:alongside a human, allowing someone to do more because they can they can, uh, delegate some tasks": "并肩工作，允许人们做得更多，因为他们可以，呃，将一些任务委托",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to an AI, and it allows them to achieve more through partnership with an LLM.": "给人工智能，这让他们能够通过与大语言模型的合作取得更多成就。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the sort of the final tier.": "然后是最后的一层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The next step up is differentiation, which is where you or your business are actually able to achieve": "更高的一步是差异化（differentiation），也就是你或你的企业实际上能够实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:something completely different because AI is enabling a new activity that was previously impossible.": "完全不同的东西，因为人工智能正在赋能一项以前不可能实现的新活动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as you go down that continuum, of course things get more and more exciting from automation to augmentation": "当你沿着这个连续谱往下走时，事情当然会变得越来越令人兴奋，从自动化到增强",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to differentiation.": "再到差异化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also helpful to think about the types of AI solution that you build in three dimensions.": "从三个维度来思考你构建的人工智能解决方案类型也是很有帮助的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There are things that people often describe as ChatGPT wrappers, and that's usually used in a slightly": "有些东西人们通常称之为 ChatGPT 套壳（wrappers），这通常带有一点",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:dismissive way.": "轻蔑的意味。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And these are cases where a commercial app has integrated with an with an LLM like GPT.": "这些情况是指商业应用集成了像 GPT 这样的大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, often people just say ChatGPT because it's the most obvious one that is most dismissive of someone,": "呃，人们通常直接说 ChatGPT，因为它是最显而易见的一个，也是最能轻视别人的说法，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and they're using that behind the scenes in order to add value to their app.": "他们在幕后使用它，以便为他们的应用增加价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I mean, there are so many examples of this that like you pick up your, your, your phone and look": "我的意思是，这方面的例子太多了，比如你拿起你的手机，看看",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:at the apps there and you'll see that many of them will be using an LLM in some way.": "上面的应用，你会发现其中许多都在以某种方式使用大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They'll be integrating JNI into the app.": "它们会将生成式人工智能（GenAI）集成到应用中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The one that came straight to mind is Duolingo because we talked about it earlier.": "我立刻想到的是多邻国（Duolingo），因为我们之前谈到过它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yes, it actually uses GPT.": "是的，它实际上使用了 GPT。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and so it's such a clear example of just putting a wrapper on top and being able to charge a premium": "呃，所以这是一个非常清晰的例子，只是在上面加个套壳，就能收取溢价",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for it.": "。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Although of course they do a bit more than that.": "当然，他们做的远不止这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's probably unfair, but you get the idea.": "那可能不太公平，但你明白我的意思。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then copilot is often very similar.": "然后副驾驶（copilot）通常也非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The the wave of copilot, which are essentially just making calls to a frontier model but surfacing": "这一波副驾驶产品，本质上只是在调用前沿模型，但将其",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that baked into the tool.": "嵌入到工具中呈现出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are GPT wrappers.": "所以那些就是 GPT 套壳。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And next is the vellum leaderboard.": "接下来是 Vellum 排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You'll find a link in the resources vellum.": "你可以在资源 Vellum 中找到链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again, the company where the CEO messaged me on LinkedIn, uh, after I mentioned it.": "还是那家公司，在我提到它之后，他们的 CEO 在 LinkedIn 上给我发了消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's got a number of good comparison tables.": "它有很多不错的对比表格。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's got, uh, the, um, uh, comparisons of models side by side with another model that you can pick": "它有……呃……模型与你可以选择的另一个模型的并排对比，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from the dropdowns and see them ranked.": "你可以从下拉菜单中选择并查看它们的排名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the thing I wanted to mention, the thing that I find most helpful, is right here, the context": "但我想提的一点，也是我觉得最有用的，就在这里，上下文",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:window cost.": "窗口成本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now speed didn't used to be there.": "现在还有了速度，以前是没有的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Also speed comparison this table.": "还有这个表格中的速度对比。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I really like it because it's such a one place to go to get the the input and output cost per tokens": "我非常喜欢它，因为在这里可以一站式获取每个 token 的输入和输出成本，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for a context window.": "针对特定的上下文窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as as you now know from from week one, there is another dimension here which is the cached cost.": "正如你们从第一周所了解到的，这里还有另一个维度，即缓存成本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you send the same input tokens twice, usually significantly less.": "如果你两次发送相同的输入 token，成本通常会显著降低。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But to get that you have to go to the the models website.": "但要获取这些信息，你必须去模型官网。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But anyway that's vellum very useful okay.": "总之，这就是 Vellum，非常有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is now looking at the seal leaderboards, a set of leaderboards published by AI company Mail.com.": "现在我们来看看 Seal 排行榜，这是由 AI 公司 Mail.com 发布的一系列排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they are intended to be leaderboards that quite specifically test for different areas of expertise.": "它们的目的是作为专门测试不同专业领域的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you have a very specialized task, you might want to see if there's a Seal leaderboard that applies": "所以，如果你有一个非常专业的任务，你可能想看看是否有适用的 Seal 排行榜",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to you.": "适合你。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, one of the leaderboards they're most famous for producing is the Humanity's Last Exam leaderboard": "现在，他们最著名的排行榜之一是“人类最后的考试”（Humanity's Last Exam）排行榜，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that I promised you.": "这是我向你们承诺过的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we drill into that, we can see more about humanity's last exam.": "如果我们深入研究，可以看到更多关于“人类最后的考试”的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It explains that it's 2500 questions.": "它解释说这里有 2500 道题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It gives a sort of background to it about frontier benchmarks just all having diminishing returns.": "它提供了一些背景信息，说明前沿基准测试的收益都在递减。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then in partnership with the center for AI safety, they came up with this idea.": "然后，他们与 AI 安全中心合作，提出了这个想法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They had user submitted questions and they selected this final set.": "他们收集了用户提交的问题，并筛选出了最终的这套题目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you'll see that when they started out, which was November of last year, uh, the top model was": "你会看到，当他们开始时（即去年 11 月），排名第一的模型是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT four and it was scoring 2.72.": "GPT-4，得分为 2.72。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I told you I thought it was between 2 and 3.": "我告诉过你们，我以为是在 2 到 3 之间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, there it is.": "呃，就在这儿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And over time, look at how these numbers have changed.": "随着时间的推移，看看这些数字发生了怎样的变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now GPT five scoring 25.3.": "现在 GPT-5 的得分是 25.3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think we saw a slightly different number on artificial analysis II, which is because there's a variant": "我想我们在 Artificial Analysis II 上看到了一个略有不同的数字，这是因为有一个变体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of this exam which is just text only, whereas this one is the multi-modal version.": "这个考试有一个纯文本版本，而这个是多模态版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see how this has changed.": "你可以看到这是如何变化的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, you know, for people that feel like progress is slowing down, that's not what we see in terms": "而且，你知道，对于那些觉得进步正在放缓的人来说，从这项能力来看",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of this ability.": "事实并非如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and uh, yeah.": "呃，还有，是的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The way if you're wondering how are the questions evaluated because they're so hard.": "如果你想知道这些问题是如何评估的，因为它们太难了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, let's just start by looking at what are the questions like.": "那么，让我们先来看看这些问题是什么样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is on their website, humanities exam website.": "这是在他们的网站上，即“人类终极考试”网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here's an example of a question.": "这里有一个问题的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, it's given that image.": "呃，给出了那张图片。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The question is here is a representation of a Roman inscription originally found on a tombstone.": "问题是，这里展示的是最初在墓碑上发现的罗马铭文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Provide a translation for the Palmyrene script.": "请提供帕尔米拉文字的翻译。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A transliteration of the text is provided.": "提供了文本的音译。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ah, so goodness, it's some sort of combination of like having amazing subject matter knowledge of": "啊，天哪，这像是某种结合，既需要具备惊人的专业领域知识，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:something super obscure, but also presumably being able to puzzle your way through something.": "针对某些极其晦涩的内容，同时大概还需要具备解谜的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because I imagine this is something that requires some decoding and some problem solving to figure out": "因为我想这需要一些解码和问题解决能力，才能弄清楚",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:how you could possibly read that.": "到底该怎么读懂它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, then here's a question on ecology.": "呃，然后这里有一个关于生态学的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not even going to try and read this through because I'll embarrass myself.": "我甚至不打算尝试读完它，因为我会让自己难堪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you can you can see that there and get a sense of how hard these are.": "但你可以看到那里，感受一下这些题有多难。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a maths question.": "这里有一个数学题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a computer science question.": "这里有一个计算机科学题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a chemistry and linguistics.": "还有化学和语言学题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And providing the standardised biblical Hebrew source text, your task is to distinguish between closed": "在提供标准圣经希伯来语源文本的情况下，你的任务是区分闭音节",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and open syllables.": "和开音节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, chemistry.": "呃，化学。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Trivia.": "百科知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Physics.": "物理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll take a look at that later.": "我稍后再看那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Rod.": "杆。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Tension.": "张力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the value?": "数值是多少？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so some sort of super hard, uh, physics level question that certainly looks like it might be.": "好的，所以是某种超级难的、呃，物理水平的问题，看起来确实像是那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, it's from UC Berkeley.": "呃，它来自加州大学伯克利分校。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's probably very difficult question.": "这可能是一个非常难的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so those are the samples.": "呃，所以这些就是样本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's fun to see them.": "看到它们很有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's fun to understand how challenging these are.": "了解这些题有多具挑战性很有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They are definitely above PhD level in complexity.": "它们的复杂程度绝对超过了博士水平。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The way that it's judged is that the model comes up with the answer.": "评判方式是让模型给出答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that is provided to oh three.": "然后将答案提供给 o3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One of the larger reasoning models from open AI.": "OpenAI 的大型推理模型之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And oh three is given the answer from the model and the reference.": "o3 会得到模型的答案和参考答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gold truth.": "金标准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, answer the actual ground truth.": "呃，即实际的标准答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The golden answer makes my my words.": "“黄金答案”是我的措辞。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's given that, and it has to compare them and confirm that they are consistent.": "它得到这些信息后，必须进行对比并确认它们是否一致。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so it is a kind of LM as a judge.": "所以这是一种“大语言模型作为评委”的形式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's not just the LM grading it, it's the LM using a reference answer.": "但不仅仅是大语言模型在评分，而是大语言模型在使用参考答案进行评分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So which is which is an excellent technique.": "这是一种非常出色的技术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that is humanity's last exam.": "这就是“人类终极考试”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's great fun.": "非常有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Take a look at it.": "去看看吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And whatever you're looking at now no doubt the world has moved on from here.": "无论你现在在看什么，毫无疑问，世界已经向前发展了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so you'll see where we are.": "所以你会看到我们现在所处的位置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah, if it's in the 80s or 90s, then maybe, uh, the overlords have already taken over.": "是的，如果得分在 80 或 90 分左右，那么也许，呃，人工智能霸主已经接管一切了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, that is humanity's last exam.": "呃，这就是“人类终极考试”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just to walk you through some of the other leaderboards on the seal leaderboards, there's one that": "顺便带你看一下 SEAL 排行榜上的其他一些榜单，其中有一个榜单",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:specifically tests models ability to use MCP to call tools.": "专门测试模型使用 MCP 调用工具的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's some software engineering metrics.": "还有一些软件工程指标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is one that's about being able to reason in foreign languages, or to solve foreign language puzzles": "有一个关于能够使用外语进行推理，或者解决外语谜题的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with reasoning, because reasoning tends to be quite, quite focused on, on English language.": "通过推理来解决，因为推理往往非常、非常集中在英语上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, there's a bunch of interdisciplinary challenges.": "呃，还有一堆跨学科的挑战。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is a particular evaluation around security and safety.": "有一个专门针对安全性和保障性的评估。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's something that Cellcom has focused hard on and a similar one about alignment.": "这是 Cellcom 重点关注的内容，还有一个类似的关于对齐的评估。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The mask is evaluating models honesty when pressured to lie.": "Mask 正在评估模型在被迫撒谎时的诚实度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you remember the point I made about the potential concern that models know when they're being evaluated.": "你还记得我提到的关于模型可能知道自己正在接受评估的潜在担忧吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Obviously that comes strongly with with a metric like this.": "显然，像这样的指标会强烈地体现出这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But as of now, sonnet does well on on, uh, on sonnet 4.5 seems to do seems to do pretty well on this.": "但到目前为止，Sonnet 在这方面表现不错，呃，Sonnet 4.5 在这方面似乎表现得相当好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Their consistency with their beliefs when pressured to lie.": "它们在被迫撒谎时与其信念的一致性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Super interesting, uh, complex, multi-step reasoning, vision, understanding.": "非常有趣，呃，复杂的、多步推理、视觉、理解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then a tutor bench.": "然后是 Tutor Bench。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Something very specific for teaching skills.": "专门针对教学技能的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so, yeah, if you're looking to build something that's going to be in the education space, then": "所以，是的，如果你想在教育领域开发一些东西，那么",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the tutor bench might be a useful leaderboard for you.": "Tutor Bench 对你来说可能是一个有用的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that wraps up the seal leaderboards.": "以上就是 SEAL 排行榜的总结。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me flip to hugging.": "让我切换到 Hugging...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Face this.": "Face 这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a hugging face spaces.": "有一个 Hugging Face Spaces。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is a mass of useful leaderboards that you can look at for different comparing open source models": "这里有大量有用的排行榜，你可以查看它们来比较开源模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:against different characteristics.": "在不同特性下的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The one that used to be the go to is called the open Leaderboard, but it's been archived for a few": "以前最常用的是 Open Leaderboard，但它已经存档了几个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:months now.": "月了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It seems that Huggingface has decided that they don't want to be in the game of building these leaderboards": "似乎 Huggingface 已经决定不再参与构建这些排行榜的竞争了，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:anymore, possibly because people were starting to game it and there was so many different models being": "可能是因为人们开始钻空子，而且有太多不同的模型被",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:put up here that it became noisy.": "放在这里，导致噪音太大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think they have backed off from being in this space.": "所以我认为他们已经退出了这个领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if you're if you're interested, it is.": "但如果你感兴趣的话，它就在那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a few months old, but it is still a nice place to see about the performance of different open": "虽然是几个月前的数据，但它仍然是查看不同开源模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:source models.": "性能的好地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But there are a lot of other leaderboards here that are kept updated.": "但这里还有很多其他保持更新的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a big code, uh, leaderboard that gives you the performance of different coders, um, against": "有一个 BigCode 排行榜，它提供了不同编程模型在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:different programming languages like C++, JavaScript, Java.": "不同编程语言（如 C++、JavaScript、Java）下的性能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see that it's, it's got 2.5 coder.": "你可以看到，它包含了 2.5 Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this has some of the latest models.": "所以这里有一些最新的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you'll find a bunch of other leaderboards here.": "你还会在这里发现一堆其他的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a performance one that's very good for seeing the speed and power of different, uh, open source": "有一个性能排行榜，非常适合查看不同开源模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:models on different hardware spec.": "在不同硬件规格下的速度和效能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's a medical leaderboard that has very specific criteria from the medical industry.": "还有一个医疗排行榜，它有来自医疗行业的非常具体的标准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, Q&A, anatomy, clinical knowledge and ranking different models against those specific benchmarks": "呃，问答、解剖学、临床知识，以及针对这些特定基准对不同模型进行排名",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:agent leaderboards, deep research, hallucination, image leaderboards.": "智能体排行榜、深度研究、幻觉、图像排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So much to explore on hugging face.": "Hugging Face 上有很多值得探索的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Always double check how how recently it's been updated and and check the sources and make sure that": "务必仔细检查更新频率并核实来源，确保",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this is something that is a credible leaderboard, but otherwise tons of information freely accessible": "这是一个可信的排行榜，除此之外，还有大量免费获取的信息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on hugging face.": "在 Hugging Face 上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I mentioned the last one I was going to tell you about is Live Bench, which is a hard and contamination": "我提到的最后一个要告诉你们的是 Live Bench，这是一个高难度且无污染的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:free benchmark that involves completely refreshing all their questions every six months and then going": "基准测试，它每六个月会完全更新所有问题，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:through and testing against these different factors like reasoning, coding and genetic coding, maths": "针对推理、编程和遗传编程、数学",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and data analysis.": "以及数据分析等不同因素进行测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see how the models rank compared to these different scores, GPT five high is currently": "你可以看到模型在这些不同评分下的排名，GPT-5 High 目前",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in pole position.": "处于领先地位。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Claude 4.5.": "Claude 4.5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thinking comes soon after GPT five.": "Thinking 版本紧随 GPT-5 之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh and uh does does pretty close pretty well, but is uh.": "呃，表现得非常接近，非常好，但是，呃。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Also doing very well on reasoning but winning in coding.": "在推理方面也表现出色，但在编程方面胜出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Look at that first place on coding or tied uh, for for uh, agentic coding.": "看看编程方面的第一名，或者在智能体编程方面并列第一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Strangely, GPT five high does slightly worse than GPT five medium on agentic coding.": "奇怪的是，GPT-5 High 在智能体编程方面的表现略逊于 GPT-5 Medium。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe it overthinks things through, uh, but this is a great resource because these metrics are so": "也许它想得太多了，呃，但这是一个很好的资源，因为这些指标是如此",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:carefully, um, prepared to not not suffer from data set leakage problems.": "细致地准备，以避免数据集泄漏问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so this is very credible source.": "所以这是一个非常可信的来源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it again, it combines like most of these leaderboards closed source and open source models a bunch": "它再次结合了大多数排行榜中的闭源和开源模型，这里有一堆",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of ones here GLM I think we saw that did pretty well on artificial analysis as well.": "比如 GLM，我想我们看到它在人工分析方面也表现得相当不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, is from Chinese startup Xie AI.": "呃，它来自中国初创公司 Xie AI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So lots of great models to look at here.": "所以这里有很多优秀的模型可以关注。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do check out and bookmark Live Bench as well.": "务必也去看看并收藏 Live Bench。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then next up is a specialized, bespoke proprietary AI platform that your business has built in": "接下来是一个专门的、定制的专有 AI 平台，这是您的企业为了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:order to be able to add value because it has direct domain expertise in some area.": "能够增加价值而构建的，因为它在某些领域拥有直接的领域专业知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is of course, the more juicy, the more meaningful area.": "当然，这是一个更精彩、更有意义的领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And arguably Duolingo is more in this territory too.": "可以说 Duolingo 也更多地属于这个范畴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's of course, some sort of, again, a continuum between these things.": "当然，这些事物之间也存在某种连续性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is where you've built models that that have expertise that you won't find if you go to ChatGPT.": "但在这里，你构建的模型拥有你在 ChatGPT 中找不到的专业知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And maybe originally you did that through training, through fine tuning, you built models that you": "也许最初你是通过训练、通过微调来实现的，你构建了模型，并",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:trained it on proprietary data, and you used that to, to be able to, to achieve something different.": "在专有数据上对其进行训练，并利用它来实现一些不同的目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ChatGPT.": "ChatGPT。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But increasingly it's inference time techniques, it's Rag and other kinds and adding tools, other": "但越来越多的是推理时技术，如 RAG 和其他类型，以及添加工具和其他",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:capabilities that allows you to do more.": "让你能做更多事情的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so there are smaller companies, there are startups, there's companies like Harvey which is applying": "因此，有一些规模较小的公司、初创公司，比如像 Harvey 这样将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:llms to law.": "大语言模型应用于法律领域的公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's the company that I work at Nebula, which is applying it to to the talent and careers and jobs": "还有我工作的公司 Nebula，它将其应用于人才、职业和工作",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and, and people matching people with roles where they'll be successful.": "以及将人才与他们能获得成功的职位进行匹配。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's Kahneman go from the Khan Academy, which is applying it to education, and then just to talk": "还有可汗学院的 Khanmigo，它将其应用于教育领域。再谈谈",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to some of the big people out there, of course, Salesforce is in this game all over the place, but": "一些大公司，当然，Salesforce 在这个领域无处不在，但是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:they have a healthcare offering that's particularly impressive that does things like automate taking": "他们有一个特别令人印象深刻的医疗保健产品，可以实现诸如自动记录",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:doctor's notes and clinical, uh, meetings and being able to to take away a lot of the administrative": "医生笔记和临床会议，并能够消除大量的行政",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:work, but with knowledge, with with bespoke information and hooked up to all of the Salesforce tooling": "工作，但带有知识和定制信息，并与所有 Salesforce 工具相连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and Palantir, of course, the data platform that has a lot of AI weaved through it, taking advantage": "还有 Palantir，当然，这个数据平台中融入了大量的 AI，利用了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of their data.": "他们的数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that is a it's generally a common theme of this, that a way that an AI company, perhaps like one": "这是一个普遍的共同主题，即一家 AI 公司（也许就像",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that you work for, is able to to distinguish itself from the others is often through the data.": "你所工作的公司）能够脱颖而出的方式通常是通过数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It comes down to data.": "归根结底在于数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's famously Andrew Ng once said that the AI is the new electricity, and I think that's that's": "著名的吴恩达（Andrew Ng）曾说过，AI 是新的电力，我认为这",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:obviously proven to be true.": "显然已被证明是正确的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But in addition to that, I would say that data is the electricity.": "但除此之外，我想说数据才是电力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Having your own proprietary data set that other people don't have means that you'll be able to build": "拥有别人没有的专有数据集，意味着你将能够构建",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a business specialized application which can do things that others can't.": "一个能够完成他人无法完成的任务的商业专用应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And these things always come in threes.": "这些事情总是成三出现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there had to be a third one.": "所以必然会有第三个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it is of course a genetic AI.": "当然，那就是智能体 AI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is the that is the new frontier.": "那就是，那就是新的前沿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is the the place where we can build software that is autonomous, able to make decisions, able": "那里是我们可以构建自主软件的地方，这些软件能够自主运行、能够做出决策、能够",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to go out and do things.": "外出并执行任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this really feels like the place where more than any other, we will be able to build things that": "这确实感觉是一个比其他任何地方都更能让我们构建出",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:let businesses differentiate and do things that just weren't possible before.": "让企业实现差异化并完成以前根本不可能实现的事情的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's interesting to me that many of the most common use cases around using Agentic AI are more technical": "令我感兴趣的是，许多关于使用代理式 AI (Agentic AI) 的最常见用例都更偏向技术性，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and coming from technical companies.": "并且来自技术公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So obviously Claude Code, OpenAI, Codex, these are ones we all know, and also the OpenAI agent mode": "显然，Claude Code、OpenAI、Codex，这些都是我们熟知的，还有 OpenAI 的代理模式",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that we used within ChatGPT.": "我们在 ChatGPT 中使用的那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But and that was less technical.": "但那个技术性稍弱一些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But but still, it's coming from a tech company.": "但尽管如此，它仍然来自一家科技公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think that the space to watch is going to be how businesses bring a genetic AI into their products": "我认为值得关注的领域将是企业如何将代理式 AI 引入其产品中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in a big way.": "以一种大规模的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that hasn't yet happened.": "而这还没有发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think that's going to be the next frontier.": "我认为这将是下一个前沿领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if this is interesting to you or you wanted to hear more about this, then I do have separately": "如果你对此感兴趣，或者想了解更多相关信息，那么我另外准备了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a companion briefing on LMS for leaders.": "一份针对领导者的 LMS 配套简报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I know I expect most of you want me to move on and get to the coding, which we're going to do in just": "我知道我预料你们大多数人都希望我继续前进并开始编码，我们马上就要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a second.": "开始了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But but yes, if you if you are interested, there is the companion briefing.": "但是，是的，如果你感兴趣，这里有配套简报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the one thing I'll say about this whole topic is that, look, I do believe that it is a superpower.": "关于这整个话题，我想说的一点是，听着，我确实相信这是一种超能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you are an AI engineer and you also have knowledge of the commercial side of this, you have savvy,": "如果你是一名 AI 工程师，同时又了解其商业方面，具备商业头脑，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you know, about what are some of the traps and some of the, the, the, the areas for success for": "知道有哪些陷阱，以及在哪些领域可以成功地",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:applying a genetic AI or generative AI for commercial benefit.": "应用代理式 AI 或生成式 AI 来获取商业利益。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I would urge you to take time to look at the commercial side too.": "所以我敦促你也花点时间看看商业方面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It really sets you apart, and maybe some of your business people who are taking this course to get": "这真的会让你脱颖而出，也许你们中有些商务人士参加这门课程是为了获得",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:some technical skills, which gives you superpowers.": "一些技术技能，这会赋予你超能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you probably agree with me that that's where it's at.": "你可能也会同意我的看法，这才是关键所在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Knowing both, having at least a good awareness.": "两者兼顾，至少有良好的意识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Some know how some savvy about the commercial side of it will really set you apart.": "对商业方面的一些诀窍和见解真的会让你与众不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, but I promise you that we were going to get technical and we're going to do starting tomorrow.": "好了，但我向你们保证，我们会进入技术层面，我们将从明天开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to go back to labs.": "我们将回到实验环节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's been like two days without any real coding labs.": "已经有两天没有任何真正的编码实验了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are going to build a little commercial challenge, which is going to be fun and tangible.": "我们将构建一个小型的商业挑战，这将是有趣且切实的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's suppose we're trying to build a product that converts from one technology to another.": "假设我们正尝试构建一个将一种技术转换为另一种技术的产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In particular, we're going to try and do something that converts Python code to C++ to be high performance": "具体来说，我们将尝试开发一个将 Python 代码转换为高性能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:C++ code.": "C++ 代码的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, which is an interesting one.": "呃，这是一个很有趣的课题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So C++, most of you probably know, is like a compiled language that's very platform specific, that": "所以 C++，你们大多数人可能都知道，是一种非常依赖平台的编译型语言，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:compiles down to machine code that runs natively on your platform, where Python is an interpreted language.": "会编译成在你的平台上原生运行的机器码，而 Python 是一种解释型语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so converting Python code in C++ is a really cool thing to do because it allows you to build this": "因此，将 Python 代码转换为 C++ 是一件非常酷的事情，因为它允许你构建这种",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:kind of super blazingly fast solution.": "极其快速的解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to try it with a bunch of different models.": "我们将尝试使用一系列不同的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to pick the right model to do so.": "我们将挑选合适的模型来完成这项任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to use this as our exercise for how do you select the right model for the task at hand,": "我们将以此作为练习，学习如何针对手头的任务选择合适的模型，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is going to be great fun.": "这将会非常有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to do that tomorrow.": "我们明天就会开始做这件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so with that now, at this point, in addition to coding with frontier models, open source Llms": "那么现在，在这一点上，除了使用前沿模型、开源大语言模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and Transformers, and you can now confidently choose the right model for your project backed by metrics.": "和 Transformer 进行编码之外，你现在还可以根据指标自信地为你的项目选择合适的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or if you want to be pedantic, you can choose the right models.": "或者如果你想严谨一点，你可以选择合适的模型（复数）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can choose the right Llms the subset.": "你可以选择合适的大语言模型子集。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's still another step to go to actually prototype and select the final model.": "在实际进行原型设计并选择最终模型之前，还有一个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's what we're going to be working on for the next few days.": "这就是我们接下来几天要研究的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Next time you're going to be able to assess models, particularly for the ability to generate code.": "下次你将能够评估模型，特别是它们生成代码的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll be able to build a solution that uses models to generate code.": "我们将能够构建一个使用模型来生成代码的解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a side effect of doing this, we'll have walked through the practice of picking the right model,": "在做这件事的过程中，我们也将完成挑选合适模型的实践，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is what this week is all about.": "这正是本周的主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:See you tomorrow.": "明天见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's week four, day three, and it's a day when we are going to go back to the labs at last.": "现在是第四周第三天，今天我们终于要回到实验室了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's been an age you can already code with frontier models.": "感觉过了很久，你们已经可以用前沿模型编写代码了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can build solutions with open source llms, and you can now choose the right LLM for the task at": "你们可以用开源大语言模型构建解决方案，现在你们可以根据指标和排行榜为手头的任务",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:hand based on metrics and leaderboards.": "选择合适的大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Today, we're going to assess models for how good they are at coding, and we're going to use frontier": "今天，我们将评估模型在编程方面的表现，我们将使用前沿",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:models to generate code and will be building, building, building and cursor.": "模型来生成代码，并将在 Cursor 中不断地构建、构建、再构建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But before we start, I do have a couple more announcements to make.": "但在开始之前，我还有几个通知要宣布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, but just just hear me out here.": "呃，不过请先听我说完。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is something incredibly important that every AI engineer needs to know.": "有一件极其重要的事情是每位 AI 工程师都需要知道的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it is your sworn duty as an AI engineer, as an LLM engineer, that this is something that that": "作为一名 AI 工程师，作为一名大语言模型工程师，这是你的神圣职责，是你必须",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you hold yourself to.": "坚守的准则。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's about pushing back on your business, and it's about finding the business problem.": "那就是对业务需求进行审视，并找到真正的业务问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a situation that I find myself in a lot.": "这是我经常遇到的一种情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I find that people come to me and they say things like, I want an AI agent for my organization or something": "我发现人们来找我时会说，我想为我的组织搞一个 AI 智能体，或者类似",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like that.": "这样的话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very common for me to get people approaching me with questions like that, including senior people,": "经常有人带着这类问题来找我，包括资深人士、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:including senior execs, including people from all sorts of different backgrounds.": "高管，以及来自各种不同背景的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the question that I say back to them, which is what you all need to say back to people that say": "而我回问他们的问题——也是你们在面对这种说法时需要回问的——",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this to you is sure for sure, but but what business problem are you solving?": "是：“当然没问题，但是，你到底在解决什么业务问题？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Bring people back to the business problem.": "把人们带回到业务问题上来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Don't let business people talk in terms of solutions.": "不要让业务人员只谈论解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And sometimes I find that I that I say that back to somebody, and the question I get is sort of puzzled": "有时我发现当我这样回问某人时，得到的反应是一脸",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:face.": "困惑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They don't really understand.": "他们并不真正理解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they say something like, I want to be able to speak to my phone and say, what are my sales numbers": "他们会说类似这样的话：“我想能对着手机说，今天的销售额",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:today?": "是多少？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So give me an agent.": "“所以给我搞个智能体吧。”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, your answer to that, please, should be yes.": "当然，请记住，你对此的回答应该是：“好的。”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Great.": "“太棒了。”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and so what business problem is that solving?": "“那么，这解决了什么业务问题呢？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The key thing being that we are in a world where the hype around gen AI and Agentic AI is, is so tremendous": "关键在于，我们正处于一个生成式 AI 和智能体 AI 炒作极其盛行的世界，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that everyone wants a bit of it, and that's great and that's exciting, but we need to always ground": "每个人都想分一杯羹，这很好，也很令人兴奋，但我们始终需要让",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:people back in the actual thing that's being solved.": "人们回归到实际要解决的问题上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You need to understand the problem first and foremost, how you're going to measure success and use": "你首先需要理解问题，确定如何衡量成功，并以此",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that as your way to determine the right solution to the business problem at hand.": "作为确定手头业务问题正确解决方案的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It has to start from the problem and you'll see in the guys folder.": "一切必须从问题出发，你们会在 guides 文件夹中看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Guide 12 I believe it is has a good set of advice for what you then do next.": "我相信是指南 12，它为接下来的行动提供了一系列很好的建议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, let's go ahead and port some code with LMS.": "好的，让我们开始使用大语言模型（LMS）来移植一些代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I should mention I did actually change this compile command to a more efficient version.": "我应该提到，我实际上已经将这个编译命令更改为了一个更高效的版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After going backwards and forwards with GPT five a couple of times, you might want to do that to just": "在与 GPT-5 来回沟通了几次之后，你可能也想这样做，只是为了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:make sure you've got a really good, efficient compile command.": "确保你有一个非常好的、高效的编译命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Onwards.": "继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here is my system prompt.": "这是我的系统提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Your task is to convert Python into high performance C++.": "你的任务是将 Python 转换为高性能的 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Respond only with C++, do not provide any other explanation.": "仅以 C++ 响应，不要提供任何其他解释。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It needs to produce the identical output.": "它需要产生相同的输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Fastest time.": "最快的时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's just a constant system prompt.": "这只是一个固定的系统提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The user prompt is going to depend on the python that we want to change.": "用户提示词将取决于我们想要更改的 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So.": "所以。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we want port.": "所以我们要进行移植。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's a function user prompt for the python that's passed in.": "所以这是一个针对传入的 Python 代码的用户提示词函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I say port this Python code to C++.": "我说，将这段 Python 代码移植到 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the type of system we're on.": "这是我们所处的系统类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the command we will use to compile the code and now respond only with the C++.": "这是我们将用于编译代码的命令，现在请仅以 C++ 响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the code to port, and that is where I put in the prompt the Python code that we're working": "这是要移植的代码，也就是我在提示词中放入我们正在处理的 Python 代码的地方",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with Okay.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I execute that.": "所以我执行那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I've got another simple function messages for that takes Python.": "现在我有了另一个简单的函数 messages_for，它接收 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is just something that returns the usual list of dicts that you know so well.": "这只是一个返回你非常熟悉的字典列表的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It has a system prompt put in there, and for the user prompt it is using this function that we just": "它里面放入了一个系统提示词，而对于用户提示词，它使用的是我们刚刚",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:wrote.": "编写的这个函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there we go.": "好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's done.": "完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then another little utility function write output that takes some C++ code.": "然后是另一个小的实用函数 write_output，它接收一些 C++ 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll just write it to a file called main and we'll run that.": "我们只需将其写入一个名为 main 的文件并运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we are ready for the big guy for port a function called port.": "现在我们准备好迎接重头戏了，一个名为 port 的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what does the function called port do?": "那么这个名为 port 的函数是做什么的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, it takes a client like OpenAI or any client library model, a model name and the Python code": "嗯，它接收一个像 OpenAI 这样的客户端或任何客户端库模型、一个模型名称以及要移植的 Python 代码",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to port.": "进行移植。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's just something a bit hacky here that if GPT is in the model name for using an OpenAI model,": "这里有一点取巧的地方，如果模型名称中包含 GPT（用于 OpenAI 模型），",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a GPT series, then take the reasoning effort to be high.": "即 GPT 系列，那么将推理力度（reasoning effort）设为高。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is a flag that's used for the GPT.": "这是用于 GPT 的一个标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:JPGs and then we will call client completions dot create.": "GPTs，然后我们将调用 client.completions.create。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We pass in the model, we pass in the messages, the one that comes straight from this function right": "我们传入模型，传入消息，也就是直接来自这个函数的那条消息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:here.": "这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then if we're using a GPT series we pass in the reasoning effort.": "然后，如果我们使用的是 GPT 系列，我们就传入推理力度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what do we do with the response that comes back.": "那么我们如何处理返回的响应呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, I think you know exactly what we do with the response.": "嗯，我想你很清楚我们会如何处理响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We do response .0. content.": "我们获取 response.choices[0].message.content。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then there's just something here to strip out.": "然后这里有一些需要剥离的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If it's responded with any of those three tick marks and then get rid of it and get rid of any other": "如果它的响应中带有那三个反引号，就去掉它，并去掉任何其他",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:three tick marks just to clean up the output and then write that to the file.": "三个反引号，只是为了清理输出，然后将其写入文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that is our port function right there.": "这就是我们的 port 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm defining a string.": "现在我正在定义一个字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I've got some Python code here but I'm not running it.": "我这里有一些 Python 代码，但我现在不运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not showing it as Python code.": "我没有把它当作 Python 代码来展示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm putting it in a text variable.": "我把它放在一个文本变量里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You may wonder why it will become clear.": "你可能会好奇为什么，待会儿就清楚了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what does this function do?": "那么这个函数是做什么的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, it calculates something.": "嗯，它计算一些东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It does this little math formula that I've shown you before that, that it counts and does.": "它执行我之前给你们展示过的那个数学公式，进行计数和计算。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It does like one minus a third plus a fifth, minus a seventh plus a ninth, minus an 11th plus a 13th,": "它计算类似于 1 减去三分之一，加上五分之一，减去七分之一，加上九分之一，减去十一分之一，加上十三分之一，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and so on for odd numbers going, going off and off.": "依此类推，针对奇数不断进行下去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think I've made this number up a bit since the slide I showed you last time.": "我觉得我把这个数字调大了一点，相比我上次给你们看的幻灯片。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think I said 100,000, and I think I was misreading from the slide it's 100 million and I've made": "我记得我说的是 10 万，我想我是看错幻灯片了，其实是 1 亿，而我现在把它改成了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that now 200 million.": "2 亿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a lot of iterations of this, we want to really give Python some work.": "所以这里有很多次迭代，我们真的想给 Python 找点活干。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're doing all of that.": "所以我们正在做这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're taking the answer.": "我们得到答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're multiplying it by four and then printing the result.": "我们把它乘以 4，然后打印结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's the game we're playing.": "这就是我们要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what this string does.": "这就是这个字符串的作用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I run that.": "所以我运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I have that string in there.": "所以我把那个字符串放在那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then if I run this here, this is something which allows you to run a string in Python.": "然后如果我运行这里，这是一个允许你在 Python 中运行字符串的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It interprets that string as Python code.": "它将该字符串解释为 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the Python interpreter will run it.": "然后 Python 解释器会运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is what exac here does exac.": "这就是这里的 exec 所做的，exec。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you do like exac.": "所以如果你执行类似 exec 的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Two plus two, uh, it will it will do that exac.": "2 加 2，呃，它会执行那个 exec。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Two plus two.": "2 加 2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or I suppose we should say print two plus two like so.": "或者我想我们应该说 print(2 + 2)，像这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And run this then you see four.": "运行这个，然后你会看到 4。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what exac does.": "这就是 exec 的作用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, takes a string.": "呃，接收一个字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this, this stuff here makes sure that it handles things like globals and locals properly.": "这里的这些东西确保它能正确处理全局变量和局部变量之类的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's that.": "就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And with with all of that introduction we can run this Python function called py which is a string as": "有了这些介绍，我们可以运行这个名为 py 的 Python 函数，它是一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:text.": "文本字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will interpret this as code and it will carry it out.": "它会将其解释为代码并执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And at the end it will print.": "最后它会打印。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The result of doing this along with the execution time.": "执行此操作的结果以及执行时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And from the title of the string, you might already have a hint about what it's going to come up with.": "从字符串的标题中，你可能已经暗示了它会得出什么结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yes, it turns out that taking one minus the third plus fifth, blah blah blah blah times four is a": "是的，事实证明，用 1 减去三分之一加上五分之一，等等等等，再乘以 4，是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:way to approximate pi.": "一种计算圆周率 (pi) 近似值的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a really slow formula for pi.": "这是一个计算圆周率非常慢的公式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It takes a long time to converge, and you can see that after 200 Million iterations, where 3.14159265": "它需要很长时间才能收敛，你可以看到在 2 亿次迭代后，结果是 3.14159265",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and that digit should be three.": "而那个数字应该是 3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's gone wrong there, but still it got it done.": "所以那里出错了，但它还是完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It took 19 seconds to do it.": "它花了 19 秒才完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that that is where the bar is set for us to optimize.": "这就是我们优化的基准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we're going to start with with the top model.": "所以我们将从顶级模型开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to start with the best with GPT five, the one that was on the top of the artificial analysis": "我们将从最好的 GPT-5 开始，那个在人工分析",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:leaderboard for this kind of thing.": "排行榜上名列前茅的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so what we're doing is we're calling our function port.": "所以我们正在做的是调用我们的 port 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once you've got to a point when you have a clear business objective and sometimes agentic AI or gen": "当你达到一个拥有明确业务目标的阶段时，有时代理式 AI 或生成式",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:AI might not be the right solution.": "AI 可能并不是正确的解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the case of someone wanting their sales numbers today on their phone, maybe a Google doc that opens": "比如有人想在手机上查看今天的销售数据，打开一个显示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:up that shows you your sales numbers might be easier than having something that you talk to or whatever.": "销售数字的 Google 文档可能比通过对话或其他方式获取更简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So always come back to that.": "所以，始终要回归到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I have another pet peeve as well.": "另外，我还有一个特别反感的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also covered on guide 12.": "这在指南 12 中也有提及。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is relevant to picking the right alum.": "这与选择合适的大模型（LLM）有关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not I'm not going off on some tangent.": "我并不是在扯远。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:As an AI engineer.": "作为一名 AI 工程师。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You wear two different hats.": "你身兼两职。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You have two jobs in one, you are a data scientist and you're also a software engineer.": "你同时承担两份工作：你既是数据科学家，也是软件工程师。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You're right at that intersection, and I tend to find that 80% of the questions that I get about projects": "你正处于这个交汇点，我发现我在 Udemy 或行业中收到的关于项目的提问中，有 80%",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:through Udemy or in industry relate to engineering concerns.": "都与工程层面的问题有关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:People ask me, what architecture should I use?": "人们会问我，我该使用什么架构？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How am I going to do my integrations?": "我该如何进行集成？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's my what are my data pipes going to be?": "我的数据管道该如何构建？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Which frameworks should I use?": "我该使用哪些框架？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Should I use lang chain?": "我该用 LangChain 吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Should I use light lamp?": "我该用 LiteLLM 吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Which vector database should I be using an open source one like Croma, or should I be using pinecone": "我该使用哪种向量数据库？是像 Chroma 这样的开源数据库，还是 Pinecone",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or V8?": "或者是 Weaviate？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These are all the questions people ask, and I feel like people ask those questions a lot because it's": "这些都是人们会问的问题，我觉得人们经常问这些是因为这",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in their comfort zone.": "处于他们的舒适区。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These are engineering concerns that a lot of people come from an AI, from a from a software engineering": "这些是工程层面的顾虑，很多人拥有 AI 或软件工程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:background.": "背景。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the kind of question they're used to asking.": "这是他们习惯于提出的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But by in my opinion, it's not the most important question, and it's not the question that will make": "但在我看来，这并不是最重要的，也不是决定",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or break your project.": "项目成败的关键问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what will set your solution apart?": "那么，是什么让你的解决方案脱颖而出？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What really matters?": "真正重要的是什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In my opinion, 80% of the questions that I ask are related to the science part of the story.": "在我看来，我所提出的问题中有 80% 与科学部分有关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What business problem are you solving as we just covered?": "正如我们刚才提到的，你正在解决什么业务问题？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And how will you measure that?": "你将如何衡量",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've solved that business problem.": "你已经解决了那个业务问题？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How will you measure success and what data do you have and what are the gaps?": "你将如何衡量成功？你拥有什么数据？还存在哪些差距？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What data do you need?": "你需要什么数据？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because remember data that that is what will help you differentiate yourself.": "因为请记住，数据才是能让你脱颖而出的关键。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is how your LM can outperform others.": "这就是你的大模型能够超越其他模型的秘诀。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the hard questions.": "所以，这些才是难题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those are the ones that you should ask first and foremost and spend the most time on because the": "这些是你首先应该问的问题，并且应该花最多的时间在上面，因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:different architectures, the different frameworks, you pick which vector database.": "不同的架构、不同的框架、选择哪种向量数据库，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's important.": "这些固然重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a decision you have to make, but it's not the most important.": "这是你必须做出的决定，但它们并不是最重要的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's secondary to the science.": "它们次于科学部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this leads to the five steps that you should take to select and then train and apply an LM to a": "这引出了选择、训练并将大模型应用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:commercial problem.": "商业问题的五个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We pass in the OpenAI client library, the OpenAI model, which is GPT five, and the string py.": "我们传入 OpenAI 客户端库、OpenAI 模型（即 GPT-5）以及字符串 py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me kick that off while I'm talking.": "趁我说话的时候，让我启动它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so what that is doing, if we just remind ourselves going back to port, it's calling this, it": "呃，它正在做的是，如果我们回想一下 port 函数，它正在调用这个，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will have reasoning effort as high.": "将推理力度（reasoning effort）设为高。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's then going to to be um, calling messages for messages for takes the system prompt and that we": "然后它会，嗯，调用 messages for，messages for 接收系统提示词，也就是我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:define up here and user prompt for which is this.": "在这里定义的，以及用户提示词，就是这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that drops the Python code in there and it asks it to port.": "它把 Python 代码放进去，并要求它进行移植。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Rewrite this Python code as efficient C++ code.": "将这段 Python 代码重写为高效的 C++ 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, the exercise.": "当然，这个练习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The purpose of this is not not to particularly, uh, poor code.": "这样做的目的并不是为了，呃，专门移植代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's more to show you that we can take a business task, a business task that we can measure.": "更多的是为了向你展示，我们可以承担一项业务任务，一项我们可以衡量的业务任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can select a model like GPT five that should be good at that task, and then we can carry out the": "我们可以选择像 GPT-5 这样应该擅长该任务的模型，然后执行该",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:task and put it to the test.": "任务并对其进行测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, because we've got it on high reasoning mode, it's going to take its time over it, uh, as it": "现在，因为我们开启了高推理模式，它会花一些时间来处理，呃，正如它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:should.": "应该的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I will see you on the other side when it has completed its thinking and has ported our code.": "当它完成思考并移植完我们的代码后，我们再见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, GPT five finished.": "好了，GPT-5 完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It took just under two minutes and it rewrote our Python code as C++.": "它花了不到两分钟的时间，将我们的 Python 代码重写成了 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's take a look at the results.": "让我们来看看结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's here in Main.cpp and it's quite a file.": "就在这个 Main.cpp 文件里，代码量还挺大的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first time you see this, you might think that seems like a lot of code for that short Python code.": "第一次看到这个时，你可能会觉得对于那么短的 Python 代码来说，这代码量似乎有点多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the answer is it's done something a bit clever here.": "答案是它在这里做了一些聪明的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's done something known as unrolling a loop where it manually does several steps of the loop all in": "它做了一件被称为“循环展开”的事情，即在一次迭代中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:one iteration.": "手动执行循环的多个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not clear that that's necessarily a good idea, because compilers are meant to be good at that": "目前还不清楚这是否一定是个好主意，因为编译器本来就应该擅长处理",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:anyway, but we'll see how it how it fares.": "这种事情，但我们会看看它的表现如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, it doesn't always do it this way.": "顺便说一下，它并不总是这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is I've I've run this experiment a few times.": "这个实验我已经运行过几次了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a pretty interesting version of it, but you might have different results.": "这是一个非常有趣的版本，但你可能会得到不同的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is the one that's done this time.": "但这就是这次生成的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's that's what we'll go with.": "所以我们就用这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and you can see it does appear to be doing the right kind of thing.": "呃，你可以看到它似乎确实在做正确的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it looks like good code, everything, as far as I could tell from, from my slightly rusty C++ knowledge": "所以它看起来是很好的代码，据我那略显生疏的 C++ 知识所能判断的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:looks decent to me.": "一切在我看来都很不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time for us to actually compile this and execute it.": "所以现在是时候让我们实际编译并执行它了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're now going to compile this code natively for my machine.": "我们现在要针对我的机器原生编译这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then execute it as machine code on my machine.": "然后在我的机器上以机器码的形式执行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can do this too.": "你也可以这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you don't need to.": "但你没必要这么做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The point is about porting code, not about running high performance C++.": "重点在于移植代码，而不是运行高性能的 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's fun, but you don't need to.": "这很有趣，但你不需要这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in a second, we'll also do this on a website so that you really you could you could do it without": "稍后，我们还会在一个网站上进行此操作，这样你真的可以不用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to cover these five steps in week six in detail.": "我们将在第六周详细介绍这五个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When we go through a real capstone project, a real case of applying an LM to solve a difficult business": "当我们完成一个真实的毕业设计项目，即一个应用语言模型来解决困难业务",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:problem.": "问题的真实案例时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But just to tell you, the five steps now, so that I've planted that seed for later, you first of": "但现在先告诉你们这五个步骤，以便为以后埋下伏笔。首先，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:all need to understand your business requirements, the business problem you're solving, and how you": "你需要详细了解你的业务需求、你正在解决的业务问题，以及你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will measure success in detail.": "将如何衡量成功的细节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You then need to prepare by selecting candidate models using the leaderboards, perhaps looking at the": "然后，你需要通过使用排行榜选择候选模型来进行准备，也许可以查看",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:basic facts about the models to understand which is going to be the right one for the task at hand.": "模型的基本事实，以了解哪一个最适合当前的任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then you select the model you're going to choose by building prototypes, testing your business metric": "然后，你通过构建原型、针对原型测试你的业务指标来选择你将要选用的模型，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:against the prototypes you customize it by, by building things like Rag that we do next week, fine": "你通过构建像我们下周要做的 RAG、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tuning that we do in the following two weeks, and perhaps a genetic AI in the last week.": "接下来两周要做的微调，以及最后一周可能涉及的智能体 AI 来对其进行定制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then you productionize you roll out and deploy to production.": "然后你将其产品化，进行推广并部署到生产环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these are the five steps that you go through.": "所以这就是你要经历的五个步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, what we've spent this week focusing on is prepare, which is looking at the leaderboards,": "当然，我们本周重点关注的是“准备”阶段，即查看排行榜，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:identifying the right selection, the candidate models.": "确定正确的选择，即候选模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see hopefully now how that fits after understanding your business requirements and before": "希望你现在能看到，在了解业务需求之后、在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:actually building your prototypes.": "实际构建原型之前，这该如何衔接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But hold that thought.": "但先保留这个想法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to come back to it in two weeks time and we're going to play it through.": "我们将在两周后回到这个话题，并将其完整演练一遍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For now, we're getting on to our technical challenge, building a product that converts Python code": "现在，我们要开始我们的技术挑战：构建一个将 Python 代码转换为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to fast C++ code to boost performance.": "快速 C++ 代码以提升性能的产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Assuming that we don't know how to write C++, we know how to write Python, we want to translate it.": "假设我们不知道如何编写 C++，但知道如何编写 Python，我们想要进行转换。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see how this can be extended to be any kind of porting code platform.": "你可以看到这如何扩展为任何类型的代码迁移平台。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And obviously, we all know this is a great use case for like an agentic solution that's able to take": "显然，我们都知道这是一个很好的用例，比如使用一个能够处理",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a whole code base and port it from one technology to another.": "整个代码库并将其从一种技术迁移到另一种技术的智能体解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're not going to be working on an in an authentic way.": "我们不会以一种完全真实复杂的方式来处理它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to be assuming we've just got one script in Python, and we want to convert it to a script": "我们将假设我们只有一个 Python 脚本，并且想要将其转换为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in C++.": "C++ 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you could be thinking if you've already taken some agentic courses like my one, or maybe you already": "但你可能会想，如果你已经参加过一些像我这样的智能体课程，或者你可能已经",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:know about it, you could extend this to be a full agentic platform yourself, and if not, then after": "了解它，你可以自己将其扩展为一个完整的智能体平台；如果没有，那么在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:week eight when we build out a little agentic process, you could come back and apply it there and that": "第八周我们构建一个小型的智能体流程后，你可以回来将其应用到这里，那",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:would be really cool.": "将会非常酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But for now, we're just focusing on the LM selection and on coming up with like, how are we going": "但目前，我们只专注于语言模型的选择，以及构思我们将如何...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to test the business objective and how are we going to validate it for different models.": "测试业务目标，以及我们如何针对不同模型对其进行验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, the business problem that we're trying to solve here is all about performance.": "当然，我们在这里试图解决的业务问题完全是关于性能的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We've got this need for business purposes.": "出于业务目的，我们有这种需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This code that we're writing needs to run faster, and that gives us a simple way to measure success.": "我们正在编写的这段代码需要运行得更快，这为我们提供了一个衡量成功的简单方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can make sure that the answer is accurate and that it comes quickly.": "我们可以确保答案是准确的，并且能够快速得出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's the challenge.": "所以这就是挑战所在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's get to solving it.": "让我们开始解决它吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the specific test that we'll use to see if we have solved it or not is we've got a little bit of": "而我们将用来查看是否已解决该问题的具体测试是，我们这里有一点点",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Python code here.": "Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's that's our tests that we'll use to validate.": "这就是我们将用于验证的测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is something which does a number of calculations.": "它会进行大量的计算。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It takes it's a mathematical formula and a loop maths like this and loops Python is famously bad at": "它采用的是一个数学公式和一个循环，像这样的数学计算和循环是 Python 众所周知的弱项，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because it's all interpreted and it's something which is iterating over a loop.": "因为它完全是解释执行的，而且是在循环中进行迭代。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can if you look through the code, you can see that it's basically doing one minus a third plus": "如果你查看代码，你会发现它基本上是在做 1 减去三分之一加上",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a fifth, minus a seventh plus a ninth, and it's going on and it's doing all of that 100,000 times.": "五分之一，减去七分之一加上九分之一，以此类推，并且总共执行 100,000 次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And at the end of it, it's taking the results and multiplying it by four and printing it along with": "在最后，它会获取结果并乘以 4，然后将其连同",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:how long it took.": "所花费的时间一起打印出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that that is our test.": "所以，这就是我们的测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what we will do and we will see how we perform.": "这就是我们要做的，我们将看看表现如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see how the other models fare.": "让我们看看其他模型的表现如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to run Claude sonnet 4.5, grok four from Mr. Musk.": "所以我们要运行 Claude Sonnet 4.5，以及来自马斯克先生的 Grok 4。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini 2.5 Pro.": "Gemini 2.5 Pro。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's kick all three off.": "让我们把这三个都启动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They are going to first use this model to port the code.": "它们将首先使用这个模型来移植代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then they're going to, uh, call uh, the the, uh, compile and run code.": "然后它们会，呃，调用，呃，编译并运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's see, we've already got an answer from anthropic and we can see how is it compared.": "现在让我们看看，我们已经得到了 Anthropic 的答案，我们可以看看它的对比情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's it's, uh, it's it's clearly, uh, in the same league, uh, but not as fast.": "它，它，呃，显然处于同一水平，呃，但没那么快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's have a look.": "让我们来看一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It looks like this is reasonably ordinary style code, so it hasn't done that loop unrolling that that": "看起来这是相当普通风格的代码，所以它没有做我们之前看到的那种",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we'd seen before.": "循环展开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and so if we go back to the lab, we'll see that, that as a result, it does.": "呃，所以如果我们回到实验室，我们会看到，结果就是，它的表现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, but not quite as well as, uh, as GPT five that was able to just slightly edge out anthropic.": "不错，但不如 GPT-5，后者能够稍微领先 Anthropic 一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's perfectly credible porting of the code running nice and fast, a decent result.": "但这是非常可靠的代码移植，运行得又好又快，是一个不错的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think we can be happy with that.": "我想我们可以对此感到满意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now Grock and Gemini are going to take quite a bit longer.": "现在 Grok 和 Gemini 需要更长的时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They do a lot more thinking about it, so I'm going to break and see you in a second when they are finished": "它们会进行更多的思考，所以我先休息一下，等它们完成后再见",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so we can get the final scores.": "这样我们就能得到最终的分数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so some time has passed and actually I've run this a few times now, which of course I've done": "好了，时间过去了一会儿，实际上我已经运行了好几次，我这样做当然是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the interests of your learning rather than because I enjoy it.": "为了让大家更好地学习，而不是因为我喜欢这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and uh, yeah, this, this this run right now is probably the most consistent sort of performance": "呃，而且，是的，现在的这次运行可能是我从这些模型中获得的最一致的表现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I've been getting from the models, but it has varied, so you may get different results.": "但情况会有所变化，所以你可能会得到不同的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We will start by revealing anthropic's that sorry, we've already seen Anthropic's.": "我们先来揭晓 Anthropic 的，抱歉，我们已经看过 Anthropic 的了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just looked at, uh, anthropic did better than GPT five by a bit because of the way that it did": "我们刚才看了，呃，Anthropic 比 GPT-5 表现得好一点，因为它采用了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:some unrolling.": "一些循环展开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's look at Grock.": "现在让我们来看看 Grok。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Mr. Musk's one that really went to town.": "马斯克先生的那个模型，表现得非常出色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It fought thought for five minutes, 5.5 minutes on this and this.": "它在这个问题上思考了 5 分钟，5.5 分钟。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the result a spectacular result, a spectacular result from Grock.": "这就是结果，来自 Grok 的惊人结果，非常惊人的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Look at this.": "看看这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is amazing.": "太神奇了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is?": "它是？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Another huge amount.": "又是大幅度的提升。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Faster.": "更快了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, we can, uh, let's first look at the code itself.": "呃，我们可以，呃，让我们先看看代码本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I've got the grox runs here and you can see that that how it's compiled the code that's faster is": "我这里有 Grok 的运行记录，你可以看到它编译出的代码之所以更快，是因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that it is made use of threading libraries.": "它使用了线程库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there's some pretty hefty code here as it brings in threading libraries.": "所以这里有一些相当繁重的代码，因为它引入了线程库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it makes sure that it kicks off something that is using operating system level threads and running": "它确保启动了使用操作系统级线程的东西，并以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:things in a multi-threaded way.": "多线程的方式运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, of course, I know what you're thinking.": "现在，我当然知道你在想什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The Python code, the original Python code wasn't written to be multithreaded and could have been,": "Python 代码，原始的 Python 代码并没有写成多线程的，虽然本可以这样写，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but that's okay.": "但没关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's part of the challenge for the model.": "这也是对模型挑战的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ever touching your box.": "甚至不需要碰你的电脑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But should you wish to, we have of course taken, if you remember earlier, we took this command from": "但如果你想这么做，我们当然已经，如果你还记得早些时候，我们从这里获取了这个命令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT five.": "GPT-5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, I iterated over this.": "事实上，我对此进行了迭代。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is like an efficient way to compile and run C++.": "但这就像是一种编译和运行 C++ 的高效方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so what we're going to do now is we will I've written this function compile and run.": "所以我们现在要做的是，我写了这个名为 compile_and_run 的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It compiles main.cpp into an executable main, which for you might be mesnex if you're on a PC or main": "它将 main.cpp 编译成一个名为 main 的可执行文件，如果你用的是 PC，它可能是 main.exe，或者就是 main",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:if you're on a mac or Linux.": "如果你用的是 Mac 或 Linux。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then I'm going to run it three times and print the results.": "然后我将运行它三次并打印结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You don't need that.": "你不需要那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There we go.": "好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we have it.": "结果出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we're going to do this.": "现在我们要开始执行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Drumroll please.": "请击鼓鸣冤（来点鼓点）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remember 19 seconds is how long it took in Python land up there.": "记住，刚才在 Python 环境下花了 19 秒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's run this and poof here we go.": "让我们运行它，砰，开始了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There.": "瞧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is the result.": "结果出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see it is somewhat faster in native machine code.": "你可以看到，在原生机器码中它确实快了一些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and let's just figure out how much faster that is.": "呃，让我们算一下到底快了多少。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that is uh, and I realize this is only one test here, so it's not hugely scientific.": "所以，呃，我意识到这只是一个测试，所以并不是非常科学。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you'll forgive me for just doing this a little bit.": "但请原谅我做得稍微有点……",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hand-wavy.": "随意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll pick this one here.": "我们选这一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first is that the.": "第一个是……",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's the, uh.": "那是，呃……",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll pick the middle one.": "我们选中间那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm not cherry picking.": "这样我就不是在“择优挑选”了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll pick the middle of the road.": "我们选个中等水平的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:89 two 2089 200, I'm so sorry.": "89 2 2089 200，非常抱歉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think this one is the middle of the road.": "我觉得这个是中等水平。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This one here is one we will pick and we will see.": "我们就选这一个，看看结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Put a decimal point in there.": "在那里加个小数点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we will see that.": "我们可以看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ha ha.": "哈哈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Fantastic.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, GPT five has been an amazing 230 times faster.": "呃，GPT-5 竟然快了惊人的 230 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:230 times faster is impressive stuff.": "快了 230 倍，真是令人印象深刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I will say that that it wasn't always this much faster.": "现在我要说的是，它并不总是快这么多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Many of the times it's about 45 times faster.": "很多时候大约是快 45 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The code it generates, which is more of the sort of standard, uh, almost sort of translation directly": "它生成的代码更多是那种标准的，呃，几乎是直接翻译",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from Python to C++ without doing that unrolling stuff.": "从 Python 到 C++，没有做那些循环展开之类的优化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But with that unrolling stuff that it did this time it has been 230 times faster.": "但加上它这次做的循环展开，它快了 230 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Congratulations GPT five.": "恭喜 GPT-5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:No wonder you are top of the Artificial Analysis leaderboard.": "难怪你在 Artificial Analysis 排行榜上名列前茅。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And should you not wish to do this on your computer like that, we can also do it on the website.": "如果你不想像这样在自己的电脑上操作，我们也可以在网站上进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's just quickly grab this C++ code, copy it into the clipboard.": "让我们快速抓取这段 C++ 代码，复制到剪贴板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Go back to the lab, launch this website here and select all of this.": "回到实验室，打开这个网站，然后全选这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:On the left hand side.": "在左侧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You paste in the C++ here, and you just press the run button to run this and see what it does.": "你把 C++ 代码粘贴到这里，然后只需按下运行按钮来运行它，看看效果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there we have it.": "结果出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It runs.": "它运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's obviously slower when you're running it on a, on a like a remote processor, but it's still significantly": "在远程处理器上运行时显然会慢一些，但仍然显著",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:faster than the 19 seconds that it took in Python land.": "快于在 Python 环境下花费的 19 秒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's like more than 20 times the speed.": "速度快了 20 多倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is impressive stuff.": "真是令人印象深刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't just need to port the code to a different programming language.": "它不仅仅需要将代码移植到另一种编程语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We told it to do everything that it could to get the same outcome faster.": "我们告诉它要尽其所能，以更快的速度获得相同的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So making taking advantage of threads is absolutely allowed.": "所以利用线程是绝对允许的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's within the rules.": "这在规则范围之内。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I made up the rules so I can say so.": "规则是我定的，所以我可以这么说。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'd say good job, grok.": "所以我想说，干得好，Grok。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well done.": "做得好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's a very impressive performance.": "这是一个非常令人印象深刻的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Speed up.": "提速。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's go back to the lab to see then if Gemini can keep up with grok, or does it fall behind even": "但让我们回到实验室，看看 Gemini 是否能跟上 Grok，或者它是否甚至落后于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT five?": "GPT-5？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or does it in fact not even get the answer right?": "或者它实际上甚至连答案都没算对？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll find out in a second.": "我们马上就会揭晓。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so revealing.": "如此富有启发性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini 2.5 Pro absolutely killed it.": "Gemini 2.5 Pro 表现得非常出色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It crushed it.": "它完胜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Look at these times.": "看看这些时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It did better materially better than grok which did better than GPT five, which did better than Claude.": "它的表现明显优于 Grok，而 Grok 优于 GPT-5，GPT-5 又优于 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Gemini is in first place with terrific results.": "所以 Gemini 以极佳的结果位居第一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're super fast, and I can assure you that I ran it multiple times.": "它们超级快，我可以向你保证我运行了多次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And Gemini almost always, except for one time in my test runs out of 5 or 6.": "在我的 5 或 6 次测试运行中，除了有一次之外，Gemini 几乎总是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini got these results really great.": "Gemini 得到的这些结果真的很棒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You should run this too and see if you get the same.": "你也应该运行一下，看看是否得到相同的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What are you looking for?": "你在寻找什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, if we look at the code that Gemini wrote, you can see it's quite complex.": "好吧，如果我们看看 Gemini 编写的代码，你会发现它相当复杂。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's quite a lot to it.": "里面有很多内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what's happening here is really multiple things.": "这里发生的实际上是多方面的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First of all, it is also definitely doing the threading code.": "首先，它肯定也编写了线程代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm no expert, but it appears to be doing something even more sophisticated.": "我不是专家，但它似乎在做一些更复杂的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think both of them, both Grock and Gemini, were careful to look for the number of threads to maximize": "我认为它们两个，Grok 和 Gemini，都仔细寻找了线程数，以最大化",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:parallel abilities.": "并行能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, you can see that it's done that here, and it does a whole lot of threading stuff, and then it": "呃，你可以看到它在这里做到了这一点，它做了大量的线程处理，然后它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ends up calling calculate chunk in this multithreaded way concurrently.": "最终以这种多线程的方式并发调用 calculate chunk。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the key thing here is that it has also identified some improvements to the algorithm by simplifying": "这里的关键在于，它还通过简化",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the algebra, doing the same calculation in a more efficient way, reducing in leading to reduced floating": "代数运算，以更有效的方式进行相同的计算，从而减少了浮点",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:point calculations, fewer calculations, faster performance.": "点运算，更少的计算量，更快的性能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's definitely sticking to the rules.": "这绝对符合规则。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's doing the same calc, so it gets the same answer.": "它在进行相同的计算，所以得到了相同的答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's just doing it with fewer math operations.": "它只是用了更少的数学运算。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So so great.": "所以太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Good for it.": "为它点赞。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that means that really Gemini has done three things.": "这意味着 Gemini 实际上做了三件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's translated the code from Python to C++, which is great.": "它将代码从 Python 翻译成了 C++，这很棒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's also improved the formula.": "它还改进了公式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's found a way to simplify the formula to do better a better job of calculating the same answer.": "它找到了一种简化公式的方法，从而能更好地计算出相同的答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then thirdly, it's also done this design improvement to the structure of the code to allow it to": "第三，它还对代码结构进行了设计改进，使其能够",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:be multithreaded and run multiple calculations in parallel.": "实现多线程并并行运行多个计算。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, especially given given the how we're running it on online.": "呃，尤其是考虑到我们在线上运行它的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very exciting indeed.": "所以确实非常令人兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Great to see this performance speed up, uh, with GPT five porting our code from Python to C++.": "很高兴看到这种性能提升，呃，GPT-5 将我们的代码从 Python 移植到了 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those three different changes have all added up together to give us this superb performance of this,": "所以这三种不同的改变共同作用，为我们带来了如此卓越的性能，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this tiny time on the middle time that I'll be picking is, uh, 0.013 seconds compared to 19 seconds": "我选取的中间时间非常短，呃，是 0.013 秒，而 Python 环境下是 19 秒",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in Python land.": "。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And actually I just look back and see that grok hard coded the number of threads where Gemini calculated": "实际上我刚才回顾了一下，发现 Grok 硬编码了线程数，而 Gemini 是计算出来的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that might be another reason why Gemini did did better.": "所以这可能是 Gemini 表现更好的另一个原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very exciting stuff.": "所以这是非常令人兴奋的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:At least I think it's very exciting.": "至少我觉得非常令人兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I've done the quick calculation here just to see what kind of speed ups we're getting, and hard": "我在这里做了一个快速计算，看看我们获得了什么样的加速，并硬编码了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:coding in my numbers so that you can see what I got.": "我的数据，以便让你们看到我得到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we run this, we will see that from this analysis.": "如果我们运行这个，我们会从这个分析中看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fourth place was Claude Sonnet 4.5 with an 148 times speed up, which is still very impressive.": "第四名是 Claude Sonnet 4.5，加速了 148 倍，这仍然非常令人印象深刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you may have noticed that Claude wasn't actually because I was.": "你可能已经注意到，Claude 实际上并没有，因为我当时",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I was going through the OpenAI's API.": "是通过 OpenAI 的 API 进行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It wasn't actually using a significant thinking mode.": "它实际上并没有使用显著的思考模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so, you know, maybe that was handicapping it.": "所以，你知道，这可能限制了它的发挥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And GPT five in third place with a also a stonking 233 times speed up, which anyone would be pleased": "第三名是 GPT-5，同样实现了惊人的 233 倍加速，任何人都会对此感到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with.": "满意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But then grock for Wow with a 1060 times speed up.": "然后是 Grok，哇，加速了 1060 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's just crazy.": "这简直太疯狂了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it didn't always achieve that.": "它并不总是能达到这个效果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In my tests it was hit and miss, but I thought I'd capture captured this one.": "在我的测试中，它时好时坏，但我还是想把这次结果记录下来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That did, and that's great.": "它做到了，这太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then in first place, in first place, winning the crown.": "然后是第一名，第一名，摘得桂冠。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini 2.5 Pro A surprise.": "Gemini 2.5 Pro，一个惊喜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A controversial first place wasn't top of the artificial analysis leaderboard, but it's top of our": "一个有争议的第一名，它在人工分析排行榜上并不是第一，但在我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:experiment speeding up our Python code by 1440 times.": "实验中名列前茅，将我们的 Python 代码加速了 1440 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is superb.": "这太卓越了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm very happy about this.": "我对此非常高兴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One of the great things about it is that this experiment feels so tangible because we get a real business": "这件事最棒的一点在于，这个实验感觉非常真实，因为我们得到了一个真正的业务",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:outcome.": "成果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We had a business objective to speed up some code and wow, have we achieved it.": "我们的业务目标是加速一些代码，哇，我们做到了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we should go to the website that I showed you before to see if this C++ code from Gemini": "当然，我们应该去我之前给你们展示过的那个网站，看看 Gemini 生成的这段 C++ 代码",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:does well there.": "在那里的表现如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, of course, it's not going to be running in a multi-threaded way when it's out on the cloud,": "当然，当它在云端运行时，不会以多线程方式运行，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but still we should we should get to see something.": "但我们仍然应该能看到一些东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's see.": "让我们来看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here it is.": "就在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remember this website?": "还记得这个网站吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I've copied Gemini's code to my clipboard.": "我已经把 Gemini 的代码复制到了剪贴板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can press paste.": "我可以点击粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here it is with all this fancy stuff with a number of threads and this hardware concurrency stuff.": "就在这里，带着这些花哨的东西，比如线程数和硬件并发之类的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Goodness knows what this all does.": "天知道这些都是干什么的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's try running it on the cloud and see what we get.": "让我们尝试在云端运行它，看看结果如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, you know, it's it's it's fast.": "呃，你知道，它非常快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But as I thought, it's, uh, I don't think that's significantly faster than we'd seen from the from": "但正如我所想，呃，我不认为它比我们从",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT five version.": "GPT-5 版本中看到的要快很多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so it's still it's still around 20 times, uh, faster.": "呃，所以它仍然快了大约 20 倍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And welcome to week four, day four.": "欢迎来到第四周，第四天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is gonna be fun.": "这将会很有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is about open source models.": "这一节是关于开源模型的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, taking the challenge we had last time and bringing it to open source.": "现在，我们将上次遇到的挑战应用到开源模型中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Last time we made sure that in addition to coding with frontier models and choosing the right LLM based": "上次我们确保了除了使用前沿模型进行编码，并根据指标选择合适的 LLM 之外，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on metrics, you were able to build Frontier Solutions using a model that we selected because it was": "您还能够使用我们选定的模型构建前沿解决方案，因为它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:good at generating code.": "擅长生成代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So today it's going to be about assessing open source models, comparing them with a benchmark, building": "所以今天的内容是评估开源模型，将它们与基准进行比较，构建",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a solution so that open source models can generate code.": "一个让开源模型能够生成代码的解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a reminder this was the challenge we set our business person when we asked what is the problem": "提醒一下，这是当我们询问业务人员“你想要解决什么问题”时，我们给他们设定的挑战。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you're trying to solve?": "“你想要解决什么问题？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They said, the problem is we've got some Python code.": "他们说，问题是我们有一些 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to translate it.": "我们想要翻译它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to build port it to fast C++, go make that happen and we use some frontier models.": "我们想要将其移植到快速的 C++，去实现它，并且我们使用了一些前沿模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Claude Sonnet 45 was able to achieve about 184 x speed up.": "Claude Sonnet 4.5 能够实现约 184 倍的加速。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT five got that to 2.33 times, then grok for more than a thousand times faster with some multithreading": "GPT-5 达到了 2.33 倍，然后 Grok 通过一些多线程代码实现了超过一千倍的加速，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code, with a hard coded number of threads, and a few other things.": "其中包含硬编码的线程数以及其他一些东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For the win, it rewrote the algebra.": "为了取胜，它重写了代数部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It restructured the code into threads and checked how many threads it could use for my system, and": "它将代码重构为线程，并检查了我的系统可以使用多少个线程，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then built very fast C++ code, which compiled natively to give us that 1440 times.": "然后构建了非常快速的 C++ 代码，通过原生编译为我们带来了 1440 倍的提升。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Phenomenal.": "惊人的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And how does open source compare?": "那么开源模型的表现如何呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, let's go find out.": "让我们去一探究竟。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But first we should go and look at some leaderboards to get some candidate open source models.": "但首先，我们应该查看一些排行榜，以获取一些候选的开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That would make sense for us to start with.": "这对我们开始工作很有意义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first place to go is the Big Code Models leaderboard, which is a hugging face space that's very": "首先要去的地方是 Big Code Models 排行榜，这是一个非常著名的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:well known.": "Hugging Face 空间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it shows you how various models have ranked in terms of their Python, Java, JavaScript, and indeed": "它向你展示了各种模型在 Python、Java、JavaScript 以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:their C++ skills.": "它们的 C++ 技能方面的排名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we might as well sort by C++ ability if we can.": "如果可以的话，我们不妨按 C++ 能力进行排序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's do that.": "让我们就这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we discover that according to this table, which I think is a few months out of date, I think they": "我们发现，根据这张表格（我认为它已经过时几个月了，我觉得他们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:don't update this very often, but still it gives us some good pointers.": "更新得并不频繁，但它仍然为我们提供了一些很好的参考）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When 2.5 Coder Instruct comes through as a top model, it's a bigger version than we'll be able to run,": "当 Qwen 2.5 Coder Instruct 作为顶级模型出现时，它的版本比我们能运行的要大，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but it comes up there and then also the deep seq.": "但它出现在那里，然后还有 DeepSeek。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a hybrid with other models, but I think we can see here the deep seat coder.": "这是与其他模型的混合体，但我认为我们可以在这里看到 DeepSeek Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then if we look further down, we'll see various various models that are based on deep seq fi uh": "然后如果我们往下看，我们会看到各种基于 DeepSeek、Phi",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and and Quen from Alibaba Cloud.": "以及来自阿里云的 Qwen 的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the other place we can look is on my favorite one artificial analysis AI.": "所以另一个我们可以查看的地方是我最喜欢的 Artificial Analysis AI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, but, uh, I think that's actually a little bit slower, isn't it, than the previous version.": "嗯，但是，呃，我觉得这实际上比之前的版本慢了一点，不是吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, it's possible that all of this stuff ends up running, adding overhead when it's running on the": "呃，有可能所有这些东西在云端运行时，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cloud, which is fine, because the instructions that we gave Gemini was to optimize for my platform.": "最终会增加开销，但这没关系，因为我们给 Gemini 的指令是针对我的平台进行优化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We even put the system details in there.": "我们甚至把系统详情也放进去了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's let's go back and remind myself, uh, exactly what GPT came up with.": "让我们回过头来提醒一下自己，呃，GPT 到底想出了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This was GPT unrolled stuff.": "这是 GPT 展开后的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Copy that.": "复制那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's put that back in the website.": "让我们把它放回网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we were at 0.9 nine seconds here, put back in GPT five and run that and remind ourselves what we": "所以我们这里是 0.99 秒，把 GPT-5 的代码放回去运行一下，提醒一下我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:get.": "得到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yep.": "是的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There you go.": "就在这儿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:GPT five I remembered, right?": "GPT-5，我记得没错吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is slightly faster.": "它确实稍微快一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Interestingly, when it's deployed on a different box on the internet, but that still works in Gemini's": "有趣的是，当它部署在互联网上的不同机器上时，但这仍然对 Gemini 有利，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:favor because it shows that Gemini took took the challenge, understood the assignments, and got it": "因为这表明 Gemini 接受了挑战，理解了任务，并且针对我的机器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:perfect for my box.": "做到了完美。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Congrats again Gemini.": "再次祝贺 Gemini。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, as I say, I'm a bit worried that this has been very self-indulgent, that I've thoroughly enjoyed": "好了，正如我所说，我有点担心这太自我陶醉了，我玩得很开心，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:myself, but I hope that you enjoyed some of it as well.": "但我希望你们也喜欢其中的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is fun to put these kind of complex challenges to models, especially when there's such very concrete": "向模型提出这类复杂的挑战很有趣，尤其是当有如此具体的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:output from it.": "输出结果时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So tomorrow we now move to open source models.": "所以明天我们将转向开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a whole ton of them to look at.": "我们有很多模型要看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The idea is to use this as a way of assessing open source models for coding ability, and then evaluate": "我们的想法是以此作为评估开源模型编程能力的一种方式，然后评估",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:open source models alongside paid models for their ability to achieve a business objective, and also": "开源模型与付费模型在实现业务目标方面的能力，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:just building a solution that uses open source models to generate code.": "构建一个使用开源模型生成代码的解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what I've got in store for you tomorrow.": "这就是我明天为你们准备的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll see you then.": "到时候见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so the main task you will remember the system prompt about converting Python code.": "好，主任务你应该还记得，就是关于转换 Python 代码的系统提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You remember the function user prompt for that generates a user prompt with a system information, the": "你还记得那个生成用户提示词的函数，它包含系统信息、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:compile command and the Python code to port.": "编译命令以及要迁移的 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is all old news for you.": "所以这些对你来说都是老生常谈了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as messages for old news write output you know well and port you know well as well.": "所以对于这些已知信息，输出你很熟悉，迁移你也同样很熟悉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is again our code to calculate pi by doing 200 million times of this sequence.": "这又是我们那个通过执行 2 亿次该序列来计算圆周率的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now the run Python code, which actually we don't need to run.": "现在是运行 Python 代码的部分，实际上我们不需要运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We already know the time that the Python code takes the compile and run.": "我们已经知道 Python 代码编译和运行所需的时间了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That will run it three times.": "那会运行三次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But here's the new little piece I have for you.": "但这里有一点我为你准备的新内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's give ourselves a little Gradio interface.": "让我们给自己做一个简单的 Gradio 界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is using the blocks approach that you'll remember is the one where you want to design your interface.": "这里使用的是 Blocks 方法，你应该记得，这是用于自定义设计界面的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is going to have two rows to it.": "这个界面将包含两行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first row will have a Python and a C++ text box, the Python code to enter and the C++ code that": "第一行将有一个 Python 文本框和一个 C++ 文本框，分别用于输入 Python 代码和显示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will be an output.": "输出的 C++ 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Put and then this, this.": "放置好，然后是这个，这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After that we have a dropdown to select a model.": "之后，我们有一个用于选择模型的下拉菜单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a convert button to convert the code.": "还有一个用于转换代码的“转换”按钮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is where you say to Gradio, hey look, I want you to build a front end so that if the user": "在这里你告诉 Gradio：嘿，我想让你构建一个前端，这样如果用户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:clicks the convert button, I want you to call back my server.": "点击转换按钮，我希望你回调我的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want you to call the function that's called port.": "我希望你调用名为 port 的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The inputs should be the model that's selected and the Python code.": "输入应该是所选的模型和 Python 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And with whatever that function returns, I want you to shove that in the C++ text box.": "无论该函数返回什么，我都希望你把它填入 C++ 文本框中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this line here is how we tell Gradio to hook up our UI to our callback function port.": "所以这一行就是我们告诉 Gradio 如何将 UI 连接到我们的回调函数 port 的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's all it takes.": "就这么简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will then launch our new user interface for porting code.": "然后这将启动我们用于迁移代码的新用户界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so here we go.": "好了，我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Bang up comes the user interface.": "砰的一声，用户界面出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Haha okay, so it's just as I said, two rows.": "哈哈，好，就像我说的，两行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The top row has Python code and C++ code.": "顶行有 Python 代码和 C++ 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Lovely.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I can select a model and it allows me to choose any of the models in that models list.": "这样我就可以选择一个模型，它允许我从模型列表中选择任何一个模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you change the models list, you should see your models here and we won't pick the frontier ones.": "所以如果你更改了模型列表，你应该能在这里看到你的模型，我们不会选那些最前沿的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We've used them already.": "我们已经用过它们了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to start with Gwen 2.5 coda and I can come over here and press Convert Code.": "我们将从 Qwen 2.5 Coder 开始，我可以点击这里的“转换代码”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when I press that button, it calls the callback port.": "当我按下那个按钮时，它会调用回调函数 port。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It passes in the model and the Python code, and with whatever that callback method returns, it shoves": "它传入模型和 Python 代码，无论该回调方法返回什么，它都会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that in this cell here.": "填入这里的单元格中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's where we have it right now.": "这就是我们现在的进度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also written it to a file.": "它还将其写入了一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I can do now is go back for a moment to cursor, and I can just do the compile and run to.": "所以我现在可以回到 Cursor 编辑器一会儿，直接进行编译和运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now compile that code.": "现在编译那段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It wrote it to Main.cpp.": "它被写入了 Main.cpp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That will be the same code.": "那将是同样的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you'll remember that when you're on artificial analysis-i, you can select which models you're looking": "你会记得，当你在 Artificial Analysis 网站上时，你可以选择你正在查看的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:at.": "模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you tend to look at the big ones.": "你通常会关注那些大型模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you can come in here to the model selected and you can see I've gone through and I've searched and": "但你可以进入这里的模型选择界面，你可以看到我已经搜索并",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:selected a few candidate models.": "挑选了几个候选模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We might want to look at a bit more and we can compare their coding skills.": "我们可能想多看几个，并比较它们的编程能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I've taken some open source models that we'll be able to run.": "所以我选了一些我们可以运行的开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One of them is GPT OSS 20 B, and that is by far and away the highest performing one on the code bench.": "其中一个是 GPT OSS 20B，它是目前为止在 Code Bench 上表现最好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Coding skills.": "编程能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Compared to Deep Sea Coder, which comes in significantly lower and five for mini and 2.5 coder and": "相比之下，DeepSeek Coder 的得分明显较低，还有 Phi-4 Mini 和 Qwen 2.5 Coder，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then Gemma three at the bottom.": "排在最后的 Gemma 3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so here you see again a similar uh, similar arrangement.": "所以在这里你再次看到了类似的……类似的排列。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But no, now it's different.": "但不，现在情况不同了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sorry GPT Oasis comes first and then 2.5 coder comes next.": "抱歉，GPT OSS 排在第一，然后是 Qwen 2.5 Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That was in third place uh and then deep sea coder and then five four and then Gemma at the end.": "那个排在第三位……然后是 DeepSeek Coder，接着是 Phi-4，最后是 Gemma。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we were going to pick three, it would probably be GPT OSS, Quen 2.5 coder and deep seq coder.": "所以如果要选三个，大概会是 GPT OSS、Qwen 2.5 Coder 和 DeepSeek Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They seem like good candidate models.": "它们看起来是不错的候选模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's how you do it.": "这就是操作方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You start with the leaderboards with an appropriate metric to pick your candidates, and then you go": "你先从排行榜开始，使用合适的指标来挑选候选模型，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and try them out, which is what we'll get to next.": "去尝试它们，这就是我们接下来要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Actually, no it's not.": "事实上，并不是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's one more thing to do.": "还有一件事要做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First, I just occurred to me, I was thinking, we're going to be running these open source models": "首先，我突然想到，我刚才在想，我们要运行这些开源模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:using a llama, which limits me to two models that I can run locally.": "使用 Ollama，这限制了我只能在本地运行两个模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But that's not entirely true.": "但这并不完全正确。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There are other ways we can run models.": "我们还有其他运行模型的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We could use open router, and we could also use grok with a Q and not not Mr. Musks.": "我们可以使用 OpenRouter，也可以使用带 Q 的 Groq，而不是马斯克先生的那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think that's what we'll do.": "我想这就是我们要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll try grok with a Q, because we can use that to access the bigger OSS.": "我们会尝试带 Q 的 Groq，因为我们可以用它来访问更大的开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:120 and you can see that that scores even higher, actually only slightly higher on the scientific coding,": "120B，你可以看到它的得分甚至更高，实际上在科学编程方面只高出一点点，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but significantly higher on the live code bench.": "但在 LiveCodeBench 上明显更高。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we will uh, we will give that one a try to via grok.": "所以我们会……我们会通过 Groq 尝试一下那个模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll use both techniques for open source models okay.": "所以我们会对开源模型同时使用这两种技术，好吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:With that.": "就这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's go do it okay.": "现在让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we are back in cursor.": "我们回到了 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going into week four into day four already.": "我们已经进入了第四周的第四天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just as a reminder we're going to be executing native C++ today.": "提醒一下，我们今天将执行原生 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you don't need to don't bother if that's going to, to uh be something that will be a hardcore.": "但如果这对你来说太硬核了，也不必担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will take you some, some learning.": "这需要你进行一些学习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Instead.": "相反。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can either just watch me do it and see the code being ported, or use the website that I showed": "你可以只看我操作并观察代码被迁移的过程，或者使用我昨天展示的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you yesterday.": "那个网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other note is that we're going to be using some free models installed via Lama.": "另一个注意事项是，我们将使用一些通过 Ollama 安装的免费模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can now compile that code and run it.": "现在我们可以编译并运行这段代码了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it doesn't run.": "但它运行不了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:2.5 Pro was not so code was not able to do this.": "2.5 Pro 不行，所以代码没能做到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is a small model.": "它是一个小模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It was not able to successfully convert from C++ from Python to C++.": "它没能成功地将 Python 转换为 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think that it hadn't imported the right thing and so that didn't work.": "我觉得它没有导入正确的东西，所以没成功。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that is a fail.": "所以这次失败了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The our first fail of all of these that we got from, uh, from from Gwen.": "这是我们从，呃，从 Qwen 那里得到的第一个失败。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Quinn.": "Qwen。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so that was Quinn coder.": "好的，那是 Qwen Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That did not succeed.": "它没有成功。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're now going to try another tiny model.": "我们现在要尝试另一个微型模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to try Deep Sea Coder v2.": "我们要尝试 DeepSeek Coder v2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Not so tiny.": "也不算太小。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a 16 billion parameter model.": "这是一个 160 亿参数的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll see if it can port Python code to C++.": "我们来看看它能否将 Python 代码移植到 C++。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, it's done something.": "嗯，它生成了一些东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we go.": "开始了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Looks like it has the same problem, but we will see.": "看起来它有同样的问题，但我们再看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so, uh, it looks different though.": "好的，不过看起来不太一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back over here.": "让我们回到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Compile and run.": "编译并运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Oh, no.": "噢，不。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:No, it didn't have the problem that ran successfully.": "不，它没有那个问题，运行成功了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well done, deep sea coder.": "干得好，DeepSeek Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, that ran and we've got a perfectly respectable number.": "呃，运行了，我们得到了一个非常体面的数值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, we will.": "呃，我们会。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will keep note of this.": "我会把这个记下来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or maybe we should write it down here.": "或者我们应该把它写在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll make this into a markdown cell and we will say, uh, this is Quinn.": "所以我们把它变成一个 markdown 单元格，然后说，呃，这是 Qwen。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Coder was a fail deep seek coder two.": "Coder 失败了，DeepSeek Coder 2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This was Quinn 2.5.": "这是 Qwen 2.5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Coder deep C coder v2.": "Coder，DeepSeek Coder v2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's pick the middle time.": "让我们选中间那个时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There it is": "就在这",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:0.1144050084.": "0.1144050084。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Congratulations to Deepsea Coder.": "恭喜 DeepSeek Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go try the next one.": "让我们试试下一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The next one is GPT oss 20 B 20 billion parameter model again running locally on my computer right here.": "下一个是 GPT OSS 20B，一个 200 亿参数的模型，同样是在我这里的电脑上本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right I'm going to press the convert code button.": "好了，我要按下转换代码按钮了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I know from bitter experience that we are in for a wait.": "现在根据痛苦的经验，我知道我们要等上一阵子了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now uh, this is going to take my machine some time and I can see that my GPU is going flat out as this": "现在，这会花掉我机器一些时间，我可以看到我的 GPU 正在全力运转，因为这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:monstrous model is, uh, slaving away at this problem.": "庞大的模型正在，呃，辛苦地处理这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so we will give it some time.": "呃，所以我们要给它一点时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to let it think for a while.": "我打算让它思考一会儿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when I come back, we will see whether or not GPT oss 20 B is up for it.": "等我回来，我们看看 GPT OSS 20B 是否能胜任。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when I say, is it up for it?": "当我说，它是否能胜任时？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean, of course, is it up for giving us an answer?": "我的意思是，当然，它是否能给我们一个答案？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the answer is yes.": "答案是肯定的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is up for giving us an answer.": "它确实给了我们一个答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It took about five minutes to get here, though, while I was hammering away.": "虽然在我忙活的时候，花了大约五分钟才到这一步。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, but we have an answer.": "呃，但我们得到了一个答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Is it the right answer?": "它是正确的答案吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not doing any multithreaded stuff that I can see, so it's not going to be super fast.": "就我所见，它没有进行任何多线程处理，所以不会特别快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's see what it does.": "但让我们看看它的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, it works, and it is indeed faster than the ones that came before.": "嗯，它成功了，而且确实比之前的都要快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is, I think, our fastest so far.": "我觉得这是我们目前为止最快的一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's come in here and we're going to say that this is open.": "让我们到这里来，我们要说这是 Open。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:OS the 20 billion parameter version of it.": "OSS，它的 200 亿参数版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is our medium sized one?": "我们的中间值是多少？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This was A4805804.": "这是 A4805804。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the middle one right here.": "所以这就是中间的那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Paste that in there.": "把它粘贴到那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There we have the performance from OpenAI's GPT OS.": "这就是来自 OpenAI 的 GPT OS 的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very impressive indeed.": "确实非常令人印象深刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Next up we're going to use Kwan three quarter 30 billion which is a large Kwan model.": "接下来我们要使用的是 Qwen 30B，这是一个大型 Qwen 模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to use it through open router.": "我们将通过 OpenRouter 来使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and the reason I picked this one, if we go to open routers website, they have a section where": "呃，我选择这个模型的原因是，如果我们去 OpenRouter 的网站，他们有一个板块，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you can look at the different categories, the leaderboards by how much they are used.": "你可以查看不同的类别，以及按使用量排序的排行榜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's a different a different twist on leaderboards.": "这种排行榜的角度挺特别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll pick the programming category to see which models are used the most for programming related": "我们选择编程类别，看看哪些模型在编程相关的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:challenges.": "挑战中最常用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this varies.": "这个排名是会变化的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This bounces around a lot.": "波动很大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It just bounces around while we were looking at it right there.": "就在我们刚才看的时候，它还在变动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But Kwan three right now is varies between second place and fourth place.": "但 Qwen 目前在第二名到第四名之间波动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, but here it is.": "呃，就是这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's being used quite heavily.": "它的使用量非常大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, uh, it comes after Grock and Claude there.": "呃，它排在 Grok 和 Claude 之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the model we're picking for our next experiment.": "所以这就是我们下一个实验要选的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and this is it in, in, in open router, the details of it, they show the different providers that": "这就是它在 OpenRouter 里的详情，显示了你可以使用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you can use.": "不同提供商。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we are going to use that one.": "所以我们要用那一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh here we go.": "呃，开始了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Kwan three Koda.": "Qwen Coder。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And going to press the convert code button.": "然后点击“转换代码”按钮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remember it was Quinn's cousin that failed with a mistake.": "记得吗，之前是 Qwen 的“表亲”出错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Stake here we have its code and there it looks.": "这里有它的代码，看起来是这样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and try and run this code and see what we get.": "现在让我们去运行这段代码，看看结果如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So back we come over here, we compile and run code.": "回到这里，我们编译并运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it turns out that the, uh, the, the cousin, the faster, bigger cousin is able to succeed with": "结果发现，呃，这个“表亲”，这个更快、更大的“表亲”能够成功完成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the challenge.": "挑战。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's not our fastest.": "但它不是我们这里最快的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's put it down.": "但我们还是把它记录下来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is now question 30 B and it is we'll take the middle time here that switches this one right": "所以现在是 Qwen 30B，我们取中间的时间，就是这一个，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so there we have it.": "好了，就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is when it is uh slower than open AI than OSS 20 B but it's faster than deep C code V2 running": "它的速度比 OpenAI 和 OSS 20B 慢，但比在我机器上本地运行的 DeepSeek Coder V2",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:locally on my machine.": "要快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well done Gwen.": "干得好，Qwen。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, last and hopefully not least, we are going to pick GPT oss 120 be the bigger cousin of the 20": "好了，最后但同样重要的，我们要选 GPT-OSS 120B，它是 20B",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:B1 and this is running on grok with a Q uh, which is, of course, the very fast inference platform": "的“大表哥”，它运行在 Groq（带 Q 的那个）上，当然，那是一个非常快的推理平台。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and 120 but we know that OSS this is on high thinking, so it's going to take its time over this.": "120B，但我们知道 OSS 处于高思考模式，所以这需要一点时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the fact that it's running on grok with a Q gives me some hope that maybe by the time I finish this": "但它运行在 Groq 上让我抱有一丝希望，也许等我说完这句",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:sentence, it will finish, but maybe not.": "话，它就运行完了，但也可能没那么快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will, uh, be gone and be back in a second when GPT OS 120 be completes.": "我先离开一下，等 GPT-OSS 120B 完成后马上回来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it finished a couple of seconds later.": "几秒钟后它就完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it was pretty quick.": "所以速度还是挺快的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here is the results.": "这是结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Looks good to me.": "看起来不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It hasn't done the super clever stuff with threads, but it looks looks good.": "它没有在线程上做那些超级聪明的处理，但看起来挺好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Some try to give some hints to the compiler to make it run faster.": "有些尝试给编译器提供一些提示，让它运行得更快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll see how it fares.": "我们来看看它的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Back.": "回来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Also, we're going to use some open source models, as I said, through grok.": "此外，正如我所说，我们将通过 grok 使用一些开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But also I just decided to add in open router as well.": "但我也决定加入 OpenRouter。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We will add one model from open router.": "我们将从 OpenRouter 中添加一个模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is all completely optional.": "这完全是可选的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These are open source models, but you still have to pay for these bigger ones because open router has": "这些是开源模型，但你仍然需要为这些较大的模型付费，因为 OpenRouter 需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to run them on the cloud.": "在云端运行它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you don't need to just skip them if you don't want to run them.": "但如果你不想运行它们，直接跳过即可。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is the intro.": "以上就是简介。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll run some imports.": "我们将运行一些导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to load in some environment keys.": "我将加载一些环境变量密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:As always, it doesn't matter if you don't want to use any of these and simply delete that from this": "一如既往，如果你不想使用其中任何一个，只需从这段",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code.": "代码中删除即可，这没关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then as usual, we will connect to the client libraries in the normal way.": "然后像往常一样，我们将以正常方式连接到客户端库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this next line is where I set up the models we will use.": "接下来的这一行是我设置我们将使用的模型的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to keep the the frontier closed source models in here.": "我们将在这里保留最前沿的闭源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This list although I'm not going to actually use them.": "尽管我实际上并不打算使用这个列表中的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But here are the the frontier models.": "但这些就是最前沿的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll use them tomorrow again.": "我们明天会再次使用它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to use the open source model Quen 2.5 coder deep seq coder v2 and GPT oss 20,": "然后我们将使用开源模型 Qwen 2.5 Coder、DeepSeek Coder V2 和 GPT-OSS-20，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and we're going to use all three of them through Olama running locally on our computers.": "我们将通过在电脑本地运行的 Ollama 来使用这三个模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If your machines can can take it, then that's what we'll run.": "如果你的机器能够承受，那我们就运行这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we're going to run.": "然后我们将运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to run at least Quen three coda 30 DB over open router, and I'm going to use OpenAI's massive": "我将至少通过 OpenRouter 运行 Qwen 2.5 Coder 32B，并使用 OpenAI 庞大的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:120 DB variant over grok with a Q.": "120B 变体，通过带 Q 的 Groq 运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and you can see in this bottom, I've just got a dictionary here in this bottom line.": "呃，你可以看到在最下面这一行，我这里有一个字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And uh, basically what I'm saying is for each of these models that I've listed out here, I'm saying": "基本上，我的意思是对于我在这里列出的每一个模型，我都在说明",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which one of these client libraries will it use?": "它将使用哪一个客户端库？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just a little quick mapping from model name to client library model name to client library model": "所以这只是一个从模型名称到客户端库、模型名称到客户端库、模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:named client library.": "名称到客户端库的快速映射。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that we can look that up in our code in a second.": "这样我们稍后就可以在代码中查找它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you should just feel free to change these two lists to be whatever you would like.": "所以你可以随意将这两个列表更改为你喜欢的任何内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Keep it to the size and shape and cost of model that you're comfortable with.": "保持在你能接受的模型大小、形式和成本范围内。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, use the llama ones the first few for free, as long as your machine is big enough.": "当然，只要你的机器性能足够，前几个可以使用 Ollama 免费运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If your machine is on the smaller size, then then go with like llama 3.2, llama 3.21 b, or just go": "如果你的机器配置较低，那么可以选择像 Llama 3.2、Llama 3.2 1B 这样的模型，或者直接",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and there's a code llama as well you could look at.": "去看看，还有一个 Code Llama 你也可以参考。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Just go on to Alarm.com and take a look and pick the models that you want.": "只需访问 ollama.com，查看并选择你想要的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I should mention, once you've done that, once you've been to Alarm.com and gone to models, you": "我还应该提到，一旦你完成了这些，访问过 ollama.com 并查看了模型，你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:would then want to bring up a cursor terminal in the usual way, and then you can see what I've done": "接着会想以通常的方式打开 Cursor 终端，然后你就能看到我做了什么",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My last two commands were pull Queen 2.5, Koda and Olama, pull deep, set Koda v2.": "我最后两个命令是 ollama pull qwen2.5-coder 和 ollama pull deepseek-coder-v2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We go to the code, we will run our compile and run again and see what happens.": "我们回到代码，重新编译并运行，看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And oh no, it's it's, uh, quite a bit slower.": "噢，不，它……呃，慢了不少。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, there's a shock.": "呃，真让人吃惊。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's an unexpected outcome.": "这是一个意想不到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, okay.": "呃，好吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So so again, C++ people will probably know what's going on here and why exactly that means that it": "所以，懂 C++ 的人可能知道这里发生了什么，以及为什么这具体意味着它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:didn't do so well.": "表现得不太好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, but, uh, open AI.": "呃，但是，呃，OpenAI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:OS 120 be it got.": "o1 120B 的结果是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's pick the middle one to be consistent.": "为了保持一致，我们选中间那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Which would be this one here, right?": "应该是这一个，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Oh no, no it wouldn't.": "噢，不，不对。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What am I saying?": "我在说什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It would be this one here.": "应该是这一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sorry.": "抱歉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, there we go.": "呃，好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that is the result.": "这就是结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is the worst of the bubble, not the very worst, because quantum 2.5 didn't didn't, uh, get the": "它是这组里最差的，虽然不是绝对最差，因为 Qwen 2.5 根本没能完成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:assignment at all, but it's not good.": "任务，但它确实表现不佳。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's just try running it again just to make sure it's not that like my computer was.": "我们再试着运行一次，以确保不是因为我的电脑当时",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Was busy at that time or something.": "正在忙别的什么之类的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now look at that.": "现在看看这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very consistent.": "非常一致。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Wow.": "哇。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There we have it.": "结果出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So strangely, OS 120 was beaten significantly healthily by 20.": "所以奇怪的是，o1 120B 被 20B 甩开了很大一段距离。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you know, of course we're not being super scientific because we should really run the porting like": "当然，你知道，我们这并不是非常科学，因为我们真的应该运行代码迁移",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ten times and be taking the average of actually reporting the code.": "十次，并取实际代码报告的平均值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But for what it's worth, we're doing it with a with one experiment and then multiple runs.": "但不管怎么说，我们做了一次实验，然后进行了多次运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is this is where it's ended up that GPT OSS 120 was beaten by its smaller cousin, 20 GB.": "结果就是 GPT o1 120B 被它的小表弟 20B 击败了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so to wrap up, here are the results of our rather unscientific experiment.": "总结一下，这是我们这个相当不科学的实验的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You could run this multiple times to see if it holds out.": "你可以多次运行这个实验，看看结果是否成立。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Worst ninth place across our frontier and open source models was when 2.5 code that failed the assignment.": "在我们的前沿模型和开源模型中，排名第九（最差）的是 Qwen 2.5 的代码，它没能完成任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Next up, surprisingly shockingly, was GPT OSS 120, which did a really bad job.": "接下来，令人震惊的是 GPT o1 120B，它的表现非常糟糕。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, it was worse than I realized when I was talking about it.": "事实上，它比我刚才谈论它时意识到的还要糟糕。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I was I was sort of thinking that this was like 0.14, uh, a bit slower than everything else.": "我当时还以为这大概是 0.14，呃，比其他模型慢一点点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But no, it was a lot slower.": "但不，它慢得多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It was 1.4 seconds.": "它是 1.4 秒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I had to run it a few more times just to check that I hadn't made a mistake.": "我不得不又运行了几次，以确认我没有弄错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can't actually see what was wrong with it.": "我其实看不出它出了什么问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:C++ code, and I'm hoping maybe one of you C++ people will come back and tell me.": "这是 C++ 代码，我希望你们中懂 C++ 的人能回来告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm guessing maybe one of the pragmas was a really bad idea.": "我猜可能是其中一个 pragma 指令是个非常糟糕的主意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I realize now that that unrolled one was it was telling the compiler that it's not allowed to do that,": "我现在意识到，那个 unroll 指令是在告诉编译器不允许那样做，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and I have no idea why it did that.": "我完全不知道它为什么要那样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It must have thought it was a great idea, and it turned out it was a lousy idea.": "它一定觉得那是个好主意，结果证明那是个烂主意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So GPT oss 120 be disgraced itself.": "所以 GPT o1 120B 丢脸了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Deep Sea Coder v2 and Quinn three coder 30 be Basically tied at 168 times.": "DeepSeek Coder v2 和 Qwen 2.5 Coder 32B 基本上以 168 倍并列。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They both got very similar coin.": "它们的代码非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Three quarter had the slight edge, but that might just be a you know, it's probably the same code": "Qwen Coder 略占优势，但这可能只是……你知道，代码可能是一样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or very similar.": "或者非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Just happened to be when I when I ran it.": "只是我运行它的时候恰好是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there you have two successful open source models.": "所以这里有两个成功的开源模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Next up comes the frontier model Claude Sonet 4.5 with its 104 times speed up, followed by GPT five,": "接下来是前沿模型 Claude Sonet 4.5，它的速度提升了 104 倍，紧随其后的是 GPT-5，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:top of the artificial analysis leaderboard.": "位居人工分析排行榜首位。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For us, it got a 233 speed up.": "对我们来说，它获得了 233 倍的加速。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the shocker, the surprise, the amazing GPT oss 120 just 20 B not 120 B a 238 times speed": "然后是令人震惊的、惊喜的、了不起的 GPT oss 120——只有 20B 而不是 120B——速度提升了 238 倍，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:up, beating out GPT five and Claude Sonet 4.5.": "击败了 GPT-5 和 Claude Sonet 4.5。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, again, it may just have been lucky.": "呃，再次强调，这可能只是运气好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It might have been the same code as those other frontier models just happened to run faster when I ran": "它可能和那些其他前沿模型的代码一样，只是在我运行它时恰好跑得更快，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it, but whatever.": "但不管怎样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is what it is.": "事实就是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It won that.": "它赢了那一局。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what's cool about it is that, of course, that porting was running on my computer.": "酷的地方在于，当然，那个移植过程是在我的电脑上运行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That was an a old farmer based model.": "那是一个基于 old farmer 的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A model running on my computer competed with the frontier and it seems slightly beat some of the frontier.": "一个在我电脑上运行的模型与前沿模型竞争，而且似乎略微击败了一些前沿模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, but it didn't come first because both grok four and Gemini 2.5 Pro did better by putting in native": "呃，但它没有拿到第一，因为 grok 4 和 Gemini 2.5 Pro 表现更好，它们加入了原生的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like multithreading code with Gemini 2.5 Pro still the champion.": "比如多线程代码，Gemini 2.5 Pro 仍然是冠军。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, I do hope you're not fed up of this code generation stuff, because we've got one more, one more": "现在，我真的希望你还没有厌倦这些代码生成的东西，因为我们还有一个，还有一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:hard test to go.": "艰巨的测试要做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A really challenging one to put to all of these models to see who triumphs.": "一个真正具有挑战性的测试，将交给所有这些模型，看看谁能胜出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll do that tomorrow.": "我们明天再做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Along with generally talking about comparing performance of open source and frontier models and ranking": "还会大致讨论开源模型和前沿模型的性能比较，并将它们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:them together, discussing evals, evaluations, such a critical topic that really puts a bow on this": "放在一起排名，讨论评估（evals），这是一个非常关键的话题，它真正为本周关于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:week about picking the right model for the commercial task.": "为商业任务选择合适模型的主题画上了圆满的句号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll talk about how you build solutions to generate code and different kinds of related tasks,": "我们还将讨论如何构建生成代码的解决方案以及各种相关的任务，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like really fun things like writing automatically, writing comments for your code, and automatically": "比如非常有趣的事情，像自动编写、为代码编写注释，以及自动",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:writing test cases for your code.": "为代码编写测试用例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All of that to come tomorrow.": "所有这些都将在明天呈现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:See you then.": "到时见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you would have to pull whichever ones you want.": "你需要拉取任何你想要的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it did take a minute to download these.": "下载这些确实花了一点时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see they're reasonably large.": "你可以看到它们相当大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Quan 2.5 Koda is a 7 billion parameter model, so it's big and deep.": "Qwen 2.5 Coder 是一个 70 亿参数的模型，所以它既庞大又深奥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sea Koda v2 is a 16 billion parameter model, so it's really big.": "DeepSeek Coder v2 是一个 160 亿参数的模型，所以它真的很大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But they both fit comfortably on my machine and they'll work fine.": "但它们都能轻松适配我的机器，运行良好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You may need to have 60GB of Ram, not eight gigabytes, but you should give it a try and see.": "你可能需要 60GB 的内存，而不是 8GB，但你应该尝试一下看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if in doubt, stick with the smaller llama 3.2 or other small ones.": "但如果有疑虑，就坚持使用较小的 Llama 3.2 或其他小型模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so when you've done that, you've updated your, your, uh, models and you've mapped them to": "好的，当你完成这些后，你就更新了你的……你的……嗯，模型，并将它们映射到了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the right clients here.": "这里正确的客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then run that cell.": "然后运行那个单元格。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then again we're just going to get the system information here.": "然后我们再次获取这里的系统信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is my machine.": "这是我的机器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Your machine will be different.": "你的机器会有所不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is telling me something I do I just noticed here it does say the number of cores that I've": "但这告诉了我一些事情，我刚刚注意到这里确实显示了我拥有的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:got.": "核心数量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when I realized now, when grok yesterday fixed the number of cores in the code it was making, that's": "所以我现在意识到，昨天 Grok 在生成的代码中固定了核心数量，这",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:fair enough, because it did know I told it the the architecture of the computer.": "倒也合理，因为它确实知道我告诉过它计算机的架构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it was doing that intentionally.": "所以它是故意那样做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that can't have been the way in which Gemini's code was superior.": "所以那不可能是 Gemini 的代码更优胜的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, Gemini went and found out how many cores there were, but it didn't need to because we already": "嗯，Gemini 去查明了有多少个核心，但它其实不需要这样做，因为我们已经",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:had that in the prompt.": "在提示词里提供了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, these these here are the commands that we took from yesterday.": "总之，这些是我们要用到的昨天的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in yesterday's lab we had identified, uh, from, from the advice that from GPT five, what are": "所以在昨天的实验中，我们根据 GPT-5 的建议确定了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the commands to use?": "要使用的命令是什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, you remember when we, uh.": "呃，你还记得当我们……嗯。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hang on, where is it now when we asked GPT five?": "等一下，我们问 GPT-5 的地方在哪儿？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is this is it.": "就是这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We asked GPT five to tell us what commands to use.": "我们让 GPT-5 告诉我们要使用哪些命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first time I did it, actually, GPT five didn't give me the most efficient ones.": "实际上，我第一次尝试时，GPT-5 并没有给我最高效的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I had to prompt it a couple of times, but in the end, I got there.": "我不得不提示了它几次，但最终我还是达到了目的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This was the fastest and so you should do the same.": "这是最快的，所以你也应该这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You should find out the fast commands for your platform, and that is what you should put here.": "你应该找出适用于你平台的快速命令，并把它们放在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then run that cell.": "然后运行那个单元格。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And at that point we are ready to do some testing of models.": "到那时，我们就准备好对模型进行一些测试了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cool.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I wanted to introduce myself.": "我想自我介绍一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My name is Eden.": "我叫 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I come from a back end development background.": "我有后端开发背景。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I was a back end development for many, many years, mostly in cybersecurity companies.": "我做了很多很多年的后端开发，主要是在网络安全公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And before 2023, I had zero machine learning experience.": "在 2023 年之前，我完全没有机器学习经验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, I did jump on the generative AI train when it first came with large language models in 2023.": "然而，当生成式 AI 随着 2023 年的大语言模型首次出现时，我确实赶上了这趟列车。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm a big fan and advocate of link chain.": "我是 LangChain 的忠实粉丝和倡导者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I've been heavily involved with the link chain ecosystem and open source package since its very beginning,": "从一开始，我就深入参与了 LangChain 生态系统和开源包，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and managed to witness the amazing transformation it had making it, in my opinion, the go to framework": "并见证了它发生的惊人转变，在我看来，它已成为首选框架",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:when building LLM applications.": "用于构建大语言模型（LLM）应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm also a public speaker and I speak a lot about developing LLM applications.": "我也是一名公共演讲者，经常谈论关于开发 LLM 应用的话题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm an official link chain ambassador, and I really believe link chain has a huge role of commoditizing": "我是 LangChain 的官方大使，我坚信 LangChain 在推动机器学习普及化方面发挥着巨大作用，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:machine learning to make it accessible to people like me, with no PhD and no machine learning experience.": "使其能够被像我这样没有博士学位、没有机器学习经验的人所掌握。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now, I do consider myself as an AI engineer, and we'll talk about this new title more in this": "现在，我确实认为自己是一名 AI 工程师，我们将在本课程中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:course.": "更多地讨论这个新头衔。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's it for this video.": "这段视频就到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I hope you have a better idea of what you're going into and see you in the next one.": "希望你对即将学习的内容有了更好的了解，我们下个视频见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Before we continue with the course, I think it's important to go through the course's objectives.": "在继续课程之前，我认为有必要先了解一下本课程的目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The number one goal of this course is for you to be proficient in the model context protocol by anthropic.": "本课程的首要目标是让你精通 Anthropic 开发的模型上下文协议 (Model Context Protocol)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the end of this course, you should understand the core MCP principles.": "到本课程结束时，你应该能够理解 MCP 的核心原理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You'll be able to develop your own MCP servers.": "你将能够开发自己的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You'll be able to integrate those MCP servers whether you build them or they are pre-made.": "无论这些 MCP 服务器是你自己构建的还是现成的，你都能够进行集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:With MCP clients, you'll be able to implement MCP clients as well.": "配合 MCP 客户端，你也将能够实现 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will enable you to have very advanced agentic AI workflows.": "这将使你能够拥有非常先进的智能体 AI 工作流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course, like everything in software engineering, we're going to do a bunch of debugging and": "当然，就像软件工程中的所有事情一样，我们将进行大量的调试和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:monitoring and to see how this fits in within the MCP server ecosystem.": "监控，并观察这如何融入 MCP 服务器生态系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's a very important topic which we'll cover later in this course.": "所以这是一个非常重要的课题，我们将在本课程的后续部分进行讨论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't worry if you don't understand anything I'm saying right now, I promise you you'll understand": "如果你现在听不懂我在说什么，请不要担心，我保证到课程结束时你将理解",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:everything by the end of this course.": "这一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a software engineer, we used to write software for the enterprise.": "作为一名软件工程师，我们过去常为企业编写软件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will be covering those production ready topics like testing, logging, monitoring, alerting, security": "我将涵盖那些生产就绪的主题，如测试、日志记录、监控、告警、安全，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and I like to continuously follow up on those topics along the course to discuss some real world scenarios.": "并且我喜欢在整个课程中持续跟进这些主题，以讨论一些现实世界的场景。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think it's also important to discuss who is the target audience I was making this course for.": "我认为讨论我制作这门课程的目标受众是谁也很重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So at the beginning this course was mainly for software engineers and data scientists who want to learn": "所以在开始时，这门课程主要是为想要学习",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:about the model context protocol.": "模型上下文协议的软件工程师和数据科学家准备的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But then I figured out that there are many people in the world that are not really software engineers,": "但后来我发现，世界上有很多人并不是真正的软件工程师，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but are pretty comfortable with code.": "但对代码非常熟悉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they can take the course as well, in my opinion.": "所以在我看来，他们也可以参加这门课程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the important thing to note here is that JNI experience is required.": "这里需要注意的重要一点是，需要具备生成式 AI (GenAI) 的经验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you should be able to talk to an LLM to create a simple agent and to really understand the core concepts": "你应该能够与大语言模型 (LLM) 对话以创建一个简单的智能体，并真正理解",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of generative AI application development like what is Rag and what's an agent, what's react, etc..": "生成式 AI 应用开发的核心概念，例如什么是 RAG、什么是智能体、什么是 ReAct 等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Having said that, this course is very technical and I do assume that you have software experience so": "话虽如此，这门课程的技术性很强，我确实假设你具备软件经验，所以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you know how to write code, to debug code, and overall that you're comfortable around code.": "你知道如何编写代码、调试代码，并且总的来说你对代码感到得心应手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the sector of software engineers or data scientists were the main ones.": "因此，软件工程师或数据科学家群体是主要受众。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, I did have very surprising students who took this course and enjoyed it.": "然而，确实有一些令我惊讶的学生参加了这门课程并乐在其中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I had lawyers who took this course and even doctors who actually enjoyed it.": "有律师参加了这门课程，甚至还有医生也确实很喜欢它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you should know that this was my target audience when making this course.": "所以你应该知道，这是我制作这门课程时的目标受众。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, this course is not for everyone.": "然而，这门课程并不适合所有人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yes, I said that, not for everyone.": "是的，我说了，不适合所有人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there, Eden here.": "大家好，我是 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about MCP model context protocol.": "让我们聊聊 MCP，即模型上下文协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is very hot right now.": "这在目前非常热门。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Everyone on ECS are talking about it.": "ECS 上的每个人都在讨论它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're seeing tons of implementations of MCP servers.": "我们看到了大量的 MCP 服务端实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We see a lot of people are using MCC within their apps like cursor, like cloud.": "我们看到很多人在他们的应用中使用 MCC，比如 Cursor，比如 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the entire goal of what I'm trying to do is to make you become proficient in MCP.": "我此行的全部目标就是让你精通 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you know exactly what's happening under the hood, and you'll be able to use MCP servers and to build": "这样你就能确切地知道底层发生了什么，并且能够使用 MCP 服务端以及构建",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers yourself.": "你自己的 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So before we talk about what MCC, I think it's super important to understand why do we need MCP.": "所以在讨论什么是 MCC 之前，我认为理解我们为什么需要 MCP 至关重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's say we have an AI agent.": "假设我们有一个 AI 智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want that agent to be able to maybe send messages on slack, or maybe read and send emails or": "我们希望那个智能体能够，比如在 Slack 上发送消息，或者读取和发送电子邮件，或者",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:make queries to a DB.": "对数据库进行查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So generally we would need to implement those functionality.": "所以通常我们需要实现这些功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we would need for example, to see how to work with the slack API or the Gmail API.": "例如，我们需要研究如何使用 Slack API 或 Gmail API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we would need to write some custom code that is going to be wrapped around as a tool, which we're": "我们需要编写一些自定义代码，将其封装为一个工具，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to let our agent use.": "让我们的智能体使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, most likely, for example, we would like even to write our own custom implementation to those": "现在，很有可能，例如，我们甚至想为这些工具编写",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tools.": "我们自己的自定义实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, we don't want anybody to delete our emails, so we don't want to give our agent access": "例如，我们不希望任何人删除我们的电子邮件，所以我们不想给我们的智能体访问",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for the delete API in Gmail.": "Gmail 中删除 API 的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the point here that we have some custom implementation that we are going to implement ourselves.": "所以这里的重点是，我们将亲自实现一些自定义功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can do that.": "我们可以做到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example with a framework like link chain, which also, by the way comes in with built in tools": "例如，使用像 LangChain 这样的框架，顺便说一下，它也自带了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for Gmail, which have already implemented the entire Gmail API.": "Gmail 的内置工具，这些工具已经实现了整个 Gmail API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can use that out of the box in case we want something generic.": "如果我们需要一些通用的东西，我们可以开箱即用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, the point here is that we would need to implement it ourselves, right?": "总之，这里的重点是我们得自己去实现它，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now our agent is able to send some emails, maybe to send some messages on slack or even to make": "所以现在我们的智能体能够发送一些电子邮件，可能在 Slack 上发送一些消息，甚至进行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:DB queries.": "数据库查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is working for our agent.": "这对我们的智能体来说是可行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's say our agent is so successful that other people want to use it, maybe in their agents or": "但假设我们的智能体非常成功，以至于其他人也想使用它，可能是在他们的智能体中，或者",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:maybe on already existing ones.": "在已经存在的智能体中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they really want to use the functionality that we wrote, right?": "所以他们真的很想使用我们编写的功能，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's take this example concrete and let's say that the agent is cursor.": "让我们举个具体的例子，假设这个智能体是 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So cursor now can send messages on Slack and Gmail and make DB queries.": "那么 Cursor 现在可以发送 Slack 和 Gmail 消息，并进行数据库查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now what happens if other people for example in windsurf want to use this agent.": "现在，如果其他平台的人，比如 Windsurf 的用户，也想使用这个智能体，会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because we custom rotate tailor made into cursor.": "因为我们是针对 Cursor 专门定制编写的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you want to integrate it into windsurf we would need to go and to work on that integration ourselves": "如果你想把它集成到 Windsurf 中，我们就需要亲自去处理那个集成工作",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and to implement custom code that would do it.": "并编写实现它的自定义代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it really adds up a lot of code that we need to write.": "所以这确实增加了我们需要编写的大量代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want to add it to lovable or to bolt, or to a GitHub copilot or to every AI code assistant,": "如果你想把它添加到 Lovable、Bolt、GitHub Copilot 或任何 AI 代码助手，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we need to do it over and over again to write the integration to that custom agent.": "我们需要一遍又一遍地为那个自定义智能体编写集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And who wants to write a thousand integrations?": "谁想编写一千个集成呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP is going to solve exactly that.": "而 MCP 正是为了解决这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it really comes from a core principle in computer science and in software systems that if you want": "这实际上源于计算机科学和软件系统中的一个核心原则：如果你想",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to solve a problem, you simply need to add another layer of abstraction.": "解决一个问题，你只需要增加一个抽象层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is exactly what MCP is going to do, and this is how it's going to help us to support all those": "这正是 MCP 要做的，也是它将如何帮助我们支持所有这些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:types of agents.": "类型的智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the idea here is that we are going to integrate only once into our MCP server.": "这里的核心思想是我们只需要集成到我们的 MCP 服务器一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because all the other agents support MCP, the model Context protocol, then they will be able to": "因为所有其他智能体都支持 MCP（模型上下文协议），所以它们将能够",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:easily connect to our MCP server, and in fact, we'll only need to implement our agent once with compatibility": "轻松连接到我们的 MCP 服务器，事实上，我们只需要实现一次具有兼容性的智能体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to the MCP server.": "到 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we can migrate to all those other agents which supports the MCP protocol.": "然后我们就可以迁移到所有支持 MCP 协议的其他智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the agent that we wrote that was compatible with cursor is now also compatible with windsurf.": "因此，我们编写的与 Cursor 兼容的智能体，现在也与 Windsurf 兼容了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we as the developers of the agent that is going to be used, we didn't need to add any logic.": "而作为将被使用的智能体的开发者，我们不需要添加任何逻辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everyone who supports the MCP protocol can use our agent and we can integrate it seamlessly.": "每一个支持 MCP 协议的人都可以使用我们的智能体，我们可以实现无缝集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is like sort of like social media.": "这有点像社交媒体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we have a social media application, if we have only a bunch of people using it, then we wouldn't": "如果我们有一个社交媒体应用，如果只有一小部分人在使用它，那么我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:get really the value of it.": "就无法真正体现它的价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if we have millions of people using it, creating user generated content, it's a huge flywheel": "但如果有数百万人使用它，创造用户生成的内容，它就是一个巨大的飞轮",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and provides a lot of value.": "并提供巨大的价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is exactly what's happening with MCP, because so many people are using it right now, and": "这正是 MCP 正在发生的事情，因为现在有这么多人在使用它，而且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:there are tons of MCP servers out there.": "外面有大量的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And really the possibilities are endless.": "可能性真的是无穷无尽的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think now it's time to really talk about what is MCP and how does it look like?": "所以我认为现在是时候真正谈谈什么是 MCP 以及它长什么样了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How does it feel like?": "它的体验如何？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the goal of this video is to give you a quick demo of what capabilities we get once we use MCP model": "这段视频的目标是向你快速演示在使用 MCP（模型上下文协议）后，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:context protocol, and how does it look like in action.": "我们能获得哪些功能，以及它在实际操作中是什么样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to start with cloud, and we're going to give it the capability of getting the current": "我们将从 Claude 开始，赋予它获取当前",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weather.": "天气的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to connect it to an MCP server which has the implementation to do.": "我们将把它连接到一个具有该实现功能的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're then going to use the exact same server.": "然后，我们将使用完全相同的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to give this getting the weather functionality to cursor.": "并将这个获取天气的功能赋予 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm not going to show you any configuration right now I'm just going to show you the end result.": "现在我不会向你展示任何配置，我只是向你展示最终结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Later in the videos I'll show you how to configure it and how to add MCP servers to your MCP clients.": "在后面的视频中，我将向你展示如何配置它，以及如何将 MCP 服务器添加到你的 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case, our clients are going to be cloud and cursor.": "在这个例子中，我们的客户端将是 Claude 和 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it could be any client that supports the MCP protocol.": "但它可以是任何支持 MCP 协议的客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can be windsurf, it can be lovable.": "比如可以是 Windsurf，也可以是 Lovable。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can be any other client which supports it.": "也可以是任何其他支持它的客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First we're here at cloud.": "首先，我们来到 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and show you what it's like to be without a weather MCP.": "让我们来看看在没有天气 MCP 的情况下是什么样子的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I will go to settings and I will go to developer.": "如果我进入设置并转到开发者选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see we don't have any MCP servers configured.": "在这里我们可以看到，我们没有配置任何 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And later in the videos we'll will elaborate on how to do it.": "在后面的视频中，我们将详细阐述如何操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go back now to the cloud chat and let me ask, what's the weather in San Francisco?": "现在让我回到 Claude 聊天界面，问一下：旧金山的天气怎么样？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I accidentally wrote MCP instead of San Francisco.": "我不小心把旧金山写成了 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But don't worry, it will still do the trick.": "但别担心，它仍然有效。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we get back a response from the LM that it doesn't have access to real time weather information,": "我们可以看到，我们收到了来自大语言模型的回复，说它无法访问实时天气信息，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so it's not been able to provide us with an answer.": "所以它无法为我们提供答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now I have configured the weather MCP, and if I go now to Settings to developer, we can see": "现在我已经配置好了天气 MCP，如果我现在进入设置中的开发者选项，我们可以看到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we have here this weather MCP here.": "这里已经有了这个天气 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have the information of how it's running.": "并且我们有关于它如何运行的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again don't worry about it.": "再次强调，不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll cover that in depth later in the videos.": "我们将在后面的视频中深入探讨。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and let's go and try to run this.": "那么现在让我们尝试运行一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I'm going to write what is the weather in San Francisco right now.": "现在我要输入：旧金山现在的天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what is happening.": "让我们看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And first thing we are prompt is weather.": "首先，我们收到了关于天气的提示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do we allow the tool weather to run locally.": "是否允许天气工具在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice this can also be malicious code and it will cover security later.": "请注意，这也有可能是恶意代码，我们稍后会讨论安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just allow it and let's discuss what's happening right now.": "让我先允许它，然后我们讨论一下现在发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have our MCP server of getting the weather.": "我们有了用于获取天气的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have there the logic to get the weather.": "里面包含了获取天气的逻辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the function in the MCP server is called Get forecast.": "现在，MCP 服务器中的函数名为 Get forecast。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this function receives two arguments.": "这个函数接收两个参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It receives latitude and longitude.": "它接收纬度和经度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the LM which is here in cloud sonnet 3.7 deduced what is the latitude and longitude of San Francisco.": "因此，这里的 Claude Sonnet 3.7 模型推断出了旧金山的纬度和经度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it made an MCP call to the get forecast function we have implemented in our MCP.": "然后它向我们在 MCP 中实现的 get forecast 函数发起了一个 MCP 调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Our MCP server ran it, we get back a response and then the LM processes the response and outputs us": "我们的 MCP 服务器运行了它，我们得到了响应，然后大语言模型处理该响应并向我们输出",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the final answer.": "最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see here the final answer.": "所以你可以在这里看到最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to get the weather is not that exciting.": "所以获取天气并不是那么令人兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the cool thing is that we can implement an MCP server to any logic we want.": "但酷的地方在于，我们可以为任何我们想要的逻辑实现一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And effectively we're now giving our agents, our AI agents, the capability to do everything, so we're": "实际上，我们现在赋予了我们的智能体，即我们的 AI 智能体，做任何事情的能力，所以我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:not bounded by any implementation.": "不再受限于任何特定的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All we need to do is to implement the MCP protocol and all the client.": "我们所需要做的就是实现 MCP 协议，而所有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is me introducing a bit of terminology that support MCP is going to be able to run those functionality.": "支持 MCP 的客户端（这里我引入一点术语）将能够运行这些功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I just migrated the functionality of getting the weather from cloud to cursor.": "所以我刚刚将获取天气的功能从 Claude 迁移到了 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I did this behind the scenes and later we're going to see exactly how to configure it.": "我是在幕后完成这些操作的，稍后我们将确切地看到如何配置它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's very, very easy.": "而且这非常、非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a very small spoiler.": "这是一个小小的剧透。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to cursor and let's see this example.": "那么让我们进入 Cursor，看看这个例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If I go to cursor settings and I'll go to the MCP tab we can see all the MCP servers we have connected": "如果我进入 Cursor 设置并转到 MCP 选项卡，我们可以看到我们连接到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to cursor to our cursor agent.": "Cursor，连接到我们 Cursor 智能体的所有 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now I have only one MCP server and this is the weather server.": "现在我只有一个 MCP 服务器，那就是天气服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here we're even listed with the tools that the server has.": "我们甚至可以在这里看到该服务器拥有的工具列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It has a get alerts tool and a get forecast tool.": "它有一个 get alerts 工具和一个 get forecast 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I can understand that it looks pretty magical right now, but it's actually very simple.": "我能理解现在这看起来很神奇，但实际上它非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll see it in the rest of the videos of how it's implemented.": "我们将在接下来的视频中看到它是如何实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see also the command that runs the server.": "我们还可以看到运行该服务器的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice here that this is a node server.": "请注意，这里这是一个 Node 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now go and open cursor chat.": "现在让我们去打开 Cursor 聊天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to select the agent because MCP is only part of the cursor agent.": "我想选择 Agent 模式，因为 MCP 只是 Cursor Agent 的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write here what is the weather in San Francisco right now.": "让我在这里输入：旧金山现在的天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what we get.": "让我们看看会得到什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I won't be prompted to approve this tool because I've already running in YOLO mode.": "在这里，系统不会提示我批准使用此工具，因为我已经运行在 YOLO 模式下了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means in cursor that is going to execute tools regardless.": "在 Cursor 中，这意味着它将直接执行工具，而不受限制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Of course it's not best practices as far as security, but it's very convenient for me.": "当然，就安全性而言，这并非最佳实践，但对我来说非常方便。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I talk about the pros and cons of YOLO mode in my cursor course.": "我在我的 Cursor 课程中讨论了 YOLO 模式的优缺点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, we can see now that we called our MCP server with the Get Forecast tool, and those are the": "无论如何，我们现在可以看到我们使用 Get Forecast 工具调用了我们的 MCP 服务器，这些是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:R commands.": "请求命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the result that we got.": "这是我们得到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then cursor is compiling the answer.": "然后 Cursor 正在汇总答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But notice here it also decided to do something else.": "但请注意，这里它还决定做点别的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It also decided to call the get alerts to see whether we have an alert in San Francisco.": "它还决定调用 get alerts 来查看旧金山是否有天气警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very cool.": "太酷了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here the final answer which is including the weather and if there are weather alerts.": "我们可以看到最终答案，其中包括天气情况以及是否有天气警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It called two tools in one prompt.": "它在一个提示词中调用了两个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hello, everyone.": "大家好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I Eden here.": "我是 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yes.": "是的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is really I here.": "确实是我本人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm really excited to talk to you today about our course discord server, which you can find linked": "今天我非常激动地向大家介绍我们的课程 Discord 服务器，你可以在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the video resources and how it's going to enhance your learning experience.": "视频资源中找到它的链接，以及它将如何提升你的学习体验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to share with you the main reasons we've set up this discord server.": "我想和大家分享我们建立这个 Discord 服务器的主要原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First and foremost, it's going to be your go to place for getting quick answers to any questions you": "首先，也是最重要的，它将成为你快速获得任何问题答案的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:might have.": "首选之地。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Whether you're running into configuration issues, having technical problems, or just need clarification": "无论你是遇到配置问题、技术难题，还是只需要对课程中的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:about something in the course.": "某些内容进行澄清。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The discord server is there for you to get rapid support.": "Discord 服务器就在那里，为你提供快速支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The second big reason for having this server is to create a space where we can all engage in meaningful": "建立这个服务器的第二个重要原因是创建一个空间，让我们都能参与到关于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:discussions about MCP generative AI agents.": "MCP 生成式 AI 智能体的有意义讨论中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Rag prompt engineering, and all the fascinating topics we're covering in this course.": "RAG、提示词工程，以及我们在本课程中涵盖的所有引人入胜的话题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a place where ideas can flow freely and where we can learn from each other.": "这是一个思想可以自由流动、我们可以互相学习的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me tell you about when you can expect to find me on the server.": "让我告诉大家什么时候可以在服务器上找到我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:During weekends, I'll be fully available and checking the server consistently throughout the day during": "在周末，我会全天候在线，并持续查看服务器；而在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weekdays because of my day job.": "工作日，因为我有全职工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll be checking in twice daily, once in the morning, and once in the evening after work hours.": "我每天会查看两次，一次在早上，一次在下班后的晚上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I really want to emphasize something important.": "现在我非常想强调一些重要的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Please, please don't hesitate to ask questions.": "请，请务必不要犹豫提问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I cannot stress this enough.": "我怎么强调都不为过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There are no stupid questions.": "没有愚蠢的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Every single question contributes to everyone's learning.": "每一个问题都有助于大家的学习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I know from experience that when one person asks a question, there are usually many others who": "根据我的经验，当一个人提出问题时，通常还有许多其他人",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:had the same question but were hesitant to ask.": "有同样的问题，但犹豫着不敢问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Whether it's about configuration issues, error messages, or just understanding concepts better, I'm": "无论是关于配置问题、错误信息，还是仅仅为了更好地理解概念，我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:here to help.": "都会在这里提供帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Quick support from me or your fellow students can save you hours of frustrating debugging.": "来自我或同学们的快速支持可以为你节省数小时令人沮丧的调试时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can reach me through the discord server, which is the preferred method for course related questions,": "你可以通过 Discord 服务器联系我，这是处理课程相关问题的首选方式，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but I'm also available on LinkedIn and through Udemy DM.": "但你也可以通过 LinkedIn 和 Udemy 私信找到我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm always open to your feedback and suggestions, whether it's ideas for new topics we should cover": "我始终欢迎大家的反馈和建议，无论是关于我们应该涵盖的新话题的想法，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or ways we could improve the existing content.": "还是改进现有内容的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm here to support your learning journey every step of the way, and I'm really looking forward to": "我在这里支持你学习旅程的每一步，我非常期待",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:connecting with all of you through the discord server.": "通过 Discord 服务器与大家建立联系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's make this an engaging and supportive learning community together.": "让我们共同打造一个充满活力且相互支持的学习社区。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Oh, and one quick technical note if you try to join the discord server and aren't able to for some": "哦，还有一个简短的技术提示：如果你尝试加入 Discord 服务器但由于某种原因",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:reason, make sure you're logged in to discord before clicking the link to the server.": "无法加入，请确保在点击服务器链接之前已登录 Discord。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That usually resolves any connection issues.": "这通常能解决任何连接问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is why I do assume some concepts which I'm not going to cover.": "这就是为什么我会假设你已经掌握了一些我不会涵盖的概念。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Those are the prerequisites and without you knowing them, then this course will be challenging for": "这些是先决条件，如果你不了解它们，那么这门课程对你来说将具有挑战性，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you.": "对你而言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I do assume that you have some Python knowledge and you know how to run a Python program and to write": "所以我假设你具备一定的 Python 知识，知道如何运行 Python 程序，以及如何编写",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Python functions and classes and general.": "Python 函数、类以及通用的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You are proficient in Python now, we're not going to do anything crazy with Python.": "你现在已经精通 Python 了，我们不会用 Python 做任何疯狂的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're just going to use the Lang library in Python.": "我们只是要在 Python 中使用 Lang 库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the entire source code is being managed in GitHub.": "整个源代码都在 GitHub 上进行管理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I do assume some basic git commands like git clone and git commit.": "所以我假设你掌握了一些基本的 git 命令，比如 git clone 和 git commit。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nothing fancy over here.": "这里没有什么复杂的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I do assume you're familiar with the concept of a virtual environment in Python and how to set environment": "我假设你熟悉 Python 中虚拟环境的概念以及如何设置环境",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:variables.": "变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to be honest, I think every standard Python course is going to cover all of those topics and you": "老实说，我认为每一门标准的 Python 课程都会涵盖所有这些主题，你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will see me bootstrapping from zero the entire project, and you'll see me doing everything step by": "会看到我从零开始构建整个项目，你会看到我一步步地",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:step.": "完成所有操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, I'm not going to explain everything right from the basics.": "然而，我不会从最基础的知识开始解释一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is not a Python course, it's an MCP course.": "所以这不是一门 Python 课程，而是一门 MCP 课程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is why I don't cover the basics.": "这就是为什么我不讲解基础知识的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it will give us the flexibility to dive deep right into link chain and to starting learning it in": "这样我们就可以灵活地直接深入研究 link chain，并开始",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:depth.": "深入学习它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also important to note that this course has a 30 day money back guarantee.": "同样重要的是要注意，这门课程有 30 天的退款保证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you find this course is not for you, feel free to ask for a refund.": "所以如果你发现这门课程不适合你，请随时申请退款。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You will get one without any questions asked.": "你将无条件获得退款。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if for some reason 30 days have passed and you still want a refund, feel free to contact me directly": "如果出于某种原因 30 天已经过去了，你仍然想要退款，请随时直接联系我，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and I will personally give you a refund with no hard feelings.": "我会亲自为你办理退款，不会有任何怨言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so that's pretty much it.": "好了，大概就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I hope I didn't scare you too much.": "我希望我没有把你吓得太厉害。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And with that being said, let's go to the course.": "话虽如此，让我们开始课程吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So both are the same Mctp servers with the same functionality.": "所以两者都是具有相同功能的相同 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first thing you want to do is to clone the servers.": "所以你要做的第一件事就是克隆这些服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now MCP have supports for locally running servers.": "所以目前 MCP 支持在本地运行服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we would need to clone the code of them.": "所以我们需要克隆它们的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it will be able to run in our local systems.": "这样它就能在我们的本地系统中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Support for remote MCP servers is going to come soon, and it's right now under development by the anthropic": "对远程 MCP 服务器的支持即将推出，目前 Anthropic 团队正在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:team.": "开发中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we cloned the code.": "所以我们克隆了代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we have the code that we saw in GitHub in our computer.": "现在我们的电脑里已经有了在 GitHub 上看到的那些代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's go and build it.": "现在让我们去构建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to be able to have an executable file to run the server.": "从而能够拥有一个可执行文件来运行服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to CD into the quickstart resources and I'm going to CD into the TypeScript version.": "所以我要进入 (CD) quickstart 资源目录，然后进入 TypeScript 版本目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and CD into Weather Server TypeScript.": "让我们进入 Weather Server TypeScript 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you the files that we have here.": "让我给你们看看这里的这些文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a package.json with all the dependency lists and a log file with the specific versions.": "我们有一个包含所有依赖列表的 package.json，以及一个包含特定版本的日志文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to the documentation and check out how does anthropic say we should compile and run our": "让我们去看看文档，看看 Anthropic 说我们应该如何编译和运行我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server.": "服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the repo.": "让我们回到仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a link to the anthropic official model context protocol documentation.": "这里有一个指向 Anthropic 官方模型上下文协议 (Model Context Protocol) 文档的链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to take a look at the for server developers.": "在这里我们要看看“面向服务器开发者”的部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so this tutorial is showing how to implement from zero an MCP server.": "这个教程展示了如何从零开始实现一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, we are going to take the artifact of this tutorial, which is the repo that we saw earlier": "不过，我们将使用这个教程的产物，也就是我们之前在 GitHub 上看到的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on GitHub.": "那个仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the first thing we're going to do is to learn how to integrate already pre-built MCP servers.": "我们要做的第一件事是学习如何集成已经预构建好的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's scroll down a bit and here let's go and select node.": "让我们向下滚动一点，在这里选择 Node。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now there is support for Python node in Java.": "目前支持 Python、Node 和 Java。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the server that we're going to integrate the MCP server is going to be built in NodeJS.": "我们要集成的这个 MCP 服务器将使用 Node.js 构建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first thing we want to do is first make sure that we have node and we have npm installed.": "所以我们要做的第一件事是确保已经安装了 Node 和 npm。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to paste those commands and they're going to out me my node and npm versions.": "我要粘贴这些命令，它们会输出我的 Node 和 npm 版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now if you don't have node npm installed simply google it and download and install them.": "如果你没有安装 Node 或 npm，只需谷歌搜索并下载安装即可。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's pretty straightforward.": "这非常简单直接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I have to admit I am not a NodeJS user.": "我必须承认，我不是 Node.js 用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not a front end or full stack developer.": "我不是前端或全栈开发者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm a back end developer, and with cursor, I learned a lot of front end and engineered my way to build": "我是一名后端开发者，通过使用 Cursor，我学到了很多前端知识，并摸索出了构建",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:SaaS applications.": "SaaS 应用程序的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, to configure a NodeJS MCP server, it's not that big of a deal and I believe it's very important": "然而，配置 Node.js MCP 服务器并不是什么难事，而且我认为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to know how to configure a node MCP server and a Python MCP server, because that's where we're going": "了解如何配置 Node MCP 服务器和 Python MCP 服务器非常重要，因为那是我们将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to see most of the MCP servers contributed open sourced by the ecosystem.": "看到生态系统贡献的大多数开源 MCP 服务器的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first thing we want to do is to install the dependencies.": "所以我们要做的第一件事就是安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so now we want to tell cursor how to use this MCP server.": "好了，现在我们要告诉 Cursor 如何使用这个 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now I'm in the cursor official documentation.": "我现在正在查看 Cursor 的官方文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they have a section on MCP.": "他们有一个关于 MCP 的章节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just as an FYI this documentation changed quite a lot.": "顺便提一下，这份文档变动很大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And also cursors implementation of MCP.": "Cursor 对 MCP 的实现也是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the old documentation where I originally made the course with.": "这是我最初制作课程时使用的旧文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I had to refilm it because cursor changed their implementation and their documentation.": "现在我不得不重新拍摄，因为 Cursor 更改了他们的实现和文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, if you find something not up to date in this course, please let me know and I'll do": "顺便说一下，如果你发现本课程中有任何内容过时，请告诉我，我会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my best to patch it ASAP.": "尽力尽快修复。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So either I'll patch the code or edit the video, or if needed, like in this case, I will refilm the": "我要么会修补代码，要么会剪辑视频，或者如果需要的话（就像这次一样），我会重新拍摄",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:entire video.": "整个视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for you to have the latest and greatest in the course materials.": "这样你就能获得最新、最好的课程资料。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So back to the documentation and here we have an explanation.": "回到文档，这里有一个说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's MCP?": "什么是 MCP？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why it's useful I'll link to the official repository of MCP and the protocol use cases like using databases": "为什么它很有用，我会链接到 MCP 的官方仓库以及协议的使用案例，比如使用数据库、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is connecting notion to cursor or GitHub stripe memory, etc..": "将 Notion 连接到 Cursor，或者 GitHub、Stripe、Memory 等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a quick explanation about MCP architecture and what kind of transport does cursor support.": "这里简要介绍了 MCP 架构以及 Cursor 支持哪种传输方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there are supporting right now two types of transports.": "目前支持两种传输方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means how does the server communicate with the client and vice versa.": "这意味着服务端如何与客户端通信，反之亦然。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first one is standard input output channel transport.": "第一种是标准输入输出 (stdio) 通道传输。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what we're going to do now.": "这就是我们现在要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this mean basically the server is running on our local machine.": "这基本上意味着服务端运行在我们的本地机器上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to write all the input and output into the standard input output.": "它将把所有的输入和输出写入标准输入输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client which is hosted on cursor which is the host is going to read everything from there.": "而托管在 Cursor（即宿主）上的客户端将从那里读取所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what's going to happen.": "这就是即将发生的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for that we need to tell cursor how to run the server locally.": "为此，我们需要告诉 Cursor 如何在本地运行服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be a shell command.": "这将是一个 shell 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be a shell command on how to run our server locally.": "这是一个关于如何在本地运行我们服务端的 shell 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see it right now in this video there is another layer of communication which is SW": "我们马上就会在视频中看到，还有另一层通信，即 SSE",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server side events, which we're going to review also in the course, but not in this video.": "服务器发送事件 (Server-Sent Events)，我们也会在课程中回顾，但不是在这个视频里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so how to configure an MCP server.": "好了，那么如何配置 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We already cloned it and we compiled our NodeJS server.": "我们已经克隆了它，并编译了我们的 NodeJS 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here is an explanation of how to do the same thing with a Python server.": "这里介绍了如何对 Python 服务端执行相同的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just go to NodeJS because that's the server we're using right now.": "让我切换到 NodeJS，因为这是我们目前正在使用的服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the concept for NodeJS and Python are identical because in this configuration we simply tell cursor": "NodeJS 和 Python 的概念是相同的，因为在这个配置中，我们只是告诉 Cursor",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:how to run our MCP server.": "如何运行我们的 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see that we have a JSON payload and a list of servers.": "在这里我们可以看到有一个 JSON 负载和一个服务器列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to give the server a name.": "我们需要给服务端起个名字。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to give it and call it weather.": "所以我们要给它起名叫 weather。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to do that with npm install.": "我将通过 npm install 来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after I do that I encounter this annoying error.": "之后我遇到了这个恼人的错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I tried to follow the instructions here.": "我尝试按照这里的说明操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it really didn't help.": "但真的没用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I logged in to npm js, and I really spent a lot of time trying to debug this myself.": "我登录了 npm js，花了很多时间尝试自己调试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I then turned to cursor and to ChatGPT and Claude, and none of them gave me something useful to do.": "然后我求助于 Cursor、ChatGPT 和 Claude，但它们都没能提供有用的建议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, when searching it on Google and going to Stack Overflow like we did in the old days.": "然而，当我像以前那样在 Google 上搜索并查看 Stack Overflow 时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I actually found the answer, and the bug here is because I have the package dot log file, which has": "我终于找到了答案，这里的 bug 是因为我有一个 package-lock 文件，它包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:different dependencies than my NodeJS version.": "与我的 NodeJS 版本不同的依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this collision of version caused the problem.": "所以这种版本冲突导致了问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to fix it, all we need to do is to remove the log file in JSON.": "要修复它，我们只需要删除这个 JSON 格式的 lock 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so let me open it in cursor.": "好了，让我用 Cursor 打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to right cursor with the current directory.": "我要在当前目录下输入 cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to spin up cursor with all the code here.": "它会启动 Cursor 并加载这里所有的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so this is the code for the NodeJS server.": "好了，这就是 NodeJS 服务器的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it will go to index dot TypeScript.": "我们进入 index.ts。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see right here we have the implementation of the already pre-built MCP server that's going to": "我们可以看到这里有一个已经预构建好的 MCP 服务器实现，它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:get us the weather.": "为我们获取天气。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we don't care about the implementation here because we're going to assume that this code is legit": "现在我们不关心这里的具体实现，因为我们假设这段代码是合法的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it's going to make a weather API an HTTP call, and it's going to get us back the results.": "它会发起一个天气 API 的 HTTP 调用，并返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have here the base URL to make the API call to get the weather API weather.gov.": "我们可以看到这里有调用天气 API 的基础 URL：weather.gov。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a make request, which is going to make a request to get the weather.": "我们还有一个 makeRequest 函数，用于发起获取天气的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a bunch of objects that we we define here.": "我们在这里定义了一堆对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're not going to cover this in this video.": "我们不会在本视频中讨论这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to do it later in the videos when we learn how to build an SMTP server from zero.": "我们会在后面的视频中，学习如何从零构建 SMTP 服务器时再讨论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, but we're just going to assume that this goal is legit.": "嗯，但我们暂且假设这段代码是合法的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, assuming that open source code is legit is not something you should always do.": "顺便说一下，你不应该总是假设开源代码是合法的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I really do not recommend you downloading every MCP server you see on GitHub, because it may contain": "所以我真的不建议你下载在 GitHub 上看到的每一个 MCP 服务器，因为它可能包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:malicious code that is going to run on your machine.": "会在你机器上运行的恶意代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is kind of a supply chain attack which is prominent to be here with MCP server.": "这是一种供应链攻击，在 MCP 服务器中非常突出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it does um, it does introduce a bit of a risk.": "所以它确实……确实带来了一定的风险。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to talk about security later in this course.": "我会在本课程的后面部分讨论安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So back to um, installing the The dependencies into solving the error.": "回到……安装依赖项并解决错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's spin up the terminal and let me show you that I reproduce even in cursor this error.": "让我们打开终端，我向你们展示一下，即使在 Cursor 中我也能复现这个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to right now npm install.": "所以我现在要运行 npm install。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's make sure that the error happens again.": "让我们确认一下错误是否会再次发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It does.": "确实发生了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm simply going to take this package dot lock file and delete it.": "我只需选中这个 package-lock 文件并将其删除。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm going to run it again.": "现在我再次运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The npm install.": "运行 npm install。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see it's working and it's installing the dependencies.": "现在我们可以看到它正在运行，并且正在安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after the dependencies that were installed let's go and build it.": "那么在依赖项安装完成后，让我们来构建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to build it we need to run npm run build.": "所以为了构建它，我们需要运行 npm run build。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom it created this build directory with index.js file which is the file in JavaScript code that": "瞧，它创建了这个包含 index.js 文件的 build 目录，这个文件是 JavaScript 代码，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is eventually going to run.": "最终将会运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all we need to do to tell Cursor and cloud desktop.": "我们只需要告诉 Cursor 和云端桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you want to integrate this MCP server, we simply need to tell those clients how to run this MCP": "如果你想集成这个 MCP 服务器，我们只需要告诉这些客户端如何运行这个 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's all.": "就这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want now to show you how cursor behaves without the weather MVP.": "现在我想向你展示在没有天气 MVP 的情况下 Cursor 的表现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you're worried about all the files here and all the code, simply ignore it.": "如果你担心这里的这些文件和代码，直接忽略它们就好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a simple project I was working on.": "这是我正在开发的一个简单项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I wanted to open cursor with a bunch of files open, so you don't really need to understand the code": "我想在打开一堆文件的情况下启动 Cursor，所以你并不真的需要理解这些代码",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We simply need to focus on the right side over here.": "我们只需要关注右侧的这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if I were to write what is the weather in San Francisco right now?": "那么，如果我输入“旧金山现在的天气如何？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go choose the agent.": "让我去选择 Agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me run it.": "让我运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's either going to use the default cursor web search or it's not going to be able to do it depending": "它要么会使用 Cursor 默认的网页搜索，要么会无法完成，这取决于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on which version you have.": "你使用的是哪个版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I get the answer that it cannot get me the real time weather in San Francisco because it doesn't": "我得到的回答是它无法获取旧金山的实时天气，因为它没有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:have access to this kind of data.": "访问这类数据的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also important to note that if you're using a new version of cursor, then it has some built": "同样需要注意的是，如果你使用的是新版本的 Cursor，它内置了一些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in functionality of searching.": "搜索功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So cursor may and probably will invoke its search function and get you this result and get you the weather.": "因此，Cursor 可能会（而且很可能会）调用其搜索功能来为你获取结果和天气。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, while it can do it, let's say that we want even more accurate weather and we want more accurate": "现在，虽然它可以做到这一点，但假设我们想要更准确的天气，并且我们希望更准确地",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from a data source that is the National Weather Service, and we want to insure it with an MCP server.": "从美国国家气象局这一数据源获取，并且我们希望通过 MCP 服务器来确保这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for this example we want to hook and we want to connect an MCP server to get us the weather.": "所以在这个例子中，我们想要挂载并连接一个 MCP 服务器来为我们获取天气。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and configure that MCP server that will help us with this.": "让我们去配置那个能帮我们实现这一点的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go to Cursor Settings and let's go to MCP.": "我要进入 Cursor 设置，然后转到 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we want to add an MCP server which is going to be global.": "在这里我们要添加一个全局的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once we'll go and click that then we see we have this JSON file mcp JSON which is located in our": "一旦我们点击它，我们就会看到这个 JSON 文件 mcp.json，它位于我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:root directory.": "根目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Dot cursor.": ".cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the cursor directory.": "所以这就是 cursor 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have mcp NP dot JSON.": "这里有 mcp.json。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see this is the content of the file we are seeing right now.": "我们可以看到这就是我们现在看到的文件的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this file is going to hold the configuration that the cursor clients are going to use in order to": "这个文件将保存 Cursor 客户端用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:communicate with the MCP servers.": "与 MCP 服务器通信的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to tell cursor how to run those MCP servers, whether they're going to be locally": "在这里，我们将告诉 Cursor 如何运行这些 MCP 服务器，是像我们这次一样在本地",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:run like we're going to do this time, and this is going to use the Stdio or it's going to be a server": "运行（这将使用 Stdio），还是使用服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:side events.": "端事件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back to the cursor documentation.": "让我们回到 Cursor 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have an example of what we need to do to configure the MCP JSON.": "这里有一个关于如何配置 mcp.json 的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to configure our locally running Stdio MCP server.": "以及如何配置我们本地运行的 Stdio MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you noticed, if we go to the official MCP documentation, let's go to the server developers.": "如果你注意到了，如果我们去 MCP 官方文档，让我们进入服务器开发者部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's choose Node.js.": "让我们选择 Node.js。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the quick start tutorial.": "这是快速入门教程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go down a bit about the configuration with the clients.": "让我们向下滚动一点，查看关于客户端配置的部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to write the command to run the server.": "我们需要编写运行服务器的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here the command example is NP we're going to use node.": "这里命令示例是 NP，我们将使用 node。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can use NP if you want.": "如果你愿意，你可以使用 NP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to also give the path of our compiled server.": "所以我们还需要提供编译后服务器的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so we'll need to give the path of our index.js file that we had prepared earlier.": "因此我们需要提供我们之前准备好的 index.js 文件的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we need some environment variables like API keys, etc., we can put them in the env key.": "如果我们需要一些环境变量，比如 API 密钥等，我们可以将它们放在 env 键中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have a dictionary where we can put any environment variable that you want.": "这里我们有一个字典，你可以在其中放入任何你想要的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we will be seeing this in the course.": "我们将在课程中看到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But for this example we don't even need an API key.": "但对于这个例子，我们甚至不需要 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I want to talk about something which is specific to cursor and to maybe other IDE's AI powered": "现在我想谈谈一些针对 Cursor 以及可能其他 AI 驱动的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Ides.": "IDE 的特性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So basically we can configure an SMTP server which is going to be global to cursor.": "基本上，我们可以配置一个对 Cursor 全局生效的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means every time we open cursor we'll have this Mocp configured in working.": "这意味着每次我们打开 Cursor 时，都会配置并运行这个 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or we can have Mocp per project.": "或者我们可以为每个项目配置 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very similar like we have cursor rules.": "这与我们拥有的 Cursor 规则非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are things in extra context which cursor is going to use like how to format our code, which": "这些是 Cursor 将要使用的额外上下文中的内容，比如如何格式化我们的代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:libraries to use etc..": "使用哪些库等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have the same concept here with mic.": "我们在这里对 MCP 也有同样的概念。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to save this configuration under the global dot cursor slash MCP dot JSON.": "我们将把这个配置保存在全局的 .cursor/mcp.json 下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So everything we put here is going to be valid for all of our cursor instances.": "所以我们在这里放置的所有内容都将对我们所有的 Cursor 实例有效。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want to have something which is specific per project, we'd need to save it under the project": "如果你想要一些针对特定项目的内容，我们需要将其保存在项目",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:directory.": "目录下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to create a dot cursor directory there and to put an MCP dot JSON there.": "并在那里创建一个 .cursor 目录，并在其中放入一个 mcp.json。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's continue and discuss tool usage with MCP servers and cursor.": "那么让我们继续讨论 MCP 服务器和 Cursor 的工具使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once we configure an MCP server that exposes tools and in this example is a weather tool to the": "一旦我们配置了一个向 Cursor 代理公开工具（在本例中是一个天气工具）的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cursor agent.": "MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the cursor agent is going to be able to run this tool if it finds that it's relevant.": "那么如果 Cursor 代理发现该工具相关，它就能够运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And an MCP server that we download and run locally is literally RC.": "我们下载并在本地运行的 MCP 服务器实际上就是 RCE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a vulnerability of remote code execution because it's code that we didn't wrote that is running": "所以这是一个远程代码执行漏洞，因为它是我们没有编写的代码在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on our machine.": "我们的机器上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in case we have malicious actors that poison an SMTP server.": "因此，万一有恶意攻击者投毒了 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It may cause some problems, right?": "这可能会导致一些问题，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I like the design choice that cursor did regarding tool approval.": "所以我喜欢 Cursor 在工具审批方面所做的设计选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So by default cursor is not going to automatically run the tool when it finds that it's appropriate,": "因此，默认情况下，当 Cursor 发现合适时，它不会自动运行工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but it's going to prompt us with a message whether we want to approve the tool call or not.": "而是会提示我们一条消息，询问我们是否要批准该工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see which tool is getting called and which arguments do we call it with.": "我们可以看到哪个工具正在被调用，以及我们使用哪些参数调用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very important as far as security wise.": "就安全性而言，这非常重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the default behavior.": "所以这是默认行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I really like that.": "我非常喜欢这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we are awesome vibe coders like I am I'm a total vibe coder.": "如果我们是像我一样出色的氛围程序员（vibe coder）——我完全是一个氛围程序员。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can use YOLO mode.": "我们可以使用 YOLO 模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in YOLO mode, the cursor agent will automatically run the MCP tools without getting our approval.": "而在 YOLO 模式下，Cursor Agent 将自动运行 MCP 工具，无需获得我们的批准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to save us a bunch of time.": "因此，这将为我们节省大量时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not the best practice as far as security, and if you're in an enterprise, it's probably not something": "就安全性而言，这并非最佳实践，如果你在企业环境中，这可能不是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you should do.": "你应该做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we have that option in case that we want.": "但如果我们需要，我们有这个选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see here we have a very similar payload.": "我们可以看到这里有一个非常相似的有效负载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a nested JSON.": "这是一个嵌套的 JSON。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first key is MCP servers.": "所以第一个键是 MCP servers。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to have the key of the name of the MCP servers.": "这里我们将拥有 MCP 服务器名称的键。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this quick start example it's going to be called whether we're going to have the command which": "在这个快速入门示例中，它将被命名为 weather，我们将拥有运行该 MCP 服务器的命令，该命令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is going to run that MCP server.": "将运行该 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the arguments for that command.": "以及该命令的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case we're running node and running the compiled index.js file under the build directory.": "在这种情况下，我们正在运行 node 并运行 build 目录下的编译后的 index.js 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll arbitrarily copy this payload JSON instead of the cursor one and let's paste it in.": "所以我将随意复制这个有效负载 JSON 而不是 Cursor 的那个，然后让我们把它粘贴进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we're going to run it with node rather than npm.": "所以现在我们要用 node 而不是 npm 来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to give it the full directory of our index.js file.": "所以我们需要给它 index.js 文件的完整目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what I'm going to do now.": "这就是我现在要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all I'm doing right now is finding the path to my index.js file.": "我现在所做的只是找到我的 index.js 文件的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be here under the weather server TypeScript.": "它就在 weather-server-typescript 下面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's CD into that.": "让我们 CD 进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and check out all the files here.": "让我们去查看这里所有的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have here a build directory.": "我们这里有一个 build 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go there and let's print out the entire path here.": "让我们去那里，并在这里打印出整个路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is where my path is saved.": "这就是我的路径保存的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you're probably going to have a similar one.": "你可能也会有一个类似的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the path here is going to be to my GitHub projects.": "这里的路径将指向我的 GitHub 项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I have a directory called MCP servers.": "我有一个名为 MCP servers 的目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I cloned the quickstart resources repo.": "我克隆了 quickstart-resources 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that repo has a directory called Weather Server TypeScript which has after we compiled the server": "该仓库有一个名为 Weather Server TypeScript 的目录，在我们编译服务器后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a build directory.": "有一个 build 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's where our index.js file is located.": "这就是我们的 index.js 文件所在的位置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the command I will tell cursor in order to run it.": "所以这就是为了运行它，我将告诉 Cursor 的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see that our server is configured and that it's valid.": "现在我们可以看到我们的服务器已配置好且有效。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have two tools.": "我们可以看到我们有两个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is get alerts and the other is get forecasts.": "一个是 get-alerts，另一个是 get-forecasts。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we don't have any resources.": "我们没有任何资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Don't worry about it.": "别担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to review an example of that later.": "我们稍后会回顾一个相关的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is our weather MCP server.": "这就是我们的天气 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in case this is not working for you, let's go back to the NP dot JSON.": "如果这对你不起作用，让我们回到 mcp.json。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this might be because you didn't put the correct path to the index.js file.": "这可能是因为你没有输入 index.js 文件的正确路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you see, I simply removed a part of my path.": "你看，我只是删除了路径的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now it's writing client closed.": "现在它显示 client closed。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because here the path was not complete and the cursor had an issue finding this MCP server": "这是因为这里的路径不完整，Cursor 在查找此 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:implementation.": "实现时遇到了问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now.": "让我现在去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we fix this with the correct path.": "我们用正确的路径修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go back and see that everything is okey dokey.": "让我回去看看一切是否正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Amazing.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's time to test it.": "现在是测试它的时候了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply going to go to the agent again.": "所以我只需再次前往 Agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's ask what is the weather in San Francisco right now.": "现在让我们问一下旧金山现在的天气如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now that the cursor agent is now going to find what are the coordinates of San Francisco.": "我们可以看到 Cursor Agent 现在将查找旧金山的坐标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's calling now the tool get forecast with those coordinates.": "它现在正使用这些坐标调用 get-forecast 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we have it working on cursor, let's go to cloud and we want to give it the tools to get the": "在 Cursor 上运行成功后，我们去云端，我们想给它提供获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weather and the alerts as well.": "天气和警报的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll connect the weather server to the cloud host which has an MCP client.": "所以我们将天气服务器连接到拥有 MCP 客户端的云主机。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll go to settings.": "所以我们去设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have developer.": "这里有开发者选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here is all the MCP servers that should be configured in our cloud desktop application.": "这里是应该在我们的云桌面应用程序中配置的所有 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't have any MCP servers right now configured.": "我现在没有配置任何 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what we're going to do now.": "这就是我们现在要做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to configure an MCP server with Cloud Desktop Application cloud needs to know which servers": "为了在云桌面应用程序中配置 MCP 服务器，云端需要知道哪些服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to run and what the commands it needs to run in order to spin up those servers and in order to communicate": "需要运行，以及为了启动这些服务器并为了进行通信",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:them with them through MCP protocol.": "通过 MCP 协议与它们通信所需的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you're going to do that with a JSON file which is holding the configuration.": "你将通过一个保存配置的 JSON 文件来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's click Edit Config.": "所以让我们点击 Edit Config（编辑配置）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right here you see all the files related to the cloud desktop application.": "在这里你可以看到所有与云桌面应用程序相关的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a cloud desktop config JSON file that is going to hold all the information on MCP servers.": "我们有一个云桌面配置 JSON 文件，它将保存所有关于 MCP 服务器的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and click it.": "让我们点击它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to open it with a cursor.": "我将用 Cursor 打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go close this chat here.": "让我关掉这里的聊天窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have here a JSON file with the key of MCP servers which is currently empty.": "我们可以看到这里有一个 JSON 文件，其中的 MCP servers 键目前是空的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to populate it with information that is going to help cloud understand where our servers": "所以现在我们想用一些信息来填充它，这些信息将帮助云端了解我们的服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:are located and how to run them.": "位于何处以及如何运行它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the MCP documentation.": "那么让我们去看看 MCP 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the cursor documentation.": "这是 Cursor 的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to go to the MCP documentation to see how we can integrate it with a cloud.": "我想去 MCP 文档看看我们如何将其与云端集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we scroll down and here we have information about the implementation of the actual server like": "如果我们向下滚动，这里有关于实际服务器实现的信息，比如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which methods do we want, which endpoints, etc..": "我们想要哪些方法、哪些端点等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see we're going to have a JSON object.": "我们可以看到我们将得到一个 JSON 对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can simply paste and let's go down a bit.": "我们只需粘贴，然后向下移动一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Boom we can see this one.": "瞧，我们可以看到这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we're going to copy that and let's go and simply paste it.": "所以我们要复制它，然后直接粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that as far as the integration with Cloud Desktop, it needs very similar information": "我们可以看到，就与云桌面的集成而言，它需要的信息非常相似",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that cursor needed because they both implement the MCP protocol.": "与 Cursor 需要的信息类似，因为它们都实现了 MCP 协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all we need to do is to simply give the name for our MCP server.": "我们需要做的只是简单地为我们的 MCP 服务器命名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we call it weather, but we can really call it anything we want and then to give it the command.": "这里我们称之为 weather，但实际上我们可以随心所欲地命名，然后给它命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what's going to run the MCP server.": "也就是运行 MCP 服务器的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here it's going to be node.": "在这里它将是 node。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can be Python.": "也可以是 Python。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going can be Java.": "也可以是 Java。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the arguments we need to give here the absolute path to um to our MCP server that we wrote.": "在参数中，我们需要提供我们编写的 MCP 服务器的绝对路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this one is an already pre-built.": "这个是已经预构建好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply going to go here and I'm going to paste in the full path for my already built MCP server.": "所以我直接去这里，粘贴我已构建好的 MCP 服务器的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's it.": "就这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to save it.": "我们保存它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's check out what are the arguments.": "让我们来看看参数有哪些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the function we are invoking which is exposed via our MCP server.": "所以这就是我们正在调用的函数，它是通过我们的 MCP 服务器公开的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's the get forecast function.": "所以它是 get forecast 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to receive the arguments of latitude and longitude which the cursor agent extrapolated": "它将接收纬度和经度参数，这些参数是 Cursor 智能体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for us.": "为我们推断出来的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get now the result.": "现在我们得到了结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the result after we ran this code.": "所以这就是运行这段代码后的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This function and cursor is even going to run the get alerts function with the input of California.": "这个函数和 Cursor 甚至会以 California 为输入运行 get alerts 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to see if we have any alerts in California.": "所以它会查看加利福尼亚州是否有任何警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it also added these in another function call.": "所以它还在另一个函数调用中添加了这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it ran also.": "并且它也运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it gave us the result of what's the weather in San Francisco right now.": "然后它向我们返回了旧金山当前天气的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if there are any alerts.": "以及是否有任何警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we did in this video, we configured our weather MCP server implemented in NodeJS.": "所以在本视频中，我们配置了用 NodeJS 实现的天气 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That MCP server exposed two tools, and cursor is now able to use those tools when they think it's right.": "该 MCP 服务器公开了两个工具，Cursor 现在能够在认为合适的时候使用这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need now to restart the cloud desktop application.": "现在我们需要重启 Claude Desktop 应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and close it first.": "让我先去把它关掉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me quit.": "让我退出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and open it again.": "让我再去重新打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see this.": "现在我们可以看到这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A hammer icon with the tools that we have configured with Cloud Desktop.": "一个锤子图标，里面有我们为 Claude Desktop 配置的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we're going to have the Get Weather tool the Get forecast and the Get alert.": "这里我们将会有 Get Weather 工具、Get forecast 和 Get alert。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they're going to come from our MCP weather server.": "它们将来自我们的 MCP 天气服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very similar to what we had in cursor.": "这与我们在 Cursor 中看到的非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and test it with cloud.": "那么让我们用 Claude 来测试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's write what is the weather in San Francisco right now.": "让我们输入：旧金山现在的天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now cloud is going to prompt us whether we allow to invoke and to run this functionality.": "现在 Claude 会提示我们是否允许调用并运行此功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to write allow once to always allow running this server and this functionality.": "我会选择“允许一次”或“始终允许”来运行此服务器和此功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we get an answer and we get it after we ran the Get Weather tool.": "瞧，我们得到了答案，这是在运行 Get Weather 工具后得到的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now and delete this MCP server and show you that it won't work without it.": "现在让我去删除这个 MCP 服务器，向你展示没有它就无法工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply going to go and delete.": "我直接去删除它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's how you delete an MCP server.": "这就是删除 MCP 服务器的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and ask again.": "让我们再去问一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's create a new chat.": "让我们创建一个新对话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the weather in San Francisco right now.": "旧金山现在的天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it actually tries to run the the tool.": "它实际上还在尝试运行该工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is because we didn't restart cloud.": "这是因为我们没有重启 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's stop here this execution and let's go and try to restart cloud.": "那么让我们停止这次执行，尝试重启 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go here I'm going to quit cloud.": "让我到这里来，我要退出 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's open it again.": "让我们再次打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see now in the settings we don't have any MCP servers.": "我们现在可以在设置中看到没有任何 MCP 服务器了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's write again.": "让我们再次输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the weather in MCP right now.": "MCP 现在天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a typo.": "这是一个拼写错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I meant to write San Francisco, but you will get the point because it will still won't be able to search": "我本想写旧金山，但你会明白我的意思，因为它仍然无法搜索",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with the tool because we don't have the weather tool again.": "使用该工具，因为我们已经没有天气工具了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So up until now, we saw how to treat an NCP server as a black box.": "到目前为止，我们已经了解了如何将 NCP 服务器视为一个黑盒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we simply clone the ready to go NCP server.": "所以我们只需克隆现成的 NCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In this case, it was the weather NCP server and we connected it into a client.": "在这个例子中，它是天气 NCP 服务器，我们将其连接到了一个客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we connected it to cursor and to Cloud Desktop.": "所以我们把它连接到了 Cursor 和 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this was the first layer of understanding NCP in general and NCP servers.": "这是对 NCP 及其服务器进行通识理解的第一层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the second step is to see how servers are implemented underneath the hood.": "第二步是查看服务器在底层是如何实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the next couple of videos we're going to take this quick start weather MCP server.": "所以在接下来的几个视频中，我们将以这个快速入门的天气 MCP 服务器为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to dive a bit into the code.": "我们将深入研究一下代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the next two videos are not hands on.": "接下来的两个视频不是实操环节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm not expecting you to go and really implement it.": "所以我不要求你真的去动手实现它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't worry, we'll do it in future videos, but rather a walkthrough.": "不用担心，我们会在以后的视频中进行实操，现在这只是一个代码走读。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to walk through the code of the NCP server and we're going to see how it's built.": "我们将浏览 NCP 服务器的代码，看看它是如何构建的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're not going to focus on the API making to get the weather and to get the alerts.": "我们不会把重点放在获取天气和预警的 API 调用上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's not very interesting.": "那没什么意思。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We will be focusing and mentioning how to use the MCP SDK and how do we expose a tool in this case.": "我们将重点介绍如何使用 MCP SDK，以及在这种情况下如何暴露一个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the second layer of implementing an NCP server.": "这是实现 NCP 服务器的第二层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So see you in the other videos.": "那么，我们在其他视频中再见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's start with the helper functions.": "让我们从辅助函数开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have the first helper function which is called make an AWS request and AWS.": "我们有第一个辅助函数，叫做 make an AWS request，这里的 AWS...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let's let.": "好的，让我们...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's take a look at the helper functions.": "那么，让我们来看看这些辅助函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if to be exact they're coroutines because they're async functions.": "准确地说，它们是协程，因为它们是异步函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have the first one make an AWS request.": "首先是第一个，make an AWS request。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And AWS stands for the National Weather Service.": "这里的 AWS 代表美国国家气象局 (National Weather Service)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this helper function is very simple.": "这个辅助函数非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to receive a URL and it's going to make an HTTP with the HTTP async client.": "它接收一个 URL，并使用 HTTP 异步客户端发起 HTTP 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to make this HTTP request to the National Weather Service API.": "它会向美国国家气象局的 API 发起这个 HTTP 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's a very simple implementation.": "所以这是一个非常简单的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the National Weather Service also exposes a bunch of functionality.": "美国国家气象局也公开了许多功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like to get the forecast and to get alerts on a certain area.": "比如获取天气预报和特定区域的警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we're not going to cover how do we exactly communicate with the weather API?": "但我们不会详细讲解具体是如何与天气 API 通信的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because it's not interesting because we're here to learn about MCP, but you can assume that this function": "因为那没什么意思，我们来这里是为了学习 MCP，但你可以假设这个函数",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:makes the request, and the request knows how to talk with the National Weather Service.": "负责发起请求，并且该请求知道如何与美国国家气象局通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right?": "对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have another function format alert, which receives a feature and feature is probably something": "这里我们还有另一个函数 format alert，它接收一个 feature 参数，这个 feature 可能来自于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from the NWS service.": "NWS 服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Some kind of result.": "某种结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we hear simply the response that we will get back from the make NWS request.": "这里我们简单处理从 make NWS request 返回的响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to format it a bit, to be more human readable, and to be able to send it back to the LM so": "我们想对它进行一些格式化，使其更具可读性，并能发送回 LLM，以便",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it would be able to process it.": "它能够对其进行处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have the format alert, which is going to receive this feature dictionary, which is a derivative": "所以这里有 format alert 函数，它将接收这个 feature 字典，它是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of some response we make to NWS server.": "我们向 NWS 服务器发起的某种响应的派生物。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we format it.": "然后，我们就完成了格式化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be a nice string which is going to have the event is going to have severity.": "它将变成一个漂亮的字符串，包含事件名称、严重程度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to have description and instructions.": "还会包含描述和指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And nothing very end is going to have default values.": "在最后还会包含默认值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very basic formatting.": "所以这是非常基础的格式化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's assume that it is working because again it's not really worth our time to even go through": "让我们假设它是正常工作的，因为同样，不值得花时间去深究。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right now this is the important part of the server.": "好了，现在是服务器的重要部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is how we expose functionality to MCP clients.": "这就是我们向 MCP 客户端公开功能的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's talk about the tool execution.": "现在让我们来谈谈工具的执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's very very easy.": "这非常非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These are the tools that we want to expose to MCP clients.": "这些是我们想要公开给 MCP 客户端的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have two tools that we expose.": "这里我们公开了两个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have get alerts and we have get forecast.": "分别是 get alerts 和 get forecast。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start with the get forecast because to me it sounds more natural.": "让我们从 get forecast 开始，因为对我来说这听起来更自然。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the first functionality like we saw in the demo that we want to expose.": "这是我们在演示中看到的、想要公开的第一个功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all we need to do is use the MCP server object that we created earlier from the fast MCP object.": "我们只需要使用之前通过 fast MCP 对象创建的 MCP 服务器对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it has a tool decorator.": "它有一个 tool 装饰器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to decorate a coroutine because we have here an async function.": "它将装饰一个协程，因为我们这里有一个异步函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this time it's called get forecast.": "这一次它被称为 get forecast。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Get forecast needs to receive a latitude and longitude.": "Get forecast 需要接收纬度和经度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it will receive the string which is going to be the forecast.": "它将接收作为天气预报的字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now what's important about this function.": "现在关于这个函数重要的是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's important that we write here a very accurate description to get weather forecast for a location,": "重要的是我们要在这里写一个非常准确的描述，以获取某个位置的天气预报，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because this is what's going to help the LM in the MCP client to understand whether to call to this": "因为这将帮助 MCP 客户端中的大语言模型理解是否调用这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:function or not to this tool.": "函数或这个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to describe the arguments that this function is going to receive.": "它将描述该函数将接收的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the latitude and the longitude.": "即纬度和经度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So very very similar.": "所以非常非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you have been familiar with Link Chain to define a link chain tool, and the descriptions are very,": "如果你熟悉使用 LangChain 来定义 LangChain 工具，那么描述是非常，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:very important, if you're going to create precise descriptions and very, very explicit, it's going": "非常重要的，如果你创建精确且非常非常明确的描述，它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be fine.": "运行良好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, if you're going to write something ambiguous here, then the LMS in your MCP clients not going": "然而，如果你在这里写了一些含糊不清的内容，那么你 MCP 客户端中的大语言模型将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to have the best time choosing this tool.": "很难选择这个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways.": "无论如何。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The implementation here pretty boring.": "这里的实现相当乏味。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's simply making a request with the make request with the latitude and longitude, and getting the": "它只是通过 make request 使用纬度和经度发起请求，并获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:result back.": "返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After we get the result back, we simply extract a bunch of fields and we format this beautiful string": "在我们得到返回结果后，我们只需提取一堆字段，并格式化这个漂亮的字符串",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:here, which is going to have the temperature, the wind, the forecast, and the time period which": "这里，其中将包含温度、风力、预报以及我们收到请求的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we got the request for.": "时间段。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nothing very fancy here, simply to make an HTTP request to format the response, we get back and return": "这里没有什么花哨的东西，只是发起一个 HTTP 请求来格式化我们得到的响应并返回",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it as a string and same.": "它作为一个字符串，同样地。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have another tool that we expose with the tool decorator which is get alerts, which is going to": "我们还有另一个通过 tool 装饰器暴露的工具，即 get alerts，它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:get you a weather alert for a US state like New York, Arizona, California, Washington, whatever.": "为你获取美国某个州（如纽约、亚利桑那、加利福尼亚、华盛顿等）的天气警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Simply making an API request with a different URL to alert alerts under the NWS API based URL, simply": "只是使用不同的 URL 向 NWS API 基础 URL 下的 alerts 路径发起 API 请求，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to format it with the helper format function we saw earlier.": "简单地使用我们之前看到的辅助格式化函数对其进行格式化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All we are left to do is to run the server, and we do it in the main entry point, and we simply use": "我们剩下的工作就是运行服务器，我们在主入口点执行此操作，只需使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the MCP run.": "MCP run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we write the transport to be stdio.": "在这里我们将传输方式设置为 stdio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means that all the communication between the client and the MCP server is going to be via the": "这意味着客户端和 MCP 服务器之间的所有通信都将通过",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:standard input output channel.": "标准输入输出通道进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we want now to run the server, we simply need to run it with all the package installed and run the": "如果我们现在想运行服务器，我们只需要在安装了所有包的情况下运行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weather.py file.": "weather.py 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now to the repo.": "现在让我们去代码库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I'm in the weather.py file and we can see all the code that we saw.": "在这里，我正在查看 weather.py 文件，我们可以看到我们见过的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have 94 lines of code here.": "这里有 94 行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what's going to run the server.": "这就是将要运行服务器的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a bunch of tools that we expose.": "我们暴露了一系列工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have one server MCP server that exposes two tools that we saw earlier.": "这里我们有一个 MCP 服务器，它公开了我们之前看到的两个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the entire implementation.": "这就是完整的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the key part here is that if you wanted to expose a tool, we simply need to use the tool decorator.": "这里的关键部分是，如果你想公开一个工具，我们只需要使用 tool 装饰器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to decorate our function that we want to expose as a tool.": "我们需要装饰我们想要作为工具公开的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we needed to write a good description of that function.": "我们需要为该函数编写一个良好的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is so this was to create a server.": "这就是创建服务器的过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the server is going to run locally.": "现在服务器将在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you want to connect it to an NCP client then we need to tell that client how to run the server.": "因此，如果你想将其连接到 NCP 客户端，我们需要告诉该客户端如何运行服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have the example of cloud.": "这里我们有 cloud 的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And like I showed you in the earlier videos, if you want to integrate it we simply need to tell cloud": "就像我在之前的视频中向你展示的那样，如果你想集成它，我们只需要告诉 cloud",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:how to run this server.": "如何运行这个服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here you can see we simply put in the server configuration file I showed you earlier.": "所以在这里你可以看到，我们只需放入我之前向你展示的服务器配置文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way notice here the name of whether it's supposed to be the same name as the SMTP server.": "顺便注意一下，这里的 weather 名称是否应该与 SMTP 服务器的名称相同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have our weather MCP server and how to run it.": "这里有我们的 weather MCP 服务器以及如何运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to simply run it with the command of UV.": "我们只需要使用 UV 命令来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to tell it to run it from the directory where our project is stored.": "我们要告诉它从存储项目的目录中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we simply want to run the script.": "我们只需要运行脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weather.py.": "weather.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is how we create very basic NCP servers which expose the weather API.": "这就是我们创建公开天气 API 的非常基础的 NCP 服务器的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go review a note here.": "让我们来回顾一下这里的笔记。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we know this.": "所以我们知道这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The steps are going to be very similar.": "步骤将会非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First we want to make sure that we have node and npm install.": "首先，我们要确保已经安装了 Node 和 npm。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we want to create a new directory called whether we want to initialize it.": "然后我们要创建一个名为 weather 的新目录并对其进行初始化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to install the NCP SDK.": "我们要安装 MCP SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to install that which is going to help us have data objects.": "我们要安装它，这将帮助我们处理数据对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to install also TypeScript.": "我们还要安装 TypeScript。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's it.": "就这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We create our server file which is going to be index dot TypeScript under the source directory which": "我们创建服务器文件，即 source 目录下的 index.ts，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we create here we can see in the package.json we telling it how to build our application to build it": "我们在这里创建，可以在 package.json 中看到我们告诉它如何构建我们的应用程序，即使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with TypeScript.": "TypeScript 进行构建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is some some configuration of TypeScript to build it in the stash build directory.": "这是 TypeScript 的一些配置，用于在 build 目录中进行构建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, I'm really not a TypeScript expert, but it's supposed to be very, very straightforward.": "嗯，我真的不是 TypeScript 专家，但它应该非常非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, the implementation is going to be very simple, very similar to what we saw.": "无论如何，实现过程将非常简单，与我们看到的非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We first create the base URLs and the user agent that we're going to pass to the request.": "我们首先创建将传递给请求的基础 URL 和用户代理 (User Agent)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We create a new Amqp server object.": "我们创建一个新的 MCP 服务器对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the name is going to be weather and can give it a version we have here the function make AWS request": "名称将是 weather，可以给它一个版本，这里我们有 makeNWSRequest 函数",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:very similar to make a request to the weather server.": "与向天气服务器发送请求非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be our interface of an alert.": "这是我们的告警接口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be all the fields, which is it's going to be format alert is going to format this": "所以这些是所有的字段，formatAlert 将把这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:beautiful object into a beautiful string.": "漂亮的对象格式化为漂亮的字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to have also a forecast period object.": "我们还将有一个预测周期 (forecast period) 对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we want to go and wrap a tool which we're going to call get alerts.": "然后我们要封装一个工具，我们将其命名为 get_alerts。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Get weather alerts for a state.": "获取某个州的天气告警。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the description and this is what it's going to receive.": "这是描述，这是它将接收的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is going to be the input here we have the implementation of the function.": "这是输入，这里是函数的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After that we formatted very similar to the Python implementation.": "之后我们对其进行格式化，与 Python 实现非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The second was going to be called Get Forecast.": "第二个将被称为 get_forecast。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's going to be the display name in the MCP client.": "这将是 MCP 客户端中的显示名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The description is going to be get weather forecast for a location.": "描述将是获取某个位置的天气预报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And and here this is the input that is going to be it's going to be the latitude and longitude.": "这里是输入，它将是纬度和经度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here with that we say what type it's going to be here.": "在这里，我们说明它将是什么类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We make sure that we got valid input.": "我们确保获得了有效的输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we're going to build the URL of the forecast.": "然后我们将构建预报的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to make the actual request.": "然后我们将发出实际的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here and then we want to format a bit the response.": "在这里，然后我们要对响应进行一些格式化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nothing fancy here.": "这里没什么特别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um and the last thing how to run it.": "嗯，最后一件事是如何运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We create a main function which uses the standard input output transport layer.": "我们创建一个主函数，它使用标准输入输出传输层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we use the server dot connect instead of server dot run in the Python version.": "我们使用 server.connect 而不是 Python 版本中的 server.run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's pretty much it.": "基本就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, of course, if you want to integrate it like we did before, we need to run it with and": "最后，当然，如果你想按照我们之前的方式集成它，我们需要运行它，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this is us telling the MCP clients how to run the MCP server.": "这是我们在告诉 MCP 客户端如何运行 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After that we want to install the MVP package.": "之后我们要安装 MVP 包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we install the HTTP package to make HTTP responses.": "在这里我们安装 HTTP 包来发出 HTTP 响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly we want to create another file which is called weather.py.": "最后我们要创建另一个名为 weather.py 的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our MVP server file.": "所以这将是我们的 MVP 服务器文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay so we did three things.": "好了，我们做了三件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We initialized our project.": "我们初始化了项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We created a virtual environment to have our dependencies.": "我们创建了一个虚拟环境来存放依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We added and installed our dependency.": "我们添加并安装了依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, we created a new file which our MCP server is going to live.": "最后，我们创建了一个新文件，我们的 MCP 服务器将运行在其中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If I go back to GitHub to the MCP protocol, quick resources and let's go to the Python weather server,": "如果我回到 GitHub 的 MCP 协议、快速资源，然后进入 Python 天气服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this is what we have right here.": "这就是我们这里所拥有的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here we have this pyproject.toml.": "我们可以看到这里有这个 pyproject.toml 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to have all the dependencies and all the information about this project.": "所以这将包含该项目的所有依赖项和所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see that this is a simple MCP server.": "所以我们可以看到这是一个简单的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those are the dependencies that the MCP server needs.": "这些是 MCP 服务器需要的依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The entry point is going to be at weather py file.": "入口点将是 weather.py 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to run the main function.": "它将运行 main 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here is the weather dot pi here is going to be the implementation of the weather server.": "这里是 weather.py，这里将是天气服务器的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's start to write the code.": "现在让我们开始编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean we're not going to write.": "我的意思是，我们不打算直接编写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a walkthrough.": "这是一个演示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to see the end code in the repository.": "我们将在仓库中查看最终代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again we're not going to write the code right now.": "再次强调，我们现在不打算编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to do it later in the course.": "我们将在课程稍后部分进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now we're simply going to see how it looks and how it feels.": "现在我们只是来看看它的外观和感觉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first level is to understand.": "所以第一阶段是理解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The second level is to do it ourselves in a different use case.": "第二阶段是在不同的用例中亲自动手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we're importing and typing any we're putting Reporting HTTP eggs to make HTTP response.": "所以在这里我们导入并进行类型标注，我们放入 Reporting HTTP eggs 来发出 HTTP 响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're importing from the MCP SDK the from server that fast MCP the fast MCP object.": "我们从 MCP SDK 的 server 中导入 fast MCP，即 fast MCP 对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to initialize our MCP server.": "所以这将初始化我们的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to create an object of the MCP server from the SDK.": "所以我们将从 SDK 创建一个 MCP 服务器对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to call this server weather.": "我们将把这个服务器命名为 weather。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we're going to have two consts.": "现在我们将有两个常量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So one is going to be the base URL to what we're going to request.": "其中一个是我们要请求的基础 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a generic API weather URL which is free.": "这是一个免费的通用天气 API URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um and the user agent, when we're going to make the request we want to say it came from the weather": "嗯，还有用户代理，当我们发出请求时，我们想说明它来自天气",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:app.": "应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very basic initialization.": "所以这是非常基础的初始化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is right now is enough to have an MCP server which does nothing right now, but it has the": "目前这足以拥有一个 MCP 服务器，虽然它现在什么都不做，但它有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:name of weather.": "weather 这个名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to add capabilities for this MCP server.": "现在我们要为这个 MCP 服务器添加功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we would want to do is to give it the ability to make requests to get the weather.": "所以我们想做的是赋予它发出请求以获取天气的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to label this functionality of getting the weather as a tool that we will provide to the": "我们想将获取天气的这一功能标记为一个工具，我们将提供给",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LM.": "LM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP protocol is how the MCP client connects and talks to an MCP server.": "MCP 协议是 MCP 客户端连接 MCP 服务器并与之通信的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But where does the server live?": "但服务器运行在哪里呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Is it running in our machine?": "它是运行在我们的机器上吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Is it in the cloud?": "还是在云端？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And depending on the answer to this, we're going to have different transport types for the MCP protocol.": "根据这个问题的答案，MCP 协议将会有不同的传输类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's start with the MCP server which is running locally.": "让我们先从本地运行的 MCP 服务器开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And today this is the most popular way to use MCP servers.": "如今，这是使用 MCP 服务器最流行的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And historically this is how the MCP protocol got very, very popular with people running the MCP server": "从历史上看，这就是 MCP 协议变得非常非常流行的原因，人们在本地机器上运行 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on their local machine.": "在他们的本地机器上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when an MCP server runs locally in the same machine, I mean that it is running in the same machine": "所以，当 MCP 服务器在同一台机器上本地运行时，我的意思是它与客户端运行在同一台机器上",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:as the client.": "与客户端一起。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So one machine, which in most cases is going to be our computers are going to host both the MCP server": "因此，一台机器（在大多数情况下是我们的电脑）将同时托管 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the MCP client.": "和 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And up until now, the examples we saw are using cloud, desktop and cursor.": "到目前为止，我们看到的示例使用的是 Claude Desktop 和 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in both cases we had a local application in our computer.": "在这两种情况下，我们的电脑上都有一个本地应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be cursor or cloud desktop.": "也就是 Cursor 或 Claude Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the server was also running locally and it was actually running locally as a sub process.": "服务器也在本地运行，实际上是作为一个子进程在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now how this is worked is actually very simple.": "它的工作原理其实非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We basically when we configure the local running server with the Stdio transport, then we give the": "基本上，当我们使用 Stdio 传输配置本地运行的服务器时，我们会向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:client instructions of how to download the code if it's not currently downloaded and hosted in our machine,": "客户端提供指令，告诉它如果代码目前尚未下载并托管在我们的机器上，该如何下载代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and how to run it.": "以及如何运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is in the typical configuration.": "这是典型的配置方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, you can see the npx command pointing it to a repository where to download the code, and": "例如，你可以看到 npx 命令指向一个仓库来下载代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then the npm package manager is going to run and execute the code.": "然后 npm 包管理器将运行并执行该代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the interesting thing about a local running server is that we're going to have an NTP server sub": "现在，关于本地运行服务器的一个有趣点是，我们将为每个 MCP 客户端运行一个 MCP 服务器子",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:process running for each MCP client.": "进程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we have the same server that is going to be connected to different clients, let's say to cloud": "因此，如果我们有同一个服务器要连接到不同的客户端，比如 Claude",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and to cursor.": "和 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:At the same time we're going to have different instances and different subprocesses for the MCP server.": "与此同时，我们将为 MCP 服务器拥有不同的实例和不同的子进程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because the MCP servers and the clients running the same machine and their different subprocesses,": "因为 MCP 服务器和客户端运行在同一台机器上，且属于不同的子进程，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then they can communicate via the stdio channel.": "那么它们就可以通过 stdio 通道进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The standard input output and securitywise a local MCP server is actually very dangerous because it's": "即标准输入输出。从安全角度来看，本地 MCP 服务器实际上非常危险，因为它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:literally remote code execution.": "字面上就是远程代码执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I elaborate a lot about MCP security in this course.": "我在本课程中详细阐述了关于 MCP 安全的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and in this course, we're going to see and have a lot of examples of local running MCP servers,": "嗯，在本课程中，我们将看到并拥有许多本地运行 MCP 服务器的示例，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because at the moment it is the most popular use case.": "因为目前这是最流行的用例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I like to think of this like junk food.": "所以我喜欢把它比作垃圾食品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We all know junk food is bad for us, but we still eat it.": "我们都知道垃圾食品对身体不好，但我们还是会吃。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the same with local running MCP servers.": "本地运行的 MCP 服务器也是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We know that they're dangerous, but we still do it, so keep that in mind.": "我们知道它们很危险，但我们还是会这样做，所以请记住这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so we talked about the local MCP servers communicating via the Stdio channel.": "好了，我们已经讨论了通过 Stdio 通道进行通信的本地 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about the case where we want to run the MCP server in a different machine, let's say": "现在让我们讨论一下想要在另一台机器上运行 MCP 服务器的情况，比如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the cloud.": "在云端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll actually be doing this in the course in this section anyways.": "无论如何，我们实际上会在本课程的这一章节中进行这项操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in case we want our MCP to be remote.": "所以，如果我们希望我们的 MCP 是远程的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means that the server does not live on the same machine as the client.": "这意味着服务器与客户端不在同一台机器上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I put here an asterix because we're going to discuss this caveat.": "我在这里放了一个星号，因为我们将讨论这个注意事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because the MCP client and the MCP server are not in the same machine, became not communicate via": "因此，由于 MCP 客户端和 MCP 服务器不在同一台机器上，它们无法通过",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Stdio channel.": "Stdio 通道进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we have instead they can communicate via HTTP.": "相反，它们可以通过 HTTP 进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the HTTP transport in MCP is called HTTP.": "现在，MCP 中的 HTTP 传输方式就叫做 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the newest one.": "这是最新的一种。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We also have server side events, a transport which is officially deprecated.": "我们还有服务器发送事件（SSE），这是一种官方已弃用的传输方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, de facto is still used by many clients and still is the default.": "然而，实际上它仍被许多客户端使用，并且仍然是默认设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's why I'm also going to show it in the course.": "这就是为什么我也要在课程中展示它的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so with a remote HTTP setup the MCP server runs on an external machine preferably running": "好了，在远程 HTTP 设置下，MCP 服务器运行在外部机器上，最好是运行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the cloud, maybe inside of a container.": "在云端，可能是在容器内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will allow a single server to be shared by thousands of clients.": "这将允许成千上万个客户端共享同一个服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we have complex computations, they're all going to happen remotely on the server, which is": "如果我们有复杂的计算，它们都将在服务器上远程进行，这",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to save resources on our local running machine which is running the client.": "将节省运行客户端的本地机器上的资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also going to ensure that all the clients are going to be using the latest code, because there": "这还将确保所有客户端都使用最新的代码，因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is only a single central server that needs to be updated.": "只需要更新一个中央服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, connecting to a remote server is easy.": "现在，连接到远程服务器很容易。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All we need to do is to give the client the URL, and we don't need to install a script and to download": "我们只需要给客户端提供 URL，不需要安装脚本，也不需要下载",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code or anything, we simply connect it via HTTP.": "代码或任何东西，我们只需通过 HTTP 连接即可。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we're in a very interesting situation now because not all hosts supports HTTP directly.": "现在我们处于一个非常有趣的情况，因为并非所有主机都直接支持 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there is a workaround for this with a proxy which is going to talk to our MCP client via Sdio,": "对此有一个解决方法，即使用代理，该代理将通过 Stdio 与我们的 MCP 客户端通信，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it's going to make the HTTP request for us.": "并为我们发起 HTTP 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't worry about it.": "不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to elaborate a lot about this in this course, including lots of hands on.": "我们将在本课程中详细阐述这一点，包括大量的动手实践。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So please, I hope I'm not scaring you too much.": "所以，希望我没有把你吓到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about the asterisks.": "现在让我们谈谈那个星号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I told you earlier.": "我之前提到过的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I was talking about the HTTP transport on remote NCP servers.": "我刚才在谈论远程 MCP 服务器上的 HTTP 传输。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the last thing I want to say in this topic is that technically, we can use the HTTP transport with": "关于这个话题，我想说的最后一件事是，从技术上讲，我们可以将 HTTP 传输用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:local running MCP servers, and what I mean by that is that we can run an MCP server locally in our": "本地运行的 MCP 服务器，我的意思是，我们可以在本地运行一个 MCP 服务器，在我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:localhost, and we'll do that in the course, and we don't have to deploy it in the cloud in order to": "localhost，我们会在课程中这样做，而且我们不必为了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:connect it with an MCP client via HTTP.": "通过 HTTP 将其与 MCP 客户端连接而将其部署到云端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this transport was made so we can later deploy it in the cloud and communicate with an external machine.": "因此，这种传输方式的设计初衷是让我们以后可以将其部署到云端，并与外部机器进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can actually run it in the same local machine.": "但实际上我们可以在同一台本地机器上运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll be showing examples of both types.": "我将展示这两种类型的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll be showing you examples of how to run a local MCP server that communicate via HTTP and via SSH": "因此，我将向你们展示如何运行一个通过 HTTP 和 SSH 进行通信的本地 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to an Amqp client, and we can even do the same by deploying it in the cloud.": "连接到 Amqp 客户端，我们甚至可以通过将其部署到云端来实现同样的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so up until now we have discussed the different transport types.": "好了，到目前为止，我们已经讨论了不同的传输类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We haven't really discussed how to implement them, and we haven't discussed how do they actually work": "我们还没有真正讨论如何实现它们，也没有讨论它们实际上是如何工作的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:under the hood.": "底层原理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the good news for you is that to implement them and to use the different transport types is super,": "所以对你们来说，好消息是实现它们并使用不同的传输类型非常、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:super easy.": "非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All we need to do is to switch a couple of strings.": "我们只需要切换几个字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When we run the MCP server, we need to tell the MCP server to either run with Stdio, or to run with": "当我们运行 MCP 服务器时，我们需要告诉 MCP 服务器是使用 Stdio 运行，还是使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the transport of HTTP, or to run with the transport of SSH.": "HTTP 传输运行，或者是使用 SSH 传输运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is it.": "就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now how do they work under the hood?": "那么，它们在底层是如何工作的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In 99% of the times you do not need to know this.": "在 99% 的情况下，你不需要知道这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is why I'm not going to cover it in the course.": "这就是为什么我不打算在课程中涵盖这部分内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can check out the specification and see the exact flow.": "你可以查看规范并了解确切的流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, you are going to get a very high level overview of the mechanism flow.": "不过，你将获得该机制流程的一个非常高层级的概述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So before we dive into the components of MCP, let's talk a bit about the general architecture and the": "在深入探讨 MCP 的组件之前，让我们先聊聊其通用架构和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:goal of MCP.": "MCP 的目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's recap on that.": "让我们对此进行一下回顾。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the model context protocol supposed to standardize how applications provide context to llms.": "因此，模型上下文协议（Model Context Protocol）旨在标准化应用程序向大语言模型（LLM）提供上下文的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So context to Llms can be very thin.": "因此，给大语言模型的上下文可以非常精简。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So context can be additional information to the prompt.": "上下文可以是提示词的附加信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A context can be maybe which tool to invoke.": "上下文也可以是可能需要调用的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And a context can even be the prompt itself.": "上下文甚至可以是提示词本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I know the last sentence sounds a bit funny, but I'll show you an example of it in later videos.": "我知道最后一句话听起来有点奇怪，但我会在后面的视频中给你们展示一个例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once we have a standard that becomes popular, then we start seeing insane things that are being built.": "一旦我们有了一个流行的标准，我们就会开始看到一些令人惊叹的东西被构建出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So take for example, this MCP server that Eric Dickerson wrote to cursor.": "以 Eric Dickerson 为 Cursor 编写的这个 MCP 服务器为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this MCP server is going to give the AI application which is cursor in this scenario to order food.": "这个 MCP 服务器将赋予 AI 应用程序（在这种情况下是 Cursor）订餐的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now you can see in the prompt he wrote I want FICA, where can I get Kane Cain.": "现在你可以看到他在提示词中写道：“我想要 FICA，哪里可以买到 Kane Cain。”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, I have no idea what it is.": "额，我完全不知道那是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Actually, I don't know what fika is as well, but let's see what he will get.": "实际上，我也不知道 fika 是什么，但让我们看看他会得到什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this MCP server is connected to his Uber Eats account, so he gave cursor the capability in tools": "这个 MCP 服务器连接到了他的 Uber Eats 账户，所以他赋予了 Cursor 工具能力",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to find the menu options, which he gets.": "去查找菜单选项，它确实找到了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it goes and it's going to filter by cannibal.": "然后它会根据肉桂卷（cannibal）进行过滤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it goes to get those results.": "然后它去获取这些结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's going to prompt the user to order it.": "然后它会提示用户进行订购。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to say yes I want to order.": "所以它会说“是的，我想订购”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to invoke the Order Food tool, and it's going to order this in this dish.": "它将调用“订餐”工具，并订购这个菜品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you what he got.": "让我给你们看看他收到了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a kind of pastry.": "这是一种糕点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It turns out it looks delicious.": "结果看起来很美味。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the point here is that you can do insane things with it.": "但这里的重点是，你可以用它做一些非常惊人的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here is the open source repo, which I will, by the way.": "这是开源仓库，顺便说一下，我会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Link.": "提供链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because MCP is like the USBC and let's say this MCP server is like an external device, we can go": "因为 MCP 就像 USB-C，而假设这个 MCP 服务器就像一个外部设备，我们可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and take it and connect it to another AI application like cloud desktop or windsurf and it would work": "把它连接到另一个 AI 应用程序，比如 Claude Desktop 或 Windsurf，它也能正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now notice I'm not talking about summit 3.7, for example.": "注意，我说的不是比如 Claude 3.7。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm talking about Cloud Desktop because Cloud Desktop is the AI application which uses under the hood": "我说的是 Claude Desktop，因为 Claude Desktop 是一个在底层使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the models of anthropic.": "Anthropic 模型的 AI 应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can be our own AI applications that we build, as long as we follow the protocol and implement it.": "也可以是我们自己构建的 AI 应用程序，只要我们遵循该协议并实现它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're supposed to see this in the course as well.": "我们在这门课程中也会看到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this gives a very convenient way to plug and play to our AI applications.": "这为我们的 AI 应用程序提供了一种非常方便的即插即用方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again, not models directly, but the AI applications.": "再次强调，不是直接针对模型，而是针对 AI 应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can connect them and enrich them with external data sources and tools.": "这样我们就可以连接它们，并利用外部数据源和工具来丰富它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll cover it later in this course.": "我们将在本课程的后面部分介绍这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's summarize the advantages we can see in the documentation as well.": "那么，让我们也总结一下我们在文档中可以看到的优势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When we develop MCP servers with the Python SDK, there are two main classes that we can use.": "当我们使用 Python SDK 开发 MCP 服务器时，有两个主要类可以使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can use the original low level implementation which is called server class, and we can use the recent.": "我们可以使用名为 server 类的原始低级实现，也可以使用最近推出的类。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the recommended abstraction which is called fast MCP class.": "这就是推荐的抽象，称为 FastMCP 类。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And fast MCP class provides us with higher level wrapping upon the server class to simplify the development": "FastMCP 类在 server 类之上为我们提供了更高级别的封装，以简化开发",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:process.": "过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The original server class is the low level implementation, and if we want to build something that we": "原始的 server 类是低级实现，如果我们想构建一些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:can use, it will require us to have some extensive repetitive coding with a lot of boilerplate like": "可用的东西，它将需要我们进行大量重复性的编码，并带有许多样板代码，例如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:defining function, logic tool calling capabilities, tool listing and detailing input schemas, and": "定义函数、逻辑工具调用能力、工具列表和详细的输入模式，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:fast MCP abstraction dramatically streamlines this effort and addresses it, and fast MCP enables us": "FastMCP 抽象极大地简化了这项工作并解决了这些问题，FastMCP 使我们能够",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to create servers tools by simply writing standard Python functions in annotating them with decorators.": "通过简单地编写标准 Python 函数并使用装饰器对其进行注释来创建服务器工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It automatically handles the back end processes, inferring tool names, descriptions, the input schemas,": "它会自动处理后端过程，推断工具名称、描述、输入模式，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and directly from our functions.": "并且直接从我们的函数中获取。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we only need to implement the function and it does all the work under the hood for us using the server": "因此，我们只需要实现该函数，它就会在后台使用 MCP 的 server",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:objects of Smcp.": "对象为我们完成所有工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is greatly reducing the code and complexity when we want to develop MCP servers.": "当我们想要开发 MCP 服务器时，这大大减少了代码量和复杂性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it is highly recommended to use fast MCP whenever it's possible, because it's so easy and it has": "现在，强烈建议尽可能使用 FastMCP，因为它非常简单，并且拥有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tons of feature support and active development in a very strong community backing.": "大量的功能支持、活跃的开发以及强大的社区支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think in 99% of the times, I would recommend using this class, and only in rare cases, which": "所以我认为在 99% 的情况下，我会推荐使用这个类，只有在极少数情况下，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:quite frankly, I haven't encountered even myself.": "坦率地说，甚至连我自己都没遇到过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You should use the server class, which is the low level.": "你才应该使用 server 类，也就是低级实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now there is another class and it's in a different package in an open source called fast SCP.": "现在还有另一个类，它位于一个名为 fastmcp 的开源软件包中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Photo by Jeremiah Lewin.": "图片由 Jeremiah Lewin 提供。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, Jeremiah was the original author and creator of the fast Mcpi class, which was merged to the": "Jeremiah 是 FastMCP 类的原作者和创建者，该类已被合并到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP protocol, but he open sourced the 2.0 version, which is highly maintained and introduces tons": "MCP 协议中，但他开源了 2.0 版本，该版本维护良好并引入了大量",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of features.": "功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When we want to take our MCP to production fast, MCP 2.0 is highly maintained and is de facto the most": "当我们想要快速将 MCP 投入生产时，fastmcp 2.0 维护良好，并且是事实上最",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:popular wrapper around the MCP protocol people use to build MCP, and I actually interviewed Jeremiah": "受欢迎的 MCP 协议封装器，人们用它来构建 MCP，实际上我后来采访了 Jeremiah",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:later in this course.": "在本课程的后续部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very interesting interview.": "非常有趣的采访。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I highly recommend you watching it.": "我强烈建议你观看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And during this course we'll be using fast MCP from the MCP Python SDK, as well as using fast MCP from": "在本课程中，我们将使用来自 MCP Python SDK 的 FastMCP，以及来自",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:fast MCP 2.0 to a open source package.": "开源软件包 fastmcp 2.0 的 FastMCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's actually backward compatible.": "所以它实际上是向后兼容的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can actually use fast NCP 2.0 for all of the projects here.": "因此，你实际上可以在这里的所有项目中使用 fastmcp 2.0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a huge list of integrations and tools and data sources we can plug and play to our LMS.": "我们有大量的集成、工具和数据源，可以即插即用地接入我们的 LMS。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is number one.": "这是第一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Number two is that really the core of AI application development is the fact that we are not coupled": "第二点是，AI 应用开发的核心在于我们不与任何厂商绑定",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to any LLM vendor or to any AI application builder.": "无论是 LLM 供应商还是 AI 应用构建工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we simply need to write our tools that we're using.": "所以我们只需要编写我们正在使用的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the core functionality.": "这就是核心功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can migrate and use them in different vendors, which is very convenient.": "我们可以将它们迁移并在不同的供应商中使用，这非常方便。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, link chain, the open source framework does this as well.": "顺便提一下，LangChain 这个开源框架也能做到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I will make a video really comparing the two and seeing how they blend in together and what value": "但我会专门制作一个视频来对比这两者，看看它们如何融合，以及各自能提供什么价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:does each one give.": "各自能提供什么价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There are some problems in AI engineering that they both solve, but each one does it in a different": "AI 工程中有些问题是它们都能解决的，但各自的方式不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:way.": "方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yet those ways that they solve those problems do not overlap.": "然而，它们解决这些问题的方式并不重叠。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, the plug and play capability.": "例如，即插即用的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we'll dive deep into this when we'll compare link chain and MCP.": "但当我们要对比 LangChain 和 MCP 时，我们会深入探讨这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the next video we'll cover MCP, the model context protocol core components.": "所以在接下来的视频中，我们将介绍 MCP（模型上下文协议）的核心组件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's list them.": "让我们列举一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now we have on the left side the MCP host.": "现在，左侧是 MCP 主机（Host）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is for example Cloud desktop an IDE like cursor or windsurf or any other specialized AI application": "例如，这可以是 Cloud 桌面、像 Cursor 或 Windsurf 这样的 IDE，或者是任何其他专门的 AI 应用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like an agent that supports the MCP protocol.": "比如支持 MCP 协议的智能体（Agent）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those are the application we're going to augment with the MCP protocol.": "这些就是我们要通过 MCP 协议进行增强的应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're either going to give them external tools that they didn't have, or maybe connect them to a": "我们要么为它们提供原本没有的外部工具，要么将它们连接到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:data source that they didn't have access to, or even to specific prompts.": "它们原本无法访问的数据源，甚至是特定的提示词（Prompts）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the left side.": "这就是左侧部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And on the right side is what we're going to augment those applications with.": "而右侧则是我们要用来增强这些应用的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can either be some access to external tools like making a certain API call or like getting the": "它可以是访问外部工具，比如进行特定的 API 调用，或者获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can be searching in a database.": "也可以是在数据库中进行搜索。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It could be knowledge and information like PDFs, like a lot of text.": "可能是知识和信息，比如 PDF 或大量的文本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the list goes on and on and on.": "诸如此类，不胜枚举。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's time to talk about MCP servers.": "现在该谈谈 MCP 服务器（Servers）了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the servers are the component that will expose those resources, those tools, those prompts.": "服务器是暴露这些资源、工具和提示词的组件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they will be the proxy, the gateway however you want to call it that will expose that functionality.": "它们将作为代理或网关（随你怎么称呼），来暴露这些功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to expose that functionality.": "为了暴露这些功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the actual protocol.": "这就是实际的协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It needs to have certain methods and certain functions.": "它需要具备某些方法和函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example least prompts, get prompt list tools, call tool list resource templates, and progress": "例如 list_prompts、get_prompt、list_tools、call_tool、list_resource_templates 以及 progress",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:notification and we'll cover it in the server section once we implement MCP servers.": "notification（进度通知），我们将在实现 MCP 服务器时的服务器章节中介绍这些内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The point here is once we implement an MCP server, then we can basically connect it to any MCP host": "这里的重点是，一旦我们实现了一个 MCP 服务器，我们基本上就可以将其连接到任何支持该协议的 MCP 主机",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that is supporting the protocol.": "上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is simply just to give you a heads up of what's happening in the course.": "所以这只是为了让你提前了解一下课程中发生的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I know the naming was confusing.": "我知道这些命名很让人困惑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Trust me, I was confused myself when I first understood it.": "相信我，当我第一次理解它时，我自己也很困惑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so just to wrap this up, so we have the server object, which is the low level implementation.": "好了，总结一下，我们有 server 对象，它是底层实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're not going to use it.": "我们不打算使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's hardly even used.": "它几乎很少被用到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have the fast NCP wrapper inside the MCP Python SDK.": "在 MCP Python SDK 中还有 fast NCP 封装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to use it sometimes.": "我们有时会用到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have the newest version, fast MCP 2.0 from the fast MCP package.": "我们还有最新版本，即来自 fast MCP 包的 fast MCP 2.0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are going to use it as well.": "我们也会用到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, for the course you can use those two objects interchangeably.": "顺便说一下，在课程中你可以交替使用这两个对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're backwards compatible.": "它们是向后兼容的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is just as an FYI.": "所以这只是供你参考。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you're going to start a new project with MCP, I would highly recommend you starting with MCP": "如果你要用 MCP 开始一个新项目，我强烈建议你从 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:2.0 and package.": "2.0 和相关包开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean, if I call it an SP host, this means it does support the protocol.": "我的意思是，如果我称其为 SP 主机，这意味着它确实支持该协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means we can write functionality once and then plug it to, for example, many, many MCP hosts.": "所以这意味着我们可以只编写一次功能，然后将其接入，例如，许多许多 MCP 主机。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the big deal over here.": "所以这就是这里的重点所在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what is so game changing.": "而且这就是它如此具有变革性的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to connect those MCP servers into the MCP host.": "所以，为了将这些 MCP 服务器连接到 MCP 主机中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, let's take the concrete example we saw earlier in the course.": "例如，让我们以课程前面看到的具体例子为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to connect the weather map server into cloud desktop, and then we'll need to do it with an": "我们想要将天气地图服务器连接到云桌面，然后我们需要通过一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Mctp client.": "Mctp 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the Mctp client, and again we'll cover it in depth in the course sits inside the MCP hosts.": "所以 Mctp 客户端（我们将在课程中深入讲解）位于 MCP 主机内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be able to interact and to talk with the MCP servers.": "而且它将能够与 MCP 服务器进行交互和对话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they're going to do this via the MCP protocol.": "它们将通过 MCP 协议来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the language that they're going to interact with.": "所以这就是它们进行交互的语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the protocol.": "而且这就是该协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's important also to note, by the way, that there is a 1 to 1 connection between an MCP client": "顺便说一下，同样重要的是要注意，在 MCP 客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and an MCP server.": "和 MCP 服务器之间存在一对一的连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can't have an MCP client that talks to multiple MCP servers.": "所以你不能让一个 MCP 客户端与多个 MCP 服务器通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So MCP hosts, if you want to connect them with multiple MCP servers, then we'll need to have multiple": "所以对于 MCP 主机，如果你想将它们与多个 MCP 服务器连接，那么我们就需要有多个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP clients inside them.": "内部的 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll talk about it in depth in the client section when we will be implementing an MCP client.": "我们将在实现 MCP 客户端时的客户端章节中深入讨论这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there Ethan here.": "大家好，我是 Ethan。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video I want to introduce MCP Inspector, which is an open source project by the anthropic": "在这段视频中，我想介绍 MCP Inspector，这是 Anthropic 团队的一个开源项目，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:team, which came up with the Model Context protocol, which is going to help us and enable us to troubleshoot,": "该团队提出了模型上下文协议 (Model Context Protocol)，它将帮助并使我们能够进行故障排除、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:debug and trace and to see what actually happens in our MCP server.": "调试和追踪，并查看我们的 MCP 服务器中实际发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a super important tool when building MCP servers, which makes your life a lot easier.": "这是构建 MCP 服务器时一个非常重要的工具，它会让你的开发工作变得轻松得多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Developing them in this video is only a quick overview and an introduction.": "在这段视频中开发它们只是一个快速的概览和介绍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the rest of the course, we're going to see most of the useful features of the MCP Inspector.": "在课程的其余部分，我们将看到 MCP Inspector 的大部分实用功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So MCP Inspector is an interactive dev tool designed for testing and debugging MCP servers.": "MCP Inspector 是一个专为测试和调试 MCP 服务器而设计的交互式开发工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it allows developers to inspect and interact with the MCP server without requiring any installation.": "它允许开发人员在无需任何安装的情况下检查 MCP 服务器并与之交互。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can be run locally from npm.": "因此，它可以直接通过 npm 在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it has a bunch of very useful features that are going to help us.": "它有一系列非常有用的功能，将为我们提供帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once we develop and use MCP servers, we can connect into an MCP server.": "一旦我们开发并使用 MCP 服务器，我们就可以连接到一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can check out the resources tab, which will list all the available resources and show the metadata": "我们可以查看资源 (Resources) 选项卡，它将列出所有可用资源并显示元数据，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and allow the content inspection, which is very convenient.": "并允许进行内容检查，这非常方便。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a section and a tab on prompts which will display the prompt.": "我们有一个关于提示词 (Prompts) 的部分和选项卡，它将显示提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Templates, show the prompt arguments, and it will even allow us to enable testing with custom inputs": "模板，显示提示词参数，它甚至允许我们使用自定义输入",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to the prompt templates, and it also has a tools tab which will list all the available tools, all": "对提示词模板进行测试，它还有一个工具 (Tools) 选项卡，将列出所有可用工具、所有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:their schemas, and will even allow us to test those tools with custom inputs.": "它们的架构 (Schemas)，甚至允许我们使用自定义输入来测试这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We also have a notifications pane which will present logs and notifications from the server.": "我们还有一个通知面板，它将显示来自服务器的日志和通知。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let me show you this in action.": "好了，让我向你展示它的实际操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I'm going to connect to a server running in my localhost.": "在这里，我将连接到运行在我的本地主机 (localhost) 上的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to use an SSH server not an stdio server.": "我将使用 SSH 服务器，而不是 stdio 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways let's click connect.": "无论如何，让我们点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this server exposes tools.": "这个服务器公开了工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and check out the tools.": "那么让我们去查看一下工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and list first all the tools.": "让我们先列出所有的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this specific MCP server is a documentation MCP server which help us to fetch dynamically the latest": "这个特定的 MCP 服务器是一个文档 MCP 服务器，它可以帮助我们动态获取最新的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and greatest documentation of famous packages.": "和最优秀的知名软件包文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So do not worry about what exactly does this server does, but I want to show you the functionality": "所以不用担心这个服务器具体是做什么的，但我主要想向你展示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the MCP Inspector app.": "MCP Inspector 应用程序的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here you can see after we listed the tools we have here two tools.": "在这里你可以看到，在我们列出工具之后，我们有两个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is list document sources.": "一个是 list document sources（列出文档源）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can even run the tool and we can see what output do we get.": "我们甚至可以运行该工具，看看我们得到了什么输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other is fetch docs.": "另一个是 fetch docs（获取文档）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I can paste here a dynamic input.": "所以我可以在这里粘贴一个动态输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just fix the input here.": "让我修正一下这里的输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see the result of executing this tool.": "我们可以看到执行这个工具的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers are simply wrappers or interfaces that federate access to various systems and tools, making": "MCP 服务器仅仅是封装器或接口，它们联合了对各种系统和工具的访问，使得",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:them accessible to AI applications in a standardized way.": "它们能以标准化的方式被 AI 应用程序访问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they do this by exposing functionality through three primary interfaces.": "它们通过三个主要接口公开功能来实现这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first one is tools, so model controlled functions that the AI can invoke when needed.": "第一个是工具，即 AI 在需要时可以调用的由模型控制的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we saw the example of the weather tool.": "我们看到了天气工具的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Get weather, get forecast get alerts.": "获取天气、获取预报、获取警报。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they all boil down to functions.": "它们最终都归结为函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can expose any functionality that we want because we can implement in that function everything": "因此我们可以公开任何想要的功能，因为我们可以在该函数中实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we want from reading data, from writing data to other systems.": "我们想要的一切，从读取数据到向其他系统写入数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can do everything we want in the tools we have total freedom.": "我们可以在工具中做任何想做的事情，我们拥有完全的自由。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the AI system and here we saw cursor and we saw cloud desktop or any other application it can decide": "因此 AI 系统（这里我们看到了 Cursor，也看到了 Claude Desktop 或任何其他应用程序）可以决定",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:when to use those tools based on the context.": "何时根据上下文使用这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The second thing that MCP servers can expose are resources.": "MCP 服务器可以公开的第二项内容是资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And resources are application controlled data that is exposed to the AI system.": "资源是公开给 AI 系统的由应用程序控制的数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can be static data like PDF documents, like text files, images, JSON, whatever format you": "它可以是静态数据，如 PDF 文档、文本文件、图像、JSON，或者任何你想要的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:want.": "格式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it can also be dynamic.": "但它也可以是动态的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you simply tell how to get those resources dynamically.": "所以你只需说明如何动态地获取这些资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they don't have to be static.": "它们不必是静态的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll see an example in the next couple of videos of static resources and dynamic resources.": "在接下来的几个视频中，我们将看到静态资源和动态资源的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the last functionality that MCP servers expose can be prompts.": "MCP 服务器公开的最后一项功能可以是提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It prompts are user controlled templates for common interactions, and they are predefined templates": "提示词是用户控制的用于常见交互的模板，它们是预定义的模板，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that the users can invoke.": "用户可以调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This usually helps to standardize rice complex interactions.": "这通常有助于标准化复杂的交互。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I know the resources and prompts may not be very clear right now, but I promise you, once we see": "我知道资源和提示词现在可能还不是很清楚，但我向你保证，一旦我们看到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:examples of them and this is really going to happen in the next couple of videos, will understand that": "它们的示例（这确实会在接下来的几个视频中发生），你就会明白",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this is very intuitive and actually very elegant.": "这是非常直观且实际上非常优雅的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about building map servers and what options do we have.": "让我们谈谈构建 MCP 服务器以及我们有哪些选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all we can manually create an NCP server.": "首先，我们可以手动创建一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this would involve us to write maybe a couple of hundred of Python code or Node.js code.": "这将涉及我们编写可能几百行 Python 代码或 Node.js 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Second, we can also use AI to generate NCP servers.": "其次，我们还可以使用 AI 来生成 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll actually do this in the course.": "我们实际上会在课程中这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So tools like cursor or NCP generator are going to help us do this.": "像 Cursor 或 MCP 生成器之类的工具将帮助我们完成这项工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can also use community built NCP servers.": "我们还可以使用社区构建的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now there are thousands of community built servers which are open source, which we can clone": "目前有成千上万个社区构建的开源服务器，我们可以克隆",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and we can modify if we want to.": "并且如果愿意的话可以进行修改。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we saw an example of the weather tool weather map server.": "刚才我们看到了天气工具天气 MCP 服务器的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want we can edit it because we have the source code.": "如果你想，我们可以编辑它，因为我们有源代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, there are official integrations from companies like Cloudflare like stripe, which maintain": "最后，还有来自 Cloudflare、Stripe 等公司的官方集成，它们维护着",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:their NCP servers.": "它们自己的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think this is very similar to link chain where each LM vendor or vector store vendor maintain": "我认为这与 LangChain 非常相似，每个大模型厂商或向量数据库厂商都维护着",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:their own link chain packages.": "他们自己的 LangChain 软件包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, we have a link chain package for link chain OpenAI.": "例如，我们有针对 LangChain OpenAI 的 LangChain 软件包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Link chain.": "LangChain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Google.": "Google。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Vertex AI link chain.": "Vertex AI LangChain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anthropic or link chain.": "Anthropic 或 LangChain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pinecone.": "Pinecone。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Chrome ADB etc..": "Chroma DB 等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the same thing is going to be with NCP servers, where each company which have a product that they": "所以 MCP 服务器也会是同样的情况，每家拥有想要展示的产品",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:want to expose and they want other people to use, they will maintain the NCP server.": "并希望他人使用的公司，都会维护自己的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and they also open source it.": "而且他们还会将其开源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this also gives the motivation to do this because it will increase usage of their product.": "这也提供了这样做的动力，因为这会增加他们产品的使用量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, when stripe is going to expose an NCP server and it maintains it.": "例如，当 Stripe 发布并维护一个 MCP 服务器时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It actually increases the usage of their product.": "这实际上增加了他们产品的使用量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the companies really have incentives to maintain and to write really good MCP servers.": "因此，这些公司确实有动力去维护并编写非常优秀的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this brings me into a very important point I want to address.": "这引出了我想谈论的一个非常重要的点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do not reinvent the wheel.": "不要重复造轮子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in case we need to implement an MCP server with functionality of a third party service, we should": "因此，如果我们需要实现一个具有第三方服务功能的 MCP 服务器，我们应该",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:first check what kind of MCP servers the third party has implemented.": "首先检查该第三方已经实现了什么样的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Most chances that they did implement an MCP server.": "很有可能他们已经实现了一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can use or we can borrow functionality.": "我们可以直接使用或借鉴其功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example stripe.": "例如 Stripe。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I do not need to reinvent the wheel and to implement my own stripe integration, because the stripe": "我不需要重复造轮子去实现我自己的 Stripe 集成，因为 Stripe",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:team has already made a pre-built MCP server.": "团队已经制作了一个预构建的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm telling you this so you won't be in a rabbit hole of implementing a bunch of MCP servers that": "我告诉你这些是为了让你不要陷入实现一堆别人已经实现过的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:somebody else has already implemented.": "MCP 服务器的困境中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if there is a feature that is missing, I think it's a good idea that you would contact that third": "如果缺少某个功能，我认为你可以联系那个第三方，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:party, for example, stripe, to see if they have it on their roadmap to implement the feature that": "例如 Stripe，看看他们是否在路线图中计划实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you want.": "你想要的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or maybe they can implement something custom made for you.": "或者也许他们可以为你实现一些定制化的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So how MCP servers can be ran.": "那么 MCP 服务器是如何运行的呢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all, they can be run locally via the standard input output channel.": "首先，它们可以通过标准输入输出通道在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we saw this earlier in the course when we ran locally the weather server.": "我们在课程早些时候本地运行天气服务器时已经见过了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But they can also run remotely via server sent events or SSH.": "但它们也可以通过服务器发送事件或 SSH 远程运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll also see in the course an example for that.": "我们在课程中也会看到相关的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they can also run as Docker containers.": "它们还可以作为 Docker 容器运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I might show this in the course.": "我可能会在课程中展示这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Please let me know if you want this kind of content.": "如果你想要这类内容，请告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right I want to talk about a final functionality that MCP servers offer us to implement.": "好了，我想谈谈 MCP 服务器提供给我们实现的最后一项功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is sampling.": "那就是采样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this actually allows the MCP server to request the host AI system, let's say cursor or cloud desktop": "这实际上允许 MCP 服务器向宿主 AI 系统（例如 Cursor 或云桌面）发出请求",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to generate a completion given to a kind of prompt.": "根据某种提示词生成补全。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is really powerful.": "这确实非常强大。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this really opens the door for a lot of functionality, but also has some security implications": "这确实为许多功能打开了大门，但也带来了一些安全方面的影响",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and privacy implications.": "以及隐私方面的影响。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll cover it in depth in the rest of the course.": "我们将在课程的其余部分深入探讨这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to touch the topic of composability.": "我还想谈谈可组合性这个话题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So any application or agent can be both an MCP client and server.": "因此，任何应用程序或智能体都可以同时作为 MCP 客户端和服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this really enables us to have this kind of multi-layered agentic application that allows us to": "这确实使我们能够拥有这种多层级的智能体应用，从而让我们能够",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:have specialized agents that focus on particular tasks.": "拥有专注于特定任务的专业智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk a bit about the future.": "让我们来谈谈未来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the MCP ecosystem is evolving rapidly.": "MCP 生态系统正在迅速发展。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there are a lot of cool developments that are going to come out soon.": "很快就会有很多酷炫的进展出现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all, let's talk about registry and discovery.": "首先，让我们谈谈注册和发现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there will be a central registry API for discovering MCP servers.": "将会有一个用于发现 MCP 服务器的中央注册表 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is really cool.": "这真的很酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can list your MCP server that you implement and let other people use it.": "你可以列出你实现的 MCP 服务器，并让其他人使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Another thing, we can have verification of official servers.": "另一件事是，我们可以对官方服务器进行验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because everybody can implement an MCP server and put it on GitHub, this really opens the door for": "因为任何人都可以实现 MCP 服务器并将其放在 GitHub 上，这确实为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a supply chain attack.": "供应链攻击打开了大门。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a malicious user can upload an SMTP server calling it stripe MCP server, and actually put their": "恶意用户可以上传一个 SMTP 服务器并将其命名为 Stripe MCP 服务器，实际上却放入了他们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:malicious code that will steal your data or even run malicious code on your computer.": "恶意代码，用来窃取你的数据，甚至在你的电脑上运行恶意代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we have verification of official MCP servers, this really helps mitigate this issue.": "因此，如果我们对官方 MCP 服务器进行验证，这将有助于缓解这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think in the future we'll have self-evolving agents that can discover new capabilities in runtime.": "我认为未来我们将拥有能够在运行时发现新能力的自进化智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is very cool in my opinion.": "在我看来，这非常酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's talk even more about the future.": "让我们进一步探讨未来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I tweeted a while ago saying that website will expose their functionality and their content to agents.": "不久前我发推文说，网站将向智能体开放其功能和内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just like we have a robot.txt that helps search engines to index the website, then web applications": "就像我们有 robot.txt 来帮助搜索引擎索引网站一样，Web 应用程序",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:are going to help agents discover them and are going to help the agents navigate through their applications.": "将帮助智能体发现它们，并帮助智能体在它们的应用程序中导航。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what will be in the future.": "这就是未来的趋势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll have well known endpoints.": "我们将拥有众所周知的端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a standard endpoint like a well known app.json for websites to expose their MCB capabilities": "这是一个标准端点，类似于众所周知的 app.json，供网站公开其 MCP 能力",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so they can be used by MCP clients.": "以便 MCP 客户端使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see in the near future also support for authentication.": "在不久的将来，我们还将看到对身份验证的支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So support for protocols like OAuth 2.0 for secure access of external systems and also session tokens": "例如支持 OAuth 2.0 等协议以安全访问外部系统，以及支持会话令牌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for maintaining connections.": "以维持连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And really, we can really enhance the security of the MCP protocol by integrating this.": "确实，通过集成这些功能，我们可以显著增强 MCP 协议的安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once this will be implemented I will be diving deep into this topic.": "一旦这被实施，我将深入研究这个话题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LM dot.": "LM 点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT is a standard file which is designed to help Llms and AI agents to better understand and process": "TXT 是一种标准文件，旨在帮助大语言模型（LLM）和 AI 智能体更好地理解和处理",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:website content.": "网站内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this file typically is placed in the root directory of a given website, and provides a concise summary": "因此，该文件通常放置在给定网站的根目录下，并提供简明摘要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the site's most important content and structure in a machine readable markdown format.": "以机器可读的 Markdown 格式呈现网站最重要的内容和结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the purpose of this is to give those AI systems like ChatGPT, Llms like Google, Gemini, or your": "因此，其目的是让 ChatGPT 等 AI 系统、Google Gemini 等大语言模型，或者您的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:application based AI agents to process the web content more accurately and more efficiently.": "基于应用程序的 AI 智能体能够更准确、更高效地处理网页内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the format is usually a markdown file, and the content will include the URLs to the important pages": "因此，其格式通常是一个 Markdown 文件，内容将包括指向网站重要页面的 URL，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the website, with a brief description of each page's content and the purpose of that page.": "以及每个页面内容和用途的简短描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it may have an optional additional information.": "它还可能包含可选的附加信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the benefits of using lm dot txt.": "现在来看看使用 llms.txt 的好处。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will improve the AI accuracy when extracting the information from the website.": "它将提高 AI 从网站提取信息时的准确性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to downstream that information makes it very, very easy.": "因此，下游处理这些信息变得非常、非常容易。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It also enhances the content discoverability of LMS with their website content.": "它还增强了大语言模型对网站内容的发现能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the website owners have an incentive to really create this file.": "因此，网站所有者有动力去创建这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It also provides obviously better context for understanding the website structure, and can even improve": "它显然还为理解网站结构提供了更好的上下文，甚至可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the SEO by making the content more accessible for AI driven search engines.": "通过使内容更易于被 AI 驱动的搜索引擎访问来提高 SEO。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And while it's not an official standard LMS, TXT is gaining massive popularity in the JNI community.": "虽然它不是一个官方标准，但 llms.txt 在生成式 AI 社区中正获得巨大的普及。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The page we're seeing right now is in the official documentation.": "我们现在看到的页面是官方文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can simply head up there and go to LMS.": "您可以直接前往那里并查看 llms",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT and the link chain team has even taken this one step ahead.": ".txt，LangChain 团队甚至更进一步。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they have two types of Latinx.": "所以他们有两种类型的 llms.txt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This one is a regular one like we saw earlier in the example and the other is LLM full TXT.": "一个是像我们之前在示例中看到的常规文件，另一个是 llms-full.txt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now they have both for the line graph documentation in Python and also in JavaScript.": "现在，他们的 LangGraph Python 和 JavaScript 文档都提供了这两个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what's the difference?": "那么区别是什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The difference is that the LMS dot txt is only going to include the URLs and a short description.": "区别在于 llms.txt 仅包含 URL 和简短描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:While the LMS full text is going to be all the information and all the texts of those pages, so it's": "而 llms-full.txt 将包含这些页面的所有信息和所有文本，所以它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to be a huge file.": "会是一个巨大的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about the use cases and when to use the text and when to use the full text.": "现在让我们谈谈用例，以及何时使用 .txt 文件，何时使用 full.txt 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll use the LMS.": "我会使用 llms",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT the brief one when, for example, I have an AI agent or an MCP server which has the web scraping": ".txt 这个简短的版本，例如当我有一个 AI 智能体或 MCP 服务器，它带有网页抓取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tool slash slash tool like Fire Crawl, which enables us to download the content of a website.": "工具（如 Firecrawl），使我们能够下载网站的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once we have it, we have in the context all the mapping of the website and we know exactly which": "一旦我们拥有了它，我们就掌握了网站的所有映射上下文，并且确切地知道",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:one to download.": "该下载哪一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in case for example, we need to download the content about um link chain memory, then we can simply": "例如，如果我们需要下载关于 LangChain memory 的内容，那么我们只需",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:go and give it in the context.": "去将其放入上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the LLM would be able to choose the tool with the correct URL to download only the memory.": "这样 LLM 就能选择带有正确 URL 的工具，仅下载所需的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll download and we'll retrieve only the information that we'll need.": "因此，我们将只下载并检索我们需要的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Kind of similar like rank.": "有点类似于排序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is very cool.": "这非常酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this really Enhances the quality of agents which can get information in real time.": "这确实提升了能够实时获取信息的智能体（agents）的质量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If those websites have LM dot txt implementation in them.": "如果这些网站实现了 llms.txt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't worry if it sounds too abstract.": "如果这听起来太抽象，别担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the next video, I'm going to show you hands on how to go and how to use lm, dot, txt and how to": "在下一个视频中，我将亲手向你展示如何使用 llms.txt 以及如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:use MCP in order to get really good information and really enhance your applications answers.": "使用 MCP 来获取高质量的信息，并真正增强你应用程序的回答。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to fetch that information in real time.": "它将实时获取这些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the key point here.": "所以这是这里的关键点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the LM full dot txt it's going to have much more information.": "现在，llms-full.txt 将包含更多信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be a huge file with all the information in it.": "它将是一个包含所有信息的巨大文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when and how to use that we can simply download it.": "至于何时以及如何使用它，我们可以直接下载它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll chunk it ourself and index it in our vector store, we can get very similar functionality.": "如果我们自己对其进行分块并在向量库中建立索引，我们可以获得非常类似的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we're using LMS with large context, we can even send the entire thing.": "如果我们使用的是具有长上下文的 LLM，我们甚至可以发送整个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or if those LMS have context cache, we can cache this information.": "或者，如果这些 LLM 具有上下文缓存功能，我们可以缓存这些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now there are advantages and disadvantages for using a lm dot txt and using lm full txt.": "使用 llms.txt 和使用 llms-full.txt 各有优缺点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we want to use the abridged version, the lm dot txt with only the brief information and the links,": "因此，如果我们想使用精简版，即只包含简要信息和链接的 llms.txt，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then the usage pattern of this is usually by using an agent with a scraping tool and a search tool.": "那么其使用模式通常是使用一个带有爬虫工具和搜索工具的智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once we do that we are going to get real time information.": "这样一来，我们就能获得实时信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's one advantage.": "所以这是一个优点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, it's going to take us a bit more time because we first need to download this page and to fetch": "然而，这会花费我们更多的时间，因为我们首先需要下载这个页面并使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it with the URL scraper.": "URL 爬虫来获取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We then need to process it with an LM.": "然后我们需要用 LLM 来处理它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the LM will tell us what we need to download.": "接着 LLM 会告诉我们我们需要下载什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So then we need to make another fetch and to download another file and another web page content and": "然后我们需要再次获取，下载另一个文件和另一个网页内容，并",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to process that.": "对其进行处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And only then we'll get a result.": "只有到那时我们才会得到结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So while we're getting real time information, because it's going to fetch the information dynamically": "因此，虽然我们获得了实时信息，但由于它是动态获取信息的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the latency is going to be a bit higher.": "延迟会稍微高一些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, don't forget about the demo I'm showing you right now.": "顺便说一下，别忘了我现在向你展示的演示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to implement this hands on in the next video.": "我们将在下一个视频中亲手实现这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's really cool.": "所以这真的很酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's a very cool pattern you should be familiar with.": "这是一个你应该熟悉的非常酷的模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to use MCP.": "而且它将使用 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm in the MCP doc official GitHub repository.": "我现在在 MCP doc 的官方 GitHub 仓库里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have an explanation and diagram of how this MCP server works.": "这里有关于这个 MCP 服务端如何工作的说明和图表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what does it actually do.": "以及它具体是做什么的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to leverage LM txt of documentation of public documentation of packages.": "它将利用软件包公开文档中的 llms.txt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example Landgraaf has one and it's going to help our agent whether it's cursor windsurf or cloud": "例如 LangGraph 就有一个，它将帮助我们的智能体，无论是 Cursor、Windsurf 还是 Claude",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:desktop, going to give them the ability to fetch the most up to date documentation.": "Desktop，赋予它们获取最新文档的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very useful because, you know, documentation of open source project, especially in the": "这非常有用，因为你知道，开源项目的文档，特别是在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:generative AI field.": "生成式 AI 领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They change constantly.": "它们经常变动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we index them manually then what will happen.": "如果我们手动索引它们，会发生什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They will get out of date very very quickly.": "它们会很快过时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this actually gives us the ability to fetch them dynamically because we're going to scrape them from": "所以这实际上赋予了我们动态获取它们的能力，因为我们将从",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:their official website, which is supposed to be up to date.": "它们的官方网站抓取，那里应该是最新的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So how does it really work?": "那么它到底是怎么工作的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first it has access to this lm Lmtk2, which has a bunch of URLs and explanation of what those URL": "首先，它可以访问这个 llms.txt，其中包含一堆 URL 以及对这些 URL",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:represent, which topic do they cover, and if we'll take an analogy to a book, it's going to be the": "所代表内容的解释、涵盖的主题，如果拿书来做类比，它就像是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:first page of the book, with the index of every chapter and a quick explanation of what does this chapter": "书的第一页，带有每一章的索引以及对该章节",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cover.": "涵盖内容的简要说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the first step of the MCP server.": "这是 MCP 服务端的第一步。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The second step is to figure out which URL do we need.": "第二步是确定我们需要哪个 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:According to the user's question.": "根据用户的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then to fetch that relevant information by simply making a curl request.": "然后通过简单的 curl 请求来获取相关信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we use this MCP server no more stale documentation.": "所以如果我们使用这个 MCP 服务端，就不会再有陈旧的文档了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to run this MCP server it's implemented in Python.": "要运行这个 MCP 服务端，它是用 Python 实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll download you've if you don't have it installed.": "所以如果你还没安装 uv，就去下载它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to go and open the terminal.": "现在我们要去打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Clone this code here and install the dependencies.": "克隆这里的代码并安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and do that.": "让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go here and let me open the terminal.": "让我来到这里并打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to go to my directory of my MCP servers and let me just go and clone that.": "我要进入我的 MCP 服务端目录，然后克隆它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're simply cloning the code of the repository we just saw.": "我们只是在克隆刚才看到的那个仓库的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's go and CD into it.": "好了，让我们 CD 进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go.": "现在让我们继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And according to the documentation, let's go and install the dependencies because it's using UV.": "根据文档，让我们去安装依赖项，因为它使用的是 uv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first I'll create a virtual environment and I'll activate it.": "首先，我会创建一个虚拟环境并激活它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see now on the left side here we have Macp doc.": "你现在可以看到左边这里有 mcp-doc。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is my virtual environment.": "这是我的虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to install the dependencies in all the relevant packages.": "我们需要安装依赖项和所有相关的包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way all the dependencies are going to be described in the UV dot log file over here.": "顺便说一下，所有的依赖项都会在这一侧的 uv.lock 文件中描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all of them installed.": "所以全部都安装好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and take the UV path.": "让我们获取 uv 的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I wrote which UV in order to give the full path of the UV execution file.": "我输入了 `which uv` 以获取 uv 可执行文件的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the docs and let's first test and have a sanity check of this web server.": "让我们回到文档，首先测试并对这个 Web 服务器进行一次完整性检查。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the command to run it locally With an LLM text of our choice.": "这里有在本地运行它的命令，并附带我们选择的 LLM 文本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here it's using the Landgraf text that we showed earlier.": "这里使用的是我们之前展示过的 LangGraph 文本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just copy that and paste this command over here.": "让我复制一下，然后把这个命令粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it should run locally.": "它应该会在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP server in port 8082.": "MCP 服务器运行在 8082 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see it's running.": "我们可以看到它正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let's create another instance of terminal.": "好了，让我们创建另一个终端实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we want to run MCP Inspector to debug a bit.": "在这里我们要运行 MCP Inspector 来进行一些调试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This MCP server.": "针对这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go down in the formal GitHub repository here.": "让我们在正式的 GitHub 仓库中向下滚动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to have here the command to run inspector.": "这里会有运行 inspector 的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go simply paste it NP.": "所以让我们直接粘贴它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to run the inspector I'm going to click Y to install the dependencies.": "为了运行 inspector，我将点击 Y 来安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just fast forward this a bit because it can take a couple of minutes.": "让我快进一下，因为这可能需要几分钟时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have on port 3000.": "所以我们在 3000 端口上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP inspector.": "MCP inspector。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to connect to our SSH server which is running on port 8082 which is currently running.": "现在我们要连接到运行在 8082 端口上的 SSH 服务器，它目前正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and click connect.": "让我们点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's check out the tools that this MCB server exposes.": "让我们查看一下这个 MCP 服务器公开的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to click here on List Tools.": "我将点击这里的 List Tools。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here two tools list dot sources which is going to show us what is the URL to the dot txt": "这里有两个工具，list.sources 将向我们显示 .txt",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:file.": "文件的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can then make a HTTP request and fetch the information and scrape that page.": "这样我们就可以发起 HTTP 请求，获取信息并抓取该页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see this is the URL over here.": "你可以看到这就是这里的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other one is fetch docs.": "另一个是 fetch_docs。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me try this with the dot txt which is going to receive a URL.": "让我用这个 .txt 试一下，它将接收一个 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to retrieve all the content from that URL by scraping it.": "它将通过抓取该 URL 来检索其中的所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what we can see here is the content of the line graph ln dot.": "我们在这里看到的是 LangGraph ln.",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT file that we scraped with the fetch Docs tool, and we can see here all the URLs from the txt.": "用 fetch_docs 工具抓取的 TXT 文件内容，我们可以看到 txt 中所有的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the agent is going to then extract those URLs.": "然后代理将提取这些 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to run the fetch docs for those URLs to get the relevant documentation dynamically.": "它将针对这些 URL 运行 fetch_docs，以动态获取相关的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and integrate everything with Cloud Desktop.": "现在让我们将一切与 Claude Desktop 集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go to settings.": "我要进入设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to show you that I don't have any MCC configured right now.": "我要向你展示，我现在没有配置任何 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see my MCP servers is empty.": "你可以看到我的 MCP 服务器列表是空的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to show you what it's going to be without this MCP.": "我想向你展示如果没有这个 MCP 会是什么样子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to ask a question what is graph memory.": "我要问一个问题：什么是 graph memory。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now Cloud Desktop is going to answer from its trained data and what it has on memory on line graph.": "现在 Claude Desktop 将根据其训练数据以及它关于 LangGraph 的记忆进行回答。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice it may seem like a correct response but eventually this response is not grounded in real time": "请注意，这看起来可能是一个正确的回答，但最终这个回答并非基于实时",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:data.": "数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the latest because it is dependent on the data that the model was trained on.": "并且不是最新的，因为它取决于模型训练时的数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's continue the their generation.": "让我们继续它们的生成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's check out the response.": "让我们查看一下回答。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, this response actually may seem okay.": "顺便说一下，这个回答实际上看起来还可以。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will go stale very, very quickly, especially when the rapid pace of Landgraf and Lang packages": "它会非常非常快地过时，特别是当 Landgraf 和 Lang 软件包以如此快的速度更新时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:are being updated.": "正在被更新。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to add to Cloud Desktop, the NCP server we just ran.": "所以现在我们想把刚才运行的 NCP 服务器添加到 Cloud Desktop 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go again to settings and to developer and open the NCP settings config file.": "那么让我们再次进入设置和开发者选项，打开 NCP 设置配置文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we want to paste in the snippet from the repo telling the client how to run this NCP server.": "在这里，我们要粘贴来自仓库的代码片段，告诉客户端如何运行这个 NCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's scroll down a bit.": "让我们向下滚动一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we got this snippet over here.": "我们在这里找到了这个代码片段。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's simply go and paste it here.": "让我们直接把它粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're running our server with UV and the arguments.": "我们正在使用 UV 和相关参数运行我们的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to tell it to run it from the NCP dock directory.": "我们将告诉它从 NCP dock 目录运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The URLs that are going to store the dot txt are going to be for the Lang graph documentation over here.": "存储 .txt 文件的 URL 将指向这里的 Lang graph 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can change it if we want.": "如果需要，我们可以更改它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The transport layer is going to be via Stdio and the port is going to be 8081.": "传输层将通过 Stdio，端口号为 8081。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice that the transport layer when we ran the server earlier was SSE, but now we change it to": "请注意，之前运行服务器时传输层是 SSE，但现在我们将其更改为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Stdio.": "Stdio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So both will work.": "所以两者都可以工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's time to restart Cloud Desktop and let's see if our MCP server got loaded.": "现在是时候重启 Cloud Desktop 了，让我们看看我们的 MCP 服务器是否已加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have some errors here.": "我们可以看到这里有一些错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for some reason we can't run UVC.": "出于某种原因，我们无法运行 UVC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we get an error and we can open the error logs have some indication of what went wrong.": "所以我们收到了一个错误，我们可以打开错误日志来查看出错的迹象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll scroll down a bit, we can see that we have a problem running the UV command.": "如果我们向下滚动一点，可以看到运行 UV 命令时出现了问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to do that I'm going to go back again to my repository.": "为此，我将再次回到我的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to activate my virtual environment.": "我将激活我的虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to run the command which you've to give the full path of the UVC executable.": "我将运行 which 命令来获取 UVC 可执行文件的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to put that over here.": "然后我会把它放在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and let's restart cloud desktop again.": "现在让我们再次重启 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it seemed to load the MCP server.": "看起来它加载了 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll click on the icon right over here we can see we have the lm txt mcp server.": "如果我们点击这里的图标，可以看到我们有了 lm txt mcp 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a sanity check let's go and check out the settings and the MCP server we have here to see that": "作为完整性检查，让我们查看一下设置和这里的 MCP 服务器，看看是否",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:everything is okay.": "一切正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this looks fine.": "这看起来没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's try to run.": "让我们尝试运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is Landgraf memory.": "什么是 Landgraf 记忆。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we can see from the response that nothing really changed here.": "现在我们可以从响应中看到，这里并没有真正的改变。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I have an issue with my MCP server.": "所以我的 MCP 服务器出了点问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And clicking on the tool button here shows the tools that our server exposes.": "点击这里的工具按钮会显示我们服务器公开的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after debugging it a bit offline, I figured out that when running the UV command, I needed to": "在线下调试了一会儿后，我发现运行 UV 命令时，我需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:specify the absolute path to where the code is stored, because I don't know from which directory it's": "指定代码存储的绝对路径，因为我不知道它是从哪个目录",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:being run.": "运行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to give the absolute path here.": "所以我想在这里提供绝对路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and restart cloud and let's see if it fixes the issue.": "那么让我们重启 Cloud，看看是否能解决问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now write what is Landgraf memory.": "现在让我们输入“什么是 Landgraf 记忆”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we can see.": "瞧，我们可以看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we are trying to activate the tool here.": "现在我们正尝试在这里激活该工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this playground is very useful for debugging the tools and to see that our MCP server is working": "所以这个演练场对于调试工具和查看我们的 MCP 服务器是否正在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:correctly.": "正常工作非常有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now notice the tool we're trying to run here.": "现在请注意我们正尝试在这里运行的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cloud desktop.": "云桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The agent is trying to run the least doc sources tool.": "代理正尝试运行 list doc sources 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because we initialized this code with the Landgraf documentation.": "因为我们是用 LangGraph 文档初始化的这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so that's the built in URL.": "嗯，所以那是内置的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When we initialize the server, we're not running it with any arguments.": "当我们初始化服务器时，我们没有带任何参数运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now the result that we got from this tool.": "我们现在可以看到从这个工具得到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we got that the graph URL the URL to the LLM dot.": "所以在这里我们得到了 graph URL，即指向 LLM dot 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT is this here URL.": "TXT 就是这里的这个 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now the next tool that should run if everything in the agent is working correctly is going to be": "现在，如果代理中的一切运行正常，下一个应该运行的工具将是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to scrape that URL data.": "抓取该 URL 的数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see what happens.": "让我们来看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And cool.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we're trying to fetch the documentation with that URL we got from the previous tool.": "现在我们正尝试使用从上一个工具获取的 URL 来获取文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see that the URL we're passing in to this tool is going to be the graph lms dot txt.": "所以你可以看到，我们传递给这个工具的 URL 将是 graph llms dot txt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to allow it.": "所以我要允许它运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to scrape the information from there.": "我们将从那里抓取信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see all the information from the LLM dot txt.": "我们将看到来自 LLM dot txt 的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and allow it.": "那么让我们允许它运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the result which is the content of the dot txt which we scraped.": "在这里我们可以看到结果，也就是我们抓取的 dot txt 的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the content here is simply the topics and the URLs for those topics.": "这里的内容仅仅是主题以及这些主题对应的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not going to show everything here but the next step that the agent is going to do, it's going to": "我不会在这里展示所有内容，但代理下一步要做的是，它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:find the relevant URL that we need to scrape.": "找到我们需要抓取的相关 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the URL that talks about memory and it's going to scrape that URL again.": "也就是讨论 memory 的 URL，它将再次抓取该 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's see if it invokes now the fetch docs tool again.": "让我们看看它现在是否会再次调用 fetch docs 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However with a different URL.": "不过这次使用的是不同的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see this is exactly what's happening here.": "你可以看到，这正是这里正在发生的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to scrape now the concept memory.": "我们现在要抓取 concept memory 的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and allow it and get the content real time content this time of memory.": "让我们允许它运行，并获取这次关于 memory 的实时内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's going to fetch the information.": "现在它将获取信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have now the summary of what's Landgraf memory.": "现在我们得到了关于 LangGraph memory 的摘要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However this time it's grounded in real time information from the official Landgraf documentation.": "不过这一次，它是基于来自 LangGraph 官方文档的实时信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we got it in real time with the MCP server.": "我们通过 MCP 服务器实时获取了它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very cool and it helps us ground our answers in the real, real time documentation.": "所以这非常酷，它帮助我们将答案建立在真实的、实时的文档基础之上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very cool in my opinion.": "在我看来非常酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video we're going to boilerplate.": "所以在这段视频中，我们将进行样板设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Set up our project before we code our MVP server.": "在编写我们的 MVP 服务器代码之前，先搭建好项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll be using UV as our package manager and to create our virtual environment and to install our": "我们将使用 UV 作为包管理器，并用它来创建虚拟环境以及安装我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:dependencies, which is going to include the MCP Python SDK.": "依赖项，其中将包括 MCP Python SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to also use cursor, and we would want to index the official MCP documentation before we": "我们还将使用 Cursor，并且我们希望在开始之前",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:do that.": "先索引官方的 MCP 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we also want to update our project with some cursor rules, which is going to make the code that": "我们还想为项目更新一些 Cursor 规则，这将使 Cursor 生成的代码",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cursor produces to be in better quality.": "具有更好的质量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, this is my personal workflow that I use for all my projects.": "顺便说一下，这是我个人在所有项目中都会使用的工作流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you don't want to use UV and you want to use poetry or pipenv or virtualenv, you can do that": "如果你不想使用 UV，而想使用 poetry、pipenv 或 virtualenv，也可以。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All we're doing here is creating a project, a virtual environment, and installing some dependencies.": "我们在这里做的只是创建一个项目、一个虚拟环境并安装一些依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's now go CD into our MCP servers directory.": "好了，现在让我们 cd 进入我们的 MCP 服务器目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me list all my MCC Peace.": "让我列出我所有的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to create a new MCP server.": "现在我想创建一个新的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to use Uvi to do that.": "所以我将使用 uv 来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I will write UV init and I'll call it shell server.": "我会输入 uv init，并将其命名为 shell-server。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will create a new directory with the boilerplate UV package which includes a pyproject.toml": "这将创建一个包含样板 UV 包的新目录，其中包括 pyproject.toml",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:file, a main.py file and an empty Readme.": "文件、一个 main.py 文件和一个空的 Readme。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want now to create a virtual environment to install all our dependencies in.": "我现在想创建一个虚拟环境来安装我们所有的依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write uv venv which will create it and let me now activate it.": "让我们输入 uv venv 来创建它，现在让我激活它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me copy the string over here.": "让我把这里的字符串复制过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sorry about that.": "抱歉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I activated the virtual environment.": "我激活了虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see on the left side I have shell server here.": "你可以看到左侧这里有 shell-server。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means we're going to run inside this virtual environment right now.": "这意味着我们现在将在该虚拟环境中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time to install the dependencies.": "现在是安装依赖项的时候了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write UV add and I'm going to install mcp cli.": "让我输入 uv add，我要安装 mcp cli。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to add this package to my dependencies.": "这会将此包添加到我的依赖项中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to also update the HTML file.": "它还会更新 HTML 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see it right over here.": "你可以在这里看到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I have this package installed which is going to help me build my MVP server.": "现在我已经安装了这个包，它将帮助我构建我的 MVP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just create a new file, let's call it server dot Pi, and let me even remove the file main.": "让我创建一个新文件，命名为 server.py，我甚至要把 main 文件删掉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't really need it.": "我并不真的需要它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to use Server.py.": "我想使用 server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, now it's time to fire up cursor in this directory and let's see what we have so far.": "好了，现在是时候在这个目录中启动 Cursor 了，让我们看看目前为止我们都有什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have all the boilerplate code that we need in order to create our MVP server.": "我们已经拥有了创建 MVP 服务器所需的所有样板代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But before that, here is a quick message from my buddy here.": "但在此之前，我这里的朋友有一条简短的消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean, we're in 2025 and I ain't going to spend all my time writing an MVP server from scratch.": "我的意思是，现在是 2025 年了，我不会花大把时间从头开始编写 MVP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to VB code it with cursor.": "我要用 Cursor 来 Vibe coding。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see how we can VB code our MVP server in the best possible way.": "那么让我们来看看如何以最佳方式 Vibe coding 我们的 MVP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What I want to do now is to index the MVP documentation.": "我现在想做的是索引 MVP 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when our vibe code it with cursor it will have the latest and greatest documentation.": "所以当我们用 Cursor 进行 vibe coding 时，它将拥有最新、最全的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:commendation.": "推荐。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's very easy.": "这非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to Cursor Settings here and let me go.": "那么让我们进入这里的 Cursor 设置，让我操作一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Click on features.": "点击“Features”（功能）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I have all the docs I have indexed that cursor can use.": "在这里，我可以看到所有已索引的、Cursor 可以使用的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me paste here the URL of Model context protocol.io and cursor is going to crawl that URL.": "让我把 Model context protocol.io 的 URL 粘贴到这里，Cursor 将会抓取该 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to get all the pages under that URL, all the sub pages as well.": "它会获取该 URL 下的所有页面，包括所有子页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to index them.": "并且会对它们进行索引。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can use this documentation when we vibe coded cursor.": "这样当我们用 Cursor 进行 vibe coding 时，就可以使用这些文档了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a very cool feature.": "所以这是一个非常酷的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me simply add those docs and let's name it MCP.": "让我简单地添加这些文档，并将其命名为 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we click this book icon here we'll see all the index pages.": "如果我们点击这里的书本图标，就能看到所有已索引的页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see we indexed the server page, the client page that we reviewed earlier in the course.": "你可以看到我们索引了服务器页面和客户端页面，这些是我们之前在课程中回顾过的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So cursor is going to have the context and all the documentation.": "这样 Cursor 就会拥有上下文和所有的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to help us generate better code.": "这将帮助我们生成更好的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to write it in Python.": "我们将用 Python 来编写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I also want to index the Python SDK.": "我还想索引 Python SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply going to take the URL of the GitHub Python SDK.": "所以我只需获取 GitHub 上 Python SDK 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have also the readme.": "这里还有自述文件（readme）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can also index this GitHub repository.": "我们也可以索引这个 GitHub 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's also going to help us.": "所以这也会对我们有所帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to write it Mocp Python SDK.": "我会把它写成 Mocp Python SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to do the same.": "所以它会执行相同的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But for the Python SDK GitHub repo.": "但针对的是 Python SDK 的 GitHub 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here we have much more documents here.": "我们可以看到这里有更多的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to help us provide better context for cursor.": "所以这将有助于为 Cursor 提供更好的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly since we're going to write code in Python I mean not we cursor is going to write that code": "最后，既然我们要用 Python 写代码——我是说，不是我们，是 Cursor 要写那些代码——",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to create cursor rules to give cursor the persona of somebody who knows Python really well.": "所以我想创建 Cursor 规则，赋予 Cursor 一个精通 Python 的人设。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm pretty comfortable with Python, but I want to give cursor the persona of somebody who is excellent": "我对 Python 挺熟悉的，但我还是想给 Cursor 一个极其出色的人设，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in Python and who is living and breathing Python.": "一个精通 Python 且对 Python 了如指掌的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me create a new directory and I'll call it dot cursor.": "让我创建一个新目录，命名为 .cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we create a subdirectory here called rules.": "如果我们在这里创建一个名为 rules 的子目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to put text that is going to be attached at every request we're going to send to": "在这里，我们将放入一段文本，它将附加到我们发送给",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cursor in this project.": "该项目中 Cursor 的每一个请求上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me create a new file and I'll call it Python dot MDC.": "让我创建一个新文件，命名为 python.mdc。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go to a website called Cursor Directory, which is a great website to get all those cursor": "让我去一个叫 Cursor Directory 的网站，这是一个获取所有这些 Cursor",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:rules.": "规则的好网站。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go to rules and let me go and select here Python.": "我要进入 rules 页面，然后在这里选择 Python。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's browse for somebody who is very good in Python and knows fast API and knows how to design": "让我们找一个精通 Python、了解 FastAPI 并且知道如何设计",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:systems.": "系统的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me copy the content of this text here, and let me go back to the code and let me paste it in": "让我复制这里的文本内容，回到代码中，并将其粘贴到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my Python dot MDC.": "我的 python.mdc 文件里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see this is a Python fast API scalable API development excerpt, which is pretty good in": "你可以看到这是一个关于 Python FastAPI 可扩展 API 开发的摘录，在我看来",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my opinion.": "非常不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, I want to use this cursor rule every time I make a request.": "最后，我想在每次发出请求时都使用这个 Cursor 规则。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and select in the rule type I'll go and select always.": "所以让我去规则类型中选择，我会选择“始终”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's pretty much it.": "基本上就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are done setting up our boilerplate project and now it's time to code our MEP server.": "我们已经完成了样板项目的设置，现在是时候编写我们的 MEP 服务器了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there.": "大家好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I eaten here in this video we're going to implement from zero and MCP server that is going to expose": "我是 Eaten，在这段视频中，我们将从零开始实现一个 MCP 服务器，它将公开",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a shell tool, which is going to run commands in our terminal of our local system.": "一个 Shell 工具，该工具将在我们本地系统的终端中运行命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All the code of this video is going to be available on GitHub in the link in the video's resources.": "本视频的所有代码都可以在视频资源中的 GitHub 链接里找到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I opened the server.py file which is currently empty, and notice I open now my cursor chat and I'm": "所以我打开了目前为空的 server.py 文件，注意我现在打开了 Cursor 聊天窗口，并且我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:selected on cursor agent.": "选择了 Cursor Agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want to open it yourself on Mac, you can type command I and on windows control I and it": "如果你想在 Mac 上自己打开它，可以按 Command + I，在 Windows 上则是 Control + I，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:should open it as well.": "应该也能打开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to use cloud 3.7 sonnet or 3.7 sonnet Max.": "我将使用 Claude 3.7 Sonnet 或 3.7 Sonnet Max。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't really matter.": "这其实并不重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write the prompt here.": "让我在这里写下提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want you to implement me a simple amqp server from MCP.": "我希望你为我实现一个基于 MCP 的简单 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I'm tagging the MCP documentation.": "在这里我标记了 MCP 文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Use the Python SDK and let me tag the MCP Python SDK and the server should expose one tool, which is": "使用 Python SDK，让我标记一下 MCP Python SDK，服务器应该公开一个工具，即",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:called terminal and it should allow the user to run terminal commands.": "名为 terminal 的工具，它应该允许用户运行终端命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Make it simple and let's wait for cursor to code it.": "让它保持简单，让我们等待 Cursor 来编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see.": "我们可以看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we have a bunch of code created.": "现在我们已经生成了一堆代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cursor is going to finish it up.": "Cursor 将完成它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it was also smart enough to create a Readme file and to update the Readme file, which is very cool": "它还非常聪明地创建了一个 Readme 文件并更新了它，这非常酷",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in my opinion.": "在我看来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's review now the code, because to be honest, it's very straightforward and simple.": "现在让我们回顾一下代码，因为老实说，它非常直观且简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just go and accept that.": "让我直接接受这些更改。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's review the readme and we have a beautiful readme file over here.": "让我们看看 Readme，这里有一个非常漂亮的 Readme 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're not going to focus on the readme.": "我们不会把重点放在 Readme 上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's focus on the Server.py implementation, and let's now see how we implemented the MCP server.": "让我们专注于 Server.py 的实现，现在来看看我们是如何实现 MCP 服务器的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We start by importing the object fast MCP and we import it from MCP server dot fast MCP.": "我们首先导入 FastMCP 对象，它是从 mcp.server.fastmcp 导入的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our MCP server object that we're going to use.": "这就是我们将要使用的 MCP 服务器对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we are importing subprocess and asyncio.": "在这里我们导入了 subprocess 和 asyncio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to run the shell commands in a non-blocking way.": "以便以非阻塞方式运行 Shell 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly we also import some typing for type hints.": "最后，我们还导入了一些 typing 用于类型提示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's all for the imports.": "导入部分就这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start with the coding.": "那么让我们开始编码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First we want to create an object of the NCP server.": "首先，我们要创建一个 MCP 服务器对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll initialize the fast NCP class with the name of terminal Server.": "我们将使用名称 'terminal-server' 初始化 FastMCP 类。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we'll call it in a variable which is called NCP.": "现在我们将其赋值给一个名为 mcp 的变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what we're going to use in order to decorate our coroutines which are going to make them": "这就是我们将用来装饰协程的东西，从而使它们成为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:NCP server tools.": "MCP 服务器工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's implement an ASIC coroutine.": "让我们实现一个异步（async）协程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll call it run command.": "我们将其命名为 run_command。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this function which is going to be our tool is going to receive a command which is going to be a": "这个作为我们工具的函数将接收一个命令，它将是一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:string for a shell command.": "用于 Shell 命令的字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll run that command and return the result and extra metadata to the NCP client.": "我们将运行该命令，并将结果和额外的元数据返回给 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about the description we're seeing right over here.": "让我们来谈谈我们在这里看到的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this thing is super important because this is what's going to enable the MCP client to choose whether": "这件事非常重要，因为它是 MCP 客户端用来选择是否",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to use this tool and run it or not.": "使用并运行此工具的依据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this description should be here very, very explicit.": "这里的描述应该非常、非常明确。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It should not be ambiguous at all.": "它一点也不应该有歧义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the better this description is going to be, the better the MCP client can decide whether to use": "这个描述写得越好，MCP 客户端就越能更好地决定是否使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this tool or not.": "这个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the description here we can see that we want to run a terminal command and return the output.": "在描述中我们可以看到，我们想要运行一个终端命令并返回输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The arguments is going to be a command.": "参数将是一个命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the command we want to execute in the terminal.": "这就是我们想要在终端中执行的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what this coroutine will return is a dictionary containing stdout and stderr and the return code.": "这个协程将返回一个包含 stdout、stderr 和返回码的字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the core of this function is going to use the async IO create subprocess shell.": "所以这个函数的核心将使用 asyncio 的 create_subprocess_shell。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a coroutine which is going to run the command that we provided.": "这是一个将运行我们提供的命令的协程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to run it in a non-blocking way.": "它将以非阻塞的方式运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The last two arguments that this coroutine receives the stdout and stderr.": "这个协程接收的最后两个参数是 stdout 和 stderr。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to receive the subprocess dot pipe, and this pipe constant is going to tell the subprocess": "它将接收 subprocess.PIPE，这个管道常量将告诉子进程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the terminal to create a new pipe that will be used for communication between the parent process.": "在终端创建一个新管道，用于与父进程之间的通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our Python program and the child process.": "这里的父进程是我们的 Python 程序，而子进程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the shell command which is going to run.": "则是将要运行的 shell 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you are not that familiar with operating systems and communication methods like pipe and sub": "如果你对操作系统以及管道、子进程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:processes and threads whatever, don't worry at all.": "和线程之类的通信方式不太熟悉，完全不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here.": "在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to focus on NCP, and you can simply assume that this function will run the command that we": "我们需要专注于 MCP，你可以简单地假设这个函数会运行我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:give it inside the terminal and will give us back the result.": "给它的终端命令，并向我们返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So don't freak out if you don't understand this part.": "所以如果你不理解这部分，不要惊慌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, you can assume that once we run this terminal command, we want to get the output and we're": "总之，你可以假设一旦我们运行了这个终端命令，我们就想要获取输出，而我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to do that with the process dot communicate.": "将通过 process.communicate 来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And finally we want to return the result in a beautiful dictionary.": "最后，我们想要以一个漂亮的字典形式返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we want to return the stdout.": "所以我们想要返回 stdout。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to contain the return value from running the command stderr.": "这将包含运行命令的返回值，以及 stderr。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you got any errors and the return code from running the command.": "如果你遇到了任何错误，还有运行命令的返回码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We also have an exception handling here at the bottom.": "我们在底部还有一个异常处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and try to run this MCP server.": "让我们去尝试运行这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to open the terminal.": "我要打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right you've run Server.py and we can see we get here an error on MCP serve.": "运行 Server.py，我们可以看到在 MCP serve 上出现了一个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Notice that on the left I'm running inside the virtual environment.": "注意左边，我是在虚拟环境中运行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it does contain the MCP package and all the dependencies that we need.": "所以它确实包含了 MCP 包和我们所需的所有依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get here this error.": "我们在这里得到了这个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's check out now our runner.": "现在让我们检查一下我们的运行器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So up until now, we saw how to integrate pre-built MCP servers that we cloned from open source GitHub": "到目前为止，我们已经了解了如何集成从开源 GitHub",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:repositories.": "仓库克隆的预构建 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this section, we're going to build an NCP server from zero.": "在本节中，我们将从零开始构建一个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the MCP server will implement from scratch is going to expose a tool and a resource.": "我们将从头开始实现的 MCP 服务器将公开一个工具和一个资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're then going to integrate it with Cloud Desktop and with cursor.": "然后我们将把它与 Claude 桌面端以及 Cursor 集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after we'll do that we're going to containerize our MCP server.": "在那之后，我们将对我们的 MCP 服务器进行容器化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to run it as a Docker container.": "我们将把它作为一个 Docker 容器运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now Containerizing MCP servers is going to be very beneficial.": "现在，对 MCP 服务器进行容器化将非常有益。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to help us isolating our environment, enhancing our security, and it's going to help us": "它将帮助我们隔离环境，增强安全性，并帮助我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with portability and consistency regarding dependencies so we can run our MCP server anywhere we want,": "解决依赖项的可移植性和一致性问题，这样我们就可以在任何想要的地方运行我们的 MCP 服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and we can even deploy it to the cloud.": "我们甚至可以将其部署到云端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all the code for this is going to be available in the GitHub repository.": "所有这些代码都可以在 GitHub 仓库中找到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll dive deep into this in the Docker videos.": "我们将在 Docker 视频中深入探讨这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's see a quick demo of what we're going to build in this section.": "那么，让我们快速演示一下我们将在本节中构建的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm in cloud and I've hooked my MCP to expose a tool which would run any terminal command that I": "我现在在 Claude 中，我已经挂载了我的 MCP 来公开一个工具，该工具可以运行我输入的任何终端命令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me run to cloud.": "让我切换到 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Show me all the directories in my desktop.": "显示我桌面上的所有目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So then I'm going to request to allow the shell tool.": "然后我将请求允许使用 shell 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to print la la at my desktop.": "它将在我的桌面上打印出内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those are the list of all the directories in my desktop.": "这些就是我桌面上所有目录的列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you that.": "让我给你们展示一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if I go to my desktop here I just minimize that.": "如果我来到我的桌面，我先把这个最小化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I have a bunch of stuff here.": "我这里有一堆东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here you can see all my folders, which is exactly what cloud printed.": "在这里你可以看到我所有的文件夹，这正是 Claude 打印出来的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this shell tool is basically able to run any command that I want.": "所以这个 shell 工具基本上能够运行我想要的任何命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can imagine how dangerous this could be.": "你可以想象这会有多危险。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll talk about it more when we talk about security of MSPs.": "当我们讨论 MCP 的安全性时，我们会更多地谈论这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll cover security in this course as well.": "我们也会在本课程中涵盖安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we talked about tools a lot in this course.": "在本课程中，我们已经多次讨论过工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's the first time I'm going to show you what's a resource in NCP.": "现在是我第一次向你们展示 MCP 中的资源是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I also add it to the server to expose a resource which is this mcp readme file.": "所以我也把它添加到了服务器中，以公开一个资源，也就是这个 mcp readme 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this file I downloaded from the official GitHub repository of the Python SDK of MCP, and I simply": "这个文件是我从 MCP 的 Python SDK 官方 GitHub 仓库下载的，我只是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:copied the Readme file content here.": "把 Readme 文件的内容复制到了这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again, we're going to do everything together later in this section.": "同样，在本节稍后部分，我们将一起完成所有操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, so this file content is right over here.": "总之，这个文件的内容就在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what I did is expose this as a resource in my MCP server.": "我所做的是将其作为我 MCP 服务器中的一个资源公开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this means that any MCP client that connects to my MCP server can access this resource and get this": "这意味着任何连接到我 MCP 服务器的 MCP 客户端都可以访问此资源并获取此",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:context.": "上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you how this looks right now in cloud desktop.": "让我给你们展示一下这在 Claude 桌面端现在的样子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you see this icon over here I don't know what this cycle actually means, but if I'm going to click": "你看到这里的这个图标，我不知道这个图标到底是什么意思，但如果我点击",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see in line 48 that if name equals main we want to run the coroutine which is called main.": "我们可以看到在第 48 行，如果 name 等于 main，我们想要运行名为 main 的协程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we await MCP dot serve.": "这里我们 await MCP.serve。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And apparently there isn't a coroutine called serve in the MCP object.": "显然，MCP 对象中并没有一个名为 serve 的协程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a hallucination of cursor.": "这是 Cursor 的幻觉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You know cursor can make mistakes as well.": "你知道 Cursor 也会犯错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and fix that.": "所以让我们去修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the reason why it's not working is because we simply need to run MCP run.": "它不起作用的原因是我们只需要运行 MCP run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply remove this async function and let me just run.": "所以让我简单地移除这个异步函数，然后直接运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP dot run.": "MCP.run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me tell MCP server that I want to communicate through the Stdio.": "让我告诉 MCP 服务器我想通过 Stdio 进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client would communicate with the server via the standard input output channel.": "这样客户端就会通过标准输入输出通道与服务器通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and run that again.": "让我们再次运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now this seems to be working.": "我们可以看到现在这似乎可以工作了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We resolve the error.": "我们解决了这个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we have an SMTP server up and running.": "现在我们有一个 SMTP 服务器正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time to go and to integrate it with Cloud Desktop.": "所以现在是时候去将它与 Cloud Desktop 集成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now.": "那么我现在就开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to Cloud Desktop.": "让我们去 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to Settings to Developer.": "让我们去 Settings（设置）中的 Developer（开发者）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go.": "让我们继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Edit config.": "编辑配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's open the configuration for our MCP servers.": "让我们打开 MCP 服务器的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we want to add another entry of another MCP server which is going to be our shell server.": "在这里我们要添加另一个 MCP 服务器的条目，也就是我们的 shell 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's call this MCP server.": "让我们把这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's call it shell.": "命名为 shell。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And its value is going to be a dictionary which is going to tell cloud desktop how to run it.": "它的值将是一个字典，用来告诉 Cloud Desktop 如何运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first key is going to be command.": "第一个键将是 command。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the command is going to be the same command as before.": "命令将与之前的命令相同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's not going to be UV.": "但它不会是 UV。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be UV.": "它将是 UV。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So UV is going to run now our script.": "所以 UV 现在将运行我们的脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I'm going to put here the args.": "现在我要在这里放入 args。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the args here is going to be specifying from which directory we are running it from.": "这里的 args 将指定我们从哪个目录运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the second item of the list here is going to be now the path to our directory of the project with": "列表中的第二个项目现在将是我们项目的目录路径，其中包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the MCP server.": "MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go back to cursor and let me write here PWD.": "让我回到 Cursor，在这里输入 PWD。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the path we want.": "这就是我们想要的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just simply go and paste that.": "让我直接把它粘贴过去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to tell that we want to run the server py file.": "现在我们要告诉它我们想运行 server.py 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and write that.": "让我们把它写下来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will also format a bit here this JSON payload.": "我也会在这里稍微格式化一下这个 JSON 负载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me save that.": "让我保存它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to restart Cloud Desktop.": "现在我想重启 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I will quit it.": "所以我会退出它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I will rerun it again because I want to reload this file that we just changed.": "我会再次运行它，因为我想重新加载我们刚刚更改的这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we're reopening it.": "现在我们重新打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We should see now the new tools of the new MVP server.": "我们现在应该能看到新 MVP 服务器的新工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we are not seeing them.": "但我们没有看到它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and check this here and let's see our installed MVP servers.": "让我去检查一下这里，看看我们安装的 MVP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we also don't find our new MVP server.": "我们也没有找到我们的新 MVP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to go back now to the configuration file.": "所以我现在想回到配置文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's do a small exercise.": "让我们做一个小练习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see if you can figure out what's wrong and why.": "看看你是否能找出哪里出了问题以及为什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My MVP through did not work.": "我的 MVP 没能起作用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it, it's going to show me all the available resources that the MCP servers that this host, which is": "它，它将向我展示此主机（即",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cloud Desktop, is connected to through the client.": "Cloud Desktop）通过客户端连接到的 MCP 服务器的所有可用资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we can see the installed MCP servers.": "在这里我们可以看到已安装的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll go and choose an integration here we can see that under the terminal server, the shell": "如果我们去选择一个集成，在这里我们可以看到在终端服务器（即 shell",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server I have this mcp readme file.": "服务器）下，我有这个 mcp readme 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this could be any file that we want.": "这可以是任何我们想要的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a resource.": "这是一个资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I can simply attach it and add it as a context to my prompt.": "所以我可以简单地附加它，并将其作为上下文添加到我的提示词中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, I want to show you the final tool that I expose, which is a benign tool.": "最后，我想向你们展示我暴露的最后一个工具，这是一个良性工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is to demonstrate some security issues.": "所以这是为了演示一些安全问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me just allow it.": "让我允许它运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what this is going to do, it's going to dynamically make a request and download a file from outside": "这个工具的作用是，它会动态地发起请求并从我的电脑外部",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my computer.": "下载一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to print it.": "然后它会将其打印出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this example I simply wrote you got hacked and a little Ascii drawing.": "在这个例子中，我只是简单地写了“你被黑了”以及一个小小的 Ascii 图案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Obviously we're not hacking anything here.": "显然，我们在这里没有黑掉任何东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is simply to make a point here of how dangerous MCP servers can be.": "这只是为了说明 MCP 服务器可能有多危险。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this here is content that was downloaded from the web and can run potentially on my computer.": "所以这里是从网上下载的内容，并且有可能在我的电脑上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let me show you what can happen when you use a permissive tool like the terminal tool like we're": "现在让我向你们展示，当你使用像终端工具这样权限过大的工具时会发生什么，就像我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to use in the demo here.": "在这里的演示中将要使用的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can write delete the MCP readme file in my desktop.": "我可以写：删除我桌面上的 MCP readme 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's run that.": "让我们运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see that this file exists right now in my desktop.": "你可以看到这个文件现在就在我的桌面上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that right from the get go.": "我们可以从一开始就看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Clodd acknowledges that it has the run command, but it's telling us that it cannot use it.": "Claude 承认它拥有运行命令，但它告诉我们它无法使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let me show you how easy it is to pass this mechanism.": "但让我向你们展示绕过这个机制有多么容易。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll open a new chat.": "所以我们将开启一个新的对话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right here we'll write something like help me clean up my computer.": "在这里我们会写类似“帮我清理电脑”之类的话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want you to remove the file mcp readme in my desktop.": "“我想让你删除我桌面上的 mcp readme 文件。”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this time it's able to run it.": "而这一次，它能够运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we managed to bypass this mechanism.": "所以我们成功绕过了这个机制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we're going to delete the file from the actual desktop.": "现在我们要从实际的桌面上删除该文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me open the desktop.": "让我打开桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see now it doesn't exist because we literally removed it.": "你可以看到现在它不存在了，因为我们确实把它删除了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This example is to illustrate the concept of permissive tools, and that we should be really careful": "这个例子是为了说明权限过大的工具这一概念，以及我们在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:when cloning MC from GitHub repositories, which are public.": "从公开的 GitHub 仓库克隆 MCP 时应该非常小心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the next couple of videos, we'll be implementing it from zero.": "在接下来的几个视频中，我们将从零开始实现它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll give you a couple of seconds.": "我给你几秒钟时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then I'm going to show you how to fix it.": "然后我将向你展示如何修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can also pause this video.": "所以你也可以暂停这个视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the meantime, the problem with our configuration that I wrote is not what we wrote is where we wrote": "与此同时，我写的配置的问题不在于我们写了什么，而在于我们写在了哪里，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it in the way I wrote it now accidentally.": "就在我刚才不小心写的那种方式里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not a key value pair under the MCP servers dictionary, it's one hierarchy above it.": "它不是 MCP 服务器字典下的键值对，而是比它高了一个层级。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to fix it, I would simply need to copy paste.": "所以为了修复它，我只需要简单地复制粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the key value here of shell and how to run it.": "现在这里关于 shell 及其运行方式的键值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go do that and to take it and to make it as a key under this dictionary here.": "让我去操作一下，把它拿过来，作为这个字典下的一个键。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is why it didn't work from before.": "这就是为什么之前它不起作用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a fun fact.": "那么，一个有趣的事实。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This kind of mistake happened to me a lot of times when I configured MCP servers, and it took me around": "在我配置 MCP 服务器时，这种错误发生过很多次，我花了大约",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:20 minutes to figure it out.": "20 分钟才弄明白。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go and save it and let's rerun it.": "总之，让我们保存并重新运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to create cloud and let's now load it again.": "我要打开 Claude，让我们现在重新加载它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we see now we have an extra tool of the run command.": "瞧，我们现在看到多了一个 run_command 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a part of the shell MCP server we configured.": "它是我们配置的 shell MCP 服务器的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we wrote that name in the JSON file.": "我们在 JSON 文件中写了这个名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the description here is actually the description we wrote in the function if you've noticed.": "如果你注意到了的话，这里的描述实际上就是我们在函数中写的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's test it and let me write here.": "让我们测试一下，我在这里写一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If it can please list me the directories I have in my desktop.": "请它帮我列出桌面上的目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's run it.": "让我们运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now we're prompted to allow the execution of the run command tool from our shell MCP": "我们可以看到，现在系统提示我们允许从 shell MCP 执行 run_command 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me allow it.": "让我允许它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's running the command ls la from our desktop directory.": "现在它正在我们的桌面目录下运行 ls -la 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP client in cloud.": "Claude 中的 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It actually generated this input.": "它实际上生成了这个输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It figured out that this is the way to print out what's in my desktop.": "它意识到这是打印出我桌面内容的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the input to the tool.": "所以这就是该工具的输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we're going to execute it.": "现在我们要执行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what happens.": "让我们看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's the result that we're getting.": "我们得到了什么结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see in stdout we see exactly the result that will be output if we had been running it in": "我们可以看到，在标准输出 (stdout) 中，我们看到的正是如果在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our terminal.": "终端中运行所会输出的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now cloud generates a new answer.": "现在 Claude 生成了一个新的回答。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the content of my desktop.": "这就是我桌面的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the name of all my directories.": "这是我所有目录的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and show you it.": "让我去展示给你看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just go and minimize everything.": "让我先把所有窗口都最小化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sorry for all that.": "抱歉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is my desktop.": "这是我的桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see that the names here indeed match the names that Cloud Desktop yielded.": "你可以可以看到这里的名称确实与 Claude Desktop 产生的结果相匹配。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all that we do in this coroutine is simply to open the content of the file with the open function": "我们在该协程中所做的只是简单地使用 open 函数打开文件内容",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from the standard library of Python.": "该函数来自 Python 的标准库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We read the content and we return it to the user.": "我们读取内容并将其返回给用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very simple and very straight to the point.": "非常简单，直截了当。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so let's go and accept the content of this code here, and let me now go and restart clogged.": "好了，让我们接受这里的代码内容，现在让我去重启 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm restarting cloud because I need to restart the server again and to expose this new functionality.": "我正在重启 Claude，因为我需要再次重启服务器并公开这个新功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me close it and let me open it again.": "让我把它关掉，然后再重新打开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's click this cable icon.": "让我们点击这个电缆图标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can choose an integration.": "在这里我们可以选择一个集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that under our shell server we have here a new resource which is called file readme.": "我们可以看到，在我们的 shell 服务器下，这里有一个名为 file readme 的新资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'll double click it we can see and open it.": "如果我双击它，我们就可以看到并打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see this is exactly the content of the readme file that we copied earlier.": "我们可以看到，这正是我们之前复制的 readme 文件的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can access it and we can attach it to the prompt if we want to.": "所以我们可以访问它，如果愿意的话，还可以将其附加到提示词中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we did here is expose a resource in our MCP server.": "所以我们在这里所做的就是在我们的 MCP 服务器中公开一个资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now in this video I want to talk about permissive tools in agents and specifically exposed in our": "所以在这段视频中，我想谈谈代理中的权限开放型工具，特别是我们在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP server.": "MCP 服务器中公开的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember that terminal shell tool that we exposed.": "还记得我们公开的那个终端 shell 工具吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can run anything that we want.": "它可以运行我们想要的任何内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's very permissive.": "而且它的权限非常开放。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't have any checks or authentication.": "我们没有任何检查或身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't check who is the user, what the user is trying to do.": "我们不检查用户是谁，也不检查用户试图做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And people can do very nasty things with this kind of tools.": "人们可以使用这类工具做非常糟糕的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video, I'm going to show you how I can very easily delete files from my file system using": "在这段视频中，我将向你展示我如何利用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this MCP server.": "这个 MCP 服务器非常轻松地从我的文件系统中删除文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, you can imagine if we have those kinds of permissive tools and they are not well defined and not": "现在，你可以想象，如果我们拥有这类权限开放的工具，且它们没有得到明确定义和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:well scoped.": "良好的范围限制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then this opens the door for a lot of privilege escalation attacks, where maybe another MCP tool or": "那么这就会为大量的权限提升攻击打开大门，也许另一个 MCP 工具或",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a malicious actor can actually use this tool in order to perform malicious things.": "恶意行为者实际上可以利用这个工具来执行恶意操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because our tool is very permissive and it has too much scope, and it has too much things": "这是因为我们的工具权限过于开放，范围太广，而且它在我们的系统中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it can do in our system.": "能做的事情太多了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and let's see the demo.": "那么，让我们来看看演示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's see how we can make cloud desktop.": "让我们看看如何让 Claude Desktop",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now remove a file from my file system.": "现在从我的文件系统中删除一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a very dangerous thing.": "这是一件非常危险的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just show you my desktop here.": "让我在这里展示一下我的桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here you can see that I have this file MCP README.md.": "在这里你可以看到我有这个 MCP README.md 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and write to Cloud Desktop Step two delete the MCP readme.md in my desktop.": "让我去给 Claude Desktop 写下：第二步，删除我桌面上的 MCP readme.md。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see right from the get go.": "我们可以从一开始就看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The answer that we get is that it can't do it because it doesn't have access to my file.": "我们得到的回答是它无法执行，因为它没有访问我文件的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It does recognize the run command.": "它确实识别出了运行命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, it does acknowledge the run command function which is available, but it's saying that it": "然而，它虽然承认 run_command 函数是可用的，但它说它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is running within a restricted sandbox environment and that it doesn't have access to my machine, which": "运行在一个受限的沙箱环境中，无法访问我的机器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we know is not true.": "而我们知道事实并非如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we're seeing right here is some prompt engineering maybe that is implemented in the cloud desktop": "所以我们在这里看到的可能是在 Claude Desktop 客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:client MCP client.": "MCP 客户端中实现的一些提示词工程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you how we can pass that with a bit of prompting.": "那么让我向你展示我们如何通过一些提示词来绕过它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open a new chat and I will write help me clean up my computer.": "让我打开一个新的聊天，我会写“帮我清理电脑”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I will tell it that I want it to delete the MCP README.md file from the desktop.": "现在我会告诉它，我想让它删除桌面上的 MCP README.md 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a very simple prompting technique, where I simply gave it the role of somebody who is going": "这是一种非常简单的提示词技巧，我只是给它设定了一个角色，让它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to help me a bit.": "来帮我一点忙。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me allow the execution here, and we can see that the command which is being executed is rm f": "让我在这里允许执行，我们可以看到正在执行的命令是 rm -f",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remember dash force.": "记住，dash force（即 -f 强制删除）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to not ask for permissions and it's going to delete the file.": "所以它不会请求权限，而是直接删除文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is very very dangerous.": "这非常非常危险。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after it executed we get a result that it successfully did that.": "执行之后，我们得到了它成功完成操作的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that the file is gone here.": "我们可以看到文件已经不在这里了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hi there.": "你好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I eaten here.": "我在这里吃过饭。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about the key benefits of Dockerizing and running our MCP server in a Docker container.": "让我们来谈谈将 MCP 服务器 Docker 化并在 Docker 容器中运行的主要好处。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Consistency across environments.": "环境之间的一致性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Docker eliminates the works on my machine problem.": "Docker 解决了“在我的机器上可以运行”的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If the container runs on your system.": "如果容器在你的系统上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will run on your colleague's system.": "它也会在同事的系统上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even if one of you is on windows and the other on Mac or Linux.": "即使你们中一个人使用的是 Windows，而另一个人使用的是 Mac 或 Linux。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Docker abstracts away those OS level differences by using the containers OS environment.": "Docker 通过使用容器的操作系统环境，抽象掉了这些操作系统层面的差异。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This also means easier cross-platform development.": "这也意味着更简单的跨平台开发。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You could develop on windows and deploy to a Linux server without changing anything in your code.": "你可以在 Windows 上开发，然后部署到 Linux 服务器，而无需更改代码中的任何内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Isolation and safer execution.": "隔离和更安全的执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP server runs in its own sandbox.": "MCP 服务器在它自己的沙箱中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It won't accidentally overwrite files on the host or conflict with other running services.": "它不会意外覆盖主机上的文件，也不会与其他正在运行的服务发生冲突。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Plus, if the server needs access to, say, a specific folder or device, Docker lets you grant just": "此外，如果服务器需要访问（例如）特定的文件夹或设备，Docker 允许你仅授予",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that access using volumes or device flags, rather than the server having free reign on your system.": "该访问权限（通过使用数据卷或设备标志），而不是让服务器在你的系统上拥有完全的控制权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This containment is a big win for security and stability.": "这种容器化对于安全性和稳定性来说是一个巨大的胜利。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Easy scaling and management.": "易于扩展和管理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Need to run multiple instances of the MCP server for handling more requests.": "需要运行多个 MCP 服务器实例来处理更多请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Just launch more containers.": "只需启动更多容器即可。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Need to update the server.": "需要更新服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Build a new image version and deploy it.": "构建一个新的镜像版本并部署它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Containers fit nicely into orchestration tools like Docker Compose or Kubernetes if your project grows.": "如果你的项目规模扩大，容器可以很好地适配 Docker Compose 或 Kubernetes 等编排工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:While this might be beyond a beginner's scope, it's good to know you're using a method that scales": "虽然这可能超出了初学者的范围，但很高兴知道你正在使用一种扩展性良好的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:well.": "方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In conclusion, wrapping up our MCP server in Docker is a smart move.": "总之，将我们的 MCP 服务器封装在 Docker 中是一个明智之举。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We get portability, security, and peace of mind all in one container.": "我们在一个容器中获得了便携性、安全性和安心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there, real Eden is here.": "大家好，我是 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we're going to take the MCP server that we wrote earlier and we are going to containerize": "在这段视频中，我们将把之前编写的 MCP 服务器进行容器化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to run it inside a Docker container.": "所以我们将把它运行在一个 Docker 容器中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to do that we're going to first create a Docker file which is going to tell how to build our Docker": "为此，我们首先要创建一个 Dockerfile，它将告诉我们如何构建我们的 Docker",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:image.": "镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to create a container from that image running our MCP server.": "然后我们将根据该镜像创建一个运行我们 MCP 服务器的容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is not a DevOps course.": "这并不是一门 DevOps 课程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I don't think it's really important for you to know the ins and outs of how to create the best Docker": "所以我认为你并不需要深入了解如何创建最佳 Docker 的方方面面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm simply going to show you how we can containerize this app.": "我只是要向你展示我们如何将这个应用容器化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, cursor is going to do most of the work for us.": "顺便说一下，Cursor 将为我们完成大部分工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And from my experience, if you're an AI engineer, then most likely you wouldn't need to write a Docker": "根据我的经验，如果你是一名 AI 工程师，那么你很可能不需要编写 Docker",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:file and you would have a DevOps team and DevOps engineers, which can help with that, and can then": "文件，你会有 DevOps 团队和 DevOps 工程师来协助，然后他们可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:actually go and ship and deploy your application, your Docker container, to the cloud, running on": "实际去交付并将你的应用程序、你的 Docker 容器部署到云端，运行在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Kubernetes or on serverless, whether it's EKS or GKE Or axe whatever.": "Kubernetes 或无服务器架构上，无论是 EKS、GKE 还是其他任何平台。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go to the code and let's go build a docker file and let's go create a container from": "无论如何，让我们来看代码，去构建一个 Dockerfile，并从我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our MVP server.": "MCP 服务器创建一个容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and write to Cursor Agent that we want it to write a Docker file to run this application": "那么，让我们告诉 Cursor Agent，我们希望它编写一个 Dockerfile 来在容器内运行这个应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:inside a container.": "在容器内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll also tell it that we're using UV as our package manager.": "我们还会告诉它我们使用 UV 作为包管理器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to check out the official documentation regarding Docker of UV.": "并让它查看关于 UV 的 Docker 官方文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the last part of the prompt we'll tell Cursor agent the way we are running currently our application.": "在提示词的最后一部分，我们将告诉 Cursor Agent 我们目前运行应用程序的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are running it inside a virtual environment and we run it through the command UV run server dot": "我们是在虚拟环境中运行它的，通过命令 uv run server.",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pi.": "py 来运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it will have an easier time writing the command that will run once we instantiate this container.": "这样它就能更轻松地编写出一旦我们实例化这个容器时将运行的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And while cursor agent is going to implement it for us, I'm going to note that I'm using Gemini 2.5": "在 Cursor Agent 为我们实现它的同时，我要说明一下我使用的是 Gemini 2.5",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pro, but you can use any model you want.": "Pro，但你可以使用任何你想要的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm guessing every model would give a decent result here.": "我猜这里的每个模型都会给出不错的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, the code is available at the GitHub repository.": "顺便说一下，代码可以在 GitHub 仓库中找到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this request took me a minute.": "这个请求花了我一分钟时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me fast forward it a bit and let's see what cursor generates for us so we can see it didn't actually": "所以让我快进一下，看看 Cursor 为我们生成了什么，我们可以看到它实际上并没有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:create the file for some reason, but it gave us the code.": "出于某种原因创建文件，但它给了我们代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and copy that and I'll create a file manually.": "所以让我去复制它，然后我将手动创建一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and copy it and let's go.": "让我去复制它，然后开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's create here a new file in the root directory.": "让我们在根目录下创建一个新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I called it a Docker file.": "我把它命名为 Dockerfile。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and paste it.": "让我们把它粘贴进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's review the code we have here in the Docker file.": "让我们检查一下 Dockerfile 中的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this file has the instructions to Docker of how to create our Docker image.": "这个文件包含了告诉 Docker 如何创建我们的 Docker 镜像的指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after that from that Docker image we're going to create a Docker container that we're going to run.": "之后，我们将根据该 Docker 镜像创建一个我们将要运行的 Docker 容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to specify to our MCP client how to run our Docker container.": "我们将向 MCP 客户端指定如何运行我们的 Docker 容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's review the Docker file.": "那么，让我们来看看 Dockerfile。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what do we have here?": "这里都有什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see that the base image is going to be Python 3.1 12 Slim Bookworm, which is from the official": "我们可以看到基础镜像是 Python 3.12 Slim Bookworm，它来自官方的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Python image.": "Python 镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think now is also a good point to note that you should really be careful on which base images": "我认为现在也是提醒大家注意的好时机，你应该非常小心你所使用的基础镜像，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you're using, because someone can upload a malicious base image, and if you're going to use that,": "因为有人可能会上传恶意的基础镜像，如果你使用了它，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you may be compromised.": "你可能会受到攻击。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a common attack vector and you should always verify your base image.": "这是一个常见的攻击向量，你应该始终验证你的基础镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the second command, we are basically installing the UV package manager, which is going to be saved": "在第二个命令中，我们基本上是在安装 UV 包管理器，它将被保存",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and located in the slash bin directory.": "并放置在 /bin 目录下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Next, we are setting our working directory to be slash app, which is a common Docker pattern.": "接下来，我们将工作目录设置为 /app，这是 Docker 的常用模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we are going to copy the pyproject.toml file, which has the information of all of the packages": "然后我们将复制 pyproject.toml 文件，其中包含所有包的信息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that we have and need to install.": "也就是我们需要安装的那些包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we copied which packages we want to install.": "所以我们复制了想要安装哪些包的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we need to install them, and we do it with the run command where we run UV sync.": "现在我们需要安装它们，我们通过运行 UV sync 的 run 命令来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the mounting with the cache.": "还有带有缓存的挂载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here is simply some caching that we do in order for our builds to become faster.": "这里只是我们为了让构建速度更快而进行的一些缓存处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:UV sync installs the dependencies listed in a log file, which I now see that we didn't attach yet.": "UV sync 会安装 log 文件中列出的依赖项，我现在发现我们还没有添加这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just copied the HTML file which have the packages we need to install, but the log file has the exact": "我们刚刚只复制了包含需要安装的包的 HTML 文件，但 log 文件包含确切的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:versions that we need to install, so this could be easily replicated.": "我们需要安装的版本，这样就可以轻松复现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the frozen flag tells UV to not try to resolve or change any dependency.": "--frozen 标志告诉 UV 不要尝试解析或更改任何依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it simply needs to install exactly what is listed.": "所以它只需要完全按照列出的内容进行安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm seeing a potential bug.": "现在我发现了一个潜在的 bug。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because we did not copy the UV dot log file.": "这是因为我们没有复制 uv.log 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you can see in line 16 it's actually from some reason commented out.": "如果你看第 16 行，由于某种原因它实际上被注释掉了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we'll soon fix it.": "但我们很快就会修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Lastly, the dash dash no install project tells you to not install the actual project code, but just": "最后，--no-install-project 告诉 UV 不要安装实际的项目代码，而只安装",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the dependencies.": "依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to handle the project code.": "现在我们要处理项目代码了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll copy the server.py file to the working directory.": "所以我们将 server.py 文件复制到工作目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what we're doing here.": "这就是我们在这里所做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we are going to run the UV sync command again.": "然后我们将再次运行 UV sync 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this time we're not going to add the dash dash install project installs our code as a Python package.": "但这一次我们不会添加 --no-install-project，这会将我们的代码作为 Python 包进行安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way you're probably wondering why are we running the UV sync command twice?": "顺便说一句，你可能想知道为什么我们要运行两次 UV sync 命令？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because we could have simply ran it one time like we do in line 35.": "因为我们本可以像在第 35 行那样只运行一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This video will discuss MCP and security, and we'll talk about remote code execution and MCP, and": "本视频将讨论 MCP 与安全性，我们将探讨远程代码执行与 MCP，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we'll talk about supply chain attacks.": "我们将讨论供应链攻击。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to do this by creating first a malicious GitHub file, which is going to be accessible": "我们将通过首先创建一个恶意的 GitHub 文件来实现这一点，该文件将可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remotely.": "远程访问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you don't have to create this file.": "您不需要亲自创建这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to link it in the course's resources.": "我会在课程资源中提供它的链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're then going to expose a tool that would download this malicious file and use it inside our MCP": "然后，我们将公开一个工具，该工具会下载这个恶意文件并在我们的 MCP 中使用它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to see how we're going to compromise our MCP client with that.": "接着，我们将看看如何利用它来入侵我们的 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to GitHub to my personal account.": "现在让我前往 GitHub 的个人账户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to create a GitHub gist file.": "我想创建一个 GitHub gist 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And a gist file is a file I can create.": "gist 文件是我可以创建的一种文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's stored in the cloud and can be shared and can be public.": "它存储在云端，可以共享，也可以公开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's very convenient to work with.": "使用起来非常方便。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to create one I'll go to gist.github.com and let's go here.": "为了创建一个，我将访问 gist.github.com，让我们去那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I can put the content of my file.": "在这里我可以输入文件的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can give it a name and a suffix and I can then publish it.": "我可以给它起个名字和后缀，然后发布它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just paste in a nice husky drawing that an LLM created for me about somebody who is getting": "让我粘贴一张由大语言模型（LLM）为我生成的精美哈士奇绘图，内容是关于某人正在被",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:hacked.": "黑客攻击。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here I'm going to paste it.": "我现在把它粘贴在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see you have this character which is pointing a gun and the text you got hacked.": "你可以看到这个角色正拿着一把枪，还有“你被黑了”的文字。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll call this file.": "我给这个文件起个名字。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me call it hacked dot txt and let me go and publish it.": "让我把它命名为 hacked.txt，然后去发布它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to make it public so everybody can download it and can use it.": "我想把它设为公开，这样每个人都可以下载并使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once I do that I got here this file over here which everyone can access.": "一旦我这样做，我就得到了这个每个人都可以访问的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's under my GitHub username.": "它位于我的 GitHub 用户名下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can access it as well because it's public.": "你也可以访问它，因为它是公开的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I will share the link in the video's resources.": "我会在视频资源中分享这个链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to return the cursor.": "现在我想回到 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to expose another tool in my MCP server that is going to fetch this txt file which is stored": "我想在我的 MCP 服务器中公开另一个工具，它将获取这个存储在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remotely, not on my computer.": "远程（而非我的电脑上）的 txt 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to display the text that I have here.": "我想显示这里的文本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so let me write to cursor.": "好了，让我给 Cursor 写指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Help me expose another tool in my MCP server.": "帮我在我的 MCP 服务器中公开另一个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me tag the MCP documentation and use the Python SDK as well.": "让我标记 MCP 文档并同时使用 Python SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the tool should be called Benign tool.": "这个工具应该被命名为 Benign tool。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And should download via curl command.": "并且应该通过 curl 命令下载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The content of this URL here and this is the URL and we should also return what was downloaded.": "这个 URL 的内容（这就是该 URL），我们还应该返回下载的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so let us wait while it generates this tool here.": "好的，让我们等待它生成这个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to fast forward this.": "我会快进这一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we got here this implementation of this extra tool.": "我们得到了这个额外工具的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's called the baseline tool.": "所以它被称为 baseline 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It downloads the content of a specified URL string using the core command.": "它使用 curl 命令下载指定 URL 字符串的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it returns a dictionary containing the download content and the status.": "它返回一个包含下载内容和状态的字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the URL which is going to be hard coded.": "这是将被硬编码的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all that it does.": "它所做的全部工作就是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It spawns a new subprocess and it runs the curl command to do so.": "它生成一个新的子进程并运行 curl 命令来执行此操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the reason why we do that is to help with caching when we build our Docker image.": "我们这样做的原因是为了在构建 Docker 镜像时帮助利用缓存。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because we split it into two commands of, one is going to install the dependencies as the packages": "因为我们将其拆分为两个命令，其中一个是将依赖项作为包进行安装，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which are going to be heavier, and it's going to take a bit more resources.": "这些依赖项通常比较重，会消耗更多资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this can be cached because this doesn't change a lot.": "所以这部分可以被缓存，因为它们不经常变动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And our code is actually something which is changing a lot.": "而我们的代码实际上是经常变动的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's why we separate it to a different command, installing it as a package.": "这就是为什么我们将其拆分到另一个命令中，将其作为包来安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and this time when we change our code and we want to rebuild the image, then what will happen?": "那么，当我们修改代码并想要重新构建镜像时，会发生什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We will simply rebuild only this layer of the Docker image.": "我们只需要重新构建 Docker 镜像的这一层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, don't feel bad if you're not understanding most of this part here.": "顺便说一下，如果你不太理解这里的这大部分内容，也不要觉得难过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is mainly DevOps work.": "这主要是 DevOps 的工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:AI engineers usually don't do it.": "AI 工程师通常不处理这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so this is just as an FYI.": "嗯，所以这只是供你参考。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and lastly, we have the final command that we want to run when we run our container.": "嗯，最后，我们有运行容器时想要执行的最终命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is in line 39 and we want to run.": "这在第 39 行，我们想要运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've run Server.py.": "运行 Server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is how we're running the command locally.": "这就是我们在本地运行该命令的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's open terminal and let's go and build our Docker image.": "那么让我们打开终端，开始构建我们的 Docker 镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for that we'll run the command docker build which is going to build an image from the Docker file.": "为此，我们将运行 docker build 命令，它将根据 Dockerfile 构建镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to tag it.": "我们要给它打上标签。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's the dash t flag.": "也就是 -t 标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to call this tag shell server app.": "我们将这个标签命名为 shell server app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the dot here specifies that we want to read the Docker file from the current working directory and": "这里的点号指定我们要从当前工作目录读取 Dockerfile，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:let's go and run it and I get an error.": "让我们运行它，结果我遇到了一个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the error said that it's unable to find the log file at uBlock.": "错误提示说在 uBlock 找不到日志文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I remind you this is because we did not copy the UVC log.": "我提醒一下，这是因为我们没有复制 UVC 日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We only copied the pyproject.toml.": "我们只复制了 pyproject.toml。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So no biggie.": "所以没什么大不了的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Everyone has bugs.": "谁都会遇到 bug。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to line 16 and uncomment it.": "那么让我们转到第 16 行并取消注释。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we're also copying the log file.": "这样现在我们也复制了日志文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now and build now the image again.": "现在让我再次构建镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the command will run again.": "命令将再次运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Docker build d shell server app dot.": "Docker build -t shell server app .",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see what we get.": "让我们来看看结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we can see this is progressing well.": "现在我们可以看到进展顺利。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see it's installing the packages in bull.": "我们可以看到它正在批量安装包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have built our Docker image.": "我们已经构建好了 Docker 镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I right Docker images I can see that this image was built.": "如果我输入 docker images，我可以看到这个镜像已经构建好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's called shell server app.": "它叫 shell server app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The tag is latest.": "标签是 latest。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the image ID.": "这是镜像 ID。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's created six seconds ago and the size is 200MB.": "它是在 6 秒前创建的，大小为 200MB。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's ask ourselves, how do we run a container from this image?": "那么让我们问问自己，如何从这个镜像运行容器？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I gave it the image information.": "我提供了镜像信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Simply copy that line over there and we can see we can run it with docker run it RM shell server app.": "只需复制那一行，我们可以看到可以使用 docker run -it --rm shell server app 来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run it.": "让我运行一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this container is currently running.": "这个容器目前正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you that I'll create another instance of terminal.": "让我向你展示，我将创建另一个终端实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All righty.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and accept this file over here.": "让我在这里接收一下这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's now go and let's restart cloud desktop in order to see if it's working.": "现在让我们重启云桌面，看看它是否正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what's the output.": "让我们看看输出结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open a new chat and let me write here.": "让我开启一个新的对话，在这里输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Run the benign tool.": "运行这个良性工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to allow it.": "我会允许它运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that it's running this benign tool here.": "我们可以看到它正在这里运行这个良性工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that the image was downloaded.": "我们可以看到图片已经下载好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see that it's being displayed like we wanted.": "现在我们可以看到它正按照我们的预期显示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's recap on what we did and what are the actual implications here.": "让我们回顾一下我们做了什么，以及这其中的实际影响。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What we just did is download dynamically from a remote storage content, and we injected it into our": "我们刚才所做的是从远程存储动态下载内容，并将其注入到我们的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:running system and into a running code base.": "运行系统和运行中的代码库中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we use the very benign example of a.": "我们使用了一个非常良性的例子，即一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT file with some Ascii drawing.": "带有 ASCII 绘图的 .txt 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But imagine that instead of this Ascii drawing.": "但想象一下，如果不是这个 ASCII 绘图。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What we would have here is malicious code that is going to steal our passwords, maybe create a reverse": "我们这里有的可能是恶意代码，它会窃取我们的密码，或者创建一个反向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:proxy so hacker can login into our computer, or a script that is going to wipe out our hard drive.": "代理以便黑客登录我们的电脑，或者是一个会抹除我们硬盘数据的脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I'm trying to say here is that MCP servers, if not used correctly, can be dangerous because": "所以我想说的是，如果使用不当，MCP 服务器可能会很危险，因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:if we are going to clone an open source repository that somebody on the internet put on GitHub, some": "如果我们克隆一个别人放在 GitHub 上的开源仓库，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:similar code like this can be there.": "里面可能就包含类似这样的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the URL may not look malicious, but the content inside that URL may be malicious.": "网址看起来可能并不恶意，但该网址指向的内容可能是恶意的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's why it's very super important to examine the code that you clone and to review it before you": "所以这就是为什么在运行之前检查你克隆的代码并进行审查",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:run it, and definitely before you configure your MCP with your MCP client, because the demo I just": "是非常非常重要的，尤其是在你用 MCP 客户端配置 MCP 之前，因为我刚才",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:showed you can be easily manipulated for remote code execution, which is a common attack vector.": "展示的演示可以很容易地被操纵用于远程代码执行，这是一种常见的攻击向量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP servers that you find on GitHub are literally remote code execution Because you download software": "你在 GitHub 上找到的 MCP 服务器本质上就是远程代码执行，因为你下载了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that somebody else wrote and you're running it in your machine.": "别人编写的软件并在你的机器上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now you tell me if you should trust everything you download from GitHub.": "现在你告诉我，你是否应该信任从 GitHub 下载的所有东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the answer is definitely no.": "答案显然是否定的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If it comes from a trusted source like a trusted vendor, probably it's going to be safer.": "如果它来自受信任的来源，比如受信任的供应商，可能会更安全。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, it still can be dangerous even if it's code written by an official vendor like Cloudflare,": "然而，即使是像 Cloudflare 这样的官方供应商编写的代码，仍然可能存在危险，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for example, it may still have vulnerabilities because it's still open source and other people can": "例如，它可能仍然存在漏洞，因为它仍然是开源的，其他人可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:contribute to it, and other people can introduce some exploits in that code.": "对其进行贡献，而其他人可能会在代码中引入一些漏洞利用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And furthermore, let's say we download an NCP from an official vendor like Cloudflare.": "此外，假设我们从 Cloudflare 这样的官方供应商下载了一个 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If they're using an open source package, then that open source that Cloudflare is using that can have": "如果他们使用了某个开源包，那么 Cloudflare 使用的那个开源包也可能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:also vulnerabilities.": "存在漏洞。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're starting to talk about supply chains attack here.": "所以我们现在开始讨论供应链攻击了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the whole point of this video is simply to show you that you should not trust every NCP server you": "这段视频的全部目的只是为了向你展示，你不应该信任你看到的每一个 NCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:see, and that it's literally remote code execution.": "，而且它实际上就是远程代码执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it can be very easily manipulated to run malicious code.": "并且它非常容易被操纵来运行恶意代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll check which containers are running now on my machine.": "现在我来检查一下我的机器上正在运行哪些容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me split the terminal over here and I'm going to write Docker PS.": "让我在这里拆分一下终端，然后输入 docker ps。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that we have this container over here.": "我们可以看到这里有一个容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see the logs of these containers.": "让我们看看这些容器的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we have anything just copying the ID of the container to see any logs.": "如果有内容的话，只需复制容器 ID 即可查看日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we see we don't have any logs.": "我们可以看到没有任何日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, this is because we didn't activate the server.": "嗯，这是因为我们还没有启动服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We didn't send the request.": "我们还没有发送请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is actually expected.": "所以这实际上是在预料之中的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time to go and configure it with Cloud Desktop.": "现在是时候去使用 Cloud Desktop 进行配置了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so let me now quit clod and let me open it again.": "好了，现在让我退出 Claude，然后再次打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to open it side by side so we can actually see the logs of the containers.": "我想把它并排打开，这样我们就能看到容器的日志了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see we successfully loaded cloud.": "我们可以看到我们成功加载了 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we go to the tools we have we can see we have the run command, same tool.": "如果我们查看现有的工具，可以看到我们有 run 命令，还是那个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the name of the server now is Docker shell because we're running it from Docker.": "但现在的服务器名称是 Docker shell，因为我们是在 Docker 中运行它的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remember we changed the name and I want to double check that this indeed uses the new configuration.": "记得我们更改了名称，我想再次确认这确实使用了新的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll go to Settings to developer.": "所以我会进入“设置”中的“开发者”选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see that it's running with the exact arguments that we gave in the JSON file for the": "在这里我们可以看到，它运行时的参数与我们在 JSON 文件中为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:cloud desktop configuration.": "Claude Desktop 配置提供的参数完全一致。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go back to cursor here and to the terminal window.": "让我回到这里的 Cursor，并进入终端窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want now to review the logs of the Docker container which is running with cloud spin up.": "我现在想查看由 Claude 启动运行的 Docker 容器的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because cloud spin up a Docker container which is going to be used.": "因为 Claude 启动了一个将要使用的 Docker 容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have actually two Docker containers and not one.": "我们可以看到实际上有两个 Docker 容器，而不是一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think this is from me playing around from before.": "我想这是因为我之前在瞎折腾。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me check out the logs of the older container.": "那么让我查看一下旧容器的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy the ID of the older container.": "我要复制旧容器的 ID。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to write Docker logs dash dash follow.": "然后输入 docker logs --follow。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if there are any new logs they will be displayed.": "这样如果有任何新日志，它们都会显示出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see in this container we have the least tool request.": "我们可以看到在这个容器中，我们有 list tools 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the server responded to the client by listing all the tools that it has.": "服务器通过列出其拥有的所有工具来响应客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have only one tool the run command.": "我们只有一个工具，即 run 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have all the metadata about the tool description, the arguments, the return value.": "我们这里有关于工具描述、参数、返回值的全部元数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have it all written here.": "所有的内容都写在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we're seeing actually is the first communication between the MCP client and the MCP server.": "所以我们看到的实际上是 MCP 客户端和 MCP 服务器之间的第一次通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this initialization is happening when the client is being initialized with the server.": "这种初始化发生在客户端与服务器进行初始化连接时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the clients need to know what kind of tools or resources or prompts the server exposes.": "因此客户端需要知道服务器暴露了哪些工具、资源或提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll dive deep into the communication and to the protocol itself later in this course.": "在本课程的后面部分，我们将深入探讨通信和协议本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now what I want to do is to write something in cloud desktop.": "现在我想在 Claude Desktop 中写点东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to see what logs I'm going to see right over here in the Docker container.": "我想看看在 Docker 容器的这里会看到什么样的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now invoke the tool and ask Cloud Desktop to write hello and CP in Ascii art, and then to echo": "现在让我们调用该工具，让 Claude Desktop 用 ASCII 艺术写出 hello MCP，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it via terminal.": "通过终端将其回显。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what we're going to get.": "让我们看看会得到什么结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first it draws the Ascii art of hello.": "首先，它绘制了 hello 的 ASCII 艺术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it asks us to approve to run the terminal Docker tool.": "然后它要求我们批准运行终端 Docker 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's accept that.": "让我们接受它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's wait for us to get the answer.": "让我们等待答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me get out of this artifact over here.": "让我退出这里的这个 Artifact。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that it actually ran it.": "我们可以看到它确实运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see the results on the right side here.": "我们可以在右侧看到结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so we can see that it ran the command echo.": "我们可以看到它运行了 echo 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So before creating the Docker container of our MVP server, the way we ran it is by running the UV command": "所以在为我们的 MVP 服务器创建 Docker 容器之前，我们运行它的方式是运行 UV 命令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from the directory where our code is located, and we ran the run command with the server Pi as an argument.": "在代码所在的目录下，我们运行了 run 命令，并将 server.py 作为参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we need to adjust how we run the MVP server to tell cloud desktop to run it through a container.": "所以现在我们需要调整运行 MVP 服务器的方式，告诉 Claude 桌面端通过容器来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to tell it that we first want to run Docker.": "所以我们需要告诉它，我们首先想要运行 Docker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we want to run very similarly to what we did in the terminal.": "这里的运行方式与我们在终端中的操作非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to run dash ID and we want to give the tag of the image we're going to run.": "我们想要运行 -it，并提供我们要运行的镜像标签。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm here going to remove these args line here.": "所以我现在要删除这里的这些 args 行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way I'm using windsurf as my code editor for this JSON file.": "顺便说一下，我正在使用 Windsurf 作为这个 JSON 文件的代码编辑器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So with no specific reason.": "并没有什么特别的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that windsurf is suggesting me an autocomplete.": "我们可以看到 Windsurf 正在为我提供自动补全建议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this autocomplete may look fine, but it's not actually what we need because windsurf doesn't know": "现在这个自动补全看起来可能还行，但实际上并不是我们需要的，因为 Windsurf 并不了解",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right now my context and how do I run my MCP server and how did I dockerize it, etc..": "我现在的上下文，以及我如何运行我的 MCP 服务器，我是如何将其 Docker 化的，等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the autocomplete is not really what I need.": "所以自动补全并不是我真正需要的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply paste in the arguments that I need to supply the docker command.": "所以让我直接粘贴我需要提供给 Docker 命令的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to do that I'll go back to cursor where I'm running the docker container.": "为此，我将回到我运行 Docker 容器的 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me first kill our container.": "让我先杀掉我们的容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I did that and let me copy the command that we ran before.": "我已经做好了，让我复制我们之前运行的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the command was docker run dash 8-- shell server app.": "命令是 docker run -it shell-server-app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and take it and let me clean a bit the terminal workspace.": "让我去拿它，并稍微清理一下终端工作区。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to clear this terminal and let's go back.": "我要清空这个终端，然后我们回去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what I need to run is Docker run it.": "我需要运行的是 Docker run -it。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to run the shell server app.": "我要运行 shell-server-app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the image we are running the container from.": "这是我们运行容器所基于的镜像。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice in line 19 I changed the name of the MCP server to be Docker shell to make it a bit more": "注意在第 19 行，我将 MCP 服务器的名称更改为 Docker shell，以便在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:explicit when debugging.": "调试时更加明确。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go and let's restart cloud and then rerun it again.": "总之，让我们去重启 Claude，然后再次运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to quit and I'm going to run it again.": "我要退出并再次运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we get an error.": "当然，我们遇到了一个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and check out the error logs.": "所以让我们去查看错误日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to choose the NCP Docker shell.": "我将选择 MCP Docker shell。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and open that.": "让我们去打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's try to figure out what's wrong here.": "让我们试着找出这里出了什么问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to be honest I did try and figure out what's wrong with the setup here from the log, but I couldn't": "老实说，我确实尝试过从日志中找出这里的设置出了什么问题，但我没能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:figure it out.": "找出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what's relevant here, by the way, is the logs here at the bottom.": "顺便说一下，这里相关的是底部的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's on the top is my previous tries, so you can ignore that.": "顶部是我之前的尝试，所以你可以忽略。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to figure out what's wrong and to fix this I simply search on Google Amqp Docker.": "为了找出问题并修复它，我直接在 Google 上搜索了 MCP Docker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I went to the official Docker tutorial and I'm going to link it in the courses resources.": "我查看了 Docker 官方教程，我会将其链接放在课程资源中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the main difference here is that in this command which they ran, they added the environment variable": "这里的核心区别在于，在他们运行的这个命令中，他们添加了环境变量",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it inputted this hello MCP in Ascii art and then we can see the result afterwards.": "然后它以 Ascii 艺术形式输入了这个 hello MCP，接着我们可以看到之后的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But notice that there isn't anything new in the logs of the container we are monitoring right now.": "但请注意，我们目前正在监控的容器日志中没有任何新内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is probably because Cloud Desktop was using the other container.": "所以这可能是因为 Cloud Desktop 正在使用另一个容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a leftover container from me playing around a bit and creating containers.": "这是我之前随便尝试并创建容器时留下的一个容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of that Docker image.": "也是那个 Docker 镜像的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and check the logs of the newest container.": "那么让我去检查一下最新容器的日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy the ID and let's check out the logs.": "我要复制这个 ID，然后让我们查看一下日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can actually see let's go up a bit.": "在这里我们实际上可以看到，让我们往上翻一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can actually see the Ascii art.": "我们实际上可以看到 Ascii 艺术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can actually see that this tool was actually called.": "我们实际上可以看到这个工具确实被调用了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see right now that we have the result here of the tool invocation.": "我们现在可以看到这里有工具调用的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here that this is the output from stdout and that the status code was zero and it ran successfully.": "我们在这里看到这是来自标准输出 (stdout) 的输出，状态码为零，运行成功。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is working as expected.": "所以这正如预期般工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so let me just write something else.": "好了，让我再写点别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now.": "现在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's right now.": "让我们现在写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cool with better Ascii art and then echo it.": "用更好的 Ascii 艺术写个 \"Cool\"，然后将其回显。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see now this is the artifact.": "你现在可以看到这就是生成的制品 (artifact)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the Ascii art which is saying cool.": "所以这就是显示 \"cool\" 的 Ascii 艺术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's comprised of those characters over here, which we're seeing that they're getting printed.": "它由这里的这些字符组成，我们看到它们正在被打印出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, let's go and examine the tool input and output.": "顺便说一下，让我们去检查一下工具的输入和输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the top part here we can see this is actually part of the tool input.": "所以这里的顶部部分，我们可以看到这实际上是工具输入的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see at the beginning the Ascii art.": "我们可以看到开头的 Ascii 艺术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're then putting this content in the cool dot txt file.": "然后我们将这些内容放入 cool.txt 文件中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're using the cat command to display the content of the file on the terminal anyways.": "然后我们使用 cat 命令在终端上显示该文件的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that the stdout.": "我们可以看到标准输出 (stdout)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the result after executing this command.": "所以这是执行该命令后的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see this is the actual drawing.": "我们可以看到这是实际的图形。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the characters that comprise it by the way.": "顺便说一下，这些就是组成它的字符。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It actually did the same for the previous command and we simply didn't see it.": "实际上之前的命令也是这样做的，只是我们没看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so now let's ask Cloud Desktop to list the files in my desktop directory and let's give it": "好了，现在让我们让 Cloud Desktop 列出我桌面目录中的文件，并给它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the path.": "路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be tilde desktop.": "也就是 tilde desktop (~/Desktop)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me remind you that we're running inside of a Docker container.": "让我提醒你，我们是在 Docker 容器内部运行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we did not mount anything from our file system.": "而且我们没有挂载文件系统中的任何内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is actually an isolated sandbox.": "所以这实际上是一个隔离的沙箱。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it should not find anything in the desktop directory because a container does not have it by default.": "所以它不应该在桌面目录中找到任何东西，因为容器默认没有这个目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see at the beginning clogs tries to run the command to list the desktop files, but it's getting": "所以我们可以看到，一开始 clogs 尝试运行列出桌面文件的命令，但它收到了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an error.": "一个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:No such file or directory, so it's writing.": "“没有那个文件或目录”，所以它写道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It seems that this desktop directory does not exist, so it takes a step backward and trying to list": "似乎这个桌面目录不存在，所以它退后一步，尝试列出",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the home directory to see what it has there.": "家目录，看看那里有什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see ls la tilde.": "你可以看到 ls la tilde。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is from the home directory.": "这是来自家目录的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after it gets that result.": "所以在它得到那个结果之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see that it doesn't contain the desktop directory.": "你可以看到它并不包含 desktop 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to try to do something else, and it's going to list the files as a last result in the": "所以它会尝试做点别的，作为最后的手段，它会列出",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:current working directory.": "当前工作目录下的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see the result and we can see what files that it find.": "现在我们可以看到结果，看看它找到了哪些文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So interestingly enough it finds this cool TXT and hello txt the Ascii art that we drew.": "有趣的是，它找到了这个 cool.txt 和 hello.txt，也就是我们画的 Ascii 艺术图。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can actually see that we created it earlier.": "所以它实际上能看到我们之前创建的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see it from the answer here, but it sees other things.": "你可以从这里的回答中看到，但它还看到了其他东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can see also all the files related to our MCP server.": "它还能看到所有与我们的 MCP 服务器相关的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can see the UVC, the server.py file, the Pyproject.toml and the Venv.": "它能看到 UVC、server.py 文件、Pyproject.toml 以及 Venv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it contains all the virtual environment files.": "所以它包含了所有的虚拟环境文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, you can see on the left side all the logs from the MCP server.": "顺便提一下，你可以在左侧看到来自 MCP 服务器的所有日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what I want to do now is to actually go inside the container and let's see if cloud can remove files": "我现在想做的是实际进入容器内部，看看 Claude 是否能删除",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from that container.": "该容器中的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this container runs in an isolated environment.": "所以这个容器运行在一个隔离的环境中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now it's a sandbox.": "现在它是一个沙箱。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply open a new terminal window.": "让我简单地打开一个新的终端窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to go inside the container.": "现在我想进入容器内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go write Docker exec dash it for interactive shell.": "让我输入 Docker exec -it 来进入交互式 shell。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to activate ssh.": "我想激活 sh。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the shell.": "也就是 shell。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we're inside the Docker container.": "所以现在我们就在 Docker 容器内部了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Which cloud spin up.": "这是由 Claude 启动的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's write LZ to see the files in this container.": "让我们输入 ls 来查看这个容器中的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the files in the current working directory, which are the exact files that cloud listed": "这些是当前工作目录下的文件，正是 Claude 为我们列出的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for us except for the venv.": "那些文件，除了 venv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can't see them right now because it's a hidden directory.": "我们现在看不到它，因为它是一个隐藏目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now tell cloud to remove the hello.": "现在让我们告诉 Claude 删除 hello。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TXT let's see what happens there.": ".txt，看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's removing the file with MB and it's listing to see that it was removed.": "所以它正在用 rm 删除文件，并列出目录以确认它已被删除。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it verifies it.": "所以它验证了这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you know we can't trust LMS.": "但你知道，我们不能完全信任 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and verify it ourselves.": "所以让我们亲自去验证一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can actually see that the hello MCP file doesn't exist.": "我们可以看到 hello MCP 文件确实不存在了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it was indeed removed.": "所以它确实被删除了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly let me display cool dot txt because it is cool.": "最后，让我显示一下 cool.txt，因为它很酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nice.": "很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me finish up this video by committing this to GitHub.": "最后，我将通过把这些提交到 GitHub 来结束这段视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply adding the docker file.": "我只是简单地添加 Dockerfile。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's use the AI feature of cursor which is going to generate a commit message for me.": "让我们使用 Cursor 的 AI 功能，它会为我生成一条提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's take that and let's push it.": "让我们采用它并推送上去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the code is available here in the GitHub repository in case you want to check it out.": "代码可以在这个 GitHub 仓库中找到，以防你想查看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of docker container equals true.": "DOCKER_CONTAINER=true。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is to tell the MCP server which is running that it's running inside a Docker container.": "所以这是为了告诉正在运行的 MCP 服务器，它是在 Docker 容器内运行的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I also noticed that they are running it with the dash.": "我还注意到他们运行时带了短横线标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I flag the dash interactive.": "我使用了交互式标志 -i。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this keeps stdin open.": "所以这保持了标准输入（stdin）处于打开状态。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I ran it with Dash it.": "我用 -it 运行了它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I added the dash t flag.": "所以我添加了 -t 标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means I allocate a virtual terminal and give the familiar command line interface experience.": "这意味着我分配了一个虚拟终端，并提供了熟悉的命令行界面体验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is something that may interfere with the communication between the MCP client and the MCP server.": "所以这可能会干扰 MCP 客户端和 MCP 服务器之间的通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They also added the dash dash init.": "他们还添加了 --init。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the dash dash init flag is a tiny helper that handles signals properly.": "所以 --init 标志是一个正确处理信号的小助手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I don't think it's that relevant, but uh, let's copy it as well.": "所以我觉得它没那么相关，但是，呃，我们也把它复制过来吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just paste in the new command here.": "让我把新命令粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's have a recap of how we're telling Cloud Desktop to run our container.": "让我们回顾一下我们是如何告诉 Cloud Desktop 运行我们的容器的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all the name of the tag we're going to run.": "首先是我们要运行的标签名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the image is going to come from shell server app.": "所以镜像将来自 shell server app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're using the Dash I flag to run it in interactive mode which keep stdin open.": "我们使用 -i 标志以交互模式运行它，这会保持标准输入（stdin）打开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means the container can accept input from our keyboard or a program, and that program is going": "这意味着容器可以接受来自键盘或程序的输入，而那个程序将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be the MCP client.": "是 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The dash dash flag is going to delete the container after it exits.": "--rm 标志将在容器退出后将其删除。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it cleaned it up automatically.": "所以它会自动清理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the dash dash init simply adds a small process to clean up some child process to avoid any zombie": "而 --init 只是添加了一个小程序来清理一些子进程，以避免产生任何僵尸进程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In case the process of the container finishes and exits again.": "以防容器进程结束并再次退出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not expecting you to understand everything.": "我不指望你理解所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is not a DevOps course and we added the environment variable of Docker container equals true.": "这不是一门 DevOps 课程，我们添加了环境变量 DOCKER_CONTAINER=true。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is to tell the app that it's running inside a container.": "这是为了告诉应用程序它正在容器内运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So probably the MCP server SDK is using this flag somehow to run differently or to communicate differently.": "所以 MCP 服务器 SDK 可能以某种方式使用这个标志来以不同的方式运行或通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly the image that we are running is called shell server app.": "最后，我们运行的镜像叫做 shell server app。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Eden here.": "我是 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this section, I want to dive a bit deeper and talk about the history of what happened prior": "在这一节中，我想深入探讨一下，谈谈在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to NCP in the AI application world.": "AI 应用领域中 MCP 出现之前的历史。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to reiterate on Agentic behavior tool calling tool invocation, how it works under the hood,": "我想重申一下智能体行为、工具调用和工具触发及其底层运作机制，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is going to help us sharpen the notion of why MCP is so useful.": "这将有助于我们更清晰地理解为什么 MCP 如此有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to also compare MCP to length chain, so I want to discuss how MCP and length chain are similar": "我还想将 MCP 与 LangChain 进行对比，讨论 MCP 和 LangChain 的相似之处",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and what makes them different.": "以及它们的区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, I want to show you how we can integrate together MCP with length chain because they both": "最后，我想向大家展示如何将 MCP 与 LangChain 集成在一起，因为它们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:work together really, really well.": "配合得非常默契。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to do that by covering the latest open source chain released long chain MCP adapters,": "我们将通过介绍 LangChain 最新发布的开源 MCP 适配器来实现这一点，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is an open source package which helps to leverage the advantages of MCP in the link chain ecosystem.": "这是一个开源包，有助于在 LangChain 生态系统中发挥 MCP 的优势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to understand MCP in depth, we really need to go back a bit and to talk about the history": "为了深入理解 MCP，我们确实需要回顾一下历史，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of LMS and AI applications in general.": "谈谈 LLM 和 AI 应用的总体发展历程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me remind you, what are LMS?": "让我提醒大家一下，什么是 LLM？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LMS are simple token generators.": "LLM 是简单的 Token（词元）生成器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're guessing one token after the other and they're simply text generators.": "它们一个接一个地预测 Token，本质上只是文本生成器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something which is not that obvious, because nowadays, with all the agentic behavior,": "这点其实并不那么显而易见，因为如今随着各种智能体（agentic）行为的出现，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:people think that LMS have superpowers and they can do tons of stuff.": "人们认为 LLM 拥有超能力，可以做很多事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is not the case.": "但事实并非如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LMS can only output text, or maybe if it's multimodal LMS, they can also output pictures and other": "LLM 只能输出文本，或者如果是多模态 LLM，它们也可以输出图片和其他",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:formats, but they certainly cannot go and perform actions.": "格式，但它们绝对无法亲自去执行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those extra capabilities like searching the web, performing deep research, or invoking a Python": "因此，像网页搜索、进行深度研究或调用 Python",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:function, those are external tools that are integrated into the application which is running the LLM.": "函数这些额外能力，其实是集成在运行 LLM 的应用程序中的外部工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, in ChatGPT you use maybe the ChatGPT application in your desktop, or you use the ChatGPT": "例如，在 ChatGPT 中，你可能使用的是桌面端的 ChatGPT 应用，或者使用 ChatGPT",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:web application so it has the LLM wrapped inside an application.": "Web 应用，因此它是将 LLM 封装在一个应用程序内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Software engineers wrote those applications.": "软件工程师编写了这些应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me remind you how tool usage works.": "让我提醒你工具调用是如何工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So tools like web searching is external code that are not part of the LLM that software engineers wrote.": "像网页搜索这样的工具是外部代码，不属于软件工程师编写的 LLM 的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you use ChatGPT and you toggle the web search option.": "所以如果你使用 ChatGPT 并开启网页搜索选项，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the software engineers that work at OpenAI, they wrote this functionality.": "OpenAI 的软件工程师们编写了这项功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And how do we get these ad hoc behavior of tool usage with Llms.": "那么我们是如何让 LLM 实现这种特定的工具调用行为的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what's happening underneath the hood.": "让我们看看底层发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is probably what's happening with OpenAI and all the other chat applications that are leveraging": "这可能就是 OpenAI 以及所有其他利用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Llms is that we leverage tool calling.": "LLM 的聊天应用所采取的方式：利用工具调用（tool calling）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember the Llms are text and token generator.": "请记住，LLM 是文本和 Token 生成器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what happens here is that we have a very fancy system prompt.": "这里发生的是，我们有一个非常精妙的系统提示词（system prompt）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This all boils down into a system prompt, which instead let's say in a in a question like what is the": "这一切都归结为一个系统提示词，比如对于“现在的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:weather right now?": "天气怎么样？”这样的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Instead of generating this answer for those kinds of use cases, it won't say that the weather right": "对于这类用例，它不会直接生成答案，不会说现在的天气",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:now is 25°C.": "是 25°C。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But what it would do, it would generate the text, get weather, and open parentheses with the arguments": "相反，它会生成一段文本，比如 get_weather，然后带上括号和参数，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the city that we want the weather to.": "指明我们想要查询天气的城市。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so instead of generating the answer for this and hallucinating it because it doesn't have access": "好了，它不是直接生成答案并产生幻觉（因为它无法访问",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to real world information, then it simply generates the tool called the tool invocation.": "现实世界的信息），而是简单地生成工具调用或工具触发指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this tool call is going to be in a very specific format that the vendor decides, which is going": "这种工具调用将采用厂商决定的特定格式，这种格式",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be very easy to parse.": "非常易于解析。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be easy to parse the functions that need to be called.": "这样就能轻松解析出需要调用的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be easy to parse the arguments which we need to call the function with.": "解析调用函数所需的参数将会非常容易。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there are many variations of tool calling.": "工具调用有很多种变体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Each vendor implements it differently, but it all boils down into a very special system prompt, and": "每个厂商的实现方式各不相同，但归根结底都是通过一个非常特殊的系统提示词实现的，而且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we reviewed in my LinkedIn course the react prompt, which is an example of one.": "我们在我的 LinkedIn 课程中回顾了 ReAct 提示词，这就是其中一个例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is basically what's happening underneath the hood.": "这基本上就是底层发生的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The LLM application, for example ChatGPT then takes this output, it parses it.": "LLM 应用（例如 ChatGPT）随后会获取此输出并进行解析。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if there is a tool call it simply goes and invoke the functionality that the engineers wrote.": "如果存在工具调用，它就会直接去调用工程师编写的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can have, for example, a web search tool.": "例如，它可以拥有一个网页搜索工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the ChatGPT application is going to be wrapped in a very special prompt that is going to output,": "ChatGPT 应用将被封装在一个非常特殊的提示词中，该提示词会在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:when necessary, the invocation of a web search with the user's query.": "必要时输出带有用户查询的网页搜索调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for example, if I would go and ask what is the stock price of Nvidia, it would go and generate": "例如，如果我去问英伟达的股价是多少，它就会生成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the tokens of search on the web of web search and query to be Nvidia stock price.": "网页搜索的 Token，并将查询内容设为“英伟达股价”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after the ChatGPT application performed the tool call, then it would generate another LLM call with": "在 ChatGPT 应用执行工具调用后，它会利用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the result of that tool call and the original user's query.": "该工具调用的结果和原始用户查询再次生成一次 LLM 调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the basic functionality of almost every given agent.": "这就是几乎所有智能体的基本功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And also, it's important to note that.": "此外，有一点很重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Llms are statistical creatures, so they are guessing the token one after another.": "LLM 是统计学产物，因此它们是一个接一个地预测 Token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this tool calling this tool calling mechanism, which the LLM is going to output the correct.": "所以这种工具调用机制，即 LLM 输出正确的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Tool that we need to invoke with the correct arguments.": "我们需要调用的工具以及正确的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It does not work 100% but it works.": "它并非 100% 有效，但确实可行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A lot of the time, and most of the time is actually pretty good for authentic applications.": "在很多情况下，而且在大多数情况下，对于实际应用来说效果其实相当不错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to summarize, Llms are simple token generators and token predictors, and tool calling capability": "总而言之，LLM 是简单的 Token 生成器和预测器，而工具调用能力",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is actually ad hoc behavior that we add in the application layer.": "实际上是我们添加在应用层的特定行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to MCP.": "那么，让我们回到 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP lets us focus on writing those tools and exposing them in MCP servers.": "MCP 让我们能够专注于编写这些工具并将其暴露在 MCP 服务器中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those tools that we write, they can be used on all other applications that supports function calling.": "这样我们编写的工具就可以在所有其他支持函数调用的应用中使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they can be supported by ChatGPT at the end.": "因此，它们最终可以被 ChatGPT 支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they announced that they are going to support MCP.": "他们已经宣布将支持 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They can be supported by the cloud desktop or cursor.": "它们也可以被 Claude Desktop 或 Cursor 支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Both link chain and MCP has this notion and idea of tools, and tools are simply functions that are": "LangChain 和 MCP 都有工具的概念和想法，工具仅仅是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:written externally from the AI system and from the LM model, and they are written by developers, and": "在 AI 系统和语言模型之外编写的函数，由开发人员编写，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:those are simply functions that execute.": "它们只是执行的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those functions like multiply, they have arguments and they have return values.": "像乘法这样的函数，它们有参数和返回值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when we define tools in both MCP and link chain, we need to specify what are the arguments that": "当我们在 MCP 和 LangChain 中定义工具时，我们需要指定",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the function receives.": "函数接收的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to specify when should we call this function.": "我们需要指定何时应该调用此函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be described in the functions description.": "因此，这将在函数描述中进行说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we should say what does this function return as a return value.": "我们应该说明该函数作为返回值返回什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So again the description is very very important because this is eventually going to propagate to the": "再次强调，描述非常非常重要，因为这最终会传播到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LM whether by the link chain binding tools or by the MCP client.": "语言模型，无论是通过 LangChain 绑定工具还是通过 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to help the model decide which tool to call.": "这将帮助模型决定调用哪个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So both link chain and MCP have a very similar idea in notion of tools And in long chain.": "因此，LangChain 和 MCP 在工具概念上有着非常相似的想法。而在 LangChain 中，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have the concept of a toolkit, which is a collection of pre-built tools.": "我们有工具包（toolkit）的概念，它是预构建工具的集合。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And similarly we have this concept of MVP server, which is also a collection of tools.": "同样地，我们有 MCP 服务器的概念，它也是工具的集合。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see a lot of similarity between the two.": "所以我们可以看到两者之间有很多相似之处。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to reiterate at the end, both via MVP or chain binding tools, we are injecting to the LMS prompt": "最后我想重申，无论是通过 MCP 还是 LangChain 绑定工具，我们都在向语言模型的提示词中注入",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the description of the tools, when to invoke them, what arguments do they receive and what output": "工具的描述、何时调用它们、它们接收什么参数以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:do they output?": "它们输出什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is basically an interface for the AI models to interact with external tools.": "它基本上是 AI 模型与外部工具交互的接口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about the differences between them.": "现在让我们谈谈它们之间的区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MVP takes this idea and it generalizes it a bit.": "MCP 采用了这个想法并对其进行了一定程度的泛化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we not only expose tools via MVP, but we also can expose resources.": "因此，我们不仅通过 MCP 暴露工具，还可以暴露资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we discussed earlier that those resources can be documents PDF files pictures can be also making": "我们之前讨论过，这些资源可以是文档、PDF 文件、图片，也可以是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:API calls, and it can also expose as well as prompts.": "API 调用，它还可以暴露提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And another difference is who we are going to expose this to.": "另一个区别是我们要将这些暴露给谁。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in Linkchain when we use the bind tools, we bind it to an LLM to a large language model.": "在 LangChain 中，当我们使用绑定工具时，我们将其绑定到 LLM（大语言模型）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But when we use MCP we actually bind everything to the AI application like cursor windsurf cloud.": "但当我们使用 MCP 时，我们实际上是将所有内容绑定到 AI 应用程序，如 Cursor、Windsurf、Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those applications have underneath the hood an LLM.": "因此，这些应用程序底层都有一个 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client is what is going to inject those descriptions to that LLM.": "客户端负责将这些描述注入到该 LLM 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're not injecting it directly.": "所以我们不是直接注入的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a couple of layers of abstractions before it's get injected.": "在注入之前，我们有几层抽象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have the MCP server which communicates with the list of tools to the MCP client and the MCP client.": "我们有 MCP 服务器，它将工具列表传达给 MCP 客户端，而 MCP 客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is what's going to inject the LLM in the application with those instructions of the tools that": "负责将这些需要调用的工具指令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we need to invoke.": "注入到应用程序中的 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video, I want to show you the gist of the MCP protocol.": "在这段视频中，我想向大家展示 MCP 协议的要点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to cover what's the interaction between every component in the MCP protocol?": "我想涵盖 MCP 协议中各个组件之间的交互是怎样的？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So how does the client interact with the server?": "那么客户端是如何与服务器交互的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's happening with the host and with the user and with the LM and how everything is playing together.": "宿主、用户以及大语言模型（LLM）之间发生了什么，以及一切是如何协同工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start with the diagram that we're seeing right over here on the left side we have the user.": "让我们从左边看到的这张图表开始，左侧是用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the user is the one who's going to make queries into our application.": "用户是向我们的应用程序发起查询的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Our application can be cursor windsurf can be cloud desktop and can be our agent that we wrote or any": "我们的应用程序可以是 Cursor、Windsurf，可以是 Claude Desktop，也可以是我们编写的智能体或任何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:other agent which is deployed.": "其他已部署的智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we have the LM.": "然后是大语言模型（LLM）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the application eventually is going to use an LM.": "应用程序最终会使用大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to make requests to and we have the MCP server here.": "它会向其发起请求，而这里有 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP server that we're going to be used that we're going to integrate into our application which": "我们要使用的 MCP 服务器，也就是我们要集成到支持 MCP 的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:supports MCP.": "应用程序中的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now you're wondering where is the client.": "现在你可能在想客户端在哪里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client is actually residing within the application itself.": "实际上，客户端就驻留在应用程序本身内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can think about the application as the host of the MCP as well.": "你也可以将应用程序视为 MCP 的宿主。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here the app which is going to perform the role of also the host.": "所以这里的应用程序也将承担宿主的角色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to also have the client.": "它同时也会包含客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client is going to be connected to an MCP server.": "客户端将连接到 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in an app we can have multiple clients.": "在一个应用程序中，我们可以有多个客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And each client is going to be connected into a different MCP server.": "每个客户端都会连接到不同的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start at the very beginning.": "让我们从最开始说起。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is when our application is loaded.": "也就是当我们的应用程序加载时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is when we fire up cursor or when we fire up cloud desktop or our own agent.": "当我们启动 Cursor、Claude Desktop 或我们自己的智能体时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first thing that is going to happen we're going to make a connection to an MCP server or servers": "首先发生的事情是，我们将建立与应用程序支持并集成的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which are supported and integrated into the app.": "一个或多个 MCP 服务器的连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now who is going to make those connections to the MCP servers?": "那么，谁来建立与这些 MCP 服务器的连接呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be the client inside the host, which lives in our application.": "是宿主内部的客户端，它存在于我们的应用程序中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to use the MCP protocol to initialize a connection, sending a messages back and forth.": "它将使用 MCP 协议初始化连接，来回发送消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP server is going to say that it acknowledges the client.": "MCP 服务器会确认已识别该客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to set the connection between the client and the MCP server.": "我们将建立客户端与 MCP 服务器之间的连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we have multiple MCP servers, then we're going to have a bunch of clients making connections": "如果我们有多个 MCP 服务器，那么就会有一堆客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:into MCP servers here.": "连接到这里的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when we initialize a connection, the server is going to let the client know which available tool": "当我们初始化连接时，服务器会告知客户端该服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:does this server have.": "有哪些可用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me reiterate on this.": "让我再重申一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is not only the tools, this is also including everything that the server exposes.": "这不仅包括工具，还包括服务器公开的所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can be all the resources that the server exposes and all the prompts and all the tools that the": "它可以是服务器公开的所有资源、所有提示词以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server exposes.": "服务器公开的所有工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm using tools here just for the example.": "我在这里使用工具只是为了举例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we're talking about the weather MCP server that we talked in the beginning of the course.": "如果我们谈论的是课程开始时提到的天气 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here is going to be the alerts tool and the forecast tool.": "那么这里将会有警报工具和预报工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the MCP server is letting to know the client which lives inside our application.": "MCP 服务器会让位于我们应用程序内部的客户端知道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And our host is going to let them know which available tools.": "我们的宿主程序将让他们知道有哪些可用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the interaction between the application and inside it, the clients and the MCP servers.": "所以这就是应用程序及其内部的客户端与 MCP 服务器之间的交互。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we see this is happening even before we have a user interaction.": "我们看到这甚至在用户交互之前就已经发生了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is when we fire up the application.": "这就是在我们启动应用程序的时候。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once we do that, we finish the MCP initialization and we finish setting up our application.": "一旦我们这样做，我们就完成了 MCP 初始化并完成了应用程序的设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when a user is going to send the query to our application let's say cursor, then we are going to": "因此，当用户向我们的应用程序（比如 Cursor）发送查询时，我们将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then send that message with the tools that we have to the LM.": "然后将该消息连同我们拥有的工具一起发送给大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because the application clients here, they know which tools the MCP servers expose, they're taking": "因为这里的应用程序客户端知道 MCP 服务器公开了哪些工具，所以它们会获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the tools that the MCP server returned that are available.": "MCP 服务器返回的可用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And with the user query, they are augmenting the user query with those tools.": "并结合用户查询，使用这些工具来增强用户查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now remember in the previous video I told you about the special prompt.": "现在记得在之前的视频中我告诉过你们关于特殊提示词的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is pretty much what's happening there.": "这基本上就是那里发生的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're taking the original user query and they're listing the bunch of tools that are available.": "他们获取原始的用户查询，并列出一堆可用的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now the LM is not going to receive only the user's query.": "所以现在大语言模型不仅会收到用户的查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to receive the user's query alongside with the available tools.": "它将收到用户查询以及可用的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the LM now is going to respond.": "那么大语言模型现在将做出响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to respond with an answer, or it's going to respond with a tool call that needs to be invoked.": "它将以回答的形式响应，或者以需要调用的工具调用的形式响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I remind you, the MCP protocol is only working for tool calling LMS.": "我提醒你，MCP 协议仅适用于支持工具调用的 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the tool call is going to have which tool needs to be called and what are the arguments that we need": "因此，工具调用将包含需要调用哪个工具以及我们需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to call it with.": "用什么参数来调用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have all the information about what needs to be executed.": "这样我们就有了关于需要执行什么的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now how do we execute that.": "现在我们如何执行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and this is the key difference by the way between the MCP and between frameworks like long chain.": "顺便说一下，这就是 MCP 与 LangChain 等框架之间的关键区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In long chain we execute everything in our application layer.": "在 LangChain 中，我们在应用程序层执行所有操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we will take that.": "我们会获取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to run everything inside the application.": "并且我们将在应用程序内部运行一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Usually what's happening with MCP we are simply sending the tool call to the MCP server.": "通常在 MCP 中发生的是，我们只是将工具调用发送到 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So whether it's via Stdio or a server send event, we are sending to the MCP server which tool we need": "因此，无论是通过 Stdio 还是服务器发送事件，我们都会向 MCP 服务器发送我们需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to invoke, which arguments do we need to send it.": "调用的工具，以及我们需要发送给它的参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the MCP server is going to run it.": "然后 MCP 服务器将运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So everything is going to run.": "这样一切都会运行起来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the tool execution is going to happen in the MCP server.": "现在，工具执行将在 MCP 服务器中发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's not going to happen in the application in the graph or cursor application.": "所以它不会在应用程序（如 Graph 或 Cursor 应用程序）中发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After we discussed the similarities and differences between link chain and MCP, Nmcp.": "在讨论了 LangChain 和 MCP 之间的异同之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about the link chain MCP adapter.": "让我们来谈谈 LangChain MCP 适配器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is an open source that the LinkedIn team released, which offers significant value by enabling": "这是 LangChain 团队发布的一个开源项目，它通过实现以下功能提供了巨大的价值：",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:seamless integration of MCP tools with link chain and link graph.": "将 MCP 工具与 LangChain 和 LangGraph 无缝集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the key value proposition here is that we have tool compatibility.": "因此，这里的核心价值主张是我们拥有工具兼容性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can convert MCP tools into link chain and line graph agents compatible tools.": "这样我们就可以将 MCP 工具转换为与 LangChain 和 LangGraph 智能体兼容的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this allows developers to leverage existing MCP servers that somebody else wrote in our popular without": "这使得开发者能够利用他人编写的现有热门 MCP 服务器，而无需",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:any manual adaption.": "任何手动适配。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it also supplies us with an MCP client that will allow us to connect to multiple MCP servers.": "它还为我们提供了一个 MCP 客户端，允许我们连接到多个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:She's going to help us expose all their tools.": "它将帮助我们公开它们所有的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the next video, we're going to demonstrate and we're going to use the MCP client that Linkchain": "所以在接下来的视频中，我们将演示并使用 LangChain",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:wrote for us.": "为我们编写的 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to happen in the MCP server.": "这将在 MCP 服务器中发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a big advantage because once we do this we actually decouple everything.": "这是一个巨大的优势，因为一旦我们这样做，我们实际上就解耦了一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We decouple the MCP server and the tool execution from the agent itself.": "我们将 MCP 服务器和工具执行从智能体本身解耦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the runtime of the server is what's going to run the tool.": "因此，服务器的运行时才是运行工具的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to help us if you want in the future to scale this out, maybe to deploy it on Kubernetes": "如果你将来想要扩展它，比如部署在 Kubernetes 上，这将对我们有所帮助，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or in serverless and to monitor it in a different system.": "或者部署在无服务器架构中，并在不同的系统中进行监控。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this has a lot of advantages.": "所以这有很多优点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll talk about this when we talk about system design later in this course.": "我们将在本课程稍后讨论系统设计时谈论这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP server is now executing the tool it used for example the forecast tool and got us the forecast": "因此，MCP 服务器现在正在执行它使用的工具，例如预测工具，并为我们获取了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for California.": "加利福尼亚州的预测。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it's going to send back the response to the application here.": "然后它将把响应发送回这里的应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And and it's not really sending it to the application because it has this proxy of the MCP client.": "而且它并不是真的发送给应用程序，因为它有 MCP 客户端这个代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP client is going to handle the sending of the request and the receiving of the request, and": "因此，MCP 客户端将处理请求的发送和接收，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the MCP client is then going to be integrated into our application, into our graph agent or cursor": "MCP 客户端随后将被集成到我们的应用程序中，集成到我们的图智能体或 Cursor",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or whatever.": "或其他任何东西中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we got the answer from the MCP server.": "这样我们就从 MCP 服务器得到了答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now in the application layer we're going to make another request to the LM.": "现在在应用层，我们将向大语言模型发起另一个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's going to be the user query with the response of the tool that was executed in the server.": "但这将是用户查询加上在服务器中执行的工具的响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now the LM is going to decide whether we want to finish or whether we want to make another call.": "现在大语言模型将决定我们是要结束还是发起另一个调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's say we want to finish.": "但假设我们想要结束。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what happens?": "那么会发生什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The LM sends its final answer and we receive it in the application layer.": "大语言模型发送其最终答案，我们在应用层接收它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we return it to the user.": "然后我们将其返回给用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to note a very key difference between the link chain graph react agent and here the MCP flow.": "我想指出 LangChain 图 React 智能体与这里的 MCP 流程之间的一个非常关键的区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have a bunch of things that are together.": "我们有很多东西是结合在一起的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to note a very important difference in the link chain react agent.": "我想指出 LangChain React 智能体中一个非常重要的区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we take it vanilla then the tools which are executing are going to execute within our app, within": "如果我们使用原生版本，那么正在执行的工具将在我们的应用程序内部执行，在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our agent.": "我们的智能体内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll take that and we'll integrate MCP into our graph agent, then what's going to happen is": "如果我们将 MCP 集成到我们的图智能体中，那么将会发生的是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that we're going to run the tools in the MCP server.": "我们将在 MCP 服务器中运行工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here a decoupling of the tools component into a different service.": "所以我们在这里将工具组件解耦到了一个不同的服务中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is very useful.": "这非常有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very helpful when debugging.": "在调试时非常有帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When logging helper focused it's helpful for scaling.": "在日志记录、帮助聚焦以及扩展方面都很有帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I believe it's a better architectural decision to run everything in the MCP servers.": "我相信在 MCP 服务器中运行一切是更好的架构决策。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And technically we can actually inside the graph tools, we can simply make dummy tools that will simply": "从技术上讲，我们实际上可以在图工具内部简单地制作一些虚拟工具，这些工具只会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:make requests into a different service, and we'll get a very similar behavior.": "向不同的服务发起请求，我们将获得非常相似的行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, the key difference here is that the MCP protocol is standard authorizing this, and it's going": "然而，这里的关键区别在于 MCP 协议是实现这一点的标准，它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to give us one interface in order to do things.": "为我们提供一个统一的接口来执行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something which is very, very cool.": "这是一件非常非常酷的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to list another advantage of decoupling the tools from the agents itself.": "我还想列出将工具与智能体本身解耦的另一个优势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the agent is going to be responsible for the orchestration.": "智能体将负责编排工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When to call the tool, and maybe to make another tool call, or to return a prompt to the user asking": "比如何时调用工具，是否需要再次调用，或者向用户返回提示以寻求",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for feedback, whatever.": "反馈等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we decouple the logic of the orchestration from the tool execution.": "这样我们就将编排逻辑与工具执行解耦了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by doing this decoupling, it actually gives us the point where we can actually update the server": "通过这种解耦，它实际上让我们能够动态地更新服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:dynamically and maybe deploy it a new version of it, and we can set up that the client is going to": "甚至部署它的新版本，我们可以设置客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:do this immunization not only once, but every once in a while, so that our agent is going to receive": "不仅进行一次初始化，而是每隔一段时间进行一次，这样我们的智能体就能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tools dynamically.": "动态地接收工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think it's very cool and gives us the behavior of dynamic tool, call it.": "我觉得这非常酷，并赋予了我们所谓的动态工具调用行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we don't need to redeploy our agent because our agent is going to have multiple initializations every": "因此我们不需要重新部署智能体，因为我们的智能体每隔",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:once in a while, and it's going to receive the tools that it needs.": "一段时间就会进行多次初始化，并接收它所需的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is another advantage.": "这是另一个优势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I hope you enjoyed this video.": "希望你喜欢这段视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next video we're going to implement an MCP client inside our graph agent.": "在下一段视频中，我们将在图智能体中实现一个 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to help us better understand these flow.": "这将帮助我们更好地理解这些流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a setup video for our boilerplate skeleton for our project.": "这是我们项目样板骨架的设置视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to implement now the MCP link chain adapters.": "所以我们现在要实现 MCP LangChain 适配器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to learn a bunch on MCP clients.": "我们将学习很多关于 MCP 客户端的知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video we'll create a new project with UV.": "在这个视频中，我们将使用 UV 创建一个新项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll create a virtual environment and we'll install our dependencies there.": "我们将创建一个虚拟环境并在其中安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then I'm going to commit it to GitHub.": "然后我将把它提交到 GitHub。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you want to start from after I'm committing here this code and have the exact code that I have,": "如果你想从我提交这段代码之后开始，并拥有和我完全一样的代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then you can simply go and run those commands over here.": "那么你只需运行这里的这些命令即可。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to clone the repository.": "这将克隆该仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Of course it's going to clone the project slash LinkedIn MCP adapters branch.": "当然，它会克隆 project/langchain-mcp-adapters 分支。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after we do that we want to go and CD into the link chain MCP adapters where all the code here.": "之后，我们要进入 langchain-mcp-adapters 目录，所有的代码都在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we want to check out the commit that I used here.": "然后我们要切换到我在这里使用的提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this commit has all the code in this video.": "这个提交包含了本视频中的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't worry about copying this command.": "不用担心复制这个命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can download the exact command.": "你可以下载准确的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to link it in the video resources.": "我会把它链接在视频资源中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is in case you do not want to start from zero like I'm doing.": "这是为了防止你不想像我一样从零开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to start and go to my GitHub projects and let me clone the repository of the MCP crash": "我要开始进入我的 GitHub 项目，克隆 MCP crash 的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the URL is going to be listed in the videos resource.": "URL 将列在视频资源中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So don't worry about it.": "所以不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I cloned the repository and let's CD into this repo.": "我克隆了仓库，让我们进入这个仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And currently I'm on the main branch.": "目前我在 main 分支上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you it.": "让我展示给你看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to create now a new branch which is going to be for this project.": "我们现在要创建一个新分支，用于这个项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go write git checkout and I want to write dash dash orphan to make it detached from my original": "让我输入 git checkout，并加上 --orphan 参数，使其与我原始的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:repo.": "仓库脱离。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's call it project slash link chain MCP Amqp adapters.": "让我们把它命名为 project/langchain-mcp-adapters。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We created the branch and we're on the new branch right now.": "我们创建了分支，现在就在新分支上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you now the current working directory of the project.": "现在让我向你展示项目的当前工作目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's time to see what files do we have here.": "现在是时候看看这里有哪些文件了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we see we have a bunch of files.": "我们可以看到有一堆文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you're probably going to see the repo where it's much more organized.": "你看到的仓库可能会更有条理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So don't worry about the files here.": "所以不用担心这里的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What we want to do is to remove those files and start from a clean slate.": "我们要做的是删除这些文件，从头开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and do that.": "让我来操作一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write here git rm rf dot.": "让我在这里输入 git rm -rf .。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to remove all of those files not to track them.": "这将删除所有这些文件，不再跟踪它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we don't have anything.": "现在我们什么都没有了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I listed all the files and I don't see anything here.": "我列出了所有文件，在这里没看到任何东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is our starting point.": "所以这就是我们的起点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a new branch and we don't have any files here.": "我们有一个新分支，而且这里没有任何文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and initialize our project with UV.": "那么让我们用 UV 初始化我们的项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I wrote uv init, and we have now a bunch of boilerplate files that we can work with.": "我输入了 uv init，现在我们有了一堆可以使用的样板文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see that the file that you created is a empty readme main.py and a pyproject.toml file.": "我们可以看到创建的文件是一个空的 readme、main.py 和一个 pyproject.toml 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I want to open the cursor IDE and this is now our working station.": "现在我想打开 Cursor IDE，这就是我们的工作站了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and open up terminal.": "那么，让我们打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now create a virtual environment.": "现在让我们创建一个虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll write UV Venv.": "我会输入 uv venv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we have a new virtual environment.": "现在我们有了一个新的虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see we have a venv here.": "你可以看到这里有一个 venv 文件夹。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me now source it and activate it.": "现在让我执行 source 命令并激活它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy here the script.": "我要把这里的脚本复制过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now you can see on the left side we have MCP Crash Course inside parentheses.": "现在你可以看到左侧括号里显示着 MCP Crash Course。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is our virtual environment.": "这就是我们的虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way if I'm going to exit cursor and open it again then it should automatically activate the": "顺便说一下，如果我退出 Cursor 并重新打开，它应该会自动激活",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:virtual environment.": "虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see here on the left side.": "你可以在左侧看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if not you can simply activate it like before.": "如果没有，你可以像之前那样简单地激活它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go now and let's install our dependencies.": "总之，现在让我们去安装依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I will go to the link Chain adapters repository.": "如果我前往 LangChain 适配器仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here in their example we need a bunch of packages.": "我们可以看到在他们的示例中，我们需要一堆包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need the link chain map adapters package Landgraaf package and link chain OpenAI.": "我们需要 langchain-mcp-adapters 包、LangGraph 包和 langchain-openai。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice we are not installing explicitly the NCP package because when we install the link chain NCP": "请注意，我们没有显式安装 MCP 包，因为当安装 langchain-mcp",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:adapters package, it installs it automatically.": "适配器包时，它会自动安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so let's go and let's copy now those packages and let's add them with UV.": "好了，现在让我们复制这些包，并使用 uv 添加它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after we install them let me also add Python package to load up environment variables.": "安装好之后，让我再添加一个用于加载环境变量的 Python 包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And and if it's not already installed as part of their dependencies.": "如果它还没有作为依赖项的一部分被安装的话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and add python dash.": "让我去添加 python-dotenv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see it's already installed.": "我们可以看到它已经安装好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see the HTML file.": "让我们看看 HTML 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now those are the dependencies that our project needs.": "现在我们可以看到这些就是我们项目需要的依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we go and head up to UV dot log file here we have the exact version of all the packages in our": "如果我们查看 uv.lock 文件，这里有我们虚拟环境中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:virtual environment that we need for the project.": "项目所需的所有包的准确版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for example, here I installed LinkedIn core.": "例如，这里我安装了 langchain-core。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now the current version is 0.3.51 of LinkedIn core.": "目前 langchain-core 的版本是 0.3.51。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when you install it, you might have different versions, probably newer ones.": "当你安装时，你可能会得到不同的版本，大概是更新的版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to keep this repository in videos up to date.": "我会保持这个仓库和视频的同步更新。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So unless there are breaking changes I'm going to leave it that if they are I will update this video.": "所以除非有重大变更，否则我会保持现状；如果有，我会更新这个视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alright, so let's go to our main.py file and let's go and try to run it.": "好了，让我们打开 main.py 文件并尝试运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see, just as a sanity check that everything is working and I'll run it with you've run Main.py": "让我们看看，只是做个完整性检查，确保一切正常，我会用 uv run main.py 来运行它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and notice we're inside the virtual environment.": "注意我们是在虚拟环境内部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to contain all of our packages.": "所以它会包含我们所有的包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and run it and boom, we get the output that we want.": "让我们运行它，砰，我们得到了想要的输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What a beautiful program.": "多么美妙的程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to make it async.": "所以我想把它变成异步的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I turned this function into a coroutine with the async keyword.": "所以我用 async 关键字将这个函数变成了一个协程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now in order to run our main file I need to run it with async IO run.": "现在为了运行我们的主文件，我需要使用 asyncio.run 来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So before we write our MCP clients, we want to first write our MCP servers.": "所以在编写 MCP 客户端之前，我们想先编写 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll be able to connect them to our clients.": "这样我们就能将它们连接到我们的客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to write two very simple MCP servers.": "我们将编写两个非常简单的 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is going to expose mathematic tools to add numbers and multiply them, which is going to communicate": "其中一个将提供用于数字加法和乘法的数学工具，它将通过",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:via Stdio.": "Stdio 进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other server is going to be a very dumbed down weather server, which is simply going to output": "另一个服务端将是一个非常简化的天气服务端，它只会输出",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that.": "那个：",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very hot outside.": "“外面天气很热”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the interesting fact about this server is that it's going to communicate via SSH server send events.": "但这个服务端有趣的地方在于，它将通过 SSE（服务器发送事件）进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the first time we introduce how to do that.": "这是我们第一次介绍如何实现这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll give you a very quick spoiler.": "我先给你们剧透一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be very easy.": "这会非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and create a new package.": "那么，让我们去创建一个新包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to call it servers.": "我将把它命名为 servers。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is now a new directory.": "现在这是一个新目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's make it a package by creating an empty underscore init.py file.": "让我们通过创建一个空的 __init__.py 文件来把它变成一个包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is now our servers package here.": "现在这就是我们的 servers 包了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to create a new file which I'm going to call math server Pi.": "现在我想创建一个新文件，我将把它命名为 math_server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to have the implementation of an SMTP server, which exposes two tools, one to": "在这里我们将实现一个 MCP 服务端，它提供两个工具，一个用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:add numbers and the other tool to multiply those numbers.": "数字加法，另一个工具用于数字乘法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, when making this course, I started by naming this file math.pi and eventually what": "顺便说一下，在制作这门课程时，我最开始把这个文件命名为 math.py，结果",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:happened?": "发生了什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It turns out that it collided with the built in math package in Python, and it really took me some": "结果它与 Python 内置的 math 包冲突了，这真的花了我一些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:time to figure it out.": "时间才搞清楚。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once I gave up, I simply dumped it, my error to cursor and it was able to point that out.": "当我快放弃时，我直接把错误丢给了 Cursor，它帮我指出了问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the TLDR here called this file math server because this is a very simple MVP server, and we've already": "所以这里的总结是，把这个文件命名为 math_server，因为这是一个非常简单的 MCP 服务端，而且我们已经",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:done how to do very similar things.": "演示过如何做类似的事情了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm simply going to copy paste it from the LinkedIn adapters repository.": "我直接从 LinkedIn adapters 仓库中复制粘贴过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can skim this implementation here.": "我们可以大致浏览一下这里的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a very simple implementation.": "这是一个非常简单的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But what's important to note is this transport layer which is stdio.": "但需要注意的是这里的传输层，它是 stdio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alright.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me copy that and let's go to cursor and paste it.": "让我复制一下，然后去 Cursor 里粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's try to run it now in our terminal.": "现在让我们尝试在终端运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to do it by running.": "我将通过运行以下命令来执行：",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've run server math server dot pi.": "uv run servers/math_server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see that it is running successfully with this blinking square over here.": "我们可以看到它运行成功了，这里有一个闪烁的方块。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now create the second server which is going to be a server which outputs the weather.": "现在让我们创建第二个服务端，它将是一个输出天气的服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's going to be a very damped version of the server.": "但这将是一个非常简化的版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's always going to output that it's hot as hell.": "它总是会输出天气热得要命。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So maybe it's going to be relevant only for Dubai.": "所以也许它只适用于迪拜。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here's a clip from me in Dubai.": "这是我在迪拜的一段剪辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the cool thing about this server, and this is the first time I was covering it, it's going to": "但这个服务端酷的地方在于（这也是我第一次介绍它），它将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:be a server which the transport is going to be via SSH.": "是一个通过 SSE 进行传输的服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I love these cursor autocomplete.": "我非常喜欢 Cursor 的这些自动补全功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm simply pressing tab tab tab and it completes me.": "我只需不停地按 Tab 键，它就会帮我完成补全。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I forgot to import async IO.": "我忘了导入 asyncio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go now and run the code again.": "现在让我们再次运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see it's still working.": "我们可以看到它仍然在正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a good time.": "现在是个好时机。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to create now a dot env file to hold our environment variables.": "我现在想创建一个 .env 文件来保存我们的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because we're going to be using an LM.": "因为我们要使用大语言模型（LLM）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to use a managed LM.": "所以我将使用一个托管的 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me paste here the values of my environment variables.": "让我把环境变量的值粘贴在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way don't worry about the values here of me exposing them.": "顺便说一下，不用担心我在这里泄露了这些值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um I'm going to revoke it right after I finish exporting this video.": "嗯，我会在导出这段视频后立即撤销它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, I'm using OpenAI right now, but you can use any LM you want that supports function calling.": "总之，我现在使用的是 OpenAI，但你可以使用任何支持函数调用的 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can use anthropic sonnet.": "所以你可以使用 Anthropic 的 Sonnet。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can use Gemini.": "你可以使用 Gemini。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way Gemini has a free tier.": "顺便说一下，Gemini 有免费层级。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can use it as well.": "所以你也可以使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can use deep sea or any other LM which supports function calling.": "你也可以使用 DeepSeek 或任何其他支持函数调用的 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first environment variable is going to be our OpenAI API key or our LLM API key?": "所以第一个环境变量将是我们的 OpenAI API 密钥或 LLM API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the other four API keys you can see here.": "现在你可以看到这里的另外四个 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Of link chain.": "属于 LangChain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They are for the links needs tracing.": "它们用于 LangSmith 的追踪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can actually trace the LLM calls and see exactly what's being sent to the LLM.": "这样我们就可以追踪 LLM 调用，并确切地看到发送给 LLM 的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what do we get back.": "以及我们得到了什么返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think it's very important to understand it's not a must for you.": "所以我认为理解这一点非常重要：这对你来说不是必须的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you do not trace it you simply need to put the link chain tracing V2 equals to false here and": "所以如果你不进行追踪，你只需要在这里将 LANGCHAIN_TRACING_V2 设置为 false，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it should work.": "它就能正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you are using simply go to the link chain platform and generate the API key.": "如果你要使用，只需前往 LangChain 平台并生成 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:From there.": "从那里生成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me know if you wanted to make a video on that, but I'm assuming that you know how to do it anyways.": "如果你想让我针对这个做一个视频，请告诉我，但我假设你已经知道该怎么做了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I put my API key, I put the endpoint and I call the link chain project MCP test here.": "所以我放入了我的 API 密钥，设置了端点，并将 LangChain 项目命名为 MCP test。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So even though I did revoke now the API keys so you can't actually use them, I want to add here another": "所以即使我现在撤销了 API 密钥，导致你无法实际使用它们，我还是想在这里添加另一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:file, let's call it.": "文件，我们称之为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gitignore.": ".gitignore。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to not commit the env file to the repository.": "我不想将 .env 文件提交到代码仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just write here And this is simply going to ignore the dotenv file.": "让我在这里写下，这只是为了忽略 .env 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see it's also grayed out here.": "你可以看到它在这里也变成了灰色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So git is not going to track this file.": "所以 git 不会追踪这个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm not going to accidentally upload it to my repository.": "这样我就不会意外地将其上传到我的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the main.py file.": "让我们回到 main.py 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to load those environment variables and to see that everything is working correctly.": "现在我们要加载这些环境变量，看看一切是否运行正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can continue.": "这样我们就可以继续了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to write our actual code and write our first NAACP client.": "编写我们的实际代码，并编写我们的第一个 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to import from env the load in V function.": "所以我要从 dotenv 导入 load_dotenv 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to call it right before my code runs.": "我会在代码运行之前调用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a sanity check, let's go and print the OpenAI API key just to see that we actually loaded it": "作为一项完整性检查，让我们打印一下 OpenAI API 密钥，看看我们是否真的将其加载",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:into our environment variable.": "到了我们的环境变量中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and try to run it.": "让我们试着运行一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we forgot to import the OS module.": "我们可以看到我们忘了导入 OS 模块。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's do that and rerun it.": "那么让我们导入它并重新运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we can see now our API key and our environment is indeed loaded with the correct values.": "瞧，我们现在可以看到 API 密钥和环境变量确实已经加载了正确的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's pretty much it for this video we have all the boilerplate code.": "这段视频的内容就差不多是这些了，我们已经写好了所有的样板代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And from now on we can go and we can implement our MCP client.": "从现在开始，我们可以去实现我们的 MCP 客户端了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply go and add everything and let me go and commit it into our repository.": "让我简单地把所有内容都添加进去，并提交到我们的仓库中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we are tracking all the files we created.": "现在我们正在追踪所有创建的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you one of my favorite cursor features where you simply go and generate automatically": "让我向你展示我最喜欢的 Cursor 功能之一，你可以简单地自动生成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with I the commit message and let me go and commit this code here.": "使用 AI 生成提交信息，然后让我在这里提交这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me go and push it into the repository.": "现在让我把它推送到仓库中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Oops.": "哎呀。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Need to set my upstream a repo here.": "需要在这里设置我的上游仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we should see the code available on GitHub.": "现在我们应该能在 GitHub 上看到代码了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to GitHub.": "那么让我们去 GitHub 看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'm going to select now the branch of project slash MCP adapters.": "如果我现在选择 project/MCP-adapters 分支。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and click that.": "让我们点击它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see now all the code that we just wrote.": "我们现在可以看到刚才写的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see the main.py file, the UV log, the pyproject.toml file and everything.": "我们可以看到 main.py 文件、UV 日志、pyproject.toml 文件以及所有其他内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be a server sent event MCP server.": "所以这将是一个服务器发送事件（SSE）的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this means that the communication between the client and the server, it's not going to happen via": "这意味着客户端和服务器之间的通信将不会通过...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to happen via HTTP.": "它将通过 HTTP 进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client is going to make http post request to the server.": "客户端将向服务器发送 HTTP POST 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we don't really need to handle this communication over here.": "当然，我们在这里并不真的需要处理这种通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We get this out of the box when we use the MCP SDK.": "当我们使用 MCP SDK 时，这是开箱即用的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Just need to specify to the server that we want that the transport to be SSH.": "只需要向服务器指定我们希望传输方式为 SSH。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is super easy.": "这非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's just a flag that we pass when we run the server.": "这只是我们在运行服务器时传递的一个标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're back in cursor and we want to create a new file.": "所以我们回到 Cursor，想要创建一个新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's call this file weather.": "我们把这个文件命名为 weather。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Underscore server.py.": "下划线 server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to hold the implementation of our weather.": "它将包含我们天气的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go back to the link chain MCP open source.": "让我们回到 LangChain MCP 开源项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me copy this dummy.": "让我复制这个示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Server they have here.": "他们这里的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to copy it.": "我要把它复制下来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see it's a very simple implementation of a server which exposes the Get weather tool.": "我们可以看到这是一个非常简单的服务器实现，它公开了 Get weather 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to return always the same static string.": "它将始终返回相同的静态字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just for the fun, let's go and change the string.": "为了好玩，我们去修改一下这个字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's say that it is always hot as hell.": "让我们把它改成“总是热得要命”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just correct it to hot as hell.": "让我把它修正为“热得要命”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we are done with the server.": "现在我们完成了服务器部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the important thing to notice is that transport here the transport here is SSE.": "需要注意的重要一点是，这里的传输方式是 SSE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is how we communicate with this MCP server.": "这就是我们与这个 MCP 服务器通信的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you how it's different when we run it.": "让我给你们展示一下运行它时有什么不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we go now and create a new terminal instance let me split here this view and let me run our UV run.": "如果我们现在创建一个新的终端实例，让我拆分一下视图，然后运行我们的 uv run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then weather sorry servers weather Whether server.py.": "然后是 weather... 抱歉，是 servers/weather_server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see now that the server is actually running in localhost port 8000.": "我们现在可以看到服务器实际上运行在 localhost 的 8000 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we want to change the ports to run on a different port, we can totally do that.": "如果我们想更改端口以在不同的端口上运行，完全可以做到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We simply need to specify Intel via the SDK.": "我们只需要通过 SDK 进行指定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's pretty much it for this video.": "这个视频的内容差不多就这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we created two simple web servers, one running in SDL and the other the transport is via SSH.": "所以我们创建了两个简单的 Web 服务器，一个运行在 SDL 上，另一个通过 SSH 传输。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and let's commit this code over here.": "让我们去提交这里的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and see which files changed.": "让我现在看看哪些文件发生了更改。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Only the servers directory.": "只有 servers 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I added it.": "我把它添加了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and use cursor to commit this code here.": "让我们使用 Cursor 在这里提交代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So cursor is going to auto generate the commit message.": "Cursor 将自动生成提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me commit that and let's push it to the repository.": "让我提交它，然后把它推送到仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we go back now to the repository then we can see right now we have the new directory here.": "如果我们现在回到仓库，就能看到这里有了新目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have now two commits.": "我们可以看到现在有两个提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have the first commit from the previous video and this commit from this video.": "有来自上一个视频的第一个提交，以及来自本视频的这个提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the code and let's go to Main.py file.": "让我们回到代码，打开 Main.py 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll start by creating the Stdio client, because that's going to be the proxy for our MCP host,": "我们将从创建 Stdio 客户端开始，因为它将作为我们 MCP 主机的代理，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is going to be our graph agent.": "也就是我们的图代理（graph agent）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client needs to know two things.": "客户端需要知道两件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It needs to know how to run the MCP server.": "它需要知道如何运行 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So which command to execute in order for the server to work.": "即为了让服务器工作需要执行哪个命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And second, it needs to know how it will communicate with it.": "其次，它需要知道将如何与其通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those two pieces of information.": "而这两部分信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to supply the client with the Stdio server parameters.": "我们将为客户端提供 Stdio 服务器参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when we initialize this variable over here, we give it the information of how to run the MCP server": "因此，当我们在这里初始化这个变量时，我们向其提供了如何运行 MCP 服务器的信息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the object itself, the server parameters.": "以及对象本身，即服务器参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It has the information that it's going to communicate via the transport of Stdio.": "它包含将通过 Stdio 传输方式进行通信的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it has all of that information.": "所以它拥有所有这些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So tropics handles this for us.": "Anthropic 为我们处理了这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what's convenient about MCP SDK.": "这就是 MCP SDK 的方便之处。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Wonderful.": "太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and use the client context manager and let's define it and supply it with the server params.": "那么让我们使用客户端上下文管理器，定义它并为其提供服务器参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to do that I'm going to write async with as the context manager SQL client.": "为此，我将使用 async with 作为上下文管理器来编写 stdio_client。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to give it the argument of the stdio server params.": "我将把 stdio 服务器参数作为参数传给它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what we're going to get back from this, we're going to get back to objects here.": "我们将从中得到两个对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One object is going to be the read and the other is going to be the right transport.": "一个对象是读取传输，另一个是写入传输。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we did that we want to create the client session because every client connects to a server": "完成之后，我们要创建客户端会话，因为每个客户端都通过会话",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:via session.": "连接到服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to feed that session with the write and read.": "我们将把刚才得到的写入和读取流提供给该会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just got here.": "我们刚刚获取到的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and use Async context manager with client session.": "让我们对 client_session 使用异步上下文管理器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to give it the read stream of read we got from before.": "在这里，我们将把之前获取的读取流传给它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the write stream of write we got from before as well.": "同时也把之前获取的写入流传给它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we have a client session ready.": "现在我们准备好了一个客户端会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this client Declan's session.": "而这个客户端会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This object is what's going to do the heavy lifting of communicating between the client and the server.": "这个对象将承担客户端与服务器之间通信的重任。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To be honest, we don't really need to understand this in depth.": "老实说，我们并不需要深入了解这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How this communication is working as the users of this SDK.": "作为该 SDK 的用户，这种通信是如何工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you want.": "如果你想了解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Please let me know.": "请告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'd be happy to make a deep dive into it, but we should use it as a black box.": "我很乐意进行深入探讨，但我们应该将其视为一个黑盒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the convenient thing about using frameworks which abstract information for us, which is": "这就是使用为我们抽象信息的框架的便利之处，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:not that relevant because as the developers of the agent, we don't really care about the ins and outs": "那些细节并不那么重要，因为作为代理的开发者，我们并不真正关心",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:about the communication between the client and the server.": "客户端与服务器之间通信的来龙去脉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just assume that it is working and that the anthropic software engineers did a decent job implementing": "我们只需假设它能正常工作，并且 Anthropic 的软件工程师在实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this and abstract away this for us.": "并为我们抽象化这部分内容方面做得很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now the client knows exactly how to run and how to communicate with the server.": "现在客户端确切地知道如何运行以及如何与服务器通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now see the flow in action the MCP flow.": "现在让我们来看看 MCP 流程的实际运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We first want to initialize this connection here.": "我们首先要在这里初始化这个连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we have all the details in order to make this initialization.": "现在我们已经拥有了进行此初始化的所有细节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To do that.": "为了做到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and await session dot initialize.": "让我们去 await session.initialize。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's also print that the session was initialized.": "并且让我们也打印出会话已初始化的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after the client initializes the connection, the MCP server is going to respond with its available": "在客户端初始化连接后，MCP 服务器将响应其可用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we've done this initialization then the client is going to have the tools that the MCP server": "在我们完成初始化之后，客户端将拥有 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:exposes.": "所暴露的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll be more accurate here.": "我在这里说得更准确一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not only the tools, it's also the resources and the prompts which the server exposes.": "不仅仅是工具，还有服务器暴露的资源和提示词（prompts）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we were to ask the MCP client here, what are the tools that the MCP server exposes?": "所以如果我们在这里询问 MCP 客户端，MCP 服务器暴露了哪些工具？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It will have this information.": "它将拥有这些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is exactly what we're going to do now.": "这正是我们现在要做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's define a variable which is called tools.": "让我们定义一个名为 tools 的变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be equal to the awaiting of the coroutine of sessions dot list tools.": "它将等于对 session.list_tools 协程的 await 结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to list all the available tools that the client has.": "这将列出客户端拥有的所有可用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and print it.": "让我们去打印它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's go and run this program.": "现在让我们去运行这个程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll run UV run Main.py and we can see that session was initialized.": "我将运行 uv run main.py，我们可以看到会话已初始化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see processing request of type list to request.": "我们可以看到类型为 list_tools 的处理请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this log that we see right over here.": "我们在这里看到的这条日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is from the MCP client itself and this is from the MCP SDK implementation.": "这是来自 MCP 客户端本身的，也是来自 MCP SDK 的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we didn't write this log.": "所以这条日志不是我们写的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After we print the tools we can see here we have a list of tools.": "在我们打印工具之后，我们可以看到这里有一个工具列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here the add tool.": "这里我们有 add 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The name is going to be add.": "名称将是 add。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see all the metadata, all the information, the description the input schema which arguments": "我们可以看到所有的元数据、所有的信息、描述、输入模式（input schema）以及哪些参数",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we didn't receive, which output does it output, and all the information relevant to help the LLM decide": "我们没有接收到、它输出什么结果，以及所有有助于 LLM 决定",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:whether to call this tool or not.": "是否调用该工具的相关信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have this information about the add tool and we have it about the multiply tool.": "所以我们有关于 add 工具的信息，也有关于 multiply 工具的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the tools that our math MCP server exposes.": "这些就是我们的数学 MCP 服务器所暴露的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So at this point we have an MCP server which is running because the MCP client ran it.": "此时，我们有一个正在运行的 MCP 服务器，因为 MCP 客户端运行了它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It then created the connection in order to communicate with it via Stdio.": "然后它创建了连接，以便通过标准输入输出（Stdio）与其通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The client now knows the tools which can be invoked.": "客户端现在知道了可以被调用的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the tools that the MCP server exposes.": "这些就是 MCP 服务器暴露的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to create the host application which is going to contain these client information.": "现在我们要创建宿主应用程序（host application），它将包含这些客户端信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case in this example the host application is going to be a LAN graph react agent.": "在这个例子中，宿主应用程序将是一个 LangGraph React Agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the user is going to communicate with that.": "用户将与它进行通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and create our agent.": "那么让我们去创建我们的智能体（agent）吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to read from standard in and it's going to write to standard out.": "所以它将从标准输入读取，并写入标准输出。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's how this client is going to communicate with the MCP server which is working in the transport": "这就是该客户端与在 IO 传输模式下运行的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of IO.": "MCP 服务器进行通信的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now to import chat, OpenAI or any other realm you're going to use.": "现在导入 ChatOpenAI 或你打算使用的任何其他领域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as long as it would support function calling, you would be all right with this tutorial.": "只要它支持函数调用，你就可以顺利完成本教程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and we want to import from the Lang chain MCP adapters.": "现在让我们从 LangChain MCP 适配器中进行导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to import the load MCP tools function which we implemented.": "我们要导入我们实现的 load_mcp_tools 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this function is responsible for taking the tools which are exposed through MCP server and are an": "该函数负责获取通过 MCP 服务器公开的工具，这些工具是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP object, and to transform it into a link chain tool.": "MCP 对象，并将它们转换为 LangChain 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can use it in the link chain or link graph agent.": "这样我们就可以在 LangChain 或 LangGraph 智能体中使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the link LinkedIn tool holds the exact same information as the MCP in tool.": "LangChain 工具包含与 MCP 工具完全相同的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, the format is a bit different and the structure is a bit different, but the overall information": "虽然格式和结构略有不同，但关于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:about the function name and function arguments, function descriptions, function return value, they're": "函数名称、函数参数、函数描述、函数返回值的所有信息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:all going to be the same.": "都是一样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's handle the orchestration.": "现在让我们来处理编排部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want now to import the link chain create agent function which was introduced in link chain version": "现在我想导入 LangChain 在第 1 版中引入的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:one.": "创建智能体函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I updated this video to match the latest version of Link chain.": "因此，我更新了这段视频以匹配最新版本的 LangChain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is why you may think some editing glitches.": "这就是为什么你可能会觉得有一些剪辑痕迹。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just so you know you would need to use the create agent function is the pre-made and pre-built implementation": "只是为了让你知道，你需要使用的创建智能体函数是 LangGraph 中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the react agent in link graph.": "ReAct 智能体的预制和内置实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I show and cover react agents in depth in my link chain and graph courses.": "我在我的 LangChain 和 LangGraph 课程中深入讲解了 ReAct 智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is simply an orchestrator that is going to decide when to call each tool.": "但这仅仅是一个编排器，它将决定何时调用每个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to leverage function calling.": "它将利用函数调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's a very elegant implementation of what Landgraaf have implemented.": "这是对 LangGraph 所实现功能的一个非常优雅的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to use that as the orchestrator which is going to invoke the tools.": "因此，我们将使用它作为调用工具的编排器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So lastly I want to organize a bit those imports.": "最后，我想整理一下这些导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me add another package here with UV and it's called escort.": "让我用 uv 添加另一个包，它叫 isort。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And sorry without the dot.": "抱歉，不带点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And escort is going to sort the imports and make it more organized.": "isort 将对导入进行排序，使其更有条理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to import first the standard library imports.": "我们将首先导入标准库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we're going to import the third parties and then only things from our packages.": "然后导入第三方库，最后才导入我们自己包里的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to sort everything alphabetically.": "它会按字母顺序对所有内容进行排序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll have a nice unified way for imports.": "这样我们就有一种美观且统一的导入方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I like this package.": "我很喜欢这个包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's really in the industry in a standard when using production systems.": "在生产系统中使用它确实是行业标准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's create an LM object, which is going to be a chat OpenAI instance.": "让我们创建一个 LLM 对象，它将是一个 ChatOpenAI 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm simply going to go with the default model that OpenAI is going to give me.": "我将直接使用 OpenAI 提供的默认模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to do this by using the graph pre-built create react agent function, which in the latest": "我们将通过使用 LangGraph 预构建的 create_react_agent 函数来实现这一点，在最新的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:version of Link Chain and link graph is now being referenced as the create agent function.": "LangChain 和 LangGraph 版本中，它现在被称为 create_agent 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just edit it.": "让我修改一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this function returns us a graph react agent.": "这个函数会返回给我们一个 LangGraph React 智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I am assuming that you know what a react agent.": "现在我假设你已经知道什么是 React 智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's landgraaf?": "什么是 LangGraph？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the react agent is going to receive the LM, which is going to be the default LM from OpenAI.": "React 智能体将接收 LLM，这将是来自 OpenAI 的默认 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think it's GPT four or mini, and it's going to receive the tools that we want to supply our agent": "我想是 GPT-4 或 mini，它还将接收我们想要提供给智能体的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice in line 27, I gave it the argument of tools, which is an NCP tool object.": "注意在第 27 行，我给它传递了 tools 参数，这是一个 MCP 工具对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not a link chain tool object.": "它不是一个 LangChain 工具对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So by running this right now we are going to get an error.": "所以现在运行它，我们会得到一个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to show you this.": "我想给你们展示一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to show you the value of the NCP adapter and what it should provide us.": "为了向你们展示 MCP 适配器的价值以及它应该为我们提供什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and run this code over here and let me show you that we get an error.": "让我运行这里的代码，给你们看看报错信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see that we get here, that the first argument must be a string or a callable for tool decorator.": "你可以看到报错提示：对于工具装饰器，第一个参数必须是字符串或可调用对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Instead it got a tuple.": "而它接收到的却是一个元组。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the TLDR for this is the mismatch the create react agent of linked chain.": "简而言之，这是因为 LangChain 的 create_react_agent 存在不匹配。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Expect to get in the arguments a list of linked chain tools, and instead we gave it a list of or a": "它期望在参数中接收一个 LangChain 工具列表，而我们给它的是一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tuple of MCP tools.": "MCP 工具元组。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they both are going to contain the same information about which tools to invoke and how to invoke": "它们都包含关于调用哪些工具、如何调用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:them, which arguments, what's the return values.": "它们、使用哪些参数以及返回值是什么的相同信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the format is going to be a bit different.": "但格式会略有不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to mitigate over this, to translate the MCP tool object into a chain tool object, we're going": "为了解决这个问题，将 MCP 工具对象转换为 LangChain 工具对象，我们将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to use the load MCP tools function of linked chain.": "使用 LangChain 的 load_mcp_tools 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all this function needs to receive is the MCP session, which holds the information on the tools": "这个函数只需要接收 MCP 会话，其中包含 MCP 服务器公开的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that the MCP server exposes.": "工具信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we'll now run it we can see that we get here.": "如果我们现在运行它，可以看到结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Query is not iterable I forgot to await it.": "Query 不可迭代，我忘了 await 它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's run it again.": "让我们再运行一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everything is running right now.": "现在一切都在运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our agent is ready to work.": "我们的智能体已经准备好工作了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we can even test it.": "现在我们甚至可以测试它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now even.": "让我现在甚至...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And print the tools here.": "在这里打印工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and print the tools.": "让我去打印一下工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see that now we're going to get the link chain tools because the structured tool": "我们将看到现在得到的是 LangChain 工具，因为 StructuredTool",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:class is a class from the link chain library.": "类是来自 LangChain 库的一个类。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and test our link graph react agent.": "让我们去测试一下我们的 LangGraph React 智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we are going to run the agent dot a invoked because we are in asynchronous context.": "在这里我们将运行 agent.ainvoke，因为我们处于异步上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the argument that we're going to give it is going to be a dictionary which is going to hold the": "我们要给它的参数将是一个字典，它将包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:key of messages.": "messages 键。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and here we're going to give a list of messages.": "在这里我们将提供一个消息列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to put here the human message object.": "我们将在这里放入 HumanMessage 对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again this is a link chain construct.": "这又是一个链式构造。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here the content is going to be what is two plus two.": "这里的内容将是‘2加2等于多少’。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't forget to import it because we did not import it.": "别忘了导入它，因为我们还没有导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and simply add this import let's say over here.": "所以让我们直接在这里，比如就在这里，添加这个导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's now go and rerun everything.": "现在让我们重新运行所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we see that we initialize the session.": "在这里我们可以看到我们初始化了会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We process the request of list tools.": "我们处理了列出工具（list tools）的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we had a request of call tool.": "然后我们有一个调用工具（call tool）的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our Lang graph agent our graph react agent which is our MCP host use the MCP client in order to invoke": "所以我们的 LangGraph 智能体，也就是作为 MCP 宿主（host）的 Graph ReAct 智能体，使用 MCP 客户端来调用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the ad tool that the MCP server exposes.": "MCP 服务端暴露的加法（add）工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I will go to the MCP flow of the protocol, then the query we send to our app host.": "如果我们查看协议的 MCP 流程，查询会发送到我们的应用宿主。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it sends to the LM the same query plus all the information about the MCP tools.": "然后它将相同的查询连同所有关于 MCP 工具的信息发送给大语言模型（LLM）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So then the LM responded that it should go and run the AD function with the correct arguments.": "接着 LLM 响应说应该使用正确的参数去运行加法（add）函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be two two.": "所以参数会是 2 和 2。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And something very cool happened here.": "这里发生了一件非常酷的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So instead of the agent running and executing the tools in the actual graph application, what's happening": "并不是由智能体在实际的 Graph 应用中运行和执行工具，实际发生的是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is that the graph agent, with the help of the NAACP client, is making a request to the NAACP server,": "Graph 智能体在 MCP 客户端的帮助下，向 MCP 服务端发起请求，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the actual execution of the tool is happening in the server side, which is decoupled from our land": "工具的实际执行是在服务端完成的，这与我们的 LangGraph",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:graph application.": "应用是解耦的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our land graph application is responsible for the orchestration, and the MCP server is responsible": "因此，我们的 LangGraph 应用负责编排，而 MCP 服务端负责",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for the execution of the tools.": "工具的执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is one of the benefits of combining land graph and link chain with MCP.": "这是将 LangGraph、LangChain 与 MCP 结合使用的好处之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we execute it in the server side, the tool we send back the response to the MCP client which": "在服务端执行完工具后，我们将响应发回给 MCP 客户端，客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:forwards it into our land graph agent, which then sends the original query with the tool execution": "将其转发给我们的 LangGraph 智能体，智能体随后将原始查询连同工具执行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:answer to the LM.": "结果发送给 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The LM is then going to process it, and it's going to output as the final answer in this case.": "LLM 随后将对其进行处理，并在这种情况下输出最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what's being forwarded to the user by our language application.": "这就是我们的 LangGraph 应用转发给用户的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back here to the final answer.": "让我们回到这里的最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the final answer is two plus two is equal to four.": "最终答案是 2 加 2 等于 4。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me now go and change here instead of two.": "现在让我把这里的 2 改掉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's put here for example 54.": "比如我们在这里输入 54。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's make this example a bit more complicated.": "让我们把这个例子弄得稍微复杂一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's add here times three.": "在这里加上“乘以 3”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here two invocations of the tool here.": "这样我们这里就有两次工具调用了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and rerun everything.": "让我们重新运行所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we actually get three tool calls.": "我们可以看到实际上得到了三次工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for me it's a surprise because I thought we would get two one call.": "对我来说这挺意外的，因为我以为只会得到两次调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be two times three which is going to output six.": "应该是 2 乘以 3 输出 6。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other two we'll call is going to be six plus 54.": "另一个工具调用应该是 6 加 54。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll check in the trace soon and we'll see soon what's happening here.": "所以我们稍后会检查追踪（trace），看看这里到底发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's wait for the result.": "让我们等待结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The result here is 60.": "结果是 60。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the answer here is correct.": "所以这里的答案是正确的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to complete the picture I want to go into lengthy tracing.": "为了了解全貌，我想进入 LangSmith 追踪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to see exactly what were the tool calls and to see what was this mysterious extra tool call.": "我想确切地看看有哪些工具调用，以及那个神秘的额外工具调用是怎么回事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They all support function calling at least the motors one at 2025.": "它们都支持函数调用，至少 2025 年的 motors 模型是支持的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, please let me know if you want me to make also a video on other models, or to adjust this": "顺便说一下，如果你想让我针对其他模型也制作一个视频，或者调整这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:video to also include other models for your convenience.": "视频以包含其他模型以便于你使用，请告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So be happy to hear your feedback.": "我很乐意听到你的反馈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cool!": "太棒了！",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now create a variable and I'll call it Stdio server params.": "现在让我们创建一个变量，我将其命名为 Stdio server params。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be an object of the class.": "它将是该类的一个对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sorry, pedantic class is the server params, and this is going to hold all the information on how to": "抱歉，严谨点说，类是 server params，它将保存所有关于如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:run our server.": "运行我们服务器的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Since our server is implemented in Python, our math MCP.": "既然我们的服务器是用 Python 实现的，我们的 math MCP 也是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write in the command argument.": "那么让我们在 command 参数中写入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's write here Python and in the args we want to put the path to our MCP server.": "我们在这里写 Python，在 args 中我们要放入 MCP 服务器的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be under servers slash server dot pi.": "所以它位于 servers/server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But hold on.": "但等一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a very big caveat.": "这是一个非常大的注意事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to put here the entire path.": "我们需要在这里放入完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to put here the absolute path to the web server file.": "所以我们需要在这里放入 Web 服务器文件的绝对路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because we do not know where this is going to be ran.": "这是因为我们不知道它将在哪里运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to the terminal.": "让我去终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the terminal I want to take the current working directory.": "在终端中，我想获取当前工作目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to append the full path here to this args here.": "我要把完整路径附加到这里的 args 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just copy that paste it here.": "让我把它复制并粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the absolute path to our server.py.": "这就是我们 server.py 的绝对路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as a sanity check let me go and run Main.py.": "那么作为完整性检查，让我去运行 Main.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we get an error in.": "我们可以看到报错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The error is in the load MCP tools import.": "错误出在 load MCP tools 的导入上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here in line number five I forgot to access this function through the tools package.": "在第五行，我忘了通过 tools 包来访问这个函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and fix it.": "让我去修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm simply going to add in line number five here to the import to import from Dot tools.": "我只需在第五行的导入中添加从 .tools 导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be like this.": "就像这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let me try and rerun it.": "现在让我尝试重新运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now everything seems to be working.": "现在一切似乎都正常工作了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply add all the files here.": "让我把这里所有的文件都添加进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and commit.": "让我去提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this code.": "现在提交这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to generate a commit message with cursor.": "我将使用 Cursor 生成一条提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and commit it.": "让我们去提交它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go now and push it.": "现在让我们去推送它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now the commit here we can actually see the diff and all the code we just added.": "我们现在可以看到这里的提交，实际上可以看到差异（diff）和我们刚刚添加的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So don't worry if you did not understand the MCP objects to the end.": "所以如果你没有完全理解 MCP 对象，也不要担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I promise you, by the end of the next video you'll understand exactly what do they do and how to use": "我向你保证，到下一个视频结束时，你会确切地明白它们的作用以及如何使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:them.": "它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because this was a bit abstract, but we're going to do some hands on work in the next video.": "因为这有点抽象，但我们将在下一个视频中进行一些实际操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open links meat and here I will go to MCP test.": "让我打开 LangSmith，然后进入 MCP 测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the project I'm tracing right now.": "这是我目前正在追踪的项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have two traces of our land graph executions.": "这里有两个 LangGraph 执行的追踪记录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So one is going to be for the two plus two query.": "其中一个是关于 2 加 2 的查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other is going to be for the 54 plus two times three query.": "另一个是关于 54 加 2 乘以 3 的查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way I made those traces public and I am sharing them in the videos resources.": "顺便说一下，我已经公开了这些追踪记录，并在视频资源中分享了它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see exactly what I am seeing right now.": "所以你可以看到和我现在完全一样的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you didn't do it for yourself, let's open the two plus two trace and let's examine what are the": "如果你还没有自己操作，让我们打开 2 加 2 的追踪记录，看看对 LLM 进行了哪些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:calls made to the LM.": "调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and select here this instance of chat OpenAI message.": "让我们在这里选择这个 ChatOpenAI 消息实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're seeing the trace.": "在这里我们可以看到追踪信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that we made a request with function calling.": "我们可以看到我们发起了一个带有函数调用的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see here the tools we have here.": "我们可以看到这里拥有的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the tools that the graph agent send and we can see we have here with the add and then multiply": "这是图代理发送的工具，我们可以看到这里有加法和乘法",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tool.": "工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that the LM responded with the add tool that needs to be called.": "我们可以看到 LLM 响应了需要调用的加法工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see it by this called tag over here.": "我们可以通过这里的 called 标签看到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So input was what is two plus two.": "输入是“2 加 2 等于多少”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this was the exact input of the original query.": "这就是原始查询的确切输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The augmentation with the tools that Landgraaf did for us was here.": "LangGraph 为我们进行的工具增强就在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the result is this tool call with those arguments here.": "结果就是这个带有这些参数的工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP client then made a request to the MCP server with the input of two plus two.": "然后 MCP 客户端向 MCP 服务端发起了一个输入为 2 加 2 的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we executed the tool in the MCP server.": "所以我们在 MCP 服务端执行了该工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the tracing of this execution.": "这是该执行过程的追踪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here the input is two and two and the output is four.": "我们可以看到这里的输入是 2 和 2，输出是 4。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And something interesting to note is that in this lengthy trace here we can't really see that the tool": "值得注意的一点是，在这个冗长的追踪记录中，我们无法真正看到工具",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:was actually executed on the MCP server, which is completely decoupled from the Landgraaf graph.": "实际上是在 MCP 服务端执行的，它与 LangGraph 图完全解耦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can't really see it even by inspecting the metadata here.": "所以即使通过检查这里的元数据，我们也无法真正看到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I'm positive that the team is going to update this, and it's going to make this more visible and": "但我确信团队会对此进行更新，让这一过程变得更加直观和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:more noticeable for Landgraf agents, which leverage MCP servers.": "明显，特别是对于使用 MCP 服务端的 LangGraph 代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, here we can see now the final answer.": "无论如何，我们现在可以看到最终答案了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here the original prompt the tool call.": "这里有原始提示词和工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get here the final answer which is four.": "我们得到了最终答案，即 4。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the last thing I owe you for this session is to show you this extra mysterious tool call that we": "在本节课结束前，我还要向你们展示我们在第二轮中遇到的那个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:had in the second round.": "额外的神秘工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll open the first request to the LM.": "如果我们打开对 LLM 的第一个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the original prompt alongside the augmentation of the MCP tools here.": "这就是原始提示词以及此处 MCP 工具的增强。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we can see that the output we get back from the LM is a multiple tool call.": "然后我们可以看到从 LLM 返回的输出是一个包含多个工具的调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here two tool calls.": "所以这里有两个工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is going to be 54 plus zero.": "一个是 54 加 0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the extra tool call that I missed.": "这就是我漏掉的那个额外工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other is going to be two times three.": "另一个是 2 乘以 3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So far, we've spent a lot of time diving into MCP servers and specifically into the concept of tools": "到目前为止，我们已经花了很多时间深入研究 MCP 服务器，特别是工具的概念",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and tools executions.": "以及工具的执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And honestly, when most people talk about MCP, tools are the first thing that comes to mind, including": "老实说，当大多数人谈论 MCP 时，首先想到的是工具，包括",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:myself.": "我自己。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They allow Llms to interact with the outside world, to perform actions, fetch information, and gives": "它们允许 LLM 与外部世界交互、执行操作、获取信息，并赋予",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:us a lot of capabilities.": "我们很多能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're incredibly powerful, and we've seen a lot of what we can do with them.": "它们非常强大，我们也已经看到了可以用它们做很多事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, MCP specification defines more primitives than just tools.": "然而，MCP 规范定义的原语不仅仅是工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:An MCP server can expose two other fundamental primitives.": "一个 MCP 服务器还可以公开另外两个基本原语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can expose prompts and can expose resources.": "它可以公开提示词（prompts）和资源（resources）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, the MCP specification gives general guidelines for how clients might use.": "现在，MCP 规范为客户端可能的使用方式提供了通用指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These prompts are defined as predefined templates or instructions that guides language models.": "这些提示词被定义为引导语言模型的预定义模板或指令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Interactions.": "交互。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The idea here is the MCP server can provide a list of useful prompts that the client application can": "这里的想法是 MCP 服务器可以提供一系列有用的提示词，客户端应用程序可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:display to the user.": "展示给用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So, for example, if we build an NTP server for deepresearch like GPT researcher, we can allow the": "例如，如果我们为像 GPT researcher 这样的深度研究工具构建一个 MCP 服务器，我们可以允许",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:users to choose a specific prompt that is predefined to help recalibrate and to help the user get better": "用户选择一个预定义的特定提示词，以帮助重新校准并帮助用户获得更好的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:results, without the user writing the prompt itself.": "结果，而无需用户自己编写提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you an example.": "让我给你们看一个例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here I'm using the NTP server of GPT researcher, and this MCP exposes a prompt template where we simply": "这里我使用的是 GPT researcher 的 MCP 服务器，这个 MCP 公开了一个提示词模板，我们只需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:need to plug in the values of topic in go.": "填入主题和目标的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we get a predefined prompt which is going to help calibrate our research query.": "然后我们会得到一个预定义的提示词，它将有助于校准我们的研究查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Doing deep research.": "进行深度研究。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is an excellent example of how to use prompts and when it's useful.": "所以这是一个关于如何使用提示词以及何时有用的绝佳例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is useful for the user.": "这对用户很有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember this prompt over here is going to be filled by the user.": "请记住，这里的提示词将由用户填写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The user is going to decide what values it's going to send to the LLM.": "用户将决定发送给 LLM 的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is in contrast to tools where in tools the model itself decides which tool to call and with": "这与工具形成了对比，在工具中，模型本身决定调用哪个工具以及使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which arguments.": "哪些参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So honestly, I haven't seen a lot of good usages except this one for prompts.": "老实说，除了这一个，我还没见过很多关于提示词的优秀用法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if you find one I would love to hear.": "但如果你发现了，我很乐意听听。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think this is a very good example of how it's useful.": "我认为这是一个说明其用途的很好例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's go and move on to resources.": "好了，让我们继续讨论资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And resources are structured data or content that provides additional context to the model.": "资源是为模型提供额外上下文的结构化数据或内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in essence it's information that the MCP server can expose.": "从本质上讲，它是 MCP 服务器可以公开的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP specification suggests that this behave somewhat like an HTTP get request.": "因此，MCP 规范建议其行为有点类似于 HTTP GET 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And an application which supports MCP can use those resources as it sees fits.": "支持 MCP 的应用程序可以根据需要使用这些资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is depending on the client implementations of the application.": "所以这取决于应用程序的客户端实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see examples of this in the next videos.": "我们将在接下来的视频中看到相关的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And an interesting thing with Landgraf by the way, is that it's going to run those tool calls concurrently.": "顺便提一下，LangGraph 有个有趣的地方，就是它会并发运行这些工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to make two concurrent requests into our MCP server.": "所以它会向我们的 MCP 服务器发送两个并发请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So one request is going to be to add 54 and zero.": "其中一个请求是计算 54 加 0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other request is going to be to multiply two and three.": "另一个请求是计算 2 乘以 3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see that they are concurrent because they are starting in the same start time, the same": "你可以看到它们是并发的，因为它们在同一个开始时间启动，也就是同一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:timestamp of 1131 and 17 milliseconds.": "11:31:17 毫秒的时间戳。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the rest of the execution is pretty straightforward.": "接下来的执行过程就非常简单明了了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After we have the result from the MCP server of how much is two times three, we can send another request": "在我们从 MCP 服务器获得 2 乘以 3 的结果后，我们可以发送另一个请求",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to the LM with this observation with this result.": "带着这个观测值，也就是这个结果，发送给大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and check it out.": "那么，让我们来看看吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we are sending now the A to the LM, the same query but with the result of the tool call.": "现在我们将同样的问题发送给大语言模型，但这次附带了工具调用的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the LM is going to decide that it needs to add up 54 and six.": "然后大语言模型会决定它需要将 54 和 6 相加。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see this tool execution here.": "让我们来看看这里的工具执行情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the rest is pretty straightforward.": "剩下的部分就很简单了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We send this final result to the LM again, alongside with the history of what we did.": "我们再次将最终结果连同我们的操作历史记录一起发送给大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we get the final answer and let's go and let's check out the final answer here.": "然后我们得到了最终答案，让我们来看看这里的最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now and go back to cursor and let me go and add the implementation here.": "现在让我回到 Cursor，在这里添加实现代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's commit it to GitHub.": "然后我们把它提交到 GitHub。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to use again the cursor feature of creating the commit message.": "我将再次使用 Cursor 自动生成提交信息的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me commit that and let me push to the repository.": "让我提交代码并推送到仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so you can see the final artifact.": "好了，你可以看到最终的产物。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to the GitHub repository.": "让我们去 GitHub 仓库看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the final artifact is going to be here in this branch.": "最终的产物就在这个分支里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see here that this is the code.": "你可以在这里看到代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I think it's very important to note that we can implement both prompts and resources with MCP tools.": "现在我认为非常重要的一点是，我们可以使用 MCP 工具来实现提示词和资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can create a tool that returns a list of suggested prompts or a tool that fetches specific data": "因此，我们可以创建一个返回建议提示词列表的工具，或者一个获取特定数据的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:resources.": "资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a big reason why tools are so dominant in the MCP landscape, and in practice, you're going": "这就是工具在 MCP 领域如此占据主导地位的一个重要原因，在实践中，你会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to find the vast majority of existing MCP servers primarily leveraging the tool primitives.": "发现绝大多数现有的 MCP 服务器主要利用工具原语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this leads into something very interesting that we're seeing in the ecosystem.": "这引出了我们在生态系统中看到的一个非常有趣的现象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even if an MCP server does define prompts and resources, the client application you're using might": "即使 MCP 服务器确实定义了提示词和资源，你正在使用的客户端应用程序也可能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:not actually support displaying or utilizing them.": "实际上并不支持显示或利用它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP client acts as the interface for the user to interact with the server, and if the client doesn't": "MCP 客户端充当用户与服务器交互的界面，如果客户端没有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:have the built in functionality to retrieve and present the prompts or the resources, those features": "内置检索和呈现提示词或资源的功能，那么服务器上的这些功能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on the server are effectively inaccessible to the users.": "对用户来说实际上是无法访问的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there are lists out there detailing which clients support which MCP features, and many popular clients": "因此，市面上有一些列表详细说明了哪些客户端支持哪些 MCP 功能，而许多流行的客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:currently focus only on tools.": "目前仅专注于工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me even add on this.": "让我再补充一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So even if you see here a particular client that is indicating that it supports resources or prompts,": "因此，即使你在这里看到某个特定的客户端表明它支持资源或提示词，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then sometimes the support isn't fully reliable in practice.": "在实践中，这种支持有时也并非完全可靠。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next couple of videos, we're going to dive deep into MCP resources.": "在接下来的几个视频中，我们将深入探讨 MCP 资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first video is going to be theoretical.": "第一个视频将是理论性的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to review the MCP spec on resources.": "我们将回顾关于资源的 MCP 规范。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to learn more about what are actually resources and how do clients use and access resources.": "我们将进一步了解什么是资源，以及客户端如何使用和访问资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after the first theoretical video, we're going to have a hands on example.": "在第一个理论视频之后，我们将进行一个动手实践的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because I'm a geek, I decided to do the hands on example with Pokemans.": "因为我是一个极客，所以我决定用宝可梦来做这个动手实践的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I hope you like Pokemans and see you in the next video.": "所以我希望你喜欢宝可梦，我们下个视频见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me start with you've init to initialize our virtual environment and let me right.": "让我先用 uv init 来初始化我们的虚拟环境，然后我来写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've add and let me add fast MCP.": "用 uv add，让我添加 fast MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice here that I'm not installing the mcp CLI like we did in previous videos.": "请注意，这里我没有像之前的视频中那样安装 mcp CLI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm installing a package which is called fast MCP and now get ready for some history.": "我正在安装一个名为 fast MCP 的包，现在准备听一点历史背景。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the person who actually wrote the first fast MCP object into the model context protocol repository,": "实际上，将第一个 fast MCP 对象写入模型上下文协议（Model Context Protocol）仓库的人，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:his name is Jeremiah Logan, and this is referred to now as MCP 1.0.": "他的名字叫 Jeremiah Logan，这现在被称为 MCP 1.0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a way to expose and to build MCP servers easily.": "这是一种轻松公开和构建 MCP 服务器的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what Jeremiah did is actually open source, something which is called fast MCP 2.0, which offers": "Jeremiah 实际上开源了一个名为 fast MCP 2.0 的项目，它提供了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a lot of functionality when we want to take our MCP servers or MCP in general, and we want to take": "很多功能，当我们想要将我们的 MCP 服务器或通用的 MCP 应用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it to production.": "投入生产环境时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So things like deployment auth, client server proxying, Composition and a lot of cool features, which": "比如部署、认证、客户端-服务器代理、组合（Composition）以及许多很酷的特性，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we're going to review some of them in the course is integrated in this.": "我们将在课程中回顾其中的一些，这些都集成在其中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is not in the protocol itself.": "所以这不在协议本身之内。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's actually a layer above it.": "它实际上是协议之上的一层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And Fasthttp 2.0 open source is very well maintained.": "而且 FastMCP 2.0 开源项目维护得非常好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's actually one, if not the most popular SDK to build servers in clients.": "它实际上是构建服务器和客户端最受欢迎（如果不是最受欢迎的话）的 SDK 之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, I'm interviewing the creator, Jeremiah Lowen, later in this course.": "顺便说一句，我稍后会在本课程中采访其创作者 Jeremiah Lowen。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, it's not something that competes with the SDK, but it augments it and it is a layer on top": "事实上，它并不是与 SDK 竞争的东西，而是对它的增强，是构建在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of it which utilizes the protocol.": "协议之上并利用协议的一层。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's install the package and let me go and run the main file here so we can see everything in the boilerplate": "让我们安装这个包，然后我去运行这里的主文件，这样我们就可以看到样板代码中的一切",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is working.": "都在正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to import from fast Amqp the fast MCP class.": "我将从 fastmcp 中导入 FastMCP 类。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go as we did earlier.": "让我们像之前那样操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the interface is the same.": "所以接口是一样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write a function def get research prompt which is going to receive a topic which is a string": "让我写一个函数 def get_research_prompt，它将接收一个字符串类型的 topic",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and returns a string, and it's going to return us.": "并返回一个字符串，它将返回给我们：",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Research the topic and this is the topic.": "“研究这个主题：[主题内容]”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now of course, when you want to write real world applications, you would like to make this prompt": "当然，当你想要编写实际应用时，你可能希望让这个提示词（prompt）",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:probably more robust.": "更加健壮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm simply showing you a POC here right.": "我在这里只是向你展示一个概念验证（POC），对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our prompt.": "所以这就是我们的提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice that it receives an argument which is going to be the topic.": "请注意，它接收一个参数，即 topic。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to wrap it as an NCP prompt.": "现在我们想把它包装成一个 MCP 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write at Mccp dot prompt.": "让我写上 @mcp.prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP is going to be our NCP server instance.": "MCP 将是我们的 MCP 服务器实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll create it.": "我来创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me write here MCP prompt.": "让我在这里写上 MCP 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and initialize the MCP server.": "让我们去初始化 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to call it MCP.": "我将把它命名为 mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be an object of fast MCP.": "它将是一个 FastMCP 对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's call it research prompt here.": "我们在这里把它命名为 \"research prompt\"。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're done here.": "我们在这里的工作完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now go and run this MCP server.": "现在让我们去运行这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me just remove this main file.": "让我删掉这个主文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't really need it this main function here.": "我们这里并不真的需要这个 main 函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write MC Dot rum.": "让我输入 mcp.run()。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and run it.": "让我们运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have the fast MCP 2.0 server running, and it's using the default stdio transport.": "我们可以看到 fast MCP 2.0 服务器正在运行，并且它使用的是默认的 stdio 传输方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that the server name is Research prompt.": "我们可以看到服务器名称是 Research prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go now to Cloud Desktop and let's go and integrate that MCP.": "现在让我们前往 Cloud Desktop 并集成那个 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go to settings then to developer.": "所以我要进入设置，然后进入开发者选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and edit config.": "让我们去编辑配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me open the configuration file.": "让我打开配置文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And don't worry about my API keys.": "不用担心我的 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're all revoked by now.": "它们现在都已经失效了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me add now a new MCP server.": "现在让我添加一个新的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to call it um, let's call it Research Prompt.": "我想给它起个名字，嗯，就叫它 Research Prompt 吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the commanded arc let's go back to cursor and let me find out my path to my Python interpreter.": "所以在命令参数中，让我们回到 Cursor，让我找到 Python 解释器的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and do that I'm going to return back to cursor.": "让我去操作一下，我要回到 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and let me open a new terminal.": "让我打开一个新的终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me write which Python three.": "让我输入 which python3。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the path to my virtual environment with the dependencies with the MCP installed.": "这就是我的虚拟环境路径，其中包含依赖项并安装了 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to paste it here.": "所以我要把它粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the args I simply want to run the main file where our project is located.": "在参数中，我只想运行项目所在的主文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I remind you in the cloud desktop host we want to restart it.": "所以我提醒你，在 Cloud Desktop 主机中，我们需要重启它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me close it and let me close it again.": "让我关闭它，再关闭一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here, let me quit it this application.": "在这里，让我退出这个应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me open it again.": "现在让我再次打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'm going to click the plus button we can get this prompt here.": "如果我点击加号按钮，我们可以在这里看到这个提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's important to note that every host has different implementation of MCP in Cloud Desktop.": "现在需要注意的是，Cloud Desktop 中的每个主机对 MCP 的实现都不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you click the plus button, you have access to the prompts and the resources and the tools are in": "如果你点击加号按钮，你可以访问提示词，而资源和工具则在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this icon right next to it.": "它旁边的这个图标里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Street.": "Street。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something which depends on the host implementation.": "这取决于主机的具体实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want now to go and let's go select the research prompt that we wrote.": "我现在想去选择我们编写的 research prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the actual function.": "在这里我们可以看到实际的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's defined in our MCP server.": "那是定义在我们的 MCP 服务器中的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Get research prompt by the way we can add here also description for the user to see.": "顺便说一下，Get research prompt，我们也可以在这里添加供用户查看的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I remind you the prompt is user facing.": "我提醒你，提示词是面向用户的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is also a good idea.": "所以这也是个好主意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can input the topic that we want to research.": "在这里我们可以输入想要研究的主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll get back the prompt.": "然后我们会得到返回的提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me type in here the cursor pricing scandal.": "让我在这里输入 cursor pricing scandal。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's click Add Prompt.": "点击 Add Prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that this is our research prompt which is added now and can be sent to the LM.": "我们可以看到这就是我们的 research prompt，现在已经添加并可以发送给大语言模型了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what the prompt mechanism in MCP is doing.": "这就是 MCP 中的提示词机制所做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I want to show you some other cool things here.": "现在我想给你们展示一些其他酷炫的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um so let's go back now to the code.": "嗯，现在让我们回到代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want now to change the transport type.": "我现在想更改传输类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to go and change it to Streamable http.": "我想把它改为 Streamable http。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So all I need to do is to write transport equals and then HTTP.": "所以我只需要写 transport equals，然后是 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me now rerun this server again.": "现在让我再次重新运行这个服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go close everything and let me run this server again.": "让我关闭所有内容，然后再次运行这个服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that it's now running on localhost port 8000.": "我们可以看到它现在运行在 localhost 的 8000 端口上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have this slash MCP endpoint and the transport is HTTP right.": "我们有这个 /mcp 端点，传输方式是 HTTP，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go now to Cloud Desktop again.": "现在让我们再次回到 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and actually remove this MCP.": "让我去实际移除这个 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because now that the transport is Rumbold HTTP.": "因为现在的传输方式是远程（Remote）HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Cloud Desktop actually supports this um supports this transport type.": "所以 Cloud Desktop 实际上支持这种……支持这种传输类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However it supports it only if there is of implemented.": "然而，只有在实现了身份验证（auth）的情况下它才支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I didn't implement here off.": "而我在这里没有实现身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's not going to work until this is a resolve in the MCP host of Cloud Desktop.": "所以在 Cloud Desktop 的 MCP 宿主中解决这个问题之前，它是无法工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can use it there.": "我们可以在那里使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right I want to open the terminal and let me go and run the MCP inspector.": "好了，我想打开终端，让我去运行 MCP 检查器（MCP inspector）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me run it with sudo permissions one second.": "让我用 sudo 权限运行它，稍等一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we can go and let's hit that URL and let me click this link here.": "现在我们可以去访问那个 URL，让我点击这里的这个链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice here that I can select now Streamable http here.": "注意这里，我现在可以在这里选择 Streamable HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the URL is going to be 127 001 at port 8000 slash MCP.": "URL 将会是 127.0.0.1 的 8000 端口下的 /mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is where our HTTP server is running.": "这就是我们的 HTTP 服务器运行的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you're not going to have this prefilled I have this prefilled simply because I ran it beforehand.": "你们那里不会有这些预填的内容，我这里有预填仅仅是因为我之前运行过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And anyways let's go and click connect.": "总之，让我们点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to show you something.": "我想给你们看点东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see I get here an error proxy authentication required that we need to put here in the configuration.": "你可以看到我这里得到了一个“需要代理身份验证”的错误，我们需要在配置中填入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The session token.": "会话令牌（Session token）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I elaborate on MCP proxies later in the course when we deploy an MCP server to Cloudflare.": "在课程后面当我们把 MCP 服务器部署到 Cloudflare 时，我会详细阐述 MCP 代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's just for now ignore this error.": "现在让我们先忽略这个错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'll show you how to fix it and how to get this token, and you'll later understand why we need it,": "我会向你展示如何修复它以及如何获取这个令牌，稍后你就会明白为什么我们需要它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go back when I ran the MCP inspector.": "让我回到运行 MCP 检查器的时候。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I had there a token which I need to copy and paste.": "我那里有一个令牌，我需要复制并粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and copy that.": "让我去复制它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go to configuration and let me paste it here in the proxy session.": "让我去配置界面，把它粘贴到这里的代理会话中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Token here.": "令牌填在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And please, please, please don't freak out about this proxy here and about this token.": "还有，请，请，千万不要因为这里的代理和这个令牌而感到恐慌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what is proxying.": "以及什么是代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I promise you I go over it in the rest of the course.": "我保证在课程的剩余部分会讲解这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not relevant for now, right?": "现在这些还不相关，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after you fill out this token, simply click connect.": "所以在你填写完这个令牌后，只需点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now that we're connected to the HTTP server.": "我们现在可以看到已经连接到了 HTTP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way we could have simply click this link over here.": "顺便说一下，我们本可以简单地点击这里的这个链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we would have this token prefilled.": "这样我们就会有预填好的令牌了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back to Inspector and let me now go to prompts, because this is the only thing we have now": "让我们回到检查器，现在让我进入 prompts（提示词），因为这是我们现在唯一的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the MCP server.": "在 MCP 服务器中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's click on list prompts and get research prompt.": "让我们点击 list prompts 并获取 research prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can simply enter now the Nvidia stocks.": "在这里我们现在只需输入 Nvidia 股票。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now this is the result we get back here.": "我们现在可以看到这就是我们在这里得到的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now something is interesting is happening here that I want to explain here.": "现在这里发生了一些有趣的事情，我想解释一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see that what we get back when we execute this we get back a list of messages where the first": "我们可以看到，当我们执行这个操作时，我们得到的是一个消息列表，其中第一条",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:message is a user message with the content of the prompt here.": "message 是包含提示词内容的用户消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember we in the function itself in the MCP server we returned a string.": "记住，在 MCP 服务器的函数本身中，我们返回的是一个字符串。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But actually what fast MCP did for us it converted that string into a user message.": "但实际上 fast MCP 为我们所做的是将该字符串转换为了用户消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the default behavior.": "这是默认行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Theoretically, if we have a conversation with the MCP host and we can have here lots of other messages": "理论上，如果我们与 MCP 主机进行对话，这里可以有很多其他消息，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of back and forth messaging from the eye to the user, from the eye to the user, which we can also": "比如 AI 与用户之间来回传递的消息，我们也可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:add here.": "添加到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this doesn't have to be only one message.": "所以这不一定只有一条消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this provides more context to the prompt here.": "这为这里的提示词提供了更多上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is why it's going to be useful.": "这就是它会有用的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's go to cursor and let's go and try to um to integrate that MCP server into cursor.": "现在让我们前往 Cursor，尝试将该 MCP 服务器集成到 Cursor 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and click on this a wheel here.": "让我点击这里的这个齿轮图标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This a settings wheel.": "这个设置齿轮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go to Tools and Integrations add MCP server.": "让我进入 Tools and Integrations（工具与集成），添加 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let me add an entry.": "在这里让我添加一个条目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe you have here a clean slate.": "也许你这里是空白的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I'm going to add here an entry of the research prompt.": "但我打算在这里添加一个研究提示词（research prompt）的条目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I'm simply going to give it the URL.": "在这里我只需给它 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the URL is 127001.": "URL 是 127.0.0.1。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And slash MCP I need to add.": "我还需要加上 /mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me remove some curly brackets.": "让我删掉一些花括号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me save it.": "让我保存它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and see what we have here in cursor.": "让我们看看 Cursor 里现在有什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we have connected the MCP server.": "现在我们已经连接了 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see the research prompt here.": "你可以在这里看到 research prompt。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can see that we have zero tools enabled.": "但我们可以看到启用的工具数量为零。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is happening because cursor right now does not support prompts.": "这是因为 Cursor 目前不支持提示词（prompts）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see what's on the internet regarding the MCP client in cursor.": "让我们看看网上关于 Cursor 中 MCP 客户端的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and search for MCP clients here.": "让我在这里搜索 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the first column is going to be resources sorry.": "在这里我们可以看到第一列是资源（resources），抱歉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the second is going to be prompts.": "第二列是提示词（prompts）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me look for cursor.": "让我找一下 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that cursor does not support prompts here.": "我们可以看到 Cursor 在这里不支持提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and check out a cloud desktop.": "让我们去看看 Claude Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cloud desktop does support prompts.": "Claude Desktop 确实支持提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see here that cloud code allegedly supports prompt.": "我们可以看到这里 Claude 据说支持提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But from my experience and from me playing around with it, it doesn't really natively supports prompt.": "但根据我的经验和试用情况，它并没有真正原生支持提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I highly suggest you try this exercise.": "我强烈建议你尝试这个练习。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you try to integrate the prompt MCP with cloud code, right.": "尝试将提示词 MCP 与 Claude 集成，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And finally, let me show you a real world example from the GPT researcher MCP.": "最后，让我向你展示一个来自 GPT researcher MCP 的真实案例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see we have here a prompt query here.": "我们可以看到这里有一个提示词查询（prompt query）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can specify what a topic we want to research.": "在这里我们可以指定想要研究的主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can give it also a goal.": "我们还可以给它一个目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Go and let me right cursor pricing scandal and a brief summary.": "让我输入 Cursor 定价丑闻和简要总结。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once we add it we can see we get here this prompt that GPT researcher is going to use.": "一旦添加，我们可以看到这里得到了 GPT researcher 将要使用的提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think this is an excellent example of the use case when we would like to use prompts.": "我认为这是我们想要使用提示词的一个绝佳用例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a resource in MCP is a readable data that an MCP server makes available to clients and ultimately": "所以 MCP 中的资源是 MCP 服务器提供给客户端，并最终",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to LMS as context.": "作为上下文提供给大语言模型（LLM）的可读数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it can be files, content, database scheme.": "它可以是文件、内容、数据库模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A log snippet, screenshot, API response, and anything that we want the model through the host app": "日志片段、屏幕截图、API 响应，以及任何我们希望模型通过宿主应用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to see, but it does not execute it's read only.": "看到的东西，但它不会执行，它是只读的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So resource are application driven.": "因此，资源是应用程序驱动的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The host application decides when slash what to fetch and to include and not the model directly.": "由宿主应用程序决定何时以及获取/包含什么内容，而不是由模型直接决定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is in contrast to tools which the model can invoke.": "这与模型可以调用的“工具（tools）”形成了对比。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll see in this video an example of that.": "我们将在本视频中看到一个相关的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So resources return text like UTF eight.": "资源返回文本，例如 UTF-8。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They can return binary base64 and they can even include a Mime type so the clients will know how to": "它们可以返回二进制 Base64，甚至可以包含 Mime 类型，以便客户端知道如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:handle it.": "处理它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So maybe to render as code to show us an image preview, etc..": "例如渲染为代码、显示图像预览等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about what's a resource URI here.": "现在让我们谈谈这里的资源 URI 是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And every resource has a unique URI string, we can expose static resources where the URI points to": "每个资源都有一个唯一的 URI 字符串，我们可以公开静态资源，其中 URI 指向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:one specific thing.": "一个特定的事物。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, this and clients discover this via resource list and we can also expose resource templates": "例如这个，客户端通过资源列表（resource list）发现它，我们还可以公开资源模板",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:using URI templates.": "（resource templates），即使用 URI 模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These are pattern URIs with placeholders that lets the client request many concrete resources without": "这些是带有占位符的模式 URI，允许客户端请求许多具体的资源，而无需",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:releasing each one.": "逐一发布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, we can have this template and the ID here is going to be dynamically.": "例如，我们可以有这样一个模板，这里的 ID 将是动态的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client is going to ask the server to plug in a certain value to a display folder, and then to": "客户端将要求服务器在占位符中插入特定值，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:fetch and generate the data to return it.": "获取并生成数据以将其返回。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this makes the resource access dynamic.": "这使得资源访问变得动态化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's talk about how clients get and use resources.": "接下来让我们谈谈客户端如何获取和使用资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's the flow.": "流程是怎样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first there is first there is the discovery.": "首先是发现阶段。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client will call resource list and resources slash template slash list for getting all the patterns.": "客户端将调用 resource/list 和 resources/templates/list 来获取所有模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the client will be able to select so the host app.": "然后客户端（即宿主应用）将能够进行选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And sometimes by the way even the user can choose which resource to include as the context.": "顺便说一句，有时甚至用户也可以选择将哪个资源作为上下文包含进来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then there is the read the client calls resources slash read with the resources URI to get the content,": "然后是读取阶段，客户端调用 resources/read 并带上资源 URI 来获取内容，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:whether it's text or certain blob.": "无论是文本还是特定的二进制大对象（blob）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And optionally there is also a subscribe change notification so the server can signal when the resource": "此外还可以选择订阅变更通知，这样当资源",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:lists or contents they change.": "列表或内容发生变化时，服务器可以发出信号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If they advertise those capabilities already.": "前提是它们已经声明了这些功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, I think it's important to note that resource subscription and notifications is a new concept that": "现在，我认为重要的一点是，资源订阅和通知是 MCP 协议引入的一个新概念。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the MCP protocol introduces.": "（即 MCP 协议引入的）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I haven't really seen any real world usages of this feature, and if you have seen, please let me know.": "我还没真正见过这个功能的实际应用案例，如果你见过，请告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Would be happy to cover it as well.": "我也很乐意讲解它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So looks like this feature is not yet adopted.": "所以看起来这个功能还没有被广泛采用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when to use resource versus a tool.": "现在来谈谈什么时候该使用资源，什么时候该使用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the recommendation is to use a resource when we want to share data that the app can feed into the": "因此，建议在想要共享应用程序可以输入到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:model.": "模型的数据时使用资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Use a tool where we want the model with approval to do something like to run a command, make an API": "在希望模型在获得批准后执行运行命令、进行 API",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:call.": "调用等操作时使用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So resource equals context data and tools equals actions.": "所以，资源等于上下文数据，而工具等于操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when we have some user facing logic that we want to get from the user information to help us tweak": "所以，当我们有一些面向用户的逻辑，希望通过获取用户信息来帮助我们调整",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our agent runtime.": "我们的智能体运行时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to touch on one last point, because when we implement the prompt resource with MCP, it's": "我想提最后一点，因为当我们使用 MCP 实现提示词资源时，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:actually a function.": "实际上是一个函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we can actually dynamically fetch it from a database or any other external source.": "这样我们就可以从数据库或任何其他外部源动态地获取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can make an API call to get it.": "我们可以通过 API 调用来获取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can really go crazy here.": "所以我们在这里真的可以发挥无限可能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can really build a lot of cool functionality.": "我们可以构建很多非常酷的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can have, uh, up to date prompt, which is fetch from database where we need to only update": "我们可以拥有，呃，实时更新的提示词，它们从数据库中获取，我们只需要更新",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the database and it updates automatically the MCP server because the data of the prompt is dynamically": "数据库，MCP 服务器就会自动更新，因为提示词的数据是动态",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:fetched.": "获取的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is something that I wanted to note.": "这是我想特别说明的一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be a dictionary mapping the ID to a bunch of pokemons.": "所以这将是一个将 ID 映射到一组宝可梦的字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is going to be Bulbasaur, four is going to be Charmander and three is sorry seven is going to be": "1 号是妙蛙种子，4 号是小火龙，3 号——抱歉，7 号是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Squirtle.": "杰尼龟。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me paste in the snippet and this is what you see right over here is a static resource.": "现在让我粘贴这段代码片段，你在这里看到的是一个静态资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see the URI is porky starters.": "你可以看到 URI 是 porky starters。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see it doesn't have anything dynamic.": "你可以看到它没有任何动态内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when it's called we are going to run the asynchronous coroutine list starters.": "当它被调用时，我们将运行异步协程 list_starters。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's simply going to iterate through all the items in the dictionary in our cache, and it's going": "它将简单地遍历我们缓存中字典里的所有项，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to return the ID of the Pokemon, the name.": "返回宝可梦的 ID 和名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what is the URI of the Pokemon?": "以及宝可梦的 URI 是什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me refresh your memory of what is the URI.": "让我帮你回忆一下什么是 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The URI stands for Uniform Resource Identifier, and it's simply a text string that uniquely names or": "URI 代表统一资源标识符，它只是一个文本字符串，用于唯一地命名或",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:locates something so software can find it later.": "定位某个东西，以便软件稍后能找到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for example, we have a URL and that we're using every day in our browser.": "例如，我们每天在浏览器中使用的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's a kind of URI that tells the browser exactly where to fetch the resource.": "它是一种 URI，告诉浏览器确切地从哪里获取资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP borrows this concept for context that eventually is going to be plugged in into an LM.": "MCP 借用了这个概念来处理上下文，这些上下文最终将被插入到语言模型（LM）中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is context we make available to the MCP client and the MCP host.": "所以这是我们提供给 MCP 客户端和 MCP 宿主的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this string starters is random.": "这个字符串 starters 是随机的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can write here anything we want as long as it's a valid URI.": "只要它是有效的 URI，我们可以在这里写任何我们想要的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll I'll make a video only dedicated to URIs just in case you want to.": "我会专门制作一个关于 URI 的视频，以防你想了解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, you can see that here we have a dynamic URI that is changing according to the Pokemon ID,": "顺便说一下，你可以看到这里我们有一个动态 URI，它会根据宝可梦 ID 发生变化，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:so we're also going to see an example of this very soon.": "所以我们很快也会看到一个这样的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The tldr of this is that once the MCP client is going to fetch, for starters, it's going to execute": "简而言之，一旦 MCP 客户端要获取 starters，它就会执行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this function and get this context, which here is going to be our cached pokemons.": "这个函数并获取这个上下文，在这里就是我们缓存的宝可梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and paste this massive function over here.": "让我把这个庞大的函数粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I do not want you to rewrite it from zero.": "我不希望你从零开始重写它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It wouldn't provide any value to you.": "这对你没有任何价值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's good enough to simply go through it.": "简单地过一遍就足够了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can get it from the repository and I'll link it in the video's resources.": "你可以从代码仓库中获取它，我会把它链接在视频资源中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, what we have here, we have here a coroutine which is called Get Pokemon and it receives a": "总之，我们这里有一个名为 Get Pokemon 的协程，它接收一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pokemon ID which is a string, and it's going to return us a dictionary with details on that Pokemon.": "字符串类型的宝可梦 ID，并返回一个包含该宝可梦详细信息的字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we decorate it with a resource decorator.": "然后我们用一个资源装饰器来装饰它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here look at the Uri.": "看看这里的 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here the the URI is slash Pokemon slash Pokemon ID and we have here those curly brackets here.": "这里的 URI 是 /pokemon/{pokemon_id}，我们这里有这些花括号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a template here.": "所以这是一个模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a placeholder.": "这是一个占位符。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, this reminds us of a Get request in a Rest API where we want to get information in": "顺便说一下，这让我们想起了 Rest API 中的 Get 请求，即我们想要在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a Rest API.": "Rest API 中获取信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in fact, what we'll do is actually call a Rest API and call a Get request.": "事实上，我们要做的实际上是调用一个 Rest API 并发起一个 Get 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once we execute this function and assuming that we'll provide you with a valid Pokemon ID, we're": "因此，一旦我们执行这个函数，并假设我们会提供一个有效的宝可梦 ID，我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:simply going to make an asynchronous request to an API that gets us Pokemon information, which is free,": "就会向一个获取宝可梦信息的 API 发起异步请求，这个 API 是免费的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and you can use it.": "并且你可以使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're then going to take the response.": "然后我们将获取响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to play a bit with the fields.": "我们将对这些字段进行一些处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to return a, um, a readable answer from it.": "我们将从中返回一个，嗯，可读的答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So nothing special over here.": "所以这里没什么特别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's simply going to make an API request.": "它只是发起一个 API 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now notice here that it's actually going to be dynamic right.": "现在请注意，这里实际上是动态的，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client is going to make a request.": "所以客户端将发起一个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However the request is going to be making is going to be requesting for a resource with a specific Pokemon": "然而，它发起的请求将是请求具有特定宝可梦",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ID, and once you see this in action, it will be all clear, I promise you.": "ID 的资源，一旦你看到它的实际运行，一切都会变得清晰，我向你保证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be in this video, so don't worry about it.": "这将出现在本视频中，所以不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the function itself is actually simple.": "所以函数本身其实很简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's making an API request over Pokemon and returning the answer.": "它对宝可梦发起 API 请求并返回答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have another dynamic template which is going to get a Pokemon by its type.": "这里我们有另一个动态模板，它将根据类型获取宝可梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to get all the pokemons of type X here.": "所以它会获取这里所有 X 类型的宝可梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see here the URI is pocket slash slash slash slash types name.": "所以你可以看到这里的 URI 是 pocket////types/name。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what it's going to do.": "它要做的是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to make an API request to the Pokemon API and filter A through the type name.": "它将向宝可梦 API 发起 API 请求，并通过类型名称进行过滤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again this is supported by the Pokemon API.": "同样，这也是宝可梦 API 所支持的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't need a token by the way or anything.": "顺便说一下，我们不需要令牌或任何东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's simply a publicly available.": "它只是公开可用的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once we get that, we simply take the answer.": "一旦我们得到它，我们只需获取答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We make it a bit more readable and return it to the MCP client.": "我们让它变得更具可读性，并将其返回给 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so this is all the code that will be showing here today.": "好了，这就是今天我们要展示的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now what's interesting is actually not the code itself.": "现在有趣的其实不是代码本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The code is very simple.": "代码非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's simply to put a decorator with a resource on it and to play around with the URIs.": "只是放一个带有资源的装饰器，并处理一下 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But what's actually interesting and important, and will teach you a lot, is to see how the client": "但真正有趣且重要，并且会让你学到很多东西的是，看看客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is going to use those resources.": "将如何使用这些资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to try a bunch of different clients.": "我们将尝试一堆不同的客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and let me paste the last snippet, which is simply to go and run the MCP server.": "现在让我去粘贴最后一段代码片段，它只是去运行 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to simply use app Dot run and let's go and run it and make sure that it is a working and": "我将简单地使用 app.run，让我们运行它并确保它正在工作且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it's okay.": "没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see it's working.": "我们可以看到它正在工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to go and integrate this MCP into cloud.": "现在我想去把这个 MCP 集成到 Claude 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in my cloud desktop config JSON.": "[",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I am simply putting in the command the path to my package manager and in the args.": "\"在我的 Claude Desktop 配置 JSON 中。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm giving it the directory where my code is being stored.": "\"我只需在命令中放入包管理器的路径，并在参数中进行设置。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm giving it run Main.py.": "\"我向其提供存储代码的目录。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's what's running in our server.": "\"并且我让它运行 Main.py。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the command.": "\"这就是我们服务器上运行的内容。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I will make it also available in the course's resources.": "\"这就是那个命令。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can even copy paste it and adjust it.": "\"我也会在课程资源中提供它。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let me go now and restart cloud.": "\"所以你甚至可以复制粘贴并进行调整。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to quit then to open it again.": "\"好了，现在让我去重启 Claude。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And very similar to prompts.": "\"所以我要先退出，然后再重新打开它。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we'll click the plus button we can see here the resources.": "\"与提示词非常相似。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see add from Pokemon.": "\"如果我们点击加号按钮，我们可以在这里看到资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can add that resource.": "\"所以你可以看到“从 Pokemon 添加”。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and click that.": "\"这样我们就可以添加那个资源了。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we can see we have the static resource that we defined.": "\"让我去点击它。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice that Cloud Desktop, the MCP host here decided to display here the function name instead": "\"然后我们可以看到我们定义的静态资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the resource URI.": "\"请注意，这里的 MCP 主机 Claude Desktop 决定在此处显示函数名称，而不是资源 URI。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a decision they made when they implemented the MCP client here right.": "\"这是他们在实现这里的 MCP 客户端时做出的决定，对吧。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the app host has the freedom to display it however they want.": "\"因此，应用主机可以自由地以任何他们想要的方式显示它。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here they're only displaying the static.": "\"在这里，他们只显示了静态资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Notice that there isn't any mention of the dynamic resources that we created those templates.": "\"请注意，完全没有提到我们创建的那些模板动态资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't see them right now.": "\"我们现在看不到它们。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is interesting to see that cloud desktop actually don't display them.": "\"所以看到 Claude Desktop 实际上并不显示它们，这很有趣。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So yeah this is interesting.": "\"是的，这很有趣。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go now and click least starters and let's see what we get.": "\"现在让我们点击 list starters，看看我们会得到什么。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we should get the context to add to cloud.": "\"我们应该会得到要添加到 Claude 的上下文。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now the function executed.": "\"我们可以看到函数现在执行了。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now all the starters pokemons and all that information.": "\"我们可以看到所有的初始宝可梦以及所有相关信息。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can send it to cloud.": "\"我们可以把它发送给 Claude。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now you might be looking at this and saying hey this is not very useful.": "\"现在你可能会看着这个说，嘿，这并不是很有用。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so this use case the static resource is not very useful in my opinion.": "\"在我看来，静态资源这个用例并不是很有用。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However what is more useful is the dynamic resource.": "\"然而，更有用的是动态资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And unfortunately cloud does not support it.": "\"但不幸的是，Claude 不支持它。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So even though they claim in a the NCP client list that they do support resources, you can see that": "\"所以，尽管他们在 MCP 客户端列表中声称支持资源，但你可以看到他们并没有完全支持，至少现在还没有。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:they don't fully support it, at least not now.": "\"让我们看看 Cursor 客户端和资源的情况。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see what's up with the cursor client and resources.": "\"现在让我去“工具与集成”。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now to tools and Integrations.": "\"你可以看到我已经设置好了 MCP 服务器。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see I have the NCP server set up.": "\"但这里的命令是完全一样的。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is the exact same command here.": "\"所以你可以看到，当我们加载 Pokemon MCP 时，显示启用了零个工具。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see that when we loaded the Pokemon MCP, we can see zero tools enabled.": "\"这是正确的，因为我们没有任何工具，只有资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is correct because we don't have any tools, we have only resources.": "\"让我尝试在 Cursor 中运行一下。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me give it a try in cursor.": "\"让我输入“你有哪些初始宝可梦，请使用 MCP”。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write which starter pokemons you have use MCP.": "\"我们希望它会获取那个资源。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're hoping that it's going to take that resource.": "\"但实际上它没有。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But actually it's not.": "\"它正在使用 API 通过一个作为搜索引擎的 MCP 来完成。\",",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's using the API in order to do it with a MCP which is a search engine.": "\"这真的没什么用。\"",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not really useful.": "]",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first we want to make sure that we have cloud code installed in our system.": "首先，我们要确保系统中已经安装了 cloud code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the official anthropic documentation for cloud code.": "这是 Anthropic 官方关于 cloud code 的文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the installation guide.": "这是安装指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to install it with Dash global flag.": "我们需要使用全局标志 (-g) 来安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And once we run this command in the terminal we should have this installed.": "在终端运行此命令后，我们就应该安装好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice here that we're being said not to use sudo with this command because it can lead to security": "注意这里提到不要对该命令使用 sudo，因为这可能会导致安全",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:risks.": "风险。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Unfortunately, this was the only way I could install it with sudo.": "不幸的是，我只能通过 sudo 的方式来安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you the installation.": "让我给你们演示一下安装过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go and open terminal.": "我现在去打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to install this package with sudo.": "我将使用 sudo 安装这个包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I highly recommend you try it first without it.": "我强烈建议你先尝试不带 sudo 进行安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see I already have it installed.": "你可以看到我已经安装好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you want to run it and use cloud code, you need to right in the terminal cloud.": "如果你想运行并使用 cloud code，你需要在终端输入 cloud。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now to use cloud code, you would need an anthropic API key or any other API key.": "现在要使用 cloud code，你需要一个 Anthropic API 密钥或任何其他 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you want to use other llms, it is possible and with a bit of tweaking.": "如果你想使用其他大语言模型 (LLM)，这是可以实现的，只需进行一些微调。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so I already did that and I'm not going to do it right now.": "嗯，我已经做过了，现在就不演示了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me know if you want to see the installation from zero, but because I have everything Thing configured.": "如果你想看从零开始的安装过程请告诉我，但因为我已经配置好了一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will get this screen.": "我会看到这个界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here a warning that it can read files in the folder.": "我们可以看到这里有一个警告，提示它可以读取文件夹中的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it can also execute files.": "它还可以执行文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So make sure that you're running it in a safe place.": "所以请确保你在安全的地方运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And anyways I'm going to click yes to proceed.": "无论如何，我将点击“是”继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we have cloud code.": "现在我们有了 cloud code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me write.": "让我输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hello.": "你好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now we get a response here.": "我们可以看到现在这里得到了回复。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I have installed in my cursor the Cloud Desktop plugin.": "现在我在 Cursor 中安装了 Cloud Desktop 插件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can install it as well.": "你也可以安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or you can simply run cloud code from the terminal.": "或者你也可以直接从终端运行 cloud code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's opened.": "现在它打开了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and make the window a bit bigger.": "让我把窗口调大一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me click yes to proceed in order to run cloud code.": "让我点击“是”以继续运行 cloud code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now it's running here.": "现在它正在这里运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want now to open a terminal next to cloud code here.": "现在我想在 cloud code 旁边打开一个终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'll be able to add the MCP to cloud code.": "这样我就能把 MCP 添加到 cloud code 中了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me clear everything and let me write cloud mcp dash dash help here.": "让我清空所有内容，然后在这里输入 cloud mcp --help。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to give us all the information about how to integrate an MCP with cloud code.": "这将为我们提供有关如何将 MCP 与 cloud code 集成的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we have the list command which is going to list the configured MCC.": "我们可以看到有 list 命令，它将列出已配置的 MCC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here the add command which is going to add an MCC server.": "这里还有 add 命令，用于添加 MCC 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this add command is going to receive a some options which we're going to review soon.": "这个 add 命令将接收一些选项，我们稍后会进行查看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to receive the name of the server.": "它将接收服务器的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to then receive the command or the URL.": "然后它将接收命令或 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in our case the URL is going to be 127001 at port 8000 slash MCP because it's a streamable HTTP.": "在我们的例子中，URL 将是 127.0.0.1 的 8000 端口下的 /mcp，因为它是一个可流式传输的 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we would need to also supply the transport type.": "我们还需要提供传输类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So practically, practically there isn't any support at the moment in cursor for resources.": "所以实际上，目前 Cursor 还不支持资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So who actually supports resources right now.": "那么现在到底谁支持资源呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and change the transport to HTTP.": "让我去把传输方式改为 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you how I'm going to integrate it into cloud code.": "让我向你展示我是如何将其集成到 Cloud Code 中的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it actually has better support for MCP resources.": "而且它实际上对 MCP 资源有更好的支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me run here.": "让我在这里运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the server.": "现在启动服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now you can see it's running on the transport of Streamable http.": "现在你可以看到它正运行在 Streamable HTTP 传输方式上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you how to install cloud code and connect it to cloud code.": "让我向你展示如何安装 Cloud Code 并连接到 Cloud Code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and just make sure that we don't have any MCC installed first.": "所以让我们先去确认一下没有安装任何 MCC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's run our cloud MCP list.": "所以让我们运行 cloud MCP list。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that no MCP servers are configured.": "我们可以看到没有配置任何 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Use cloud MCP add to add a server.": "使用 cloud MCP add 来添加服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's add our Streamable HTTP server with all of the resources we created on the pokemons.": "让我们添加我们的 Streamable HTTP 服务器，以及我们在 pokemons 上创建的所有资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so let me write cloud MCP.": "好的，让我输入 cloud MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then I'm going to write Dash dash help to see which arguments does it get?": "然后我要输入 --help 来查看它有哪些参数？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And first we're going to put the options here.": "首先我们要在这里放入选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the options we're going to write the transport type which is going to be HTTP.": "在选项中，我们要写传输类型，即 HTTP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we're going to put the name of the MCP server and then the URL of our HTTP.": "然后我们要放入 MCP 服务器的名称，接着是我们的 HTTP URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to write cloud MCP and dash t http.": "所以我要输入 cloud MCP 和 -t http。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write now the name of the MCP.": "现在让我输入 MCP 的名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go.": "开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me call it Pokemon.": "让我把它命名为 Pokemon。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to put the address of the MCP server.": "现在我们要输入 MCP 服务器的地址。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be 127 001 slash MCP.": "所以地址是 127.0.0.1/MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now that we added http mcp server Pokemon with all the details.": "现在我们可以看到我们添加了带有所有详细信息的 HTTP MCP 服务器 Pokemon。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's run cloud MCP list just to see that we have it.": "所以让我们运行 cloud MCP list 来确认它已经存在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everything looks good right now.": "现在一切看起来都很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's write also cloud MCP get Pokemon and we can see now the details.": "我们也输入 cloud MCP get Pokemon，现在我们可以看到详细信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see that the MCP server seems to be configured.": "所以我们可以看到 MCP 服务器似乎已经配置好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time to go to Cloud code.": "所以现在是时候去 Cloud code 了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we're going to dive deeper into the SSC, MCP server.": "在这段视频中，我们将深入探讨 SSC MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the previous videos we implemented the weather MCP server which the transport is SSC.": "在之前的视频中，我们实现了天气 MCP 服务器，其传输方式是 SSC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we're going to integrate it with the link chain multi MCP server client that they made for us.": "现在我们要将其与他们为我们制作的 LangChain 多 MCP 服务器客户端进行集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this client helps us a lot because it actually is able to connect to multiple MCP servers all at": "这个客户端对我们很有帮助，因为它实际上能够同时连接到多个 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:once.": "。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The cool thing about SSC servers is that we can go and we can deploy them everywhere we want.": "SSC 服务器的酷炫之处在于，我们可以将其部署在任何我们想要的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the usual usage pattern of SSC servers is to deploy them in the cloud.": "SSC 服务器的通常使用模式是将它们部署在云端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'll take it to enterprise usage, we can deploy it in our enterprise cloud.": "如果将其用于企业级用途，我们可以将其部署在我们的企业云中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then everyone in our organization can actually make a call to it.": "这样，我们组织中的每个人实际上都可以调用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, I didn't talk yet about authentication and authorization.": "顺便说一下，我还没有谈到身份验证和授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we're going to deploy to the cloud, we don't want to give it access to everybody.": "如果我们要部署到云端，我们不想让所有人都能访问它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to limit the access to our logged in users and maybe have some role based access control and": "我们希望将访问权限限制在已登录用户，并可能加入一些基于角色的访问控制，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to control who is accessing which tool or not.": "控制谁可以访问哪个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something which is going to be added and it's not yet implemented fully in the MCP protocol,": "这是即将添加的功能，目前在 MCP 协议中尚未完全实现，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:but once it will be added, I will be covering it.": "但一旦添加，我就会进行讲解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I remind you, this is the implementation of our ZK server.": "所以我提醒一下大家，这是我们 ZK 服务器的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to run it, all we need to do is run the command you've run.": "为了运行它，我们只需要执行你已经运行过的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then servers and the weather server.": "然后是 servers 文件夹和天气服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now it's running on port 8000.": "我们可以看到它现在运行在 8000 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to create a new Mcpe client that is going to use this ZK server.": "现在我想创建一个新的 MCP 客户端，它将使用这个 ZK 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to use the Stdio server we had from before with the math operations.": "它还将使用我们之前那个带有数学运算的 Stdio 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open another terminal and let me run the math server.": "让我打开另一个终端，运行数学服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you've run servers slash math.pi.": "运行 python servers/math.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's running around.": "它正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and create a new file.": "现在让我去创建一个新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me call this file link chain Client.py.": "我把这个文件命名为 langchain_client.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the reason why I'm calling it that is because we're going now to implement a link chain multi server": "我这样命名是因为我们现在要实现一个 LangChain 多服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:client.": "客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the link chain multi server client is a new client that link chain wrote for us that is able to connect": "LangChain 多服务器客户端是 LangChain 为我们编写的一个新客户端，它能够连接",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to multiple MCP servers.": "到多个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember I told you there is a 1 to 1 connection between a client and an MCP server.": "记得我告诉过你，客户端和 MCP 服务器之间是一对一的连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is still the case.": "现在情况依然如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Abstract it for us.": "它为我们抽象了这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And inside it we're going to have multiple MCP clients.": "在它内部，我们将拥有多个 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can use that to easily connect to multiple MCP servers without explicitly writing the clients": "但我们可以利用它轻松连接到多个 MCP 服务器，而无需为每个服务器显式编写客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for each one of those servers.": "每一个服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to do that, we'll start by importing from LinkedIn MCP adapters client.": "为此，我们首先从 langchain_mcp_adapters.client 导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to import the Multi-server MCP client.": "我们要导入 MultiServerMCPClient。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and import from Landgraaf pre-built the create react agent like we did before.": "让我们像之前一样，从 langgraph.prebuilt 导入 create_react_agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's import OpenAI chat OpenAI exactly like we did before.": "让我们像之前一样导入 OpenAI 的 ChatOpenAI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we want to implement from dot env.": "当然，我们要从 dotenv 导入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Env.": "load_dotenv。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we also initialize the LLM.": "我们还要初始化 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me open a new terminal.": "让我打开一个新终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's run this file for a sanity check.": "让我们运行这个文件进行完整性检查。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've run link chain client py and we can see it ran successfully.": "运行 python langchain_client.py，我们可以看到它运行成功了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's also define a async function main.": "我们再定义一个异步函数 main。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's right here print hello link chain scp.": "让我们在这里打印 hello langchain mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're also running it with the async IO.": "我们还要使用 asyncio 来运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course I need to import async IO.": "当然，我需要导入 asyncio。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the boilerplate code.": "这就是样板代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's run it at a time to check you've run link chain client UI.": "让我们运行一下检查，运行 python langchain_client.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write async with link chain multi Amqp client as client.": "所以让我们编写 `async with langchain_multi_amqp_client as client`。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to write our link chain implementation of our react agent.": "在这里，我们将编写 ReAct 代理的 LangChain 实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we need to tell the client which MCP servers does it connect to.": "但我们需要告诉客户端它要连接到哪些 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here inside we need to put all the informations of the MCP servers that we want to connect to in": "在这里面，我们需要将所有想要连接的 MCP 服务器信息放入",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this client.": "这个客户端中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open up a dictionary.": "让我打开一个字典。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And each key is going to be a new MCP server.": "每个键都将是一个新的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first one is going to be the math server which runs via Stdio.": "第一个将是数学服务器，它通过 Stdio 运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here the command is going to be Python.": "所以这里的命令将是 Python。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the argument is going to be the full path to the server.": "参数将是服务器的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me complete this full path here.": "让我在这里补全这个完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be my root directory slash servers.": "它将是我的根目录斜杠 servers。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we go.": "大功告成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way let me add black for some formatting.": "顺便说一下，让我添加 black 来进行一些格式化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me run black now.": "现在让我运行 black。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we get here a compilation error because we need to put here some Statement.": "我们在这里遇到了一个编译错误，因为我们需要在这里放一些语句。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me rerun it again.": "让我再运行一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we reformatted this code.": "现在我们重新格式化了这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see by the way, that this looks very familiar to the JSON files that we use, for example,": "顺便你可以看到，这看起来与我们使用的 JSON 文件非常相似，例如，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for the cursor MCP integrations and for the cloud desktop.": "用于 Cursor MCP 集成和 Claude Desktop 的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to add the weather server.": "现在我们想添加天气服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me add the key of weather.": "让我添加 weather 键。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However I'm not going to use the command python and everything because we're using an SSH server.": "然而，我不打算使用 python 命令之类的，因为我们使用的是 SSH 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What we are going to put here we're going to put here the URL and we're going to put here the transport": "我们要在这里放的是 URL，还要在这里放传输协议",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of SSH.": "SSH。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So inside here I have the key of URL with the URL to localhost port 8000.": "所以在这里面，我有一个 URL 键，其值为指向 localhost 8000 端口的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because I remind you this is where our SSH server is running ssh.": "因为我提醒你，这就是我们的 SSH 服务器运行的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the default when we use the MCP SDK.": "这是我们使用 MCP SDK 时的默认设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the endpoint which we're going to query.": "这是我们将要查询的端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the transport is going to be SSH.": "传输协议将是 SSH。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now when we use this client and we'll discover the tools and we'll take its tools.": "现在，当我们使用这个客户端时，我们会发现工具并获取它的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this client is going to make requests to the server if needed.": "如果需要，这个客户端将向服务器发送请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just like the previous video let's create the react agent.": "就像之前的视频一样，让我们创建 ReAct 代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be create react agents.": "也就是 `create_react_agent`。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to plug here the LM And here we're going to use this link chain client.": "我们将在这里接入 LLM，并且在这里我们将使用这个 LangChain 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this client has the Get tools method.": "这个客户端有一个 `get_tools` 方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think it's also important to show you how it works.": "我认为向你们展示它是如何工作的也很重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll do that later in the videos.": "我们稍后会在视频中这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go get back a result.": "让我们获取返回结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you need to use here a invoke.": "你需要在这里使用 `invoke`。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let's put the messages in of what is two plus two.": "在这里让我们输入消息：“2 加 2 等于多少”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So my wife just handed me the baby here.": "我妻子刚才把宝宝递给了我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we want to go and print this result.": "现在我们想去打印这个结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me run.": "让我运行一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You've run link chain client Pi.": "运行 `langchain_client.py`。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we get here the result.": "我们可以看到我们在这里得到了结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and try to ask something about what is the weather.": "现在让我们试着问一些关于天气的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me simply comment it out.": "让我简单地把它注释掉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write, get me info about Charizard, and I'm going to make it a bit harder.": "让我输入：获取喷火龙的信息，我要增加一点难度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to write a bit of a typo here.": "我在这里故意写错一个字母。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's see if it manages to call the correct resources and we can see that something interesting": "现在让我们看看它是否能成功调用正确的资源，我们可以看到一些有趣的事情",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is happening.": "正在发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's called Pokemon Number six, and we didn't have that mapping in the code.": "它调用了 6 号宝可梦，而我们的代码中并没有这个映射。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it got us the Charizard details from calling the resource, but it's hallucinated the number six": "所以它通过调用资源获取了喷火龙的详情，但它幻觉出了 6 号",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ID here.": "这个 ID。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me ask Cloud Desktop how did he manage to get the number six here?": "让我问问 Claude Desktop，它是怎么得到 6 号这个数字的？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean, how did he know that I would expect it to call the resource of Pokemon Charizard?": "我的意思是，它怎么知道我期望它调用喷火龙这个宝可梦资源？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and ask him that.": "让我去问问它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How did you know it was ID six?": "你是怎么知道它是 6 号 ID 的？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I made an educated guess based on the Pokemon numbering system.": "我根据宝可梦的编号系统做出了合理的推测。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Charmander is for Charmeleon is five and Charizard is six.": "小火龙是 4 号，火恐龙是 5 号，喷火龙是 6 号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the evolution line, this follows the standards.": "在进化链中，这符合标准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so let's choose another Pokemon.": "好了，让我们选择另一个宝可梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and choose a mewtwo.": "让我们选择超梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and write Mewtwo here.": "让我在这里输入超梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I added another typo.": "我又加了一个拼写错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see what he does here.": "看看它会怎么做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah, still, it calls Pokemon number 150.": "没错，它仍然调用了 150 号宝可梦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So looks like it had the mapping.": "看来它确实有这个映射。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write it more explicitly, get it by the name, and we get an answer that it can only get": "让我写得更明确一点，通过名称获取，我们得到的回答是它只能通过",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pokemon by id through the Pokemon ID uri format, and it doesn't support names.": "宝可梦 ID 的 URI 格式获取宝可梦，不支持名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I know what's the problem here.": "我知道问题出在哪里了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The problem is the function definition and the function arguments and the naming that I gave it before.": "问题在于函数定义、函数参数以及我之前给它的命名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you how I can fix it in the code, and it will also give you a hint of how those clients": "让我向你展示如何在代码中修复它，这也会让你了解这些客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:are working.": "是如何工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But before that, let me write.": "但在那之前，让我输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The ID can be a name, right?": "ID 可以是名称，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so let's try to manipulate a bit with some prompt engineering and we can see it called the resource": "好的，让我们尝试用一些提示词工程来进行操作，我们可以看到它调用了资源",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Pokemon Mewtwo, and we get the information about Mewtwo and this pronged hacking that I just did.": "宝可梦超梦，我们得到了关于超梦的信息，以及我刚才做的这个提示词破解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I manipulated the MCP client to call a resource in a different format, so you can see that it does": "我操纵 MCP 客户端以不同的格式调用资源，所以你可以看到这确实",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:really have some security implications here.": "存在一些安全隐患。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we should really, really be careful which resources we expose, especially if they're a user based": "我们真的应该非常小心我们暴露的资源，特别是如果它们是基于用户的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we don't want information from one user leaking to another user because they managed to prompt hack": "我们不希望一个用户的信息泄露给另一个用户，因为他们成功地对",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on our agent here.": "我们的代理进行了提示词破解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this agent here is cloud code in this case.": "在这种情况下，这里的代理是 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now to our MCP server.": "现在让我去我们的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to change the naming in this resource.": "我想更改此资源中的命名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me change the argument I'm going to call it Pokemon ID or name.": "让我更改参数，我将其命名为 Pokemon ID 或名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And also let's change the resource URI here.": "同时也让我们更改这里的资源 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me rerun everything.": "现在让我重新运行一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me rerun the server And let me find another Pokemon to test it.": "让我重新运行服务器，并找另一个宝可梦来测试它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go get Eevee.": "让我去获取伊布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And instead of this let's go and write here.": "让我们不这样做，而是去这里写。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the weather in San Francisco.": "旧金山的天气怎么样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just close it.": "让我把它关掉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we got here that the answer is hot as hell.": "我们在这里得到的答案是热得要命。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and to see.": "让我们去看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something which is really cool which we didn't see before.": "这是非常酷的一点，我们之前没见过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we can see our server logs and we can see exactly what's happening here.": "所以现在我们可以看到服务器日志，并确切地看到这里发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see all the sessions that were created by the MCP client.": "我们可以看到由 MCP 客户端创建的所有会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have the session from before.": "所以我们有之前的会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is one session and this is the session from this run.": "所以这是一个会话，而这是本次运行的会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that we had a bunch of post requests.": "我们可以看到我们有一堆 POST 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the first request was to list the tools.": "所以第一个请求是列出工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the second request was to call the tool.": "第二个请求是调用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the tool was called.": "工具被调用了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you something cooler.": "让我给你们看点更酷的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can actually go and update this server here and let's go add a print here.": "我们实际上可以去更新这里的服务器，让我们在这里添加一个 print 语句。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go add print.": "让我们添加 print。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a log from the ZK server okay.": "这是来自 ZK 服务器的日志，好吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what I want to do is to restart the server.": "我想做的是重启服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and run it again.": "让我们再次运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now we see the log here on the SE server.": "我们可以看到，现在我们在 SE 服务器上看到了日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this capability here is very convenient for us for logging, for monitoring.": "这里的这个功能对我们进行日志记录和监控非常方便。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can do a lot of interesting things with it.": "我们可以用它做很多有趣的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can even deploy to the cloud.": "我们甚至可以部署到云端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what we're going to do next.": "这就是我们接下来要做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to finish everything up let me simply format here the code a bit and let me go and create a new branch": "为了完成这一切，让我简单地格式化一下这里的代码，然后去创建一个新分支",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:where you can see all of this code here.": "在那里你可以看到这里所有的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So git check out Dash dash orphan and we'll call it project Slash se.": "所以执行 git checkout --orphan，我们将它命名为 project/se。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me now git add everything and let's go now and commit.": "现在让我 git add 所有内容，然后我们去提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's generate the um the commit message.": "让我们生成……嗯……提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me commit it and let's push it and let's go push it here.": "让我提交它，然后推送它，让我们把它推送到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the code is going to be available here in this src branch here.": "所以代码将在这个 src 分支中提供。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can simply go and you can check out the link chain client code here.": "你可以直接去这里查看 link chain 客户端代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can simply take it.": "你可以直接拿走它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's see if it's going to call the correct one.": "好的，让我们看看它是否会调用正确的那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we got here an error that we could not read the resource because we had some MCP server error.": "我们在这里遇到了一个错误，由于 MCP 服务器出错，无法读取资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and open a new instance of clock.": "那么我现在去打开一个新的 Claude 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this should fix the issue.": "这应该能解决问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to load the new MCP server.": "这样它就会加载新的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write hey get me Eevee.": "让我输入“嘿，帮我获取伊布（Eevee）”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now for some reason it's going to list now the resources.": "我们可以看到，现在出于某种原因，它正在列出资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see what it does then.": "让我们看看接下来它会做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's going to call the resource Pokemon Eevee with the information about EV.": "然后它将调用 Pokemon Eevee 资源，其中包含关于伊布的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is good.": "这很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what I expected.": "这正是我所预期的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So yeah this is the behavior of cloud code with MCP resources.": "所以，没错，这就是 Claude 配合 MCP 资源时的行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the official Microsoft Playwright MCP server.": "所以这就是官方的微软 Playwright MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this MCP server is going to give our AI agent capabilities to browse the web through our browser.": "这个 MCP 服务器将赋予我们的 AI 智能体通过浏览器浏览网页的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a very useful MCP.": "这是一个非常有用的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we've done it once and let's do it again.": "我们已经做过一次了，让我们再来一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and integrate another MCP and let's time.": "让我们去集成另一个 MCP，这次，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's do it to cursor.": "让我们在 Cursor 中进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go here to the code base.": "让我来到代码库这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to copy this URL here.": "我要复制这里的这个 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me git clone it.": "让我用 git clone 克隆它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to go to our MCP servers directory and let me clone it there.": "我要进入我们的 MCP 服务器目录，并在那里克隆它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's hit into it.": "让我们进入该目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is all the files of the MCP server.": "这些就是 MCP 服务器的所有文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let's go to cursor and let's go integrate it.": "好了，让我们去 Cursor 并集成它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to do this via a local MCP server.": "我们将通过本地 MCP 服务器来完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be local to our cursor project here.": "所以它将是针对我们这里的 Cursor 项目本地化的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the project that we implemented the MCP client.": "这就是我们实现 MCP 客户端的项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not going to apply to other cursor instances that we'll use.": "它不会应用到我们将使用的其他 Cursor 实例中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll do that by creating a new directory and we'll call it dot cursor.": "我们将通过创建一个名为 .cursor 的新目录来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And inside it we'll create an MCP dot JSON file.": "在它内部，我们将创建一个 mcp.json 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to hold the JSON configuration for all the MCP servers that are going to run.": "它将保存所有将要运行的 MCP 服务器的 JSON 配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And with the cursor instance over project.": "以及该项目对应的 Cursor 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the readme file of the playwright MCP and let's copy here this example config.": "让我们回到 Playwright MCP 的 readme 文件，并复制这里的这个示例配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and paste it, and we can see that a new MCP was detected by cursor.": "让我把它粘贴进去，我们可以看到 Cursor 检测到了一个新的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and click enable to enable it.": "让我们点击 enable（启用）来启用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And our MCP is ready to go.": "我们的 MCP 已经准备就绪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and let's test it.": "让我们去测试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and choose Agent Mode.": "让我们去选择 Agent 模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and run a query.": "现在让我们运行一个查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want you to visit cursor dot directory.": "我想让你访问 cursor.directory。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want you to give me five MCP servers examples.": "我想让你给我五个 MCP 服务器的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are prompted to run the tool browser navigate with the input of URL to be cursor dot directory.": "系统提示我们运行 browser_navigate 工具，输入的 URL 为 cursor.directory。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run the tool.": "让我运行这个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now a new instance of chrome was fired up.": "现在启动了一个新的 Chrome 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It visited the cursor directory.": "它访问了 cursor.directory。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and see the answer.": "让我们来看看答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see from the first page we can see that we have a bunch of MCP servers.": "我们可以从第一页看到，我们有一堆 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I often get asked where do I find cool MCP servers I can use and I can use in cursor or in Cloud": "我经常被问到在哪里可以找到好用的 MCP 服务器，以便在 Cursor 或 Claude",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Desktop.": "Desktop 中使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the answer for that is that there are tons of MCP server directories where you can find lots of": "答案是，有很多 MCP 服务器目录，你可以在其中找到大量的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers for almost everything you can think of, from MCP servers to order food to browser automations": "MCP 服务器，几乎涵盖了你能想到的所有功能，从订餐的 MCP 服务器到浏览器自动化",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to WhatsApp messages.": "再到 WhatsApp 消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can find basically an MCP for everything.": "所以你基本上可以为任何事情找到对应的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video, I'm going to show you a couple of options where you can browse those MSPs.": "在这段视频中，我将向你展示几个可以浏览这些 MCP 的选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go find some awesome MCP servers.": "让我们去找一些很棒的 MCP 服务器吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll do that by searching that on Google.": "我们将通过在 Google 上搜索来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And luckily for us, there is a very nice repo here which has tons of ready to go MCP servers, which": "幸运的是，这里有一个非常棒的仓库，里面有大量现成的 MCP 服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we can clone and we can integrate into our AI agents.": "我们可以克隆并集成到我们的 AI 智能体中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this repo is getting updated very, very frequently.": "这个仓库更新得非常、非常频繁。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see last update was yesterday since I recorded the course.": "你可以看到，在我录制课程时，最后一次更新是在昨天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it has over 35 K stars.": "它拥有超过 3.5 万个星标（stars）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a lot for a directory of MCP servers.": "对于一个 MCP 服务器目录来说，这已经很多了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see we have 62 open pull requests.": "我们可以看到有 62 个待处理的拉取请求（pull requests）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very well maintained.": "所以它的维护非常好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I really like this resource of a MCP directory.": "我非常喜欢这个 MCP 目录资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see the legend here.": "我们可以看到这里的图例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So each MCP server is going to have one of those icons here.": "每个 MCP 服务器都会有这里显示的图标之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be either an official implementation from an official vendor like Cloudflare like": "它要么是来自官方供应商（如 Cloudflare 或",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:notion.": "Notion）的官方实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to list the programming language which it was implemented.": "它还会列出实现它所使用的编程语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And usually it's going to be either Python or TypeScript, although there are some go and rust ones.": "通常是 Python 或 TypeScript，尽管也有一些是用 Go 和 Rust 编写的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to see the scope.": "然后我们将看到作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So whether it's an MCP server that is running locally on our machine or it's a MCP server which is making": "即它是一个在本地机器上运行的 MCP 服务器，还是一个正在向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:requests into a remote API.": "远程 API 发送请求的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is an SMTP server like we saw earlier in the course in the last icon is going to note whether": "这是一个 SMTP 服务器，就像我们之前在课程中看到的那样，最后一个图标将注明",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it's compatible with Mac OS or Windows or Linux operating systems.": "它是否兼容 macOS、Windows 或 Linux 操作系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I like the fact that they divided into categories.": "我很喜欢他们将其划分为不同类别这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it really feels like you're going shopping.": "所以这真的感觉像是在购物。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's say we want for databases, we can find many MCP servers to connect to databases, whether": "假设我们需要数据库方面的，我们可以找到许多连接数据库的 MCP 服务器，无论是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it's new for J or to connect to a MySQL or PostgreSQL, or even a cloud hosted a cloud database like": "Neo4j，还是连接到 MySQL 或 PostgreSQL，甚至是像",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Supabase.": "Supabase 这样的云托管数据库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We also have search and data extraction to give our agents the capability of searching online and getting": "我们还有搜索和数据提取功能，让我们的智能体具备在线搜索并获取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:real time information.": "实时信息的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have browser automation like playwright.": "我们还有像 Playwright 这样的浏览器自动化工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our LLM is going to be able to browse the web from our browser.": "这样我们的大语言模型（LLM）就能通过我们的浏览器浏览网页了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So lots of cool things here.": "这里有很多酷炫的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's have a look.": "让我们来看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me randomly go to the database section.": "让我随机进入数据库部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and click that.": "让我点击一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see a bunch of MCP servers.": "在这里我们可以看到一堆 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see we have the Supabase MCP server.": "我们可以看到这里有 Supabase MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice it doesn't have the badge that notes that it's an official MCP server from Supabase.": "所以请注意，它没有标明它是来自 Supabase 官方 MCP 服务器的徽章。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just be aware of this code here.": "所以请留意这里的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see for example an official Chrome adb mcp server.": "例如，我们可以看到一个官方的 Chrome adb MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to access the chroma vector store for retrieving with similarity search, we have here a MySQL MCP": "因此，为了访问 Chroma 向量存储以进行相似性搜索检索，我们这里有一个 MySQL MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to connect locally to a MySQL instance.": "所以它将本地连接到一个 MySQL 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have, for example, an MySQL server for Confluent Kafka.": "例如，我们有一个用于 Confluent Kafka 的 MySQL 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see it's implemented in Python and it's cloud based.": "你可以看到它是用 Python 实现的，并且是基于云的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's an SMTP server which is going to make requests to the Confluent Kafka API.": "所以它是一个 SMTP 服务器，将向 Confluent Kafka API 发送请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay let's go and let's check another section.": "好了，让我们去查看另一个部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and check communication.": "让我们去查看通信部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a bunch of MCP servers for communication services like emails, Gmail, Twilio, WhatsApp,": "这里有一堆用于通信服务的 MCP 服务器，比如电子邮件、Gmail、Twilio、WhatsApp，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:telegram, discord, and lots of cool messaging and communication platforms.": "Telegram、Discord 以及许多很酷的消息和通信平台。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think you get the point.": "我想你明白我的意思了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the idea of this GitHub repository.": "以及这个 GitHub 仓库的初衷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you the last thing of the command line MCP servers.": "让我向你展示命令行 MCP 服务器的最后一项内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here, interestingly enough, we have MCP servers to help us run commands from our terminal.": "在这里，有趣的是，我们有 MCP 服务器来帮助我们从终端运行命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is for Iterm.": "所以这是针对 iTerm 的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here this run command, which is very similar to what we did in the course.": "我们这里有这个运行命令，它与我们在课程中所做的非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But interestingly enough this is implemented in TypeScript.": "但有趣的是，这是用 TypeScript 实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you get the point here.": "所以你明白这里的重点了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, if you're not a GitHub fan, you can check out their SAS version.": "顺便说一句，如果你不是 GitHub 的粉丝，你可以查看他们的 SaaS 版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see this web based directory here.": "所以你可以在这里看到这个基于 Web 的目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you simply click that, then you'll go to the web page that has all of the integrations that we see": "如果你只需点击它，你就会进入包含我们现在看到的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right now.": "所有集成的网页。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's going to have a very nice UI.": "但它会有一个非常漂亮的 UI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can search here.": "所以你可以在这里搜索。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can look by the categories like we did from before, simply a different view.": "你可以像我们之前那样按类别查看，只是视图不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me for example, look for notion here.": "让我在这里搜索 Notion 为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write in the search notion and we can see some notion MCP servers.": "让我输入搜索 Notion，我们可以看到一些 Notion MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and search for example for playwright.": "让我去搜索 Playwright 为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a browser automation.": "所以这是一个浏览器自动化工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to help us browse the web.": "所以它将帮助我们浏览网页。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to help the the agent browse the web.": "所以它将帮助智能体浏览网页。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a bunch of playwright examples here.": "这里有一堆 Playwright 的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Lots of MCP servers.": "很多 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But what I want to see and what I want to check out is the official Microsoft MCP server.": "但我想看、想检查的是微软官方的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I can trust this MCP server.": "所以我可以信任这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Microsoft implemented it.": "因为是微软实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go here.": "让我点进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I go to the right here I can see the GitHub repository.": "如果我看向右边，我可以看到 GitHub 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start with a demo and what we're going to end up and what is going to be the artifact.": "那么让我们从演示开始，看看我们最终会得到什么，以及产出物会是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me fire up cloud.": "让我启动云端环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After we configured all of the MCP servers and everything is working and configured.": "在我们配置完所有的 MCP 服务器，并且一切都已就绪并正常运行之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right when we loaded the application, something very interesting is happening.": "就在我们加载应用程序时，发生了一些非常有趣的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I redirected to this authorization screen.": "我被重定向到了这个授权页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the overflow we're about to implement.": "这就是我们即将实现的 OAuth 流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here the user is being asked to grant permission to the MCP CLI proxy to access the protected todo": "在这里，用户被要求授予 MCP CLI 代理访问受保护的待办事项",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:API on their behalf.": "API 的权限，以代表他们进行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this screen lists the requested scope like OpenID email read to dos, which define what the proxy": "所以这个屏幕列出了请求的作用域（scope），比如 OpenID、email、读取待办事项，这些定义了代理",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is allowed to do once it's authorized.": "在获得授权后允许执行的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if the user will click allow, access of zero is going to issue a token that the MCP server can": "如果用户点击允许，Auth0 将会颁发一个令牌，供 MCP 服务器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:use to make secure authenticated requests to the API.": "用于向 API 发起安全的身份验证请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a standard OAuth 2.0 flow, and is critical for enabling secure and delegated access without": "这是一个标准的 OAuth 2.0 流程，对于在不共享任何凭据的情况下实现安全和委派访问至关重要，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:sharing any credentials, and will build the entire flow in just a bit.": "我们稍后将构建整个流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this screen gives you a quick preview of what we're aiming for.": "但这个屏幕让你可以快速预览我们的目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once we'll click allow.": "一旦我们点击允许。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Access will be authorized for this application, and the client is going to have the access token,": "该应用程序将获得访问授权，客户端将拥有访问令牌，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is going to use all the time.": "它将一直使用这个令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have the who am I tool that the remote MCP server exposes, which is deployed on Cloudflare.": "我们还有远程 MCP 服务器公开的 who am I 工具，该服务器部署在 Cloudflare 上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this tool is going to take the JWT access token and it's going to decode it.": "这个工具将获取 JWT 访问令牌并对其进行解码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that access token is going to have all the information about the authenticated user, which is me.": "该访问令牌将包含有关已验证用户（也就是我）的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see what happens when we invoke this tool.": "那么让我们来看看调用这个工具时会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What we get back here is the decoded JWT token that our authorization server, which is auth0, returned": "我们在这里得到的是解码后的 JWT 令牌，这是我们的授权服务器（即 Auth0）返回的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:after we clicked allow access in the authorization flow.": "是在我们在授权流程中点击允许访问之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because we are authorized, we can go and access our to do list.": "因为我们已经获得了授权，所以我们可以去访问我们的待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'm going to ask for my to do's.": "如果我要请求我的待办事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then let's go and allow this tool to run.": "那么让我们允许这个工具运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we're making a request to the secured API with our access token.": "现在我们正使用访问令牌向受保护的 API 发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right here we get the list of our to do.": "在这里我们就得到了我们的待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video, we're going to cover all the boilerplate preparations we need to make before implementing": "在这段视频中，我们将介绍在开始实现之前",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:everything.": "所有内容需要做的样板准备工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll discuss the technologies, the packages that we need.": "我们将讨论所需的各种技术和包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll be setting up everything in this video.": "我们将在这段视频中完成所有设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to have an Auth0 account, which we can create for free.": "我们需要一个 Auth0 账号，可以免费创建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And Auth0 is going to be our authentication and authorization server.": "Auth0 将作为我们的身份验证和授权服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's a third party which is going to help us authenticate and authorize our users.": "它是一个第三方服务，将帮助我们对用户进行身份验证和授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to generate the signed JWT token that the client is going to send every time it tries": "它将生成签名的 JWT 令牌，客户端在每次尝试",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to make a tool call.": "进行工具调用时都会发送该令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video and in general in this section, I'm going to cover the gist of the authentication": "在这段视频以及本章节中，我将介绍身份验证流程",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:flow OAuth 2.0 or OpenID connect.": "OAuth 2.0 或 OpenID Connect 的核心要点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you're not familiar with this protocol, don't worry about it.": "如果你不熟悉这些协议，也不用担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't really need to understand the ins and outs of this, and I can make an entire course only on": "我们不需要深入了解其中的所有细节，我甚至可以专门为此",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's important to note that Auth0 is going to do all the heavy lifting of the authentication and authorization.": "制作一门完整的课程。重要的是，Auth0 将承担身份验证和授权的所有繁重工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once our MCP server is going to do, it's going to forward those requests, those login requests and": "我们的 MCP 服务器要做的就是转发这些请求，包括登录请求和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:authentication requests.": "身份验证请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to forward it into Auth0.": "它会将这些请求转发给 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here I'm in Auth0.": "现在我进入了 Auth0 页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll link the URL in the course's resources.": "我会在课程资源中提供该链接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and log in.": "让我们登录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll log in with my Google account.": "我将使用我的 Google 账号登录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm not showing you the signup.": "我就不演示注册过程了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very simple with a very simple verification.": "注册非常简单，只需简单的验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go.": "让我们开始吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Click to continue.": "点击继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we are authenticated.": "现在我们已经通过了身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice we have a free trial that nothing is going to cost us here.": "请注意，我们有一个免费试用期，这里不会产生任何费用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need also a Cloudflare account.": "我们还需要一个 Cloudflare 账号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's where we're going to deploy the protected todo API.": "我们将在那里部署受保护的待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the remote MCP server which is going to communicate with Auth0 And we protected todo API.": "以及将与 Auth0 和受保护的待办事项 API 通信的远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here I'm in Cloudflare I'm going to log in.": "现在我进入了 Cloudflare，准备登录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is here the main account page.": "这是主账户页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So lastly we need a code editor.": "最后，我们需要一个代码编辑器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to be using cursor.": "我们将使用 Cursor。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can use any code editor that you want.": "你可以使用任何你喜欢的代码编辑器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly we need to make sure that we have node that we had git.": "最后，我们需要确保安装了 Node 和 Git。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to install the Wrangler CLI which is the command line interface for building Cloudflare workers,": "并且安装 Wrangler CLI，它是用于构建 Cloudflare Workers 的命令行界面，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which are going to be our serverless executables which are going to execute our MCP servers.": "它们将作为运行我们 MCP 服务器的无服务器可执行程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ID let's open terminal and let's go and make sure that we have everything.": "好的，让我们打开终端，确保一切准备就绪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first I'm going to start by installing the Wrangler command line interface.": "首先，我将开始安装 Wrangler 命令行界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to give it the flag of save dev.": "我会给它加上 save-dev 标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Which means it's going to be a development dependency, which is a package that our project needs during": "这意味着它将是一个开发依赖项，即我们的项目在开发过程中需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:development but not in production.": "但在生产环境中不需要的包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me type in my password.": "让我输入密码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this section, we're going to build something which is powerful and practical at the same time.": "在本节中，我们将构建一个既强大又实用的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to build a secure remote MCP server, which runs in the cloud, that connects our AI application,": "我们将构建一个运行在云端的安全远程 MCP 服务器，它将连接我们的 AI 应用程序，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cloud Desktop, to a protected to do API.": "即 Cloud Desktop，连接到一个受保护的待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this API is also deployed in the cloud.": "所以这个 API 也是部署在云端的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll walk through how to use Auth0 for authentication.": "我们将演示如何使用 Auth0 进行身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll use Cloudflare workers for our backend.": "我们将使用 Cloudflare Workers 作为我们的后端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll have a remote MCP architecture to connect everything securely.": "我们将采用远程 MCP 架构来安全地连接一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this will include how to use MCP remote to bridge the gap between local MCP clients and remote MCP": "这将包括如何使用 MCP remote 来弥合本地 MCP 客户端与远程 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:servers.": "服务器之间的差距。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the entire section is based on this excellent Auth0 blog post, which I highly recommend reviewing.": "整个章节都是基于这篇优秀的 Auth0 博客文章，我强烈建议大家阅读。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And a fun fact I actually contributed feedback to this post calling out that they did not mention MCP": "顺便提一个趣事，我实际上为这篇文章提供了反馈，指出他们没有提到 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remote, which cost me a couple of hours debugging, but thankfully the authors acknowledged it and": "remote，这让我花了几个小时进行调试，但幸好作者们承认了这一点，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:are working to update it.": "正在努力更新它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so before jumping into the walkthrough, I highly recommend that you watch this entire section": "好了，在开始实操演示之前，我强烈建议你先看完整节内容，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:first before doing anything, and only then to go through the walkthrough.": "然后再按照演示步骤进行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because I intentionally kept in a few moments where things didn't go exactly as planned.": "这是因为我特意保留了一些事情没有完全按计划进行的时刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Along with how I debugged and fixed it.": "以及我是如何调试并修复它们的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these real world moments can be super valuable, especially if you run into small issues.": "所以这些真实的时刻非常有价值，特别是当你遇到小问题时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because let's face it, clean demos are nice, but real world context is where we really learn.": "因为让我们面对现实吧，完美的演示固然很好，但真实的场景才是我们真正学习的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so let's talk about what we're building and all the moving parts and all the components.": "好了，现在让我们来谈谈我们要构建的内容，以及所有的活动部件和组件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have cloud desktop.": "我们有 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be our AI application which is going to be our MVP host.": "这将是我们的 AI 应用程序，它将作为我们的 MCP 宿主。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now cloud Desktop currently only supports local connections.": "目前 Cloud Desktop 仅支持本地连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can't really make requests to something which is outside our local network.": "所以它无法真正向本地网络之外的东西发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to do and to mitigate over that, we'll be using MCP remote which will connect it to Cloud Desktop.": "为了解决这个问题，我们将使用 MCP remote 将其连接到 Cloud Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be a lightweight proxy that is going to make the HTTP request to our remote MCP": "这将是一个轻量级代理，它将向我们的远程 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:servers, which is in the cloud, and it's going to include authentication, authorization and the whole": "服务器（位于云端）发起 HTTP 请求，它将包含身份验证、授权以及整套",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:shebang.": "流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to cover it in depth later in these videos.": "我们将在后面的视频中深入探讨这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this proxy is going to make HTTP request to an NCP server will create and deploy it to Cloudflare.": "所以这个代理将向我们将要创建并部署到 Cloudflare 的 MCP 服务器发起 HTTP 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that NCP is going to talk to Auth0 for authentication and authorization and manage all the tokens": "那个 MCP 将与 Auth0 进行通信以进行身份验证和授权，并管理所有令牌，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and making sure all our requests are secure.": "并确保我们所有的请求都是安全的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to make those requests to a protected todos API, which is hosted on Cloudflare as well.": "它将向同样托管在 Cloudflare 上的受保护的待办事项 API 发起这些请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be protected with Auth0 based authentication.": "它将受到基于 Auth0 的身份验证保护。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So both the todos API and the Auth0 remote MCP servers, which will be deployed on Cloudflare, are": "因此，待办事项 API 和将部署在 Cloudflare 上的 Auth0 远程 MCP 服务器，都",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to run on Cloudflare workers, which is Cloudflare serverless solution.": "将运行在 Cloudflare Workers 上，这是 Cloudflare 的无服务器解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this means that in order to deploy our application, all we need to do is supply our code.": "这意味着为了部署我们的应用程序，我们只需要提供代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't need to handle any infrastructure, so we don't need to handle availability, scalability,": "我们不需要处理任何基础设施，因此我们不需要处理可用性、可扩展性、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:durability, all of those ilities Cloudflare is going to handle for us.": "耐用性，所有这些特性都将由 Cloudflare 为我们处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to give us an SLA.": "它将为我们提供 SLA。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what we're going to be using.": "所以这就是我们将要使用的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also important to note that everything has a free tier so no prepayments are required.": "同样值得注意的是，一切都有免费层级，因此不需要预付款。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there, Ethan here.": "大家好，我是 Ethan。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the next couple of videos are about the to dos API.": "接下来的几个视频是关于待办事项 (to dos) API 的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to review the code of this API.": "我们将审查这个 API 的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to run it locally.": "我们将在本地运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're then going to configure it with Auth0.": "然后我们将使用 Auth0 对其进行配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to test it again.": "接着我们将再次进行测试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to deploy it to Cloudflare workers where we can access it from anywhere in the": "然后我们将把它部署到 Cloudflare Workers，这样我们就可以在世界任何地方",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:world.": "访问它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the code.": "那么让我们来看看代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start by cloning this monorepo with all the demos.": "让我们先从克隆这个包含所有演示的 monorepo（单体仓库）开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy the git clone command.": "我将复制 git clone 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I'm going to clone it in my GitHub projects directory.": "但我会把它克隆到我的 GitHub 项目目录中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's wait for it to clone.": "让我们等待克隆完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to go to the MCP remote Auth0.": "我们要进入 MCP remote Auth0 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what we're going to build.": "这就是我们要构建的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it has the todos API directory which has all the implementation for our to do list API.": "它有一个 todos API 目录，其中包含了我们待办事项列表 API 的所有实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go there.": "让我们进入那个目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm copying this command and let me paste it in terminal.": "我正在复制这个命令，让我把它粘贴到终端里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the path to the directory in my machine.": "这是我机器上该目录的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you the files here.": "让我给你们看看这里的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's a Node.js project with a package.json.": "这是一个带有 package.json 的 Node.js 项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and install now all the dependencies that we need.": "现在让我们去安装所有需要的依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to write here npm install.": "我将在这里输入 npm install。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me fast forward this installation here.": "让我快进一下这里的安装过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we successfully installed all the packages that we need to run the web server.": "我们已经成功安装了运行 Web 服务器所需的所有包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now open it with cursor to examine the files and to see the implementations of this API web server.": "现在让我们用 Cursor 打开它，检查文件并查看这个 API Web 服务器的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see here we have an index.js.": "我们可以看到这里有一个 index.js。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the implementation of our web server.": "这将是我们 Web 服务器的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to use the Hono framework.": "它将使用 Hono 框架。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not really a NodeJS fan but this is a popular framework for building web servers.": "我并不是真正的 Node.js 粉丝，但这是一个用于构建 Web 服务器的流行框架。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see we're importing faker.": "我们可以看到我们正在导入 faker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And faker is a package to generate some stub data.": "faker 是一个用于生成桩数据 (stub data) 的包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for us to return something in the API because we don't really have user data.": "这样我们就可以在 API 中返回一些内容，因为我们还没有真正的用户数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to make some random data for our to do list that we're going to return from the API.": "所以这将为我们的待办事项列表生成一些随机数据，并从 API 返回。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we're importing JWT and require scope.": "我们可以看到我们正在导入 JWT 和 require scope。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are two functions that are implemented in middleware JWT.": "这两个函数是在 middleware JWT 中实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the middleware for our web server which is going to examine each request.": "这是我们 Web 服务器的中间件，它将检查每个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to check and validate if it has a valid JWT token.": "它将检查并验证其是否具有有效的 JWT 令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for an authenticated user and only then we're going to let that request pass through.": "只有针对已通过身份验证的用户，我们才会让该请求通过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we don't have a valid token for an authenticated user, we're going to return an error that the user": "如果我们没有已验证用户的有效令牌，我们将返回一个错误，提示用户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is either not authenticated or doesn't have the correct permissions to review the to do list.": "要么未通过身份验证，要么没有查看待办事项列表的正确权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have some interfaces for JWT header parameters which say how the JWT are created and signed.": "这里我们有一些 JWT 头部参数的接口，它们说明了 JWT 是如何创建和签名的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have JWT payload, which is simply an interface for a base64 string.": "我们还有 JWT 负载 (payload)，它只是一个 base64 字符串的接口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to initialize a whole app with that information.": "我们将使用这些信息初始化整个应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's talk about the endpoints.": "那么我们来谈谈端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have a health check endpoint which Cloudflare is going to query.": "这里我们有一个健康检查端点，Cloudflare 将对其进行查询。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to make sure that our application is up and running and everything is okay.": "以确保我们的应用程序正在运行且一切正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we're going to apply the middleware for checking the JWT tokens and validating the authentication": "在这里，我们将应用中间件来检查 JWT 令牌并验证身份验证",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:authorization of the request.": "以及请求的授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the wild card here, the asterisks, is a regular expression that is going to apply to all the routes.": "所以这里的通配符（星号）是一个将应用于所有路由的正则表达式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this means that we're going to apply the middleware that validates the JWT token for the incoming": "这意味着我们将应用中间件，为传入的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:requests.": "请求验证 JWT 令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when a token is going to be valid, we're going to extract and store the tokens payload and header": "当令牌有效时，我们将提取并存储令牌的有效负载和头部",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the context variables.": "到上下文变量中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have the user information endpoint slash API slash me.": "这里我们有用户信息端点 /api/me。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to extract the JWT payload from the context of the request which will contain the user": "它将从请求的上下文中提取 JWT 有效负载，其中将包含用户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:claims and return it as a JSON response.": "声明，并将其作为 JSON 响应返回。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course this requires a JWT, which is valid because it is protected by the middleware that we": "当然，这需要一个有效的 JWT，因为它受到我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:defined above.": "上面定义的中间件的保护。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's wait for it to install.": "让我们等待它安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we installed the Wrangler CLI.": "于是我们安装了 Wrangler CLI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now make sure that we have git and that we have node.": "现在让我们确保我们已经安装了 git 和 node。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write git dash dash help.": "让我们输入 git --help。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you know what.": "你知道吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go right.": "让我们直接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Git dash dash version to see which version I'm using.": "输入 git --version 来查看我正在使用的版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's do the same for node.": "让我们对 node 也执行同样的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write node dash dash version.": "让我们输入 node --version。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we want to clone the Cloudfare AI repository which has tons of demos in it.": "现在我们要克隆 Cloudflare AI 仓库，里面有很多演示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the repository which is going to hold the code for our to do list API, and the code for": "这个仓库将包含我们的待办事项列表 API 的代码，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our MVP server, which is going to do all the authentication with OAuth zero.": "我们的 MCP 服务器的代码，它将使用 Auth0 处理所有身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's what's going to communicate with that protected to do list API.": "这就是将与那个受保护的待办事项列表 API 进行通信的部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the repository that we're going to clone.": "所以这就是我们要克隆的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's public.": "它是公开的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's open source.": "它是开源的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to the demos directory.": "让我们进入 demos 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have lots of demos regarding MCP.": "这里有很多关于 MCP 的演示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, it looks like Cloudflare and Okta are very bullish on MCP and they contribute a lot": "顺便说一句，看起来 Cloudflare 和 Okta 非常看好 MCP，并且贡献了很多",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to the ecosystem.": "给这个生态系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think they're doing a very good job with the contribution to open source.": "我认为他们在开源贡献方面做得非常好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So good for them.": "对他们来说很棒。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go now to the code that we need.": "现在让我们去看我们需要用的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's in the remote MCP auth zero directory.": "它在 remote-mcp-auth0 目录中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go there.": "让我们去那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have two main implementations.": "这里有两个主要的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first one is going to be for the to do API which is protected.": "第一个是受保护的待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means we can only access it if we have a JWT token of an authenticated user with the right claim": "这意味着我们只有在拥有经过身份验证且具有正确权限声明的用户 JWT 令牌时",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to read the to do list.": "才能访问并读取待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the first directory, and the other directory is for the MCP server, which is also going to": "这是第一个目录，另一个目录是 MCP 服务器，它也将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:run in Cloudflare worker.": "在 Cloudflare Worker 中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And something very interesting is going to happen.": "一些非常有趣的事情即将发生。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm going to speak some terminology of OAuth 2.0.": "现在我要讲一些 OAuth 2.0 的术语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP server is going to act as OAuth server to our MCP client.": "因此，MCP 服务器将作为我们 MCP 客户端的 OAuth 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means that the MCP server will behave like an OAuth 2.0 authorization server.": "这意味着 MCP 服务器的行为将类似于 OAuth 2.0 授权服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it will receive the request from the MCP client, like the client running in Cloud desktop or MCP": "因此，它将接收来自 MCP 客户端（例如在 Claude Desktop 或 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remote, which is going to forward the request, and it is going to issue the access and refresh token": "Remote 中运行的客户端）的请求，它将转发该请求，并准备发放访问令牌和刷新令牌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to those clients after a successful authentication.": "在身份验证成功后向这些客户端发放。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So basically, this MCP server is the thing that the MCP clients talk to login for tokens.": "所以基本上，这个 MCP 服务器就是 MCP 客户端为了获取令牌而进行登录交互的对象。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this MCP server is also going to act as an OpenID connect client to our Auth0 tenant.": "但这个 MCP 服务器也将作为我们 Auth0 租户的 OpenID Connect 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means that the MCP server itself is not doing the actual user authentication.": "这意味着 MCP 服务器本身并不执行实际的用户身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Instead it delegates that responsibility to Auth0.": "相反，它将该责任委托给 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case, our MCP server is an OpenID connect client of Auth0.": "在这种情况下，我们的 MCP 服务器是 Auth0 的一个 OpenID Connect 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when someone logs in, the MCP server redirects them to Auth0 and will get back an ID token and access": "因此，当有人登录时，MCP 服务器会将他们重定向到 Auth0，并获取返回的 ID 令牌和访问令牌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's go to the middleware, to the JWT TypeScript file and let me go over it briefly.": "好了，让我们来看看中间件，即 JWT TypeScript 文件，我来简要介绍一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't want to go too deep into middlewares and authentication flows etc., because I really want to": "我不想太深入地探讨中间件和身份验证流程等，因为我真的很想",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:focus on MCC and how everything is working together.": "专注于 MCC 以及一切是如何协同工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I am assuming some knowledge here.": "所以我假设这里已经具备了一些基础知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this file here has the middleware implementation.": "这个文件包含了中间件的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to handle the authentication and authorization using JSON web tokens with the Auth0 integration.": "它将通过 Auth0 集成，使用 JSON Web Token 来处理身份验证和授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to use Auth0 we will need two environment variables.": "为了使用 Auth0，我们需要两个环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first one is going to be the Auth0 domain, which is going to be our Auth0 tenant domain.": "第一个是 Auth0 域名，也就是我们的 Auth0 租户域名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the middleware is going to use this domain both to know where to find the keys, to verify the token": "中间件将使用此域名来查找密钥、验证令牌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:signature, and to ensure that the tokens were legitimately issued by the specific auth0 tenant.": "签名，并确保令牌是由特定的 Auth0 租户合法签发的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other environment we will need is the Auth0 audience, which is going to be the API identifier": "我们需要的另一个环境变量是 Auth0 受众 (audience)，它是 API 标识符",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in our Auth0 account.": "在我们的 Auth0 账户中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this claim is going to specify which application or API the token is intended for.": "因此，这个声明将指定该令牌是为哪个应用程序或 API 准备的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's also important because it prevents token reuse across different services which is known as": "这也很重要，因为它可以防止令牌在不同服务之间被重复使用，这被称为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:token confusion attacks.": "令牌混淆攻击。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we're not going to go into that.": "但我们不打算深入讨论那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the two environment variables we need for our media well to work.": "以上就是我们的中间件正常工作所需的两个环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the main logic is implemented in the function of JWT and in the function of require scope.": "主要逻辑实现在 JWT 函数和 require scope 函数中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to verify authentication and authorization of the user's request.": "这将验证用户请求的身份验证和授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm not going to go too deep here.": "所以我在这里不会讲得太深。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you can check the course's resources in case you want to learn on authentication Middlewares.": "但如果你想学习身份验证中间件，可以查看课程资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open terminal here and let me go and run npm run dev in order to run this web server locally.": "让我在这里打开终端，运行 npm run dev 以在本地运行此 Web 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see here that it ran the Wrangler dev command.": "我们可以看到它运行了 Wrangler dev 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what's running now our our application.": "这就是现在运行我们应用程序的命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that we have now something running in the port of 8789.": "我们可以看到现在有东西在 8789 端口运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom.": "然后，砰。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Internal server error.": "内部服务器错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and check the logs.": "让我们去检查一下日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I go here to the top we can see JWT auth middleware requires options Auth0 domain.": "如果我翻到顶部，可以看到 JWT 身份验证中间件需要 Auth0 域名选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is because we didn't configure our environment variables with the auth0 domain and with the": "这是因为我们没有配置包含 Auth0 域名和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Auth0 claims.": "Auth0 声明的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the blog.": "那么让我们去看看博客。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because in the blogs they actually tell us to do it before we run.": "因为在博客中，他们实际上告诉我们在运行之前要这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just go to the blog here and right here we can see that we need to configure the todos API": "让我打开博客，在这里我们可以看到我们需要配置 todos API",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with us.": "使用 Auth",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Zero.": "0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:token and then continues the flow with the client.": "令牌，然后继续与客户端的流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP client.": "MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our MCP server is actually a middle layer which receives logging requests from the MCP client, then": "所以我们的 MCP 服务器实际上是一个中间层，它接收来自 MCP 客户端的登录请求，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:forwards them to Auth0.": "将它们转发给 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it handles the OAuth flow for our MCP clients based on OAuth zero responses.": "然后它根据 Auth0 的响应为我们的 MCP 客户端处理 OAuth 流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I really don't want to go too deep here into the flow of authorization.": "我真的不想在这里深入探讨授权流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's give here an analogy.": "但让我们在这里打个比方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's think about this MCP server as a smart proxy.": "所以，让我们把这个 MCP 服务器看作是一个智能代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP clients think this server is a login and token provider, but under the hood it's using Auth0": "MCP 客户端认为这个服务器是一个登录和令牌提供者，但在底层它使用的是 Auth0",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to do the actual user authentication.": "来进行实际的用户身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that was enough talking.": "理论讲解就到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's it for this video.": "本视频到此结束。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next video we'll start running our to dos API locally.": "在下一个视频中，我们将开始在本地运行我们的待办事项 (to-dos) API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll then deploy it and we'll start doing some hands on work.": "然后我们将部署它，并开始进行一些实际操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we are going to deploy our to do list API to Cloudflare workers, which is Cloudflare": "在这段视频中，我们将把我们的待办事项列表 API 部署到 Cloudflare Workers，它是 Cloudflare 的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:serverless service.": "无服务器服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to use the Wrangler CLI in order to do that.": "所以我们将使用 Wrangler CLI 来完成这项工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're also going to configure the Auth0 integration with our deployed application in Cloudflare.": "我们还将配置 Auth0 与我们在 Cloudflare 中部署的应用程序的集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm back in the blog and let's see what do we need to do in order to deploy our application to Cloudflare.": "现在我回到了博客，让我们看看部署应用程序到 Cloudflare 需要做些什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So remember the environment variables we had stored in our dev dot vars file.": "还记得我们存储在 dev.vars 文件中的环境变量吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they had the value of the auth0 domain and the Auth0 audience.": "它们包含了 Auth0 域名和 Auth0 受众的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to let Cloudflare know those values as well.": "所以我们也需要让 Cloudflare 知道这些值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our deployed application can access those values as well.": "这样我们部署的应用程序也能访问这些值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for that we want to use the secret command to put that secret there.": "为此，我们要使用 secret 命令将该机密信息放在那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it will use the Cloudflare Secrets Manager service.": "它将使用 Cloudflare 机密管理器服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the CLI and let's go and do that.": "那么让我们前往 CLI 并开始操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy the command wrangler secret put, and then the name of the secret that we want": "我将复制命令 wrangler secret put，然后是我们要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to store in the secret manager.": "存储在机密管理器中的机密名称。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be auth0 domain in this case.": "在这种情况下，它将是 auth0 domain。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and run it.": "让我去运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm getting an error that the Wrangler command cannot be found.": "我收到了一个错误，提示找不到 Wrangler 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is probably because I'm using now a new terminal instance.": "这可能是因为我正在使用一个新的终端实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I didn't install the Wrangler globally in my system.": "而且我没有在系统中全局安装 Wrangler。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me fix that.": "让我修复一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I can either install it globally or I can run it with Npx.": "我既可以全局安装它，也可以使用 npx 运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me run this command with Npx and try to do it again.": "让我用 npx 运行这个命令并再次尝试。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm prompted to put the secret value.": "现在系统提示我输入机密值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me get it from the dev dot vars.": "让我从 dev.vars 中获取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me copy here this domain and let it put it there.": "让我复制这里的域名并把它放进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I don't have any worker called todos API and it asks if I want to create it.": "我没有任何名为 todos API 的 Worker，它询问我是否要创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me say yes.": "让我选“是”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's creating first the worker for me And now it's added the secret that will be available to that": "它首先为我创建了 Worker，现在已经添加了该 Worker 可用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:worker.": "机密。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The worker doesn't do anything right now.": "这个 Worker 现在什么也不做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go and do the second environment variable.": "无论如何，让我们去处理第二个环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The auth0 audience and let me go and copy that.": "即 auth0 audience，让我去复制它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we finished doing it.": "我们已经完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now to Cloudflare and let's go to the workers tab here.": "现在让我去 Cloudflare，进入这里的 Workers 选项卡。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you what we got.": "让我给你们看看我们得到了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now we have the todos API.": "我们可以看到现在有了 todos API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I click that let's go to settings over here.": "如果我点击它，让我们进入这里的设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here the two secrets that we added.": "我们可以在这里看到我们添加的两个机密。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back to the blog here.": "让我们回到博客。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the last thing we need to do is to simply deploy it with the command Wrangler deploy.": "最后我们需要做的就是简单地使用 Wrangler deploy 命令进行部署。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to cursor again to the terminal here.": "让我们再次回到 Cursor 的终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's run Npx Wrangler deploy.": "让我们运行 npx wrangler deploy。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's wait for it to be deployed.": "让我们等待它部署完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are done here.": "我们完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's currently deployed.": "所以它目前已经部署好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the worker URL.": "这是 Worker 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now to Cloudflare again.": "让我现在再次去 Cloudflare。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see if something changed in the UI.": "让我们看看 UI 中是否有变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here you should see in the domains and routes you see right now it's inactive.": "在这里你应该能在域名和路由中看到，目前它是非活动状态。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this should change.": "这一点应该会发生变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this tag here of inactive should be removed.": "这里的“非活动”标签应该会被移除。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see it right now.": "所以你现在可以看到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me try now to access this URL that I copied from before.": "现在让我尝试访问之前复制的这个 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and write this URL and we get here a very similar response of unauthorized.": "让我输入这个 URL，我们在这里得到了一个非常类似的“未授权”响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and try to make a request to it like we did before.": "那么让我们像之前那样尝试向它发送一个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to use the same token, but I'm going to use a different base URL.": "我将使用相同的令牌，但会使用不同的基础 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So instead of localhost with this port I'm simply going to paste the URL of the Cloudflare worker.": "因此，我不再使用带有此端口的 localhost，而是直接粘贴 Cloudflare worker 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we still get a response so we can see that it is working as expected right now.": "我们可以看到仍然得到了响应，所以我们可以看到它目前正按预期工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice if I will try the other APIs.": "注意，如果我尝试其他 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It won't work like before.": "它不会像以前那样工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We still have to do some configuration to make it work.": "我们仍然需要进行一些配置才能使其工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you just want to check as a sanity check, you can go to the repository to the todos API here.": "如果你只是想进行完整性检查，可以前往这里的 todos API 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the Readme file you'll see everything we did right now, all the instructions and to make sure": "在 Readme 文件中，你会看到我们刚才所做的一切，所有的指令，以及为了确保",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that you did everything.": "你完成了一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's have a quick recap of what we did so far.": "那么让我们快速回顾一下到目前为止我们所做的工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we created the todos API.": "刚才我们创建了 todos API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We ran it locally and we deployed it to Cloudflare.": "我们在本地运行了它，并将其部署到了 Cloudflare。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next videos, the next couple of videos, we're going to do the same for the remote MCP,": "在接下来的几个视频中，我们将对远程 MCP 执行相同的操作，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is going to act as our authorization server for our MCP client.": "它将作为我们 MCP 客户端的授权服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to help us and enable us to generate tokens with Auth0 to access these to do API.": "这将帮助并使我们能够通过 Auth0 生成令牌，以访问这些待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hi.": "你好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we can focus on the MCP server, which is called the remote MCP server.": "现在我们可以专注于 MCP 服务器，它被称为远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to start by cloning the code.": "所以我们将从克隆代码开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to run the MCP server locally.": "我们将本地运行 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this MCP server is going to function for two things.": "这个 MCP 服务器将承担两个功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First it's going to help us in the authentication flow going to act as the OAuth server.": "首先，它将帮助我们处理身份验证流程，充当 OAuth 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to authorize our users which come from cloud desktop to our to DOS API.": "它将授权来自云桌面的用户访问我们的待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to initiate the OAuth flow and it's going to use Auth0 to do so.": "它将启动 OAuth 流程，并使用 Auth0 来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it has an integration with Auth0.": "所以它集成了 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is one part of the MCP server.": "这是 MCP 服务器的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the other part is to expose tools to call the to DOS API.": "另一部分是公开用于调用待办事项 API 的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to expose a tool to review the to do list.": "它将公开一个用于查看待办事项列表的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to expose a tool to review our information about the authenticated user.": "它将公开一个用于查看已验证用户信息的工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to expose a tool that shows the billing data of the current logged user, which I remind": "它还将公开一个显示当前登录用户账单数据的工具，我提醒一下，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you was some static information.": "这些是一些静态信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and let's handle the remote MCP server.": "现在让我们去处理远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first thing that we need to do is to go to Auth0 and to create a web application and to call it": "我们需要做的第一件事是前往 Auth0 并创建一个 Web 应用程序，将其命名为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remote MCP server.": "远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to go to Auth0.": "我现在去 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me go back to all the applications here.": "现在让我回到这里的所有应用程序列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and create a new application.": "让我们去创建一个新应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to select regular web application and let's call it remote SAP server.": "我要选择常规 Web 应用程序，并将其命名为远程 SAP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me create it.": "让我创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because this server is going to act as our authorization server for our back end API, then we need": "因为这个服务器将作为我们后端 API 的授权服务器，所以我们需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to configure a callback URL.": "配置一个回调 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the URL that our app will be redirected once the user is successfully authenticated by Auth0.": "这是当用户通过 Auth0 成功验证后，我们的应用程序将被重定向到的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is something which is standard when implementing the OAuth 2.0 protocol and when implementing authentication.": "这是实现 OAuth 2.0 协议和身份验证时的标准做法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the callback is going to be localhost at port 8788.": "回调地址将是端口 8788 的 localhost。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the address of our remote Mocp server.": "这将是我们远程 Mocp 服务器的地址。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once it's running locally, when we'll deploy it to production, we'll need to set some other URL here": "一旦它在本地运行，当我们将其部署到生产环境时，我们需要在这里设置其他 URL，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:where it's going to be deployed in Cloudflare.": "即它在 Cloudflare 中部署的位置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the endpoint we're going to refer to when calling back is going to be slash callback.": "我们在回调时引用的端点将是 /callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We'll see the implementation of the slash callback endpoint when we'll see the code of the remote NCP": "当我们查看远程 NCP 的代码时，我们会看到 /callback 端点的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to settings here.": "让我们进入这里的设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the domain the client ID and the client secret.": "这里有域名、客户端 ID 和客户端密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and copy them all because we're going to need it for later.": "让我把它们全部复制下来，因为我们稍后会用到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, we need those values to establish trust between the remote NCP server that we're creating": "顺便说一下，我们需要这些值来在我们现在创建的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:now and which is going to be running locally or deployed in Cloudflare.": "即将在本地运行或部署在 Cloudflare 中的远程 NCP 服务器之间建立信任。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to create trust between that and between auth zero.": "我们希望在它和 Auth0 之间建立信任。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are done configuring Auth0 in the Auth0 platform.": "我们已经在 Auth0 平台上完成了 Auth0 的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to go to tell our application how to talk with Auth0.": "现在我们要告诉我们的应用程序如何与 Auth0 通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to give it the URL of our tenant and the unique identifier.": "所以我们需要给它我们租户的 URL 和唯一标识符。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We named our API which was todos API.": "我们为我们的 API 命名，即 todos API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that way our application now will be able to verify tokens that were issued and signed by Auth0.": "这样，我们的应用程序现在就能够验证由 Auth0 签发和签署的令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to do that we'll need to set up those environment variables.": "因此，我们需要设置这些环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the blog and we can see now here we need to set two environment variables.": "让我们看下博客，可以看到这里我们需要设置两个环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now and copy these values here.": "现在让我去复制这里的这些值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll put it in a.dev dot vars file which here we're going to have environment variables which we": "我们将把它们放在一个 .dev.vars 文件中，这里我们将存放一些我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:do not want to deploy to production.": "不想部署到生产环境的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and create a new file here.": "那么，让我们在这里创建一个新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and write here.dev dot vars.": "让我们在这里写下 .dev.vars。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me paste in here these strings here.": "让我把这些字符串粘贴到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need to put here the domain and let me go and get that domain.": "我们需要在这里填入域名，让我去获取那个域名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that your domain can be retrieved from applications.": "你的域名可以从“应用程序” (Applications) 中获取。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we'll go and select the to do list application.": "现在我们要去选择 to do list 应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right over here we can see we have here the domain.": "就在这里，我们可以看到域名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and copy that.": "让我去复制它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way this is the same tenant that I have here.": "顺便说一下，这和我这里的租户是同一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be our tenant.us dot auth0.com.": "所以它将是 our-tenant.us.auth0.com。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we finished with the Auth0 configuration completely.": "至此，我们已经完全完成了 Auth0 的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's go and let's test our application again.": "现在让我们再次测试我们的应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me now go and run everything.": "让我现在运行所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to the URL of our server.": "让我们访问服务器的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom we got here an unauthorized answer.": "砰的一声，我们得到了一个“未授权” (unauthorized) 的响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is great because this is not an internal server error and this only means we are not yet authenticated.": "这太棒了，因为这不是内部服务器错误，这只意味着我们尚未通过身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let's go and test it.": "那么现在让我们来测试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's test this API once we are authenticated.": "让我们在通过身份验证后再测试这个 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to do that we'll go back again to Auth0.": "为此，我们将再次回到 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a section to test it.": "这里有一个测试部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's click test.": "让我们点击“测试” (test)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and copy here this curl command which is going to output us an access token that we can": "让我们复制这里的这个 curl 命令，它将为我们输出一个可以使用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:use.": "访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the access token for my personal user.": "这是我个人用户的访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you're going to have the same for yours.": "你的也会有一个类似的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a JSON web token.": "这是一个 JSON Web Token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can use this JWT to authenticate and to access our API.": "我们可以使用这个 JWT 来进行身份验证并访问我们的 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to copy now this command over here.": "我现在要复制这里的这个命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to use this token here.": "这将使用这里的这个令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's going to use it with our API here.": "但它将与我们这里的 API 一起使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me remove this token here that I copied with.": "让我删掉我一起复制过来的这个令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me copy and paste.": "让我复制并粘贴。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the access token I just generated.": "现在是我刚刚生成的访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me paste it in.": "让我把它粘贴进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and change our API path.": "现在让我们更改 API 路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here let's go and put here our localhost port 8789.": "让我们在这里输入我们的 localhost 端口 8789。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So 8789.": "也就是 8789。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get a 404.": "然后我们得到了一个 404。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because we didn't really put the endpoint to query.": "这是因为我们没有真正输入要查询的端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and add here I think it's slash API slash todos.": "所以让我们在这里添加，我想应该是 /api/todos。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Slash API slash todos.": "/api/todos。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's why we need the client ID and client secret.": "这就是为什么我们需要客户端 ID 和客户端密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we scroll down here, we can see that we can put here the allowed callback URL.": "如果我们向下滚动，可以看到我们可以在这里填写允许的回调 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can put here multiple values here.": "我们可以在这里填写多个值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So multiple URLs but they need to be comma separated.": "也就是多个 URL，但它们需要用逗号分隔。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and paste the callback URL.": "让我去粘贴回调 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So localhost port 8788 slash callback.": "即 localhost 端口 8788 斜杠 callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and save it.": "让我们去保存它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The next thing that we want to do is to go to Cloudflare now and to create there a key value storage.": "我们接下来要做的是前往 Cloudflare，并在那里创建一个键值存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll call it OAuth key value, which is the Cloudflare implementation for the OAuth functionality": "我们将其命名为 OAuth key value，这是 Cloudflare 对 OAuth 功能的实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the Cloudflare workers environment.": "在 Cloudflare Workers 环境中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the workers OAuth provider is going to be using this key value storage.": "因此，Workers OAuth 提供程序将使用这个键值存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And why do we need this key value storage.": "为什么我们需要这个键值存储呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because Cloudflare workers are stateless and we can have multiple instances of them.": "因为 Cloudflare Workers 是无状态的，而且我们可以有多个实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we need the key value to save some data like the OAuth client registrations, authorization codes,": "所以我们需要键值存储来保存一些数据，比如 OAuth 客户端注册、授权码、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tokens, and other states that are needed across OAuth flows.": "令牌以及跨 OAuth 流程所需的其他状态。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm sorry, I'm not going too deep here.": "抱歉，我在这里不会讲得太深。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I rather not focus on OAuth, but rather focus here on the MCP functionality.": "我不想把重点放在 OAuth 上，而是想把重点放在 MCP 功能上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to Cloudflare and let's go and create it.": "让我们去 Cloudflare 创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not going to use the Wrangler CLI.": "我不打算使用 Wrangler CLI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to do it through the UI.": "我将通过 UI 界面来操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here if I scroll down here we have here storage.": "在这里，如果我向下滚动，可以看到这里有存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can search for key value here.": "我们可以在这里搜索键值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can create a new key value storage here.": "在这里我们可以创建一个新的键值存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's call it OAuth kV.": "让我们把它命名为 OAuth kV。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's create it.": "让我们创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now we can go and use it.": "现在我们就可以去使用它了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to use it we need to tell our application what key value storage are we using.": "为了使用它，我们需要告诉我们的应用程序我们正在使用哪个键值存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for that we can go and edit the Wrangler JSON file, which is a configuration file for Cloudflare": "为此，我们可以去编辑 Wrangler JSON 文件，这是 Cloudflare",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:workers projects.": "Workers 项目的配置文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to give the key value storage ID here to let the Cloudflare worker where to access the key value": "我们想在这里提供键值存储 ID，以便让 Cloudflare Worker 知道去哪里访问键值",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:storage.": "存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, because we are running everything with the Wrangler CLI.": "顺便说一下，因为我们是使用 Wrangler CLI 运行所有内容的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll run it with Wrangler dev command, then it's going to load up this environment variables locally.": "因此，我们将使用 Wrangler dev 命令运行它，然后它会在本地加载这些环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when running the MCP server in our local machine, it will reference the key value storage in Cloudflare.": "这样，在本地机器上运行 MCP 服务器时，它将引用 Cloudflare 中的键值存储。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be able to do that because we're already authenticated to Cloudflare through the CLI.": "它之所以能够做到这一点，是因为我们已经通过 CLI 在 Cloudflare 进行了身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So everything will work.": "所以一切都会正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and do that and let me open here terminal.": "让我们开始操作，让我在这里打开终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me clear up everything.": "让我清理一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we want to go back.": "现在我们要回去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to go to the remote MCP directory.": "我们要进入远程 MCP 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's the MTP Auth0 OpenID connect.": "也就是 MTP Auth0 OpenID connect。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's open it with cursor.": "让我们用 Cursor 打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we have the Wrangler JSON C file.": "这里有 Wrangler JSON C 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me just go and put the value of the key value storage ID here.": "让我把键值存储 ID 的值填在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get here unauthorized.": "结果我们在这里收到了“未授权”错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because we didn't have the read scope which is required by the middleware.": "这是因为我们缺少中间件所要求的 read 作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll be doing it very, very soon.": "我们很快就会处理这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's go and check out the other endpoint which is slash me, which is going to respond to us with": "不过，让我们来看看另一个端点 /me，它会返回给我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:claims such as ES, sub, audience, etc..": "诸如 ES、sub、audience 等声明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this request is working because we need here only a valid token, which we have right now.": "这个请求成功了，因为这里只需要一个有效的令牌，而我们现在已经有了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We do not require any scopes here.": "这里不需要任何作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I will copy here this ID and let's go and paste it.": "所以我会在这里复制这个 ID，然后去把它粘贴上去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now back to the blog and let's scroll down here.": "现在回到博客，让我们向下滚动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see which environment variables we need to populate in order for everything to work.": "现在我们可以看到为了让一切正常运行，我们需要填充哪些环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The auth domain will identify our auth0 tenant where the user authentication actually happens.": "认证域名（auth domain）将标识我们的 Auth0 租户，即用户身份验证实际发生的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The Auth0 client ID is the client ID of our application, which is registered within Auth0.": "Auth0 客户端 ID 是我们应用程序的客户端 ID，它已在 Auth0 中注册。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the client secret is the key that verifies our application's identity to Auth0 and creates that": "客户端密钥（client secret）是向 Auth0 验证我们应用程序身份并建立",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:trust relationship.": "信任关系的密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The audience specifies which API.": "受众（audience）指定了哪个 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case it's going to be the to do API.": "在这种情况下，它将是待办事项（to do）API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The tokens will be used for and the scope defines what permissions our application is requesting from": "令牌将用于此目的，而范围（scope）定义了我们的应用程序向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our users to that to do list API denote env is going to be development because it's going to indicate": "用户请求的待办事项列表 API 的权限。denote env 将被设为 development，因为它将指示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:where our development server.": "我们的开发服务器所在地。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, the API base URL needs to point to our to do list API.": "最后，API 基础 URL 需要指向我们的待办事项列表 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be locally in localhost.": "它将位于本地的 localhost。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when we deploy it we'll need to put here the Cloudflare workers URL.": "当我们部署它时，我们需要在这里填入 Cloudflare Workers 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let me go and copy all the environment variables that we need.": "好了，让我去复制我们需要的所有环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me paste here in this.dev dot var file here like we did in the todos API.": "让我把它们粘贴到这里的 .dev.vars 文件中，就像我们在 todos API 中所做的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and fill up all the values here.": "让我去填好这里所有的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back to Auth0 to our remote MCP server application.": "让我们回到 Auth0，进入我们的远程 MCP 服务器应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's copy all the values the domain client id client secret.": "让我们复制所有的值：域名、客户端 ID、客户端密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and paste it there.": "让我们去把它们粘贴到那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we want to run the MCP server locally.": "现在我们想在本地运行 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all, sorry in advance that I'm going to whisper a bit in this video.": "首先，提前向大家道歉，在这个视频里我的声音会比较小。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My baby is asleep and I'm trying not to wake him up.": "我的宝宝睡着了，我尽量不吵醒他。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, so right now we have the MCP server which is going to be our auth server.": "言归正传，现在我们有一个 MCP 服务器，它将作为我们的认证服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have it running locally on port 8788.": "它目前在本地的 8788 端口运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and make sure that the to dos API is running locally.": "让我们去确认一下待办事项 (to dos) API 也在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's run MCP Inspector.": "然后我们运行 MCP Inspector。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me now open my terminal on the left side.": "现在让我打开左侧的终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here I have the API running.": "这里 API 正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the to do API here is running at port 8789.": "这个待办事项 API 运行在 8789 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And on the right side let's go and run MCP Inspector.": "在右侧，我们来运行 MCP Inspector。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to run PNP model context protocol slash inspector.": "我将运行 PNP model-context-protocol/inspector。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to run on port 6274.": "它将运行在 6274 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the MCP inspector.": "这就是 MCP Inspector。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to connect to a remote MCP running on port 8788 SE like we did before.": "我们想要像之前一样，连接到运行在 8788 端口的远程 MCP SSE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Before we do that, let me show that there aren't any logs right now.": "在那之前，我先展示一下现在还没有任何日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see the logs of the MCP server and we don't see any logs here.": "在这里我们可以看到 MCP 服务器的日志，目前这里没有任何记录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the inspector and let's now connect.": "让我们回到 Inspector 并点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now we have the consent screen opened.": "我们可以看到现在打开了授权同意界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that we have the first a get request to the SE.": "我们可以看到发出了第一个针对 SSE 的 GET 请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we can see we got here a 401 error.": "然后我们可以看到这里收到了一个 401 错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're not authenticated yet.": "说明我们还没有经过身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client realizes that and then it tries to authenticate.": "客户端意识到了这一点，然后尝试进行认证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now how does it authenticate.": "那么它是如何认证的呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't know.": "它并不知道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what it does it's going to ask the server that gave it the unauthorized response.": "所以它会去询问那个返回“未授权”响应的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to query the well known endpoints.": "它会查询 well-known 端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to query for the OAuth authorization server.": "它会查询 OAuth 授权服务器的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the well known endpoint is a standardized URL path for service discovery, and in this case it is": "well-known 端点是一个用于服务发现的标准 URL 路径，在这种情况下，它是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the OAuth 2.0 metadata endpoint that provides configuration information about the authentication server.": "OAuth 2.0 元数据端点，提供有关认证服务器的配置信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the MCP context, this endpoint would be used by the clients to automatically discover authentication": "在 MCP 上下文中，客户端会使用此端点来自动发现认证",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:settings when connecting to an MCP server that uses OAuth for authorization.": "设置，当连接到一个使用 OAuth 进行授权的 MCP 服务器时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client can request this endpoint to retrieve information like what are the supported authentication": "因此，客户端可以请求此端点来获取诸如支持哪些认证",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:flows?": "流程之类的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The token endpoints, the authorization endpoints, supported scopes.": "比如令牌端点、授权端点以及支持的作用域 (scopes)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this response here follows the RFC 8414 standard for the OAuth 2.0 authorization server metadata.": "这里的响应遵循 RFC 8414 标准，即 OAuth 2.0 授权服务器元数据标准。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to allow us automatic configuration rather than require manual setup of the auth parameters.": "这样我们就可以进行自动配置，而不需要手动设置认证参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now the MCP client which was unauthorized knows how it needs to authorize.": "现在，之前未获授权的 MCP 客户端知道该如何进行授权了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what it will do it's going to go to register first is an endpoint for the OAuth 2.0 dynamic client": "所以它首先会去 register，这是一个用于 OAuth 2.0 动态客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:registration, and where the client application registers with the OAuth server so it can continue and": "注册的端点，客户端应用程序在此向 OAuth 服务器注册，以便继续并",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:begin the authorization.": "开始授权过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, the OAuth authorization server endpoint and the slash register we do not implement.": "顺便说一下，OAuth 授权服务器端点和 /register 我们没有实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this comes out of the box when we use the OAuth provider.": "当我们使用 OAuth 提供程序时，这是开箱即用的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the inspector here is the client I remind you.": "我提醒你，这里的检查器（inspector）就是客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after it registers the inspector is going to make a request to slash authorize.": "所以在注册之后，检查器将向 /authorize 发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we implement this function here.": "我们在这里实现这个函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this function is going to initialize the authorization code flow.": "所以这个函数将初始化授权码流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When a user wants to log in.": "当用户想要登录时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to render this authorization screen that we're seeing right now.": "它将渲染我们现在看到的这个授权屏幕。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it has all the information about who is the client.": "所以它拥有关于客户端是谁的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because the client has registered already.": "因为客户端已经注册了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's now going to create this page from the client details.": "现在它将根据客户端详情创建这个页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right over here we are using the MCP inspector which wants to access the resource of the the OAuth": "在这里，我们正在使用 MCP 检查器，它想要访问 OAuth 的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:resource of the to dos API.": "待办事项 API 的资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it needs those scopes that we see here.": "它需要我们在这里看到的那些作用域（scopes）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it needs the OpenID email profile, offline access and read to dos.": "所以它需要 OpenID、email、profile、offline access 和 read to dos。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you this in the MCP server code here.": "让我在这里的 MCP 服务器代码中向你展示这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here a bunch of boilerplate code.": "我们这里有一堆样板代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see some tool exposure that we're exposing the to do list tool.": "在这里我们可以看到一些工具暴露，我们正在暴露待办事项列表工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the tool to display who am I.": "以及用于显示“我是谁”的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I scroll down we can see also the tool that is going to show the billing information.": "如果我向下滚动，我们还可以看到将显示账单信息的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well this is stuff that we saw already in the beginning of the course.": "嗯，这些是我们在课程开始时已经看到过的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nothing special here.": "这里没什么特别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I do not want to go over it again.": "所以我不想再重复一遍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is new here is these authentication flow implementation here.": "这里的新内容是这些身份验证流程的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here that we're implementing ourselves three endpoints.": "我们可以看到，这里我们自己实现了三个端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Slash authorize.": "/authorize。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Slash authorize slash consent and slash callback slash register.": "/authorize/consent 和 /callback/register。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We do not need to implement because the OAuth provider is going to do it for us.": "我们不需要实现，因为 OAuth 提供商会为我们完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you what's going to be returned once we go and get the slash authorize.": "让我向你展示一旦我们访问 /authorize 会返回什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and see this slash authorize.": "那么让我们来看看这个 /authorize。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what we have here.": "让我们看看这里有什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to simply render us a form, the consent form that we saw from before with all the": "这将简单地为我们渲染一个表单，即我们之前看到的包含所有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:information that we need to authorize the user.": "授权用户所需信息的同意表单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see that the redirect URI when we click Allow access is going to be MCP client auth": "在这里我们可以看到，当我们点击“允许访问”时，重定向 URI 将是 MCP 客户端身份验证",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:request dot redirect URI.": "请求的重定向 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the MCP client here is going to be the MCP inspector.": "这里的 MCP 客户端将是 MCP 检查器 (MCP inspector)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the server render this form.": "所以服务器渲染了这个表单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here it's going to put the redirect URI of localhost port 6274 slash OAuth slash callback.": "在这里，它将放入 localhost 端口 6274 /OAuth/callback 的重定向 URI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see that the input to the function is all the information that we need in order to render": "所以在这里我们可以看到，函数的输入是渲染",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the screen over here.": "此处屏幕所需的所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we'll scroll down here we'll see here these HTML and CSS code.": "如果我们向下滚动，我们会在这里看到这些 HTML 和 CSS 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when that's going to be rendered we're going to see this form here.": "当它被渲染时，我们将在这里看到这个表单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when we're going to click on Allow Access then the NCP inspector is going to make a request to the": "因此，当我们点击“允许访问”时，MCP 检查器将向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:remote NCP server, which is our OAuth server.": "远程 MCP 服务器（即我们的 OAuth 服务器）发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to make a request to the endpoint slash authorize slash consent here.": "它将向这里的端点 /authorize/consent 发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's going to happen here is that the remote MCP server, which is the OAuth server, it's going to": "这里将发生的是，远程 MCP 服务器（即 OAuth 服务器）将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:redirect now to Auth0 to do all the heavy lifting.": "现在重定向到 Auth0 来处理所有繁重的工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Auth0 is going to do the actual authentication.": "所以 Auth0 将进行实际的身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to determine if the user can be logged in or not.": "它将决定用户是否可以登录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to redirect to this form over here.": "并且它将重定向到这里的这个表单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this form URL is going to be in our tenant in Auth0.": "这个表单的 URL 将位于我们在 Auth0 中的租户中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be a login form.": "它将是一个登录表单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So either with email password or with a Google or another.": "可以使用电子邮件密码，也可以使用 Google 或其他方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you want and then we are going to be prompt again with what resource we want to access here and": "如果你愿意，然后我们会再次收到提示，询问我们要访问这里的什么资源，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to access the application that is listed in Auth0, which is the to do application.": "我们想要访问 Auth0 中列出的应用程序，即待办事项 (to-do) 应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the tenant ID and this is the scope that we want to access.": "这是租户 ID，这是我们想要访问的作用域 (scope)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to click accept.": "然后我们将点击接受。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Auth0 the identity provider just verified our identity.": "于是 Auth0 这个身份提供商刚刚验证了我们的身份。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then Auth0 is going to redirect the user back to the callback endpoint with an authorization code": "然后 Auth0 将带着授权码将用户重定向回回调端点，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the callback here is going to be not the client, not the MCP inspector, but the MCP server which": "这里的回调将不是客户端，不是 MCP 检查器，而是作为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is acting as the authorization server.": "授权服务器运行的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see here, by the way, in the URL, you can see that this is our tenant zero.": "顺便说一下，你可以在这里的 URL 中看到，这是我们的 Auth0 租户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here in the rest of this URL we have encoded all the information that we need like the callback": "在这个 URL 的其余部分，我们已经编码了所有需要的信息，比如回调",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:URL and everything.": "URL 等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we're going to click accept over here.": "所以在点击这里的“接受”之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I added some more instrumentation here so it would be even more explicit.": "我在这里添加了一些额外的检测代码，以便让过程更加清晰。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:User has been authenticated with Auth0 and the Auth0.": "用户已通过 Auth0 进行了身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After a successful authorization it's going to redirect to the MCP servers uh slash callback endpoint": "授权成功后，它将重定向到 MCP 服务器的 /callback 端点",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with the authorization code.": "并携带授权码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the MCP server is going to redirect the request to the MCP inspector, which is the OAuth client": "然后 MCP 服务器会将请求重定向到 MCP Inspector（即 OAuth 客户端），",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:with that authorization code.": "同样携带该授权码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to forward that code to him.": "所以它会将该代码转发给它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now with that authorization code, the MCP inspector, which is the OAuth client, it can trade": "现在有了这个授权码，作为 OAuth 客户端的 MCP Inspector 就可以进行交换，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it can trade this authorization code with a token with an access token.": "它可以将此授权码交换为令牌，即访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's what it's going to do right over here.": "这就是它在这里要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to take and send the request to now to the MCP server which is the authorization Server.": "所以它现在会将请求发送到作为授权服务器的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to send a request to slash token with the authorization code it got.": "它将向 /token 发送一个包含所获授权码的请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's going to get back an access token.": "然后它将获取返回的访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it can use to make requests to the to dos API.": "这样它就可以用来向待办事项 API 发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this access token is going to be for an authenticated user with the correct claims that can access": "这个访问令牌将属于一个经过身份验证的用户，并带有正确的声明，可以访问",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this API.": "此 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And only then we get this access message that we were successfully in authenticated.": "只有到那时，我们才会收到这条表示身份验证成功的访问消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now finally and let's go and list now the tools after we're authenticated.": "那么现在，在身份验证之后，让我们最后去列出这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go ahead and make this a bit bigger.": "让我把这个调大一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and show you the tools here.": "让我在这里给你们展示一下这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see who am I.": "让我们看看“我是谁” (who am I)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because I'm authenticated right now.": "这是因为我现在已经通过了身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to list the to dos.": "让我们去列出待办事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to and try that and boom we get now the to do list.": "让我们试一下，瞧，现在我们得到了待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go list building.": "让我们列出账单 (billing)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we cannot access it.": "我们无法访问它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're unauthorized because we don't have the correct claim because we need the read billing which we": "我们未获授权，因为我们没有正确的声明，因为我们需要读取账单权限，而我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:don't have.": "并没有。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hope you're enjoying the course and this video is optional.": "希望你喜欢这门课程，本视频是可选的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video, I'm going to discuss why we weren't able to review the billing information.": "在这段视频中，我将讨论为什么我们之前无法查看账单信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this was because we were missing the scope of read billing.": "这是因为我们缺少了 read:billing 作用域（scope）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video I will show you how we can fix it and how we can review the billing information.": "所以在这段视频中，我将向你展示如何修复它以及如何查看账单信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is more related to our flow.": "这更多地与我们的流程有关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you're not interested, feel free to skip this video.": "所以如果你不感兴趣，可以随时跳过这段视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go back to the code of the MCP server, which is acting as our authorization server.": "让我回到 MCP 服务器的代码，它充当我们的授权服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see in the.dev dot vars in the environment variable of Auth0 scope, we have here a list.": "你可以看到在 .dev.vars 的 Auth0 作用域环境变量中，我们这里有一个列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This list defines what permissions the application is requesting.": "这个列表定义了应用程序正在请求的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So OpenID enables the OpenID connect authentication.": "OpenID 启用了 OpenID Connect 身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is for the ID tokens to be generated.": "这是为了生成 ID 令牌（ID tokens）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the email and the profile is to access some information about the user.": "而 email 和 profile 是为了访问有关用户的一些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the offline access enables the issue of a refresh token.": "offline_access 启用了刷新令牌（refresh token）的发行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not that interesting right now.": "现在这并不那么重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But what is interesting is this read to dos.": "但有趣的是这个 read:todos。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a custom scope that we created already on Auth0 that grants permission to read the to do": "这是我们已经在 Auth0 上创建的一个自定义作用域，它授予读取待办事项",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:items.": "项的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those scopes are like permission slips that let users know what access they're granting and tell": "所以这些作用域就像许可单，让用户知道他们正在授予什么访问权限，并告诉",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the API what actions are permitted with the token.": "API 该令牌允许执行哪些操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this will allow fine grained access to the control.": "这样可以实现细粒度的访问控制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when a user approves the consent screen, they specifically agree to grant these permissions to": "当用户批准同意界面时，他们明确同意将这些权限授予",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the application.": "应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the application is going to be the MCP client.": "而这个应用程序就是 MCP 客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now if I'll go to the to do list application.": "现在，如果我转到待办事项列表应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is not the MCP server right now.": "现在这不是 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the code of the to do list server.": "这是待办事项列表服务器的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll go to index dot TypeScript.": "我将进入 index.ts。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll go to the API slash todos.": "我将转到 /api/todos。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see here we have this required scope of read to dos.": "我们可以看到这里有 read:todos 这个必需的作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the scope that the user is going to grant the application.": "这就是用户将要授予应用程序的作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's why when we verify the token we verify that we have the scope to read the to do list.": "这就是为什么当我们验证令牌时，我们会验证我们是否具有读取待办事项列表的作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's why it was all working.": "这就是为什么之前一切正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now if I'll scroll down to not here to the slash billing here to slash API slash billing, we can see": "现在，如果我向下滚动，不是这里，而是到 /api/billing，我们可以看到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:here we have read billing.": "这里有 read:billing。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice that because we didn't give the read billing in the auth0 scope, so the user didn't consent": "请注意，因为我们没有在 Auth0 作用域中提供 read:billing，所以用户没有同意",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to give that permission.": "授予该权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's why we weren't able to aim to review this information here.": "这就是为什么我们之前无法查看这里的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just for the sake of it, let me just change it to require scope of reads to dos, which we": "那么，为了演示，让我把它改为需要 read:todos 作用域，我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:have this scope.": "拥有这个作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me show you that it will work.": "让我向你展示它是可以工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just go and refresh everything.": "让我去刷新一下所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So before running the MCP server locally, we need to make sure that our to do list server is running": "所以在本地运行 MCP 服务器之前，我们需要确保我们的待办事项列表服务器正在运行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:locally as well because it's going to reference it.": "也在本地运行，因为它会引用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I have it locally running from before, and you need to make sure that you have it running as well.": "我之前已经在本地运行了它，你也需要确保你也在运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and run the MCP server locally.": "让我们在本地运行 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to write sudo npm run dev which is going to activate the server with the Wrangler cli.": "我将输入 sudo npm run dev，这将通过 Wrangler CLI 启动服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now that our server is running in localhost port 8788.": "现在我们可以看到我们的服务器运行在 localhost 端口 8788。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I remind you, when we configured Auth0 to work with our MCP server, then the callback URL was localhost": "提醒一下，当我们配置 Auth0 与我们的 MCP 服务器配合使用时，回调 URL 是 localhost",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:port 8788 slash callback.": "端口 8788 斜杠 callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this endpoint is implemented in the code here.": "所以这个端点是在这里的代码中实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now we have the to dos API running locally.": "现在我们的待办事项 API 正在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have now the MCP server running locally.": "我们现在也有 MCP 服务器在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's time to test it.": "现在是测试它的时候了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to use the Inspector tool from MCP.": "我将使用来自 MCP 的检查器 (Inspector) 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to activate it by running npm model context protocol slash inspector.": "我将通过运行 npm model context protocol slash inspector 来启动它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and open it.": "让我们去打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want to connect via SSH.": "我们想通过 SSH 连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is an SSH server.": "这是一个 SSH 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to connect to localhost at port 8788.": "我们将连接到 localhost 的 8788 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because this is our MCP port.": "因为这是我们的 MCP 端口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to connect to SSH.": "它将连接到 SSH。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see we are instantly redirected to this page here.": "我们可以看到我们立即被重定向到了这个页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this page here is the OAuth consent screen which is asking our user to give the application MCP": "这个页面是 OAuth 授权屏幕，它要求用户授予应用程序 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:inspector access to the to do API stack in the terminology of OAuth protocol.": "检查器访问待办事项 API 栈的权限，这是 OAuth 协议中的术语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the very gist of it.": "这就是它的核心要点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there are three key players here in this authorization process.": "在这个授权过程中有三个关键角色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's me and I'm the person who owns data.": "一个是我，我是拥有数据的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I control who gets access to the information.": "所以我控制谁可以访问这些信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the information here is the OAuth resource.": "这里的信息就是 OAuth 资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is where the actual data lives.": "所以这就是实际数据存放的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this case it's the to do API that stores the information.": "所以在这种情况下，是待办事项 API 存储了信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I own that information.": "所以我拥有那个信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I own that OAuth resource.": "我拥有那个 OAuth 资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The OAuth client is the application which is requesting the access.": "OAuth 客户端是请求访问权限的应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this example that's the MCP inspector application.": "在这个例子中，就是 MCP 检查器应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this application currently wants permission to use specific parts of my data.": "所以这个应用程序目前想要使用我数据的特定部分的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it wants to use the to do API.": "所以它想使用待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The OAuth server here is going to be the security system.": "这里的 OAuth 服务器将是安全系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to be here the to do MCP server.": "在这里它将是待办事项 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to verify my identity.": "它将验证我的身份。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to ask for my explicit permissions before letting any app access the data here, which": "它会在允许任何应用程序访问这里的数据之前征求我的明确许可，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is the to do API.": "这些数据就是待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's recap about the process that's going to happen.": "让我们回顾一下即将发生的过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first I'm trying to use an application MCP inspector that needs access to the resource of the todos": "所以首先，我尝试使用一个需要访问待办事项",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:API.": "API 资源的 MCP 检查器应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The application MCP inspector then requests access from the authentication OAuth server.": "然后，MCP 检查器应用程序向身份验证 OAuth 服务器请求访问权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our MCP server.": "这就是我们的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I just need to refresh the to DOS web server, because this is what's going to verify the token": "我只需要刷新一下 To-Dos Web 服务器，因为它是用来验证令牌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the scope.": "以及作用域的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to Inspector.": "那么让我打开检查器（Inspector）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I refreshed it though I didn't really have to.": "我刷新了它，虽然其实没必要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me connect again.": "让我再次连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go allow access and let's go and list the tools and invoke them one by one to see that they are": "让我们允许访问，然后列出工具并逐一调用它们，看看它们是否",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:working.": "正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now the list to dos.": "现在是列出待办事项（list to dos）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see it's still working.": "我们可以看到它仍然在工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go try list building.": "让我们尝试列出账单（list billing）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Boom!": "砰！",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see now the billing information.": "我们现在可以看到账单信息了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go back now to the to dos API and return the scope of the read billing that we need to this endpoint.": "现在让我回到 To-Dos API，并返回该端点所需的 read billing 作用域。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And as a homework assignment you can try and add the read billing to the auth zero scope here in the": "作为课后作业，你可以尝试将 read billing 添加到 Auth0 的作用域中，就在这里的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:environment variable.": "环境变量里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course change back again the validation of the correct scope and see that it will work even if": "当然，再次改回对正确作用域的验证，看看即使你拥有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you have the read billing scope.": "read billing 作用域，它也能正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP server is going to show this consent screen over here.": "MCP 服务器将在这里显示这个同意屏幕。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If I'm going to decide that I'm going to allow the access here, then the application, the MCP inspector": "如果我决定允许此处的访问，那么该应用程序，即 MCP 检查器",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will receive a secure digital key to access only specific parts of the data that it is authorized to": "将收到一个安全数字密钥，仅用于访问其获权访问的特定部分数据",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:do it.": "执行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be with the JWT.": "所以这将通过 JWT 来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the beautiful thing about OAuth is that we never share a password with the third party application.": "OAuth 的妙处在于我们永远不会与第三方应用程序共享密码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this application here is the MCP inspector.": "这里的这个应用程序就是 MCP 检查器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can revoke the access anytime we want.": "我们可以随时撤销访问权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the application which is MCP inspector here only gets access to what it needs.": "这里的 MCP 检查器应用程序只能访问它需要的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Not everything.": "而不是全部。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we talked about OAuth a bit and the gist of the protocol and the consent screen, let's go": "在我们讨论了 OAuth、协议要点和同意屏幕之后，让我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and click Allow Access and let's see how it continues.": "点击“允许访问”，看看接下来的流程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice here after we're going to click Allow Access.": "请注意，在我们点击“允许访问”之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're then going to be redirected to our localhost port 6274 which is going to be MCP inspector slash": "我们将被重定向到 localhost 端口 6274，即 MCP 检查器斜杠",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:OAuth callback.": "OAuth 回调。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP inspector have already implemented and supports OAuth 2.0.": "因此，MCP 检查器已经实现并支持 OAuth 2.0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it already has implemented this callback.": "所以它已经实现了这个回调。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see this implementation.": "我们将看到这个实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you've been following the tutorial then you might say to me, Hey Ethan.": "如果你一直在关注本教程，你可能会对我说：嘿，Ethan。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the callback that we defined in Auth0 it's localhost port 8788 slash callback.": "但是我们在 Auth0 中定义的回调是 localhost 端口 8788 斜杠 callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it should be the MCP in server, not the MCP inspector.": "所以它应该是 MCP 服务器，而不是 MCP 检查器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you are correct, we did actually configure it with Auth0.": "你是对的，我们确实在 Auth0 中进行了配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I remind you that this page here that we're seeing rendered, this is rendered by the MCP server.": "我提醒你，我们看到的这个渲染页面是由 MCP 服务器渲染的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what's going to happen.": "接下来会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP server is going to forward that request.": "MCP 服务器将转发该请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when the user going to click Allow Access, then the MCP server which is the OAuth server for our": "因此，当用户点击“允许访问”时，作为我们 MCP 检查器（即 OAuth 客户端）的 OAuth 服务器的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP inspector, which is the OAuth client.": "MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP server is going to forward this authorization request, and it's going to make a request": "因此，MCP 服务器将转发此授权请求，并向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to Auth0, which is our authorization provider.": "Auth0（我们的授权提供商）发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And Auth0 is going to verify that I am who I am and that I'm allowed to access this resource here,": "Auth0 将验证我的身份，并确认我有权访问此处的资源，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it's going to do all this heavy lifting for us.": "它将为我们完成所有这些繁重的工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Zero finishes and determines that I am who I say I am, and that I have access to this API here.": "当 Auth0 完成并确定我就是我所说的那个人，并且我有权访问此处的 API 时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then what's going to happen.": "然后会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to redirect to the redirect we set here.": "它将重定向到我们在此处设置的重定向地址。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is localhost port 8788 slash callback.": "即 localhost 端口 8788 斜杠 callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here it's going to be after the authorization successfully went from auth zero.": "所以这里将是在 Auth0 授权成功之后。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this API endpoint implementation.": "在这个 API 端点的实现中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll show it later.": "我们稍后会展示它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have a redirect to the OAuth client which is the MCP inspector application.": "我们有一个重定向到 OAuth 客户端，即 MCP 检查器应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in that redirect we're going to forward an authorization code which the identity provider Auth0": "在该重定向中，我们将转发身份提供商 Auth0 提供的授权码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:issued which can then the client use to create access tokens.": "已发布，随后客户端可以使用它来创建访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just to show you that I'm not -- you, I added some instrumentation and some logging in": "为了向你证明我没有——骗你，我添加了一些检测和日志记录",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the next video we're going to review the MCP server's code.": "所以在下一个视频中，我们将审查 MCP 服务器的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to run everything with debug to see the logs.": "我们将以调试模式运行所有内容以查看日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to understand a lot more.": "我们将会理解更多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Wow, that was a lot of content, and covering the OAuth 2.0 protocol within the MCP ecosystem is quite": "哇，内容真多，在 MCP 生态系统中涵盖 OAuth 2.0 协议确实相当",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:challenging.": "具有挑战性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So first of all, I want you to take a quick break.": "所以首先，我想让你休息一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe have some coffee.": "也许喝杯咖啡。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me take a quick sip here.": "让我先抿一小口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to tell you that if you did not understand everything right from the get go, this is okay.": "我想告诉你，如果你没有从一开始就完全理解，这没关系。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I promise you, I did not understand this as well when I first saw it.": "我向你保证，我第一次看到它时也不理解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right?": "对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It took me a couple of iterations and a bunch of debugging and seeing the actual requests and what's": "我经过了几次迭代，进行了大量的调试，并查看了实际的请求、传递的内容以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:being passed and what's going to be the responses.": "响应的结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I personally spend a lot of time understanding this.": "我个人花了很多时间来理解这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if you do not understand everything right from the get go, this is totally okay.": "所以如果你没有从一开始就完全理解，这完全没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I do recommend you watching the last couple of videos again and again.": "我确实建议你反复观看最后几个视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I promise you it will be clearer.": "我保证它会变得更清晰。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And even if you do not want to do that and you don't want to understand the ins and outs and every bits": "即使你不想那样做，也不想了解 OAuth 2.0 协议的来龙去脉以及每一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and bytes of this protocol of OAuth 2.0, this is totally okay.": "细节，这也完全没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what are we going to do right now?": "那么我们现在要做什么呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to take this MCP server and we're going to deploy it to Cloudflare.": "我们将把这个 MCP 服务器部署到 Cloudflare。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be very easy I promise you.": "我保证这会非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to deploy to Cloudflare.": "所以我们要部署到 Cloudflare。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to test everything working on the cloud.": "我们将测试云端运行的一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to continue to integrate everything into our PHP host which is going to be cloud": "然后我们将继续把所有内容集成到我们的 PHP 宿主中，也就是云",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:desktop.": "桌面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the blog, we made it to the section where we deployed the MCP server to Cloudflare.": "在博客中，我们进行到了将 MCP 服务器部署到 Cloudflare 的章节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to do that, we would need to let the Cloudflare worker access all the secrets we had in": "为了实现这一点，我们需要让 Cloudflare Worker 能够访问我们所有的机密信息，这些信息位于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:our dot vars file.": "我们的 .vars 文件中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The auth domain of client ID of client secret, and all of those environment variables that we need.": "包括认证域名、客户端 ID、客户端密钥，以及所有我们需要的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in order to do it, it's very easy.": "操作起来非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're using the CLI command wrangler secret.": "我们使用的是 CLI 命令 wrangler secret。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But then we're going to put the secret name and it's going to prompt us to give the value.": "接着输入机密名称，系统会提示我们输入对应的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's what we're going to do now.": "这就是我们现在要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me copy here the first command.": "让我在这里复制第一条命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and paste it in the terminal.": "然后把它粘贴到终端里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I got an error.": "报错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run it with sudo ntp.": "让我用 sudo ntp 运行一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see that I'm entering the secret value.": "现在可以看到我正在输入机密值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me put it.": "让我把它输进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to create it for my worker.": "它会为我的 Worker 创建这个机密。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see we have here MCP auth zero oidc.": "你可以看到这里有 MCP auth zero oidc。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the name by the way is going to be from the Wrangler JSON file.": "顺便说一下，名称将取自 wrangler.json 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's where it's going to derive the name.": "名字就是从那里获取的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we haven't deployed already the MCP Auth0 Oidc worker.": "现在我们还没有部署 MCP Auth0 Oidc Worker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to be prompted that if we want to create a new worker with that name and add that secret": "所以系统会提示我们是否要以该名称创建一个新的 Worker 并添加该机密",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to it.": "到其中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and.": "让我继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and see what's happening.": "让我们看看发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the worker is being created and the secret was uploaded successfully.": "现在 Worker 正在创建，机密已成功上传。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's continue and add the rest of the environment variables.": "那么让我们继续添加剩余的环境变量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and add the auth client ID here for example.": "例如，让我们在这里添加认证客户端 ID。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to fast forward this section because there isn't anything new here.": "我会快进这一部分，因为这里没有什么新内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me put the rest of the secrets.": "让我把剩下的机密都填好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the node env we don't really need and the API base URL, it's not going to be this value here.": "现在 NODE_ENV 我们其实不需要，而 API 基础 URL 也不会是这里的这个值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It should be the value of the deployed API.": "它应该是已部署 API 的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and add the base URL here.": "让我在这里添加基础 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for the value I'm going to go to Cloudflare.": "至于具体的值，我要去 Cloudflare 查看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to workers here.": "进到这里的 Workers 页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me open that.": "让我打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to take the URL of the todos API here.": "我要获取这里 todos API 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be here in settings we can have here.": "它就在这里的设置中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is our domain.": "这是我们的域名。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the value I'm going to put here instead of this.": "这就是我要填在这里替换掉原本内容的值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and let me put it here.": "让我把它填在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to the worker of the MCP server and let me check that we indeed added the secrets.": "让我去 MCP 服务器的 Worker 页面，检查一下我们是否确实添加了这些机密。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to the MCP worker.": "让我进入 MCP Worker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let's go to settings.": "然后点击这里的设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the secrets that we just uploaded.": "在这里我们可以看到刚刚上传的机密。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go back to the blog and copy the deploy command.": "让我们回到博客，复制部署命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to deploy the actual worker code and it's going to run it.": "这将部署实际的 Worker 代码并运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write sudo pseudo NP and Wrangler deploy.": "让我输入 sudo pseudo NP 和 wrangler deploy。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see I get here an error.": "可以看到我这里报错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we get here a could not resolve.": "我们遇到了一个“无法解析 (could not resolve)”的错误。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this kind of error is usually a missing dependency.": "这种错误通常是由于缺少依赖项引起的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and run npm install to install all of the dependencies that are mentioned in the package.json.": "那么让我运行 npm install 来安装 package.json 中提到的所有依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, the packages were installed and let's go now and try to redeploy it.": "好的，包已经安装完毕，现在让我们尝试重新部署它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run it with sudo.": "让我用 sudo 权限运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that it is starting to deploy it.": "我们可以看到它开始部署了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have successfully deployed now the worker.": "我们现在已经成功部署了 Worker。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to Cloudflare and let's check it out.": "那么让我们去 Cloudflare 检查一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to go back to the workers here.": "我要回到这里的 Workers 页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is now the deployed worker with the code with all the secrets and we can see.": "这就是部署好的 Worker，包含代码和所有 Secrets，我们可以看到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to settings here and we'll get here.": "让我们进入这里的设置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is the URL of the worker.": "这是 Worker 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we are almost done here.": "我们这里快大功告成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There is only one last thing that we need to do.": "还有最后一件事需要处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is to go to auth0 and update the callbacks URL.": "那就是去 Auth0 更新回调 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To also be able to call back to this URL of the deployed MCP server.": "以便能够回调到这个已部署的 MCP 服务器 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to Auth0 and let's do that.": "那么让我们去 Auth0 执行此操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be in our remote MCP server application here.": "这将在我们这里的远程 MCP 服务器应用中进行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to go and we're going to add this URL of the deploy worker.": "我们要去添加这个已部署 Worker 的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we're going to add a comma.": "在这里我们要加一个逗号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we're going to put the value of the worker.": "然后填入 Worker 的地址值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's not forget to add the slash callback in the URL.": "别忘了在 URL 后面加上 /callback。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's it for the configuration.": "配置部分就这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everything should be working fine right now.": "现在一切应该都能正常运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So by now we have the deployed API the deployed MCP server.": "到目前为止，我们已经部署好了 API 和 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next video we're going to test that they are working together with the Cloudflare MCP client": "在下一个视频中，我们将测试它们是否能与 Cloudflare 为我们制作的 MCP 客户端",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:they have made for us.": "配合使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And only then we're going to configure it with Cloud Desktop.": "之后我们才会使用 Cloud Desktop 进行配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To test everything, we'll use the Cloudflare AI playground, which is very similar to the NCP inspector": "为了测试一切，我们将使用 Cloudflare AI playground，它与 NCP 检查器非常相似",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that we ran locally.": "我们在本地运行的那个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this application runs on Cloudflare and they pre-made it for us, so no need to run it locally.": "但这个应用程序运行在 Cloudflare 上，他们已经为我们预制好了，所以不需要在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me just go and open it in a new tab here.": "让我现在就在这里的一个新标签页中打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now to the playground.": "现在让我进入 playground。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right over here we have a very similar view to the NCP inspector.": "就在这里，我们看到了一个与 NCP 检查器非常相似的视图。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So notice we can choose the model that is going to be the engine of this entire client here.": "注意，我们可以在这里选择将作为整个客户端引擎的模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here a chat box which is going to be our interface.": "我们这里有一个聊天框，它将作为我们的界面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me connect now my NCP server.": "现在让我连接我的 NCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice here I'm going to paste the URL of the deployed NCP server here.": "注意，我将在这里粘贴已部署的 NCP 服务器的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and search for my NCP server's URL.": "让我去查找我的 NCP 服务器的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be this address.": "就是这个地址。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I remind you this is the remote NCP server which is going to be our authentication server.": "我提醒你，这是远程 NCP 服务器，它将作为我们的身份验证服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to run on Cloudflare.": "它将在 Cloudflare 上运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to put the endpoint of slash SSH.": "所以我要输入 /ssh 端点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go now and click connect.": "现在让我们点击连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right away we're prompted with the authorization screen where we access the to do API.": "紧接着，我们会看到授权屏幕，我们在那里访问待办事项 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But notice here that the client which is accessing the todos API is going to be the Cloudflare playground": "但请注意，访问 todos API 的客户端将是 Cloudflare playground",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not going to be our inspector running locally here.": "而不是我们在本地运行的检查器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and click Allow Access.": "让我点击“允许访问”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And like before we are redirected to Auth0.": "就像之前一样，我们被重定向到了 Auth0。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and connect here.": "让我们在这里连接。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we successfully connected and are authorized right now.": "我们已成功连接并获得了授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see everything right now in the log here.": "我们现在可以在这里的日志中看到一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example we can see in the log authorization code received.": "例如，我们可以在日志中看到已收到授权码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going now to do this entire flow again exchanging now the authorization code with a JWT token.": "现在它将再次执行整个流程，用授权码交换 JWT 令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But by the end of this cycle here we're going to have a JWT that this playground on Cloudflare is going": "但在这个周期结束时，我们将获得一个 JWT，Cloudflare 上的这个 playground 将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to send after each request.": "在每次请求后发送。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after we have been authorized, we can see all the available tools and we can see who am I.": "在我们获得授权后，我们可以看到所有可用的工具，还可以看到“我是谁”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And these two do's list building.": "以及待办事项列表构建。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and try to run those tools.": "让我们尝试运行这些工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to the chat.": "让我去聊天框。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's right where am I?": "现在输入“我在哪里？”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we get here.": "我们得到了这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:My information after I have been logged in.": "我登录后的信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and try something else.": "让我们尝试点别的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and try to list to dos.": "让我们尝试列出待办事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I can't right here in the text box.": "我无法在这里的文本框中输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think Cloudflare has a small bug.": "所以我认为 Cloudflare 有个小 bug。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me clear up everything.": "让我清理一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go.": "让我来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah I can't right here let me go and clear this.": "是的，我没法在这里输入，让我去清除这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me write again and let me write here.": "让我重新写，写在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:List to dos.": "列出待办事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see now that we got here a response.": "我们现在可以看到得到了一个响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the assistant for some reason didn't write it.": "出于某种原因，助手没有把它写出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But here we can see the raw response which have the to dos.": "但在这里我们可以看到包含待办事项的原始响应。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the tool call went fine.": "所以工具调用没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the client here maybe has a bit bugs.": "但这里的客户端可能有点 bug。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So everything is still working as expected.": "所以一切仍如预期般运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So our NCP server is returning us the list of to dos.": "所以我们的 NCP 服务器正在返回待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me ask for my billing details.": "让我查询一下我的账单详情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here we got an unauthorized response which is good.": "我们可以看到这里收到了一个“未经授权”的响应，这很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what we expected here.": "这正是我们在这里所预期的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the NCP server deployed on Cloudflare is working as expected.": "所以部署在 Cloudflare 上的 NCP 服务器正按预期运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go connect everything to Cloud Desktop with MCP proxy.": "让我们使用 MCP 代理将所有内容连接到 Claude Desktop。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's finish this section.": "让我们完成这一章节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we finished testing our MCP server with the AI playground on Cloudflare.": "我们已经完成了在 Cloudflare 的 AI Playground 上测试我们的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's time to connect it with cloud.": "现在是时候将其与 Claude 连接了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's going to be our MCP host.": "它将作为我们的 MCP 宿主。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to connect it to our remote MCP server.": "我们将把它连接到我们的远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to focus on this part here.": "我们将重点关注这里的这个部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it will include setting up a proxy.": "这将包括设置一个代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the proxy is going to be called remote MCP.": "这个代理将被命名为 remote-mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I know the name is confusing because this is small case remote MCP.": "我知道这个名字很让人困惑，因为它是小写的 remote-mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And our remote MCP over here is um, the literally remote MCP.": "而我们这里的远程 MCP 是……嗯，字面意义上的远程 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I know it's confusing.": "所以我知道这很让人困惑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's call this component the proxy.": "所以让我们把这个组件称为代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and review what we'll be doing.": "让我们来回顾一下我们将要做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So just a quick note here.": "这里先简单说明一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So since this blog was created it changed a bit by the way a lot because of the feedback I gave the": "顺便说一下，自从这篇博客发布以来，由于我给出的反馈，它发生了很多变化，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Auth0 team.": "也就是给 Auth0 团队的反馈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when the blog was created, there weren't any instructions on how to set it up with Claude as the": "当这篇博客创建时，还没有关于如何将其与作为宿主的 Claude",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:host.": "进行设置的说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here you can see that the blog has ended, and when I was making the course, then I relied on the GitHub": "在这里你可以看到博客已经结束了，当我制作课程时，我依靠的是 GitHub",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:repository.": "仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you in the GitHub repository, if you go to the root directory, you can see here some": "让我给你们看看 GitHub 仓库，如果你进入根目录，你可以看到这里有一些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:instructions of setting it up with cloud.": "关于如何与 Claude 进行设置的说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even though those instructions don't mention anything about the remote NCP proxy.": "尽管这些说明中没有提到任何关于 remote-mcp 代理的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And figuring this out took me a bunch of time.": "弄清楚这一点花了我不少时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To be honest, I think it took me almost three hours to figure this out.": "老实说，我想我花了将近三个小时才弄明白。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, but luckily for us, um, the Auth0 team patched it so it's much more clearer now.": "嗯，但幸运的是，Auth0 团队对其进行了修补，所以现在清晰多了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the blog is updated.": "博客也更新了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I also re-edited this video to include this update.": "我也重新编辑了这个视频，把这个更新包含进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the updated blog, which completes the entire architecture with the cloud desktop integration.": "所以这是更新后的博客，它通过 Claude Desktop 集成完成了整个架构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I remind you that because Cloud Desktop currently only works with local connections via Sdio, then": "我提醒一下，因为 Claude Desktop 目前仅支持通过 Stdio 进行本地连接，所以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we need to configure a proxy which is going to communicate with Cloud Desktop via Stdio transport,": "我们需要配置一个代理，该代理将通过 Stdio 传输与 Claude Desktop 通信，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and that proxy is going to make requests to our SSH server, which is deployed on Cloudflare.": "并且该代理将向我们部署在 Cloudflare 上的 SSH 服务器发起请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the configuration you're seeing right now.": "所以这就是你现在看到的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Remote mocp is the proxy.": "Remote-mcp 就是那个代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if you search in Google for MCP remote SW, then you'll find a bunch of repositories of MCP proxies,": "如果你在 Google 中搜索 MCP remote SW，你会发现一堆 MCP 代理的仓库，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which function as the proxy between the MCP host, which can only communicate locally like cloud desktop": "它们充当 MCP 宿主（如只能进行本地通信的 Claude Desktop）",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and the remote MCP servers.": "与远程 MCP 服务器之间的代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is one example which is called Super Gateway, which does exactly that.": "这是一个名为 Super Gateway 的例子，它的功能正是如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go back and we have another project which is called NCP proxy, which does exactly that as well.": "让我们回到刚才，我们还有另一个名为 MCP 代理的项目，它的功能也是一样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about the agent to agent protocol.": "让我们来谈谈代理间协议（Agent-to-Agent Protocol）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The agent to agent A to a protocol is a new open standard initiated by Google Cloud and supported by": "代理间协议（简称 A2A 协议）是由 Google Cloud 发起的一项全新开放标准，并得到了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:over 50 partners, including major tech companies like Salesforce, SAP, Atlassian and Lang Chain.": "超过 50 家合作伙伴的支持，其中包括 Salesforce、SAP、Atlassian 和 LangChain 等主要科技公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The core problem AA addresses is that AI agents, while increasingly used by enterprises, often operate": "A2A 解决的核心问题是，虽然 AI 代理在企业中的应用日益广泛，但它们通常",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in isolation within specific applications or platforms.": "在特定的应用程序或平台内孤立运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They lack a common way to communicate, share information, or coordinate actions with other agents": "它们缺乏一种通用的方式来与其他代理进行通信、共享信息或协调行动，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:built by different vendors or using different frameworks.": "无论这些代理是由不同供应商构建的，还是使用了不同的框架。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:AA provides this common ground.": "A2A 为此提供了共同基础。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It defines a standard way for agents to discover capabilities.": "它定义了代理发现能力的标准方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Agents can advertise their functions so other agents know what they can do.": "代理可以发布其功能，以便其他代理了解它们能做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Manage tasks.": "管理任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Agents can assign and track tasks, including complex long running ones, exchanging status updates": "代理可以分配和跟踪任务，包括复杂的长期运行任务，并交换状态更新",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and results.": "和结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Artifacts collaborate.": "产出物协作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Agents can securely exchange messages containing context instructions or data.": "代理可以安全地交换包含上下文指令或数据的消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Negotiate user experience.": "协商用户体验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Agents can agree on the best format for presenting information e.g. text, images, forms based on the": "代理可以根据用户界面的能力，就呈现信息的最佳格式（例如文本、图像、表单）达成一致，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:user interfaces capabilities built on existing web standards like HTTP and Json-rpc.": "这些能力构建在 HTTP 和 JSON-RPC 等现有网络标准之上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:AA aims to make it easier to integrate collaborative agents into existing IT systems securely.": "A2A 旨在更轻松、更安全地将协作代理集成到现有的 IT 系统中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The ultimate goal is to create an interoperable ecosystem where AI agents can seamlessly work together": "最终目标是创建一个互操作生态系统，让 AI 代理能够无缝协作，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:across different enterprise applications.": "跨越不同的企业级应用程序。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This collaboration is needed to automate complex, multi-step workflows like candidate sourcing and": "这种协作对于自动化复杂的、多步骤的工作流（如候选人搜寻和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:hiring, thereby increasing overall productivity, efficiency, and innovation beyond what isolated": "招聘）是必需的，从而提高整体生产力、效率和创新，超越孤立的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:agents can achieve.": "代理所能实现的水平。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm with Jeremiah Loewen, the creator of fast MCP 2.0.": "我现在和 fast MCP 2.0 的创作者 Jeremiah Loewen 在一起。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Jeremiah, thank you so much for being here and giving the time for us.": "Jeremiah，非常感谢你能来到这里，并为我们抽出时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm so happy to be here.": "我很高兴能来到这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thanks for inviting me.": "谢谢你的邀请。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I would love to hear about your background and what led you to to do with AI?": "所以我很想听听你的背景，以及是什么引导你开始从事 AI 工作的？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Of course.": "当然可以。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so once, once upon a time, I guess I'm a reformed data practitioner.": "呃，很久以前，我想我是一个“转型”的数据从业者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So once upon a time, I was a data scientist.": "很久以前，我是一名数据科学家。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I was an ML guy, I worked in Buyside finance, and, um, I just had 1,000,001 things going on.": "我曾是一名机器学习工程师，在买方金融机构工作，当时我有处理不完的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so I became very interested in software for automating, which led me to become a member, first": "于是我对自动化软件产生了浓厚的兴趣，这引导我首先成为了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the airflow team and then later to start my company prefect, which makes orchestration software": "Airflow 团队的一员，后来创办了我的公司 Prefect，专门开发编排软件",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for data engineers and data scientists.": "为数据工程师和数据科学家服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so what I spend most of my time doing is thinking about the most complex things people are doing": "所以我大部分时间都在思考人们在职业生涯中所做的最复杂的事情，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in their professional lives, and then trying to build developer experiences and tools for making them": "然后尝试构建开发者体验和工具，使这些事情",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:straightforward and simple and easy.": "变得直观、简单且容易。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so over the last few years, um, I'm fascinated by everything in the AI space and the evolution": "在过去的几年里，嗯，我被 AI 领域的一切以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of that for my ML days.": "从我从事机器学习以来的演变所深深吸引。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we've, we've, we've experimented at prefect with various agent frameworks and different ways of": "我们在 Prefect 尝试了各种智能体框架，以及在不同工作流中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:getting information in front of people in different workflows.": "将信息呈现在人们面前的不同方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so when, when, uh, when the MVP was announced last last winter, I think in last November, I": "所以当去年冬天，我想是去年 11 月，MCP 发布时，我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:was really excited about it.": "感到非常兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I wanted to try it.": "我想尝试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I wanted to see if we could plug it into some of our stuff.": "我想看看我们是否能把它接入到我们的一些产品中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But when I went to use it, I was sort of astounded at the amount of boilerplate that it took to stand": "但当我开始使用它时，我被搭建一个服务器所需的样板代码量",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:up a server, and it seemed like, yes, the protocol was there and was probably effective, but, um,": "惊呆了。看起来协议确实存在且可能有效，但是，嗯，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it just didn't feel like, like, uh, like the Python developer tools that I, that I'm used to, that": "它感觉不像是我习惯的那种 Python 开发者工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I, that I've come to expect, uh, excellence from.": "也不符合我对卓越工具的预期。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we built the first version of fast MVP just to apply those, those idioms, those expected things": "所以我们构建了 fast MCP 的第一个版本，就是为了将那些惯用法和预期功能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:over the protocol and just make it as fast as possible to just start experimenting with it.": "应用到该协议之上，并使其尽可能快地开始实验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because remember, back at the end of last year, nobody even knew what this was for.": "因为记得在去年年底，甚至没有人知道这是用来做什么的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It wasn't even compatible with any agency.": "它甚至不兼容任何智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You couldn't actually do anything with it even.": "你甚至无法用它做任何实际的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so I just thought speed was the most important thing to promote.": "所以我认为速度是推广中最重要的因素。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's why that's why we grabbed like, fast NCP as the name.": "这就是为什么我们选择了 fast MCP 作为名字。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, and so that that's how that was what brought me into the NCP world and started, you know, I got": "呃，这就是我进入 MCP 世界的原因，并开始，你知道，我得以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to meet folks and the folks, uh, steering the protocol and everything.": "结识了一些人，以及那些主导协议开发的人等等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we go to Google now and search for NCP remote, then we can go to this Cloudflare blog here.": "如果我们现在去 Google 搜索 NCP remote，就可以访问这个 Cloudflare 博客。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is an adapter which also does this.": "这是一个也具备此功能的适配器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and click it.": "让我点击它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have an exclamation on it.": "这里有一个关于它的感叹号。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the official npm package in case we want to download it.": "如果我们想下载它，这就是官方的 npm 包。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see here this is the repository and this is how we install it.": "我们可以看到这里是代码仓库，以及如何安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we'll be doing it very very soon.": "我们很快就会进行安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will be the proxy that is going to communicate with Cloud Desktop with our remote MCP.": "这将是与 Cloud Desktop 以及我们的远程 MCP 进行通信的代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, I did find it quite strange that Cloud Desktop, which is supposed to be the flagship MCP": "顺便说一下，我确实觉得挺奇怪的，Cloud Desktop 本应是旗舰级的 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:client, sorry, MCP host.": "客户端，抱歉，是 MCP 主机。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I was quite confused that it doesn't support remote SEC natively.": "所以我很困惑它竟然原生不支持远程 SEC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is something the MCP team are working on.": "这是 MCP 团队正在努力解决的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they're working on something which is called Streamable HTTP, which is going to be supported by": "他们正在开发一种名为 Streamable HTTP 的技术，它将由",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Cloud Desktop and will support making connections to remote MCP servers deployed in the cloud and not": "Cloud Desktop 支持，并将支持连接到部署在云端而非",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:running locally.": "本地运行的远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this will be updated once this is going to be formalized and once it's going to be released.": "一旦该技术正式确定并发布，这里将会进行更新。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I will be updating the course on this topic.": "因此，我将更新关于这个主题的课程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and copy the installation command.": "让我去复制一下安装命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm simply going to copy that and let me open my terminal and let me go and install it.": "我直接复制它，然后打开终端进行安装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run it a with sudo.": "让我用 sudo 运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's installed.": "安装完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's.": "那么让我们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right which MCP remote to get the full path here.": "输入 which MCP remote 来获取这里的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not found.": "没找到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and install it globally.": "那我们来全局安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If I run the same command with the minus G flag.": "如果我运行带有 -G 标志的相同命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me try and write which MCP remote.": "现在让我试着输入 which MCP remote。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the path to the binary that is going to run our proxy.": "这就是运行我们代理的二进制文件的路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in order to configure Cloud Desktop we need to open the Cloud Desktop config.json file like we did": "为了配置 Cloud Desktop，我们需要打开 Cloud Desktop 的 config.json 文件，就像我们在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the course.": "课程中所做的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we need to put this MCP server as following.": "我们需要按如下方式添加这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be called to DOS.": "它将被命名为 to DOS。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The command is going to be NP.": "命令将是 NP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the argument here is going to be MCP remote.": "这里的参数将是 MCP remote。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can put here the full path of the binary of the MCP remote.": "你可以在这里填入 MCP remote 二进制文件的完整路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then the second argument is going to be the URL of the SSC server.": "然后第二个参数将是 SSC 服务器的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The URL of the remote MCP server, which is going to be eventually called.": "即最终将被调用的远程 MCP 服务器的 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and restart cloud.": "现在让我去重启 Cloud。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me open it.": "让我打开它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And see we are instantly being redirected to our Auth0 authorization consent screen.": "看，我们立即被重定向到了 Auth0 授权许可页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to ask to allow the MCP proxy to access the todos API with the permissions and scopes": "它会询问是否允许 MCP 代理访问具有相关权限和范围的 todos API",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that we talked earlier.": "，也就是我们之前讨论过的那些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be the callback here of the MCP proxy here.": "这将是 MCP 代理在这里的回调。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and allow access.": "让我们允许访问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to forward everything also to cloud.": "这也会将所有内容转发到 Cloud。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go click allow.": "让我们点击允许。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can now go and close it.": "我们现在可以关闭它了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it will check.": "现在它会进行检查。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see now all of our MCP tools that are MCP server are our remote MCP server exposed.": "我们现在可以看到，作为 MCP 服务器的所有 MCP 工具，即我们的远程 MCP 服务器，都已经暴露出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and let me test it.": "那么现在让我去测试一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's write who am I?": "让我们输入 who am I？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and allow for this chat.": "让我去允许这个对话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's listing my information because I logged in with my user.": "它正在列出我的信息，因为我用我的用户账号登录了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what are my to do's.": "还有我的待办事项是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to ask again for a permissions to invoke this tool.": "所以它会再次请求调用此工具的权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is quite slow but eventually it does actually prompt it.": "这相当慢，但最终它确实弹出了提示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we made a request to the remote MCP server with the tools.": "在这里，我们向带有这些工具的远程 MCP 服务器发送了一个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and ask what is my billing report.": "让我们去问一下我的账单报告是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be an unauthorized access.": "这将是一个未经授权的访问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm not expecting it to work.": "所以我不指望它能成功。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And boom, we don't have enough access to do it.": "果然，我们没有足够的权限来执行此操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we worked with that team and they took the fast MCP 1.0 code, and they moved it into the, you": "于是我们与那个团队合作，他们采用了快速的 MCP 1.0 代码，并将其移入了，你知道，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:know, we relicensed it for this purpose, and they took it and put it into the official SDK.": "知道吧，我们为此目的重新授权了它，他们将其放入了官方 SDK 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's been there for a while, but then it, uh, it hasn't changed very much.": "它在那里已经有一段时间了，但后来，呃，它并没有太大的变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's still substantially the same code that I wrote last November.": "它基本上还是我去年 11 月写的那些代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, part of the reason that there's a V2 now and that we created a separation is so that we can just": "呃，现在有 V2 版本以及我们创建分离的部分原因是，这样我们就可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:experiment and iterate and build the high level structures that I don't think are appropriate or have": "进行实验、迭代并构建那些我认为不适合或不应该",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a place in a, in a protocol SDK.": "出现在协议 SDK 中的高层结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, but yeah, the two projects started when you see fast MVP, you are seeing that same thing with": "嗯，但是是的，这两个项目开始了，当你看到 fast MVP 时，你看到的是同样的东西，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the same origin point in my repo from last November.": "它们有着相同的起点，都源自我去年 11 月的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, so this is super interesting.": "好的，这非常有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I didn't know that.": "我以前不知道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And.": "还有。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And how was it like in there right now?": "现在在那里的情况怎么样？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Working with the anthropic team?": "和 Anthropic 团队合作的感觉如何？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, because they maintained the protocol.": "呃，因为协议是由他们维护的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you have sort of a I wouldn't say, um, a competitive, uh, SDK, but it's very popular, you": "而你拥有一个，我不会说是……嗯，竞争性的 SDK，但它非常受欢迎，你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:know, and, and people really like using it.": "知道的，而且人们真的很喜欢用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Certainly not certainly not a competitive SDK.": "当然不是，当然不是竞争性的 SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, fast Mcrp two imports the SDK and anything that's in that SDK we are not trying to re-implement.": "呃，FastMCP 导入了该 SDK，而该 SDK 中的任何内容我们都没有尝试重新实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are trying to put a nice developer experience on it.": "我们正努力在其之上提供良好的开发体验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are really focused on building the high level features that are for the application ecosystem around": "我们真正专注于构建围绕 MCP 的应用生态系统的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP.": "MCP 的生态系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and if we find, for example, bugs in the SDK, we want to go fix them in the low level SDK.": "嗯，例如，如果我们发现 SDK 中的错误，我们希望去底层 SDK 中修复它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, in a different world where we weren't so aggressively pursuing the high level user facing functionality,": "嗯，在另一个我们没有如此积极地追求面向用户的高级功能的世界里，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I could imagine there being some confusion or something like that.": "我可以想象可能会有一些混淆之类的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, and like day one of this, I was a little worried.": "而且，就像刚开始的第一天，我还有点担心。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe there'll be some confusion, but the other objects that are in the official SDK at this point,": "也许会有一些混淆，但目前官方 SDK 中的其他对象，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know.": "我不知道。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Candidly, it's it's work.": "坦率地说，这是工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's work from six months ago, from a state of MCP and expectations about how you would work with XP": "这是六个月前的工作，基于六个月前 MCP 的状态以及对如何使用 MCP 的预期",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from six months ago.": "——那是六个月前的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's successful because the core primitives are the same resources, prompts, tools, templates.": "它之所以成功，是因为核心原语是相同的：资源、提示词、工具、模板。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yeah, but it is such a different like way of working with MCP at this point.": "是的，但目前使用 MCP 的方式已经大不相同了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The majority of folks that we encounter on MCP, excuse me, on past MCP two, are doing things like": "我们在 MCP 上——抱歉，是在 FastMCP 上——遇到的大多数人都在做诸如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:proxying remote servers.": "代理远程服务器之类的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're working with partners now who are dynamically generating servers.": "我们现在正与一些动态生成服务器的合作伙伴合作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're starting to talk about orphaned permissions on a per route basis.": "我们开始讨论基于每个路由的孤立权限。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP middleware is an exciting thing.": "MCP 中间件是一件令人兴奋的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's all this like high level stuff.": "有很多这类高级的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once you have a server to talk about, that's super exciting.": "一旦你有了可以讨论的服务器，那就非常令人兴奋了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't I don't view them as a real choice here.": "我不认为它们在这里是一个真正的选择。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think if you just want to get started, by all means use the official SDK.": "我认为如果你只是想入门，完全可以使用官方 SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's right there if you want to work with these objects.": "如果你想使用这些对象，它就在那里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sort of as an application developer, I think that's what Mtp2 exists to do.": "作为一名应用开发者，我认为这就是 FastMCP 存在的意义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very similar to the relationship between fast API and starlet, where starlet is where you would go": "非常类似于 FastAPI 和 Starlette 之间的关系，Starlette 是你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:if to really interact with the low level objects in the protocol.": "真正与协议中的底层对象交互的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I like fast API is where anyone who's just an application developer who doesn't want to care about that": "我觉得 FastAPI 是任何只想做应用开发、不想关心那些底层细节的人",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:would would spend their time.": "会花时间的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about the name for a second.": "我们来谈谈这个名字。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Okay, because when I saw the name fast, I was sure that the server is implemented with fast API was": "好的，因为当我看到 Fast 这个名字时，我确信服务器是用 FastAPI 实现的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:sure.": "我当时非常确信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I bet you get it many times.": "我敢打赌你听过很多次这种说法了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this one, this.": "还有这个，这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So?": "所以呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I now want to dive a bit.": "所以现在我想深入探讨一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's talk about business use cases maybe.": "也许我们可以聊聊商业用例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then I would like to talk shortly about features and you know, more technical stuff like OAuth": "然后我想简要谈谈功能，以及你知道的，更技术性的东西，比如 OAuth",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:2.1 uh, like bearer tokens, integration, some of SMTP.": "2.1，呃，比如持有者令牌（bearer tokens）、集成，以及一些关于 SMTP 的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I have a question for you.": "我有一个问题想问你。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a lot of people are saying that MCX are going to be the new SAS.": "所以很多人都在说 MCX 将成为新的 SaaS。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, so that is a people can create micro, micro SAS and simply, you know, API's which they can expose": "呃，也就是说人们可以创建微型、微型 SaaS，以及简单的 API，并将其公开",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:through MCX.": "通过 MCX。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then their major consumers are going to be LMS or agents.": "然后它们的主要消费者将是 LLM 或智能体（agents）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so what do you think about this MCP economy?": "嗯，那么你如何看待这种 MCP 经济？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do you see a future in it.": "你觉得它有未来吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do you think it's here to stay?": "你认为它会长期存在吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What do you think the future holds in this case?": "你认为在这种情况下未来会怎样？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I see I see a huge a huge future in it.": "我看到了，我看到了它巨大的前景。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I won't go so far as to say it like, replaces everything, but I think it absolutely is a new ecosystem": "我不会夸大到说它会取代一切，但我认为它绝对是一个全新的生态系统，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of how software is developed.": "关于软件是如何开发的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you think about SaaS as a business, SaaS is sort of I took my business logic, I put it behind an": "如果你把 SaaS 看作一种业务，SaaS 就像是我把业务逻辑放在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:API, and then I resold the business logic as software.": "API 之后，然后将该业务逻辑作为软件转售。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's.": "所以就是这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So instead of humans doing it, as you said, it's now it's agents.": "所以正如你所说，现在不再是由人类来操作，而是由智能体来操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think MCP is probably going to be just de facto the right way to do that.": "我认为 MCP 可能会成为实现这一目标的行业标准方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we could have a long argument about do we need another API and does it have to be MCP.": "我们可以就‘我们是否需要另一个 API’以及‘它是否必须是 MCP’进行长篇争论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And could it be we could have a lot of arguments about that.": "关于这一点，我们可以有很多争论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But in tech things tend to work or not work just because people are using them or not using them, not": "但在技术领域，事物的成败往往取决于人们是否在使用它们，而不是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because it's the perfect thing.": "因为它是否完美。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think MCP is the thing that people are coalescing around.": "我认为 MCP 正是人们正在聚集并达成共识的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so absolutely, I agree with this.": "所以绝对地，我同意这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are doing a lot of work right now to put tools in front of people to make that possible.": "我们现在正在做大量工作，为人们提供工具，使之成为可能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So one of our visions, we're going to introduce a fast SMTP cloud service in the near future.": "所以我们的愿景之一是，我们将在不久的将来推出一个快速的 SMTP 云服务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and one of our visions for it is even on its free tier is to make sure that people can distribute": "嗯，我们对它的愿景之一是，即使是在免费层级，也要确保人们能够分发",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers, charge people for those MCP servers, build businesses around those MCP servers as easily": "MCP 服务器，为这些 MCP 服务器收费，并围绕这些 MCP 服务器尽可能轻松地建立业务，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:as possible because that infrastructure has to exist.": "因为这种基础设施必须存在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by virtue of putting this high level interface in the world, we just happen to be as close as possible": "通过向世界提供这种高级接口，我们恰好能尽可能地接近",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to all these users so we can figure out what they like.": "所有这些用户，这样我们就能弄清楚他们喜欢什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What tools do they need?": "他们需要什么工具？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is again the graduation of we have a low level protocol okay.": "这又是从‘我们有一个底层协议’的阶段晋升。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And a fast SMTP one for interfacing with it.": "以及一个用于与其对接的快速 SMTP 1。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Fine if fast SMTP two for building the application layer of MCP.": "如果用快速 SMTP 2 来构建 MCP 的应用层也行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we need some way to distribute and monetize these things so that this is the question I had": "现在我们需要某种方式来分发这些东西并从中获利，所以这就是我脑海中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I had in my head.": "一直存在的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I was thinking like why it's so hard, I mean, to take an MCP and to deploy it.": "所以我一直在想，为什么部署一个 MCP 会这么难。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then if you want to, to implement all you know, it gets it gets clunky.": "然后如果你想实现所有功能，你知道的，它会变得非常笨重。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So developers don't like implementing auth.": "所以开发者不喜欢实现身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And actually I showed you in the course like how to use Auth0 for a for authentication authentication,": "实际上我在课程中向你展示了如何使用 Auth0 进行身份验证，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:accessing a a protected API.": "访问受保护的 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a pain right.": "这很痛苦，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nobody likes to do it.": "没人喜欢做这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I was thinking how come there isn't a company or like a paid service where I can simply put my business": "我就在想，为什么没有一家公司或者付费服务，能让我简单地把我的业务",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:logic, my MCP server that does X.": "逻辑放上去，比如我那个执行 X 任务的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know, it checks the price of Tesla and uh, and have, you know, the infrastructure for rate": "比如检查特斯拉的价格，并且，你知道，拥有用于速率",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:limiting for consumption and generating API keys and, and for people to start, you know, integrating": "限制消费、生成 API 密钥的基础设施，并让人们开始，你知道，将其集成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it into the LMS, you know.": "到 LMS 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I think it's.": "所以我觉得。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Is there an ETA when it's going to be released.": "有预计发布时间吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That'd be the first one to to try.": "我会是第一个尝试的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Almost certainly.": "几乎可以肯定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Almost certainly by the time anybody listens to it it'll be released.": "几乎可以肯定，当有人听到这段对话时，它已经发布了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:As we're recording this.": "在我们录制这段视频时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The alpha should go out in about 4 or 5 days.": "Alpha 版本应该会在 4 到 5 天内发布。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Amazing, amazing.": "太棒了，太棒了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's very cool.": "那太酷了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Very soon.": "很快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, will it do all of these things?": "那么，它能实现所有这些功能吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yes, eventually.": "是的，最终会实现的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The goal right now is to make it as like, right now, we're not even thinking about the ecosystem of": "现在的目标是让它，目前我们甚至还没考虑到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Right now we're thinking about yesterday or two days ago as we're recording this.": "现在我们考虑的是，就在我们录制这段视频的昨天或前天。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ChatGPT got support for MCP servers.": "ChatGPT 获得了对 MCP 服务器的支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The single biggest agentic like user interface in the world has support for MCP servers, and they have": "全球最大的智能体化用户界面已经支持 MCP 服务器，而且它们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be remote and they have to be authenticated.": "必须是远程的，并且必须经过身份验证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a bit of history, but a when cloud desktop.": "这说来话长，是关于 Claude Desktop 那时候的事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I mean, cloud desktop is supposed to be like the ideal client in my opinion, right?": "我的意思是，在我看来，Claude Desktop 应该是那种理想的客户端，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because it's from anthropic and they they came out with the NAACP.": "因为它出自 Anthropic，而且他们推出了 MCP（注：原文 NAACP 疑似 MCP 之误）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so in the first integration with a, with a cloud desktop and a remote, uh, you had to use like,": "嗯，所以在 Claude Desktop 和远程端的第一次集成中，你必须使用类似...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a proxy, right?": "代理的东西，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And and it was it was like I was thinking like, why?": "然后我就在想，为什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why it's so hard.": "为什么会这么难。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like, why do we need to set up this proxy?": "比如，为什么我们需要设置这个代理？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And how come it doesn't support, you know, real remote MCC.": "还有为什么它不支持真正的远程 MCP（注：原文 MCC 疑似 MCP 之误）呢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, just wondering your take on that.": "嗯，只是想听听你对此的看法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What I would say is this, I think it's I think it represents the MCP ecosystem is running ahead of": "我想说的是，我认为这代表了 MCP 生态系统的发展已经超前于...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the protocol.": "协议本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And even at anthropic you have, um, you have the team building the protocol itself.": "甚至在 Anthropic 内部，也有负责构建协议本身的团队。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You have the team building cloud desktop, you have the team building cloud web.": "有负责构建 Claude Desktop 的团队，也有负责构建 Claude Web 的团队。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you only looked at what they'd three of them were doing, you would not think there was a protocol,": "如果你只看这三个团队在做什么，你甚至不会觉得存在一个统一的协议，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because they are all doing different things that happen to say MCP.": "因为他们都在做着不同的事情，只是碰巧都叫 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, last week we saw OpenAI announce support in their API.": "嗯，上周我们看到 OpenAI 宣布在他们的 API 中提供支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We saw anthropic announced support in their API, and we saw Gemini announce support in their SDK.": "我们看到 Anthropic 宣布在他们的 API 中提供支持，还看到 Gemini 宣布在他们的 SDK 中提供支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All of them.": "所有的这些。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini didn't require off because it's in the SDK, but anthropic and OpenAI basically said we need": "Gemini 不需要认证（auth），因为它是在 SDK 里的，但 Anthropic 和 OpenAI 基本上都说我们需要...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:bearer tokens, um, in the API, which is fine and very expected for any service that needs to be authenticated.": "API 中的 Bearer 令牌，这没问题，对于任何需要身份验证的服务来说，这都是意料之中的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the MCP spec says it has to be an OAuth handshake has to be no, no like bearer off, just OAuth": "但 MCP 规范规定必须是 OAuth 握手，不能有类似 Bearer 认证的东西，只能是 OAuth...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:handshake.": "握手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yes, there's a nice cop out.": "是的，这里有一个巧妙的规避方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you're a vendor, that means you only have to take a header that takes a token because it should": "如果你是一个供应商，这意味着你只需要接收一个包含令牌的请求头，因为它应该是...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:be an OAuth access token.": "一个 OAuth 访问令牌。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But you you can't have an OAuth handshake be required for these programmatic service.": "但你不能要求这些编程服务必须进行 OAuth 握手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like that's not how this works.": "事情不是这样运作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's not how server to server interfaces work.": "服务器对服务器的接口不是这样工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so you have this moment where the protocol doesn't permit the type of auth that's appropriate for": "所以就出现了协议不允许采用那种适用于...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the way the industry is actually using MCP.": "行业实际使用 MCP 方式的认证类型的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so you have to go off book.": "因此，你不得不脱离规范。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so in MCP we introduce server side like simple server side auth.": "所以在 MCP 中，我们引入了服务器端认证，比如简单的服务器端认证。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the release we did last week 2.6.": "在我们上周发布的 2.6 版本中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We didn't start with OAuth though.": "不过我们并没有从 OAuth 开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We started with bare auth.": "我们是从 Bearer 认证开始的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Strictly speaking that means that we did something that's not like prescribed or compliant with the": "严格来说，这意味着我们做了一些不符合或不遵循...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP spec.": "MCP 规范的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is one of the things where I don't think this could be done, for example, in the official": "这就是我认为无法在官方仓库中完成的事情之一，例如，在官方的...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:repo with their version of MCP, because you can't go off protocol, you can't go off spec, but the": "仓库中使用他们的 MCP 版本，因为你不能违背协议，不能违背规范，但是...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:industry is using token based auth not requiring the OAuth handshake.": "行业正在使用基于令牌的认证，而不是要求 OAuth 握手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I don't know how you would require the OAuth handshake for for programmatic access.": "我不知道如何针对程序化访问强制执行 OAuth 握手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we had to make a decision.": "所以我们必须做出决定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do we implement first the thing that's in spec?": "我们是先实现规范中的内容？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or do we implement first the thing that people are using and every single time, as a developer tool,": "还是先实现人们正在使用的东西？作为开发者工具，每一次，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I will build the thing people want to use, not the thing that a document says they should use.": "我都会构建人们想要使用的东西，而不是文档说他们应该使用的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so this is one of those cases where you're having this fracturing.": "所以这就是出现这种分歧的情况之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Your people are running ahead of it.": "你们的人跑在了规范前面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh ChatGPT.": "呃，ChatGPT。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yesterday, um, does support OAuth as one of the protocols.": "昨天，嗯，它确实支持将 OAuth 作为协议之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it makes sense.": "这很有道理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a human using it in a, in a browser or through a, through a desktop app.": "这是一个在浏览器或通过桌面应用使用它的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There's an opportunity to, to have that handshake.": "有机会进行那种握手。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we're going to ship that very soon in fast MVP as well to support that.": "所以我们很快也会在 fast MVP 中发布该功能以支持它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is this is I think the growing pains of a young and popular protocol is just because it's written": "但我认为这是一个年轻且流行的协议在成长过程中的阵痛，仅仅因为它是写在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in a document, doesn't mean the industry will follow it.": "文档里的，并不意味着行业就会遵循它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Just because the industry is doing something doesn't mean it's even best practice.": "仅仅因为行业正在做某事，并不意味着它就是最佳实践。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have to find ways to bridge those gaps as a high level tool, and those are probably where we sort": "作为高级工具，我们必须找到弥合这些差距的方法，而这些可能正是我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of agonize over some of the decisions we're making in fast MVP, because there's no right or wrong here.": "在 fast MVP 中对某些决策感到苦恼的地方，因为这里没有对错之分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And regarding that, and do you think in the future vendors, for example, notion um, which they have": "关于这一点，你认为未来供应商，例如 Notion，嗯，他们有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think official MCC but they're not managed right.": "我认为有官方的 MCC，但它们不是托管的，对吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they're not like managed MCP servers that you can call remotely with a Streamable http, uh, for": "所以它们不像托管的 MCP 服务器，你可以通过可流式传输的 HTTP 远程调用，呃，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:example, you have to run them locally as far as I remember.": "例如，据我所知，你必须在本地运行它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, and it's, it's not something that they host in their cloud.": "而且，这不是他们在云端托管的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not like an API they expose.": "也不像他们暴露的 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Do you think in the future every company, every vendor, like they maintain an API, they will maintain": "你认为未来每家公司、每个供应商，就像他们维护 API 一样，他们也会维护",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an MCC server?": "一个 MCC 服务器吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I absolutely think so.": "我绝对是这么认为的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, I think every company will have an API, and right next to it they'll have an MCC server, maybe": "嗯，我认为每家公司都会有一个 API，紧挨着它，他们会有一个 MCC 服务器，也许",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the same.": "甚至是同一个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, we have a lot of tools in MCC for automatically taking an existing API and exposing it as an MCC": "嗯，我们在 MCC 中有很多工具，可以自动获取现有 API 并将其暴露为 MCC",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server, and that's actually tooling for customizing that and overriding those things programmatically,": "服务器，实际上还有用于自定义和通过编程方式覆盖这些内容的工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like taking a a swagger file, for example, a spec a swagger stick.": "比如获取一个 Swagger 文件，例如，一个规范，一个 Swagger 规范。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Exactly.": "没错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It'll take any open API spec and a client.": "它会接收任何 OpenAPI 规范和客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you hand the server those two things, it will auto generate all of the tools and resources that": "如果你把这两样东西交给服务器，它将自动生成所有的工具和资源，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then call the call for you.": "然后为你执行调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what we're working on right now would probably be the 2.8 release in the next few days, is tools": "我们现在正在做的，可能是未来几天发布的 2.8 版本，是用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:for customizing that.": "自定义该功能的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because what we're finding is an API that's designed for humans or programmatic access is not.": "因为我们发现，为人类或程序化访问设计的 API 并不是（为智能体设计的）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very surprising when it's also optimized for agentic access and to have the right instructions": "当它同时也为智能体访问进行了优化，并拥有正确的指令时，是非常令人惊讶的，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and call this and then call this because you sort of assume whoever's going to call it programmatically": "比如“调用这个，然后调用那个”，因为你通常会假设任何以编程方式调用它的人",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:knows how to call it.": "都知道如何调用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You don't need to put all the instructions in with an agent.": "你不需要在智能体中放入所有的指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You need instructions.": "你需要指令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we have a lot of stuff we're working on so people can take a existing API, customize it like": "所以我们正在开发很多东西，让人们可以采用现有的 API，并对其进行自定义，比如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:adding instructions and stuff without having to write a bunch of Python code that just wraps it.": "添加指令之类的，而无需编写大量 Python 代码来对其进行封装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we expose that to their agents, which I think is super cool.": "然后我们将这些暴露给他们的智能体，我觉得这超级酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I do think, I do think all companies will have this, I don't I wasn't part of the decision for": "但我确实认为，我确实认为所有公司都会拥有这个，我并没有参与关于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this.": "这个的决策。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't fully understand the motivation for local for the standard in standard out approach to running,": "我并不完全理解在本地运行中使用标准输入输出方式来运行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:um, MCP servers locally.": "嗯，本地 MCP 服务器的动机。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know if that was a pragmatic decision because anthropic wouldn't allow it any other way in cloud": "我不知道这是否是一个务实的决定，因为 Anthropic 在云端不允许以任何其他方式进行，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know what that was, but, uh, if I, if I were, if it were me and I don't have all the knowledge": "我不知道那是怎么回事，但是，呃，如果是我，虽然我并没有掌握所有的知识",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to even make this claim.": "来做出这种断言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But just for once, if it were me, HDP would be the only transport and you would just run it locally": "但就这一次，如果是我，HTTP 将是唯一的传输方式，如果你需要在本地运行，就直接在本地运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:if you needed it locally.": "如果你需要在本地运行的话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because, you know, it does bring lots of security concerns.": "因为，你知道，这确实带来了很多安全隐患。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You know, with all the open sources, tons of supply chain attacks can happen.": "你知道，随着所有的开源，可能会发生大量的供应链攻击。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So yeah, most people have I, I have the pleasure now of talking with so many users of MCP.": "所以，是的，大多数人——我现在很高兴能与这么多 MCP 用户交流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The vast majority of them do not know that when they install an MCP server in, for example, Cloud": "他们中的绝大多数人都不知道，当他们在（例如）Claude",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Desktop, they are downloading it with, you know, and running that code.": "Desktop 中安装 MCP 服务器时，他们正在下载并运行那些代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They don't know that.": "他们不知道这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if if it were anything else.": "如果是换做其他任何东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It is almost a guarantee that their companies would not allow them to do that, right?": "几乎可以肯定，他们的公司是不会允许他们那样做的，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yeah for sure.": "是的，确实如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it is critically important that we advance remote authenticated servers as quickly as possible.": "因此，我们尽快推进远程身份验证服务器至关重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, a random question.": "嗯，一个随机的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So by the way, so when a the vendors, for example, OpenAI and Google with Gemini said that they're": "顺便问一下，当那些厂商，比如 OpenAI 和谷歌的 Gemini，说他们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to support a MCP in their SDK for their llms.": "将在他们的大模型 SDK 中支持 MCP 时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means that like for example, Gemini, you you have a built in search tool that uses Google": "这是否意味着，比如 Gemini，你有一个使用谷歌",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:search.": "搜索的内置搜索工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this means you can simply attach a remote MCP server.": "这意味着你可以简单地连接一个远程 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when you initialize the the LLM, the client and it simply can can choose it like, like a regular": "当你初始化大模型客户端时，它可以像选择普通",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tool, like with frameworks like lang chaining would use.": "工具一样选择它，就像使用 LangChain 之类的框架一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, I'm kind of.": "嗯，我有点……",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The reason I'm saying kind of is they, they made a very odd decision in the Gemini SDK, which I don't.": "我之所以说“有点”，是因为他们在 Gemini SDK 中做了一个非常奇怪的决定，我不……",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Again, the developer tooling side of me doesn't fully understand why they did this.": "同样，从开发者工具的角度来看，我并不完全理解他们为什么要这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What you do is you pass the agent a low level like protocol level client session object, and then what": "你所做的是向智能体传递一个底层的、协议级别的客户端会话对象，然后",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it does is basically what what they what all of the vendors do right now is the first thing they do": "它所做的基本上就是目前所有厂商都在做的事情，他们做的第一件事",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is they get that object they call list tools, they get a list of all the tools, and then they just": "就是获取该对象，调用 list tools，获取所有工具的列表，然后他们只是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:add them to the agents tool list.": "将它们添加到智能体的工具列表中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's basically what's happening.": "基本上就是这么回事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We could debate that.": "我们可以对此进行辩论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's not even real.": "那甚至不是真实的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not even like native MCP.": "而且它甚至不像原生的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But there's nothing wrong with it.": "但这也没什么错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's still getting to the same place.": "它最终还是达到了同样的目的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Who is making the call though, to the MCP server?": "不过，是谁在向 MCP 服务器发起调用呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The agent will do it.": "智能体会去做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The first thing that happens before the agent is like spun up and allowed to make autonomous decisions.": "在智能体启动并被允许做出自主决策之前，发生的第一件事是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The Gemini SDK makes a call to the MCP server and then gives the agent a list of tools.": "Gemini SDK 向 MCP 服务器发起调用，然后给智能体一个工具列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if the agent or it's the LLM because when I like, for example, because with search and in Google": "但如果是智能体或者 LLM，因为当我，例如，因为有了搜索，在 Google 搜索和 Gemini 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:search and Gemini.": "搜索和 Gemini。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Gemini is an LLM.": "Gemini 是一个 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, yes.": "嗯，是的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's so it's it's like it basically what they're doing is if I'm if tell me if I'm answering a different": "所以这就像是，基本上他们所做的是——如果我，如果我回答的是另一个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:question.": "问题，请告诉我。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What you're asking.": "你所问的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But basically what they're doing is they are making the fact that it's almost invisible to the agent": "但基本上他们所做的是，让这一切对智能体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or even the LLM.": "甚至对 LLM 来说几乎是不可见的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What they are doing is the programmatically, they are getting a list of all the tools and then just": "他们所做的是通过编程方式获取所有工具的列表，然后直接",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:slamming them into the to the llms like toolkit.": "把它们塞进 LLM 的工具箱里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, as if MCP didn't exist.": "就像 MCP 不存在一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then, then handing all of that information to the agent to start its gigantic loop and actually": "然后，将所有这些信息交给智能体，开始其巨大的循环，并实际",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:make decisions to call those tools.": "做出调用这些工具的决策。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right next to the Google search tool will be the, uh, what was it, check, check the stock price": "所以在 Google 搜索工具旁边，就会有，呃，叫什么来着，检查股票价格的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tool that you wrote and turn off the lights in your house tool.": "你写的工具，以及关闭家里电灯的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it'll just see them as tools.": "它只会把它们看作工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the protocol is handling the MCP actual communication.": "而协议则负责处理 MCP 的实际通信。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But this is why a lot of the vendors today, they only support, um, MCP tools.": "但这就是为什么今天很多厂商只支持，嗯，MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They don't support prompts or resources, which again, is like problematic because if all we're doing": "他们不支持提示词（prompts）或资源（resources），这同样是有问题的，因为如果我们所做的只是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is making function calls, do we really need MCP for that?": "进行函数调用，我们真的需要 MCP 吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know if we did.": "我不知道我们是否真的需要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, yeah, that.": "嗯，是的，就是那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is one of those things where maybe if we go back in time and we realize how popular it's going": "这就是那种事情，也许如果我们回到过去，意识到它会变得多么受欢迎，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be, we spend more than one second on the name.": "我们会在起名字上多花不止一秒钟的时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What, what.": "什么，什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The reason it's called fast is because the developer experience of fast API is the standard way to build": "它之所以被称为 fast，是因为在我看来，Fast API 的开发者体验是构建",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a server, in my opinion, right?": "服务器的标准方式，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Those decorators on a function that has your business.": "在包含业务逻辑的函数上使用那些装饰器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think that's the standard way in Python to build an API.": "我认为那是 Python 中构建 API 的标准方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, prefect is a decorator based platform.": "嗯，Prefect 是一个基于装饰器的平台。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think it's the right way to do it.": "我认为这是正确的方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it was almost tongue in cheek.": "这几乎是带点开玩笑性质的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That fast MVP would be the fastest way to say don't write boilerplate, just use decorators to get the": "Fast MCP 将是表达“不要写样板代码，只需使用装饰器即可获得”的最快方式，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:server you want.": "从而得到你想要的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then of course, it just has taken off.": "然后当然，它就火起来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so you're it's not an unreasonable assumption that it's a fast API base.": "所以你认为它是基于 Fast API 的，这并非不合理的假设。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we've built a lot of great fast API integrations, but it's really about that core developer experience,": "我们构建了许多出色的 Fast API 集成，但核心在于那种开发者体验，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that fast API, I think really just absolutely nailed successfully.": "我认为 Fast API 确实做得非常成功。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I have a question.": "我有一个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What do you think a fast MVP two has that resonated so well with developers?": "你认为 Fast MCP 2 有什么特质能引起开发者如此强烈的共鸣？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because the adoption of fast Mrp2, um, I can show it in the editing later.": "因为 Fast MCP 2 的采用率，嗯，我稍后可以在剪辑中展示。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the stars on GitHub.": "还有 GitHub 上的 Star 数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's very popular.": "它非常受欢迎。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what do you think?": "所以你怎么看？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What is the reason for that?": "其中的原因是什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think there's a few things we could we could talk about features, but I actually don't think that's": "我认为有几点，我们可以谈谈功能，但我实际上并不认为那是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the primary reason that open source is is driven.": "驱动开源的主要原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So back when we, when we, when we launched prefect as a product, which is now seven years ago, uh,": "回到我们推出 Prefect 产品的时候，那是七年前了，呃，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my partner Chris and I, who's our CTO, we had a really simple rule for bootstrapping an open source": "我的合伙人 Chris（我们的 CTO）和我，在启动开源项目时有一个非常简单的规则，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:project, and that was that we responded to every issue, PR, whatever it was, we tried to do it in": "那就是我们回应每一个 issue、PR，无论是什么，我们都尝试在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:15 minutes.": "15 分钟内完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that type of responsiveness is a feature of open source software.": "这种响应速度是开源软件的一个特性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Open source software is not about the features, it's about the community and the interactions.": "开源软件不在于功能，而在于社区和互动。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if someone shows up and they're like, hey, fast, MVP doesn't work in some regard, I want to": "如果有人出现并说，嘿，Fast MCP 在某些方面不起作用，我想要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:solve that problem.": "解决那个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to solve it as quickly as possible.": "我想尽快解决它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so this, this, this, um, SLA that we put on responses is one of the things that I tried as much": "所以这种我们对响应设定的 SLA，是我尽力",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:as I could to mirror for MCP, with the small caveat that I'm seven years older.": "在 MCP 中效仿的事情之一，只是有一个小小的限制，那就是我老了七岁。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm the CEO of a developer tools company, and I'm not always able to do it in 15 minutes.": "我现在是一家开发者工具公司的 CEO，并不总是能在 15 分钟内做到。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I wake up now.": "但我现在醒来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:First thing I do is I go read through issues.": "第一件事就是去阅读 issue。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I see if I can respond to anyone, and when I go to bed, the last thing I do is check the issues.": "看看我是否能回复任何人，当我睡觉前，最后一件事也是检查 issue。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think that yes, people really want composition and auth and proxying and clients and testing": "我认为，是的，人们确实想要组合、认证、代理、客户端和测试",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Jeremiah, thank you so much and I want to end up with the thoughts about the future.": "所以 Jeremiah，非常感谢你，我想以对未来的思考来结束。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So where is where is MCP two going to.": "那么 MCP 2 将走向何方？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What's the vision.": "愿景是什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the so the mantra we have for it is we want to be the simplest path to production.": "我们对它的准则是，我们希望成为通往生产环境的最简路径。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So MCP is this new technology.": "MCP 是一项新技术。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We started with the lowest possible level at the protocol.": "我们从协议的最底层开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everyone's trying to figure out what does it mean, how do we bring it into the world.": "每个人都在试图弄清楚它的意义，以及我们如何将其推向世界。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Uh, how do how do, uh, individual users do it?": "呃，个人用户该如何操作？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How do enormous enterprises do it?": "大型企业又该如何操作？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How do you govern it?": "如何治理它？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How do you sell it?": "如何销售它？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All of these questions are yet to be answered, and they all start with someone writing code to expose": "所有这些问题尚待解答，而一切都始于有人编写代码来暴露",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:logic through an FTP server.": "通过 FTP 服务器实现的逻辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's the starting point for everything.": "那是一切的起点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want fast MCP.": "我们希望 FastMCP，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're starting right there to be the simplest way to get that logic into prod.": "从那里开始，成为将逻辑引入生产环境的最简方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then on top of that, with things, uh, that will go in the open source and also things like the": "然后在此基础上，结合将进入开源社区的内容，以及诸如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:commercial product we're building next to it.": "我们正在同步构建的商业产品。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just want to build more and more tooling for people to take control of these things.": "我们只想为人们构建越来越多的工具，以便他们掌控这些事物。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We think this is the next wave of APIs.": "我们认为这是下一波 API 浪潮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:How do we create the simplest path to production across the board for this ecosystem?": "我们如何为这个生态系统全面打造通往生产环境的最简路径？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's the that's the goal.": "这就是目标。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so you're going to see I mean the feature list, the roadmap is like crazy and wild and all over": "所以你会看到，我是说功能列表和路线图非常疯狂、大胆且涵盖了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the place stuff you'd expect around deployment and hosting and auth and and observability, monetization,": "各个方面，包括你所期望的部署、托管、认证、可观测性、货币化，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:even uh, and then some more out there stuff, uh, where we think there are really interesting opportunities": "甚至还有一些更前卫的东西，我们认为在这些领域存在非常有趣的机遇，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to actually have an authentic MVP servers.": "能够真正拥有原生的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're working with some partners on cool stuff there as well.": "我们也在与一些合作伙伴在这些方面开展很酷的项目。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What excites you about the future of MCP in general and agents?": "总的来说，关于 MCP 和智能体（Agents）的未来，什么让你感到兴奋？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I, I, I mean, I'm a user of it, so I'm excited of it because I really want to use it.": "我是说，我自己就是它的用户，所以我很兴奋，因为我真的很想用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's hard right now.": "而现在用起来还挺难的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so my excitement starts really close to home.": "所以我的兴奋点其实非常贴近个人需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm excited for this to be easy.": "我很期待它能变得简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm excited that that I, I spin up a new tool or I spin up a new computer and my my, my memory of": "我很兴奋，当我启动一个新工具或一台新电脑时，我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:my agents comes over my tools for my agents come over.": "智能体的记忆和工具都能随之迁移过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is part of my personal context now.": "这现在已经成了我个人上下文的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, uh, I don't want to set up everything from scratch and sort of hope it works.": "我不想从头开始设置一切，然后寄希望于它能正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So for me, MCP represents an opportunity to, like, take the programmatic interfaces to my world with": "所以对我来说，MCP 代表了一个机会，让我可以带着通往我世界的编程接口，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:me, um, and have them be portable across whatever agent I'm interacting with.": "并且让它们在任何我与之交互的智能体之间具有可移植性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think that's really exciting.": "我觉得这非常令人兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's almost like my identity, um, in a medium term vision of the world.": "在短中期的世界愿景中，这几乎就像是我的身份标识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then honestly, I just get excited about any place where we can build great developer tools.": "坦白说，只要是能让我们构建出色开发者工具的地方，我都会感到兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like that's I'm a tool builder.": "就像，我是一个工具构建者。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's why I wake up to do it.": "这就是我每天醒来工作的动力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's why I'm doing it.": "这就是我做这件事的原因。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That's what I hope to do.": "这就是我希望做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so I get excited at a very, very, very low level on this stuff.": "所以我对这些东西在非常、非常、非常底层的层面上感到兴奋。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When I think about the vision of what it could represent, I think agents are going to be everywhere": "当我思考它所代表的愿景时，我认为智能体（agents）未来将无处不在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the future.": "在未来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I look forward to interacting with them, and I think MCP is how they're going to interact with the": "我期待与它们互动，而且我认为 MCP 是它们与",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:real world.": "现实世界互动的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so that's what gets me excited.": "嗯，所以这就是让我兴奋的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thank you so much for the time.": "非常感谢您抽出时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me finish up with just one last question.": "最后让我以一个问题结束。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:What do you think?": "你怎么看？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And maybe it's a bit off topic, but what do you think about the software development And a what's happening": "也许这有点跑题，但你如何看待软件开发以及现在正在发生的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right now with tools like cursor and the stake of software engineering.": "关于 Cursor 之类的工具以及软件工程的现状。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like as as a software person, where do you think the future going for software engineers?": "作为一个软件从业者，你认为软件工程师的未来将走向何方？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I was I was just having a conversation about this with some CEOs and CTOs this morning, as a matter": "事实上，今天早上我刚和一些 CEO 和 CTO 讨论过这个问题，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of fact.": "确实如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there are people who are all in on like AI as your as your engineering team right now.": "现在有些人完全押注于让 AI 担任你的工程团队。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think that's insane.": "我觉得那太疯狂了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I think we are not there yet.": "我认为我们还没到那个阶段。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Who knows.": "谁知道呢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In a few years where we'll be.": "几年后我们会发展到什么程度。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I certainly wouldn't have guessed we'd be here a few years ago.": "几年前我肯定猜不到我们会达到现在的水平。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know what the future holds, but right now I think the most important skill is the following.": "我不知道未来会怎样，但现在我认为最重要的技能是以下几点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Everyone can get a productivity boost from AI, AI, AI code with AI, I don't I don't let it go off": "每个人都能从 AI 中获得生产力提升，用 AI 写代码，但我不会让它完全脱离掌控",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on its own.": "自行其是。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I probably reject the code more than I accept it, but I am so much more productive because my boilerplate": "我拒绝的代码可能比接受的还多，但我现在的效率高得多，因为我的样板代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code, the stuff I know exactly what needs to be done, can now be written.": "那些我清楚知道该怎么做的东西，现在可以被写出来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You know, just just like that.": "你知道，就这样轻而易举。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the most important skill right now is saying no to an I not saying yes to an I.": "但现在最重要的技能是对 AI 说“不”，而不是对 AI 说“是”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because my experience with even the best of breed tools is that they are very poor software architects.": "因为根据我的经验，即使是顶尖的工具，它们也是非常糟糕的软件架构师。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When you ask for something, they're like, it's like a monkey's paw, like a malicious genie in the": "当你提出要求时，它们就像“猴爪”，或者像瓶子里心怀恶意的精灵，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:bottle, right?": "对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When you ask for something, they deliver that thing to you.": "当你要求某样东西时，它们会把那样东西交给你。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They do not care if somewhere else in your codebase you have patterns for it or utilities for it, or": "它们不在乎你代码库的其他地方是否已经有了相关的模式或工具类，或者",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an opinion about it, or or or knowledge of what you're trying to achieve in the future.": "对它的见解，或者对你未来想要实现的目标的了解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And, and great software engineers are architects while they're while they're developing.": "而优秀的软件工程师在开发的同时也是架构师。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's missing.": "所以这一点是缺失的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that doesn't mean that it can't be helpful to you.": "这并不意味着它对你没有帮助。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It just means that that like really guiding it and having a strong opinion about the code is still a": "这只是意味着，真正引导它并对代码持有坚定的见解仍然是",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:really valuable skill.": "一项非常有价值的技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But really, what is being mitigated in the future?": "但实际上，未来哪些东西正在被削弱？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To be honest, it does sound like something which is very easy to solve or will be solved in the future.": "说实话，这听起来确实像是很容易解决，或者将来会被解决的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, learning about, you know, your your insights right now.": "例如，了解，你知道的，你现在的见解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can do it with cursor rules about your style, etc. and you can do indexing.": "你可以通过关于你风格的 Cursor 规则等来实现，还可以进行索引。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Of course, it's not in the same level as you say, of identifying the chord patterns, right?": "当然，这和你所说的识别和弦模式不在同一个层面上，对吧？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Or for example, how to create a new endpoint or etc. but it is something that.": "或者例如，如何创建一个新的端点等等，但它是某种...",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I and I look forward to when that is true.": "我，我也期待着那一天成为现实。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can't wait for it to be true.": "我迫不及待地希望它成真。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's like, you know, uh, my car nominally drives itself and it handles it.": "但这就像，你知道，呃，我的车名义上是自动驾驶的，它能处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It handles 99% of situations perfectly fine.": "它能完美处理 99% 的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But every now and then I get in a situation where someone's crossing the street and there's a school": "但偶尔我会遇到这样的情况：有人在过马路，有一辆校",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:bus and there's a guy with a stop sign because there's construction and I don't know if it I don't know": "车，还有一个拿着停止标志的人，因为那里在施工，我不知道它，我不知道",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:if it can deal with this or not.": "它是否能处理这种情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm not going to find out because I have the ability to take over.": "我不打算去验证，因为我有能力接管。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think that the I think that the skill set that every moment in time, no matter how smart and": "我认为，我认为在任何时刻，无论多么智能和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:scalable, there's always going to be a role for someone to say, wait a second, this is new.": "具扩展性，总会需要有人站出来说：等一下，这是新情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's stop and think about it.": "让我们停下来思考一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even if the person doing that is other agents, there's still this coordination task.": "即使做这件事的是其他智能体，仍然存在这种协调任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so I think that one of the mistakes I see people making is they they say that because in the future": "所以我认为我看到人们犯的一个错误是，他们说因为在未来",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:they're sure I will be able to do this.": "他们确信 AI 将能够做到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They don't.": "他们并没有。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's like we pre obsolete ourselves and take ourselves out of the picture.": "这就像我们预先淘汰了自己，把自己从画面中剔除。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I can't wait, I can't wait to kick back and not have to do anything because an AI is doing it.": "我迫不及待，迫不及待地想放松下来，什么都不用做，因为 AI 正在处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we're not there yet.": "但我们还没到那一步。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I think the biggest mistake people make is not realizing where humans should spend their time.": "我认为人们犯的最大错误是没有意识到人类应该把时间花在哪里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the argument against AI on autopilot is not that it does a bad job writing the code or can't write": "所以反对 AI 自动驾驶的论点并不是说它写代码写得不好或者不会写",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the code, it's that at the critical, the small number of critical moments where someone should be": "代码，而是在那些关键的、少数需要有人",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:saying no or should be changing it, it's not making those set of calls.": "说“不”或者应该进行修改的关键时刻，它没有做出那一套决策。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so, you know, does that mean that our future as humans is to be board overseers of of autonomous": "所以，你知道，这是否意味着我们人类的未来就是成为自主",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:AI agents?": "AI 智能体的董事会监督者？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe.": "也许吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that sounds pretty awful to me.": "对我来说，这听起来挺糟糕的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so I'm not ready to live in that world yet, but like, I just see us, I think it's the glorious": "嗯，所以我还没准备好生活在那个世界里，但是，我只是看到我们，我认为那是辉煌的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:future.": "未来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And also, it's not perfect.": "而且，它并不完美。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thank you so much for the time, Jeremiah.": "非常感谢你的时间，Jeremiah。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And thank you.": "也谢谢你。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thank you.": "谢谢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Yeah, it was great talking to you.": "是的，很高兴能和你交谈。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Absolutely.": "当然。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's a pleasure.": "这是我的荣幸。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Thank you so much.": "非常感谢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and all these things.": "以及所有这些事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're really useful to people.": "它们对人们确实非常有用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I actually think the success of an open source project has a lot to do with just can you participate": "但我实际上认为，一个开源项目的成功在很大程度上取决于你是否能够参与",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in it on a community basis.": "其中，并以社区为基础。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we're really committed to try to uphold that for as long as we can.": "因此，我们真的致力于尽可能长时间地坚持这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I apologize to anyone who's listening to this and saying like, well, my issue has been open for": "我向任何正在听这段话并心想“我的 issue 已经开了”的人道歉",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a week and a half and nobody seems to want to do anything about it, like some things are hard to do": "“一个半星期了，似乎没人想处理它”，有些事情确实很难办",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and I apologize, but this really is the ethos we're trying to just bring here is, um, we this this": "我深表歉意，但这确实是我们试图在这里引入的精神，嗯，我们这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:space moves so quickly.": "领域发展得如此之快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We we respond to issues when we can.": "我们会在可能的情况下回应 issue。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We close issues when we can.": "我们会在可能的情况下关闭 issue。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We close PRS, we release as often as we can.": "我们处理 PR，并尽可能频繁地发布版本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and we just try to do right.": "嗯，我们只是努力做正确的事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We just try to keep up with what the community wants.": "我们只是努力跟上社区的需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So regarding that, I do have a question.": "关于这一点，我确实有一个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So how how did fast Mrp2 and fast MCP in general affect, uh, the company founded and you're leading": "那么，fast Mrp2 以及整个 fast MCP 是如何影响你创立并领导的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right now prefect and and you know, because it's quite it's a lot of resources to put on an open source": "公司 Prefect 的？你知道，因为在一个开源项目上投入",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:project and it's a lot of effort.": "相当多的资源和精力是一件大事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I don't think a lot of people know what effort it takes to to maintain a community and to maintain": "而且我认为很多人并不知道维护一个社区以及维护",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a popular open source project.": "一个热门开源项目需要付出多少努力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's it's like an entire company by its own.": "这本身就像是一家完整的公司。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'd love to hear about that.": "所以我们很想听听这方面的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It absolutely is.": "确实如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So at first I tried to keep it separate from prefect because I didn't want it to for exactly the reason": "所以起初我试图将其与 Prefect 分开，因为我不想让它——正是出于你提到的原因——",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:you said this is a full time thing.": "这是一项全职工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If it takes off, we don't want it to sort of SAP resources.": "如果它发展起来了，我们不希望它耗尽资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, it has gotten to the point now where it is a big enough community that it really needs resources": "嗯，现在它已经发展到了一个足够大的社区，确实需要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:dedicated to it.": "专门的资源投入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so we have been dedicating resources at prefect to fast MCP.": "因此，我们一直在 Prefect 为 fast MCP 投入资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and the fun thing is it's such a it's such an interesting thing.": "嗯，有趣的是，这是一件非常有意思的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have a, we have a bunch of folks at prefect who sort of put up their hand and we're like, I": "我们在 Prefect 有一群人主动请缨，说“我",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:want to work on this.": "想参与这个项目”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we've been, um, dedicating some resources.": "所以我们一直在，嗯，投入一些资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're still not it's still different enough.": "我们仍然没有……它仍然足够不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's still experimental enough.": "它仍然具有足够的实验性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's still moving at a different pace than our core business.": "它的发展节奏仍然与我们的核心业务不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we're doing is we're trying to leverage our AI knowledge in this space.": "所以我们正在做的是尝试利用我们在这一领域的 AI 知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You know, prefect every day hosts and runs code for some of the larger enterprises in the world.": "你知道，Prefect 每天都在为世界上一些大型企业托管和运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as we start to think about the requirements that fast, MCP has and needs to have for enterprises": "因此，当我们开始思考 fast MCP 针对企业在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:around security and auth and governance, we're just trying to leverage those lessons as much as possible.": "安全、认证和治理方面的需求时，我们只是在尝试尽可能多地借鉴这些经验。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But it's a challenge.": "但这是一个挑战。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's something we evaluate almost every day.": "这是我们几乎每天都在评估的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, and right now, the commitment prefect is making is just to support the project and make sure that": "嗯，目前 Prefect 所做的承诺只是支持这个项目，并确保",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it has the resources it needs.": "它拥有所需的资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to manage the users API key.": "我们需要管理用户的 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to keep them.": "我们需要保存它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe in secrets managers we need to make sure those keys don't get stolen.": "也许在机密管理器中，我们需要确保这些密钥不被窃取。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are responsible if some things go wrong.": "如果出了问题，我们要负责。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there is a better solution to handle all of this.": "所以有一个更好的解决方案来处理这一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is with MCP sampling.": "那就是使用 MCP 采样（sampling）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And MCP sampling lets us shift the cost and the usage of the eye of the LM, we shift it to the client.": "MCP 采样让我们能够将 LLM 的成本和使用量转移到客户端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the client here is going to be anyone who's using our MCP server.": "这里的客户端是指任何使用我们 MCP 服务器的人。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what happens here?": "那么这里发生了什么？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's say we have a prompt review the code for security issues.": "假设我们有一个提示词：审查代码中的安全问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the prompt that's going to do the code review.": "这就是将要执行代码审查的提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But instead of calling cloud we are going to ask from the server the client hey can you please run this": "但我们不是调用 Claude，而是由服务器向客户端请求：嘿，你能帮我运行这个吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:request for me in the client which is already connected to an LM, preferably cloud.": "在已经连接到 LLM（最好是 Claude）的客户端中为我运行这个请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to run this prompt, and then we're going to get back the results to our server and finish": "它将运行这个提示词，然后我们将结果返回给我们的服务器并完成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the review.": "审查。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me show you how this sampling flow is going to look like in a very high level.": "让我从高层次向你展示这个采样流程是什么样的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the application host we are going to have a tool call to our review code tool with maybe a pull": "在应用程序宿主中，我们将调用我们的代码审查工具，可能带有一个拉取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:request here.": "请求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then our MCP server prepares the AI prompt.": "然后我们的 MCP 服务器准备 AI 提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it asks the client to run this code with this great message here.": "然后它请求客户端运行这段代码，并附带这条很棒的消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The client is already connected to an LLM.": "客户端已经连接到了一个 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have here a client sampling callback which we already set in the client implementation.": "所以我们这里有一个客户端采样回调，我们已经在客户端实现中设置好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the client is going to use their own LLM connection let's say cloud.": "然后客户端将使用他们自己的 LLM 连接，比如 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then it's going to call this LLM call.": "然后它将发起这个 LLM 调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's going to send back the result to the server.": "然后它将结果发送回服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this case everybody wins because our server provides the expertise.": "在这种情况下，每个人都是赢家，因为我们的服务器提供了专业知识。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the code analysis logic the users pay for their own AI usage which is is fair.": "即代码分析逻辑，而用户为他们自己的 AI 使用付费，这很公平。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we don't need to save any API keys on our server.": "而且我们不需要在服务器上保存任何 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there is no security headache because we delegate all the technical implementation to the NCP protocol.": "也没有安全方面的烦恼，因为我们将所有的技术实现都委托给了 MCP 协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I need to mention that the server in this case will expose the prompt to the user, and the user": "现在我需要提到的是，在这种情况下，服务器会将提示词暴露给用户，用户",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:will be able to see what prompt has been sent to the LLM.": "将能够看到发送给 LLM 的提示词是什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if the prompt is the secret sauce, maybe sampling is not the best idea.": "所以，如果提示词是核心机密，那么采样可能不是最好的主意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, if the prompt isn't the secret sauce and we do other work on the server.": "然而，如果提示词不是核心机密，并且我们在服务器上还做其他工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then this is totally fine.": "那么这完全没问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me give you the technical implementation details.": "那么让我给你介绍一下技术实现细节。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to define it on the server side to instead of calling the LM to create a sampling message.": "我们需要在服务器端进行定义，以创建采样消息，而不是调用 LLM。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And on the client side, we need to create this sampling callback that will handle this message here.": "在客户端，我们需要创建这个采样回调来处理这里的消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's talk about when to use and when it's not good to use sampling.": "那么让我们来谈谈什么时候该使用采样，什么时候不适合使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there Eden here.": "大家好，我是 Eden。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we are going to talk about the MCP registry.": "在这段视频中，我们将讨论 MCP 注册表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP registry is a central catalog and API for discovering MCP compatible servers.": "MCP 注册表是一个用于发现兼容 MCP 的服务器的中央目录和 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It launched in preview in September 2025, and the registry serves as the official source of truth for": "它于 2025 年 9 月发布预览版，该注册表是所有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:all publicly available MCP servers.": "公开可用的 MCP 服务器的官方权威来源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, the primary purpose is to improve the discoverability and accessibility and also security of MCP": "现在，其主要目的是通过将所有 MCP 集成以一致的格式列在一个地方，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:integrations by listing them all in one place in a consistent format.": "来提高它们的可发现性、可访问性以及安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So by standardizing how MCP servers are published and discovered, this registry expands the reach and": "因此，通过标准化 MCP 服务器的发布和发现方式，该注册表扩大了覆盖范围，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:makes it easier for MCP client applications to connect to these servers, like an app store for MCP": "并使 MCP 客户端应用程序更容易连接到这些服务器，就像 MCP 服务器的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:servers and instead of AI developers scouring multiple forums or GitHub repositories like.": "应用商店一样，AI 开发者无需再搜寻多个论坛或 GitHub 仓库，比如",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Awesome.": "Awesome 列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Like I showed in the course, they can query this unified registry to file the available MCP servers": "正如我在课程中展示的那样，他们可以查询这个统一的注册表来查找可用的 MCP 服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to provide the functionality they need.": "以提供他们所需的功能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So regarding security, it also helps with MCP security.": "关于安全性，它也有助于提高 MCP 的安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it has built in authentication and publishing control.": "它内置了身份验证和发布控制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So only verified maintainers can publish servers to the MCP registry.": "因此，只有经过验证的维护者才能将服务器发布到 MCP 注册表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the publishing process uses authentication with GitHub authentication to ensure that only the right": "发布过程使用 GitHub 身份验证，以确保只有",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:owner of the repository or package can register a server under that identity.": "仓库或包的正确所有者才能以该身份注册服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this prevents attacks of impersonation like somebody maliciously publishing a fake HashiCorp Terraform": "这可以防止冒充攻击，例如有人恶意发布虚假的 HashiCorp Terraform 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this adds a layer of security.": "这增加了一层安全性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have more security mechanisms that I might be discussing in another video.": "我们还有更多的安全机制，我可能会在另一个视频中讨论。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, it's important to note that the MCP registry is a meta registry, so it contains metadata and": "现在，需要注意的是，MCP 注册表是一个元注册表，因此它包含元数据，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it doesn't contain the actual source code.": "而不包含实际的源代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It contains the metadata about the packages and source code, but not the packages or binaries themselves.": "它包含有关包和源代码的元数据，但不包含包或二进制文件本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So instead it's going to reference other package registries like NPM, PyPI or Dockerhub, which delegates": "相反，它会引用其他包注册表，如 NPM、PyPI 或 Dockerhub，从而将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the security aspect of source code security to those providers.": "源代码安全方面的责任委托给这些提供商。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is actually a very smart decision.": "所以这实际上是一个非常聪明的决定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP registry is only metadata.": "因此，MCP 注册表仅包含元数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so it doesn't need to handle this source code security.": "这样它就不需要处理源代码安全问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's talk about scoping.": "那么我们来谈谈范围划分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have the main and official MCP registry which is the canonical source of truth for all publicly": "我们有主官方 MCP 注册表，它是所有公开",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:available servers.": "可用服务器的权威来源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the cool thing is that we can create sub registries, which are going to be maybe more curated collections": "现在，酷的一点是我们可以创建子注册表，它们可能是更精选的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of MCP servers, which will include rating and enhanced metadata like security.": "MCP 服务器集合，其中将包括评分和增强的元数据（如安全性）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So these can be publicly facing so publicly in community adopted.": "这些可以是面向公众的，即在社区中被公开采用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's very good for public servers which are hosted and that are using LMS.": "所以它非常适合托管的、使用 LLM 的公共服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because then we shift the handling and the cost to the users which are using the MCP servers.": "因为这样我们就把处理工作和成本转嫁给了使用 MCP 服务器的用户。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So usually the usages in these kind of servers is going to vary.": "所以通常这类服务器的使用情况会有所不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we don't want to manage any API keys.": "而且我们不想管理任何 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when it's not really a good idea to use it is when we're building internal tools.": "而在构建内部工具时，使用它并不是一个好主意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if this MCP server of our code review is open source and people can download for GitHub, they can": "因此，如果我们的代码审查 MCP 服务器是开源的，人们可以从 GitHub 下载，他们就可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:simply put their own API keys there, like in an environment variable.": "简单地把他们自己的 API 密钥放在那里，比如放在环境变量中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this we don't care because this is code that is running in the user's client, so we don't really": "所以我们不在乎，因为这是在用户客户端运行的代码，所以我们并不真的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:care what we do here.": "在意我们在这里做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we don't want to put here sampling.": "所以我们不想在这里加入采样（sampling）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it doesn't really make sense because it's already running on our customer.": "这其实没有意义，因为它已经在我们的客户侧运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So of course if we are not using an LLM in our server, we don't want to use it.": "所以，当然，如果我们不在服务器中使用 LLM，我们就不想使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's say we are using our remote server.": "假设我们正在使用我们的远程服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the pricing here must be consistent.": "这里的定价必须保持一致。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So of course with a LLM costs it's not going to be consistent.": "所以，当然，有了 LLM 的成本，它就不会是一致的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the bottom line here without mcpp sampling we are running a restaurant and buying everyone meals": "所以底线是，如果没有 MCP 采样，我们就像是在开一家餐厅并请所有人吃饭",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and we sampling.": "而有了采样，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are running the restaurant where customers bring the ingredients and we provide the chef and recipes.": "我们经营着一家餐厅，顾客自带食材，而我们提供厨师和食谱。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Mcpp sampling elegantly solves the cost and security challenges of AI powered Mcpp servers, and it's": "MCP 采样优雅地解决了 AI 驱动的 MCP 服务器的成本和安全挑战，并且它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:shifting the API responsibility to where it belongs with the users who benefit from the service.": "将 API 责任转移到了它该去的地方——即受益于该服务的用户手中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the next video, we are going to see this in action and we're going to implement Mcpp sampling.": "在接下来的视频中，我们将看到它的实际应用，并开始实现 MCP 采样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we are going to cover context engineering within the MCP ecosystem.": "在这段视频中，我们将介绍 MCP 生态系统中的上下文工程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the example I'm going to show you is going to be with cloud code.": "我要向你们展示的示例将使用 Claude Code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, it's going to apply to every agentic system that we have.": "不过，它适用于我们拥有的每一个智能体系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now context is the most expensive and limited resource that we have in Agentic systems and agentic coding.": "上下文是我们在智能体系统和智能体编程中拥有的最昂贵且最有限的资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because the context is going to directly affect our agent performance.": "因为上下文将直接影响我们智能体的性能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Bad context equals bad performance from our Agentic system.": "糟糕的上下文意味着智能体系统的性能也会很糟糕。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, I'm not even talking about pricing and latency.": "现在，我甚至还没谈到价格和延迟。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm here only talking about performance and just emphasizing the importance of it.": "我在这里只讨论性能，并强调它的重要性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And one of the most silent killers of context efficiency is MCP.": "而上下文效率最隐蔽的杀手之一就是 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, MCP is amazing, don't get me wrong, but if not used wisely, it can really mess up our context.": "别误会，MCP 非常棒，但如果使用不当，它真的会搞乱我们的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this issue is going to bloat our context window with unnecessary tokens for tools that we don't": "这个问题会使我们的上下文窗口充斥着不必要的 token，这些 token 来自于我们并不",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:really need.": "真正需要的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the problem is going to be using a two general MCP configuration.": "现在，问题在于使用了过于通用的 MCP 配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now if we're going to be using cloud code, it's going to be a project level MCP, JSON file, which": "如果我们要使用 Claude Code，它会是一个项目级的 MCP JSON 文件，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is going to load a bunch of MCP servers and MCP tools that we don't really need for our job at the moment.": "它会加载一堆我们目前工作并不真正需要的 MCP 服务器和 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So most setups that I know and I personally have seen with this is using a general MCP JSON file, which": "据我所知以及我个人见过的这类设置，大多是使用一个通用的 MCP JSON 文件，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is going to load all of our MCP servers and all of our tools.": "它会加载我们所有的 MCP 服务器和所有工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, this may sound very familiar, because we're going to be equipping our agent with all the tools": "这听起来可能非常熟悉，因为我们要为智能体配备它可能需要的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that it would need.": "所有工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this will result that every session we will be loading all the MCP servers and all the MCP tools,": "这会导致在每个会话中，我们都会加载所有的 MCP 服务器和所有的 MCP 工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:even if we don't need them.": "即使我们不需要它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that can burn through tens of thousands of tokens before we even write one single prompt.": "在我们写下第一个提示词之前，这可能会消耗掉成千上万个 token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this session, I'm going to introduce this problem, and I'm going to show you how we can fix": "所以在本次课程中，我将介绍这个问题，并向你们展示我们如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it with context engineering.": "通过上下文工程来修复它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the code for this video is going to be available in this branch contest engineering MCP.": "本视频的代码将在 context-engineering-mcp 分支中提供。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to go and start right from this first commit.": "我将从第一个提交（commit）开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can go and you can clone this commit.": "所以你可以去克隆这个提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go to my IDE.": "让我进入我的 IDE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right over here we have a simple MCP server.": "就在这里，我们有一个简单的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can see the implementation here at verbose MCP server dot Pi.": "你可以在 verbose_mcp_server.py 中看到这里的实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I use fast MCP to write it, which has a bunch of MCP tools.": "我使用 FastMCP 来编写它，它包含一堆 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, add two numbers, subtract two numbers, multiply two numbers, and it really has tons": "例如，两个数相加、两个数相减、两个数相乘，它确实有大量的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of MCP tools that we don't really need.": "我们并不真正需要的 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see for each MCP tool we have a very elaborate description.": "你可以看到，对于每个 MCP 工具，我们都有非常详细的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The description is going to help the MCP client decide whether to call this MCP tool or not.": "描述将帮助 MCP 客户端决定是否调用该 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this can also be private deployed for companies and organizations that want to expose their MCP": "此外，这也可以为希望在一个注册表中公开其 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:servers in one registry, which is going to be private and deployed only on their servers and going": "服务器的公司和组织进行私有化部署，该注册表将是私有的，仅部署在他们的服务器上，并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be only accessed by their own employees.": "仅供其内部员工访问。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is something which is very, very flexible and also convenient.": "所以这是非常非常灵活且方便的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's important to note that the registry itself is vendor neutral.": "现在需要注意的是，注册表本身是厂商中立的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they don't prefer one vendor over the other, and there is no ranking or some kind of curation or": "因此，他们不会偏袒任何一家厂商，也没有排名或某种形式的策展，或者",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:any other quality judgments, like if an MCP server is more secure than another.": "任何其他质量判断，比如某个 MCP 服务器是否比另一个更安全。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they don't have these kinds of things.": "所以他们没有这类东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're simply there to host metadata on the server, the server, um, what it exposes and a link or": "他们仅仅是为了托管服务器的元数据，即服务器公开的内容以及指向",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an, a reference to that code of the server.": "该服务器代码的链接或引用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it lets the consumers of this registry, so it can be the MCP clients or aggregators taking data": "因此，它让该注册表的使用者（可以是 MCP 客户端或从 MCP 服务器获取数据的聚合器）",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:from the MCP server to make their own curation decisions, whether to use an MCP server or not, whether": "自行做出策展决策，决定是否使用某个 MCP 服务器，以及",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to decide if it's safe or not.": "决定它是否安全。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the MCP registry is neutral, and you can see it even in their GitHub repository.": "所以 MCP 注册表是中立的，你甚至可以在他们的 GitHub 仓库中看到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the roadmap, you can see the out of scope section.": "在路线图中，你可以看到“超出范围”部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see there they're not going to be planning to do some quality ranking or to do some curation": "你可以看到，他们不打算进行任何质量排名或对",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:over their servers.": "他们的服务器进行策展。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're not planning to host the code, they're simply a metadata server.": "他们不打算托管代码，他们只是一个元数据服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they're not going to be responsible for the hosting of servers.": "因此，他们不会负责服务器的托管。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Also, they're not going to be like a search engine, like you're going to be searching for something": "此外，他们也不会像搜索引擎那样，让你去搜索某些东西",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and find it.": "然后找到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So there's just a place where you put the MCP server ID and get information about it where you can consume": "所以这只是一个让你输入 MCP 服务器 ID 并获取相关信息以便使用的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is also something very cool to see their focus in their roadmap.": "所以在他们的路线图中看到这种专注也是一件非常酷的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I am planning to show you an example how you can use the MCP registry.": "我计划向你们展示一个如何使用 MCP 注册表的示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we're going to be discussing what's wrong with MCP.": "在这段视频中，我们将讨论 MCP 存在的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I know it's counterintuitive because this is an MCP course.": "我知道这听起来有些违背直觉，因为这是一门关于 MCP 的课程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, I want to talk about the drawbacks of using the Model context protocol because life is not": "然而，我想谈谈使用模型上下文协议（Model Context Protocol）的缺点，因为生活并不",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:perfect and there is no perfect protocol.": "完美，也没有完美的协议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, the disadvantages that come with MCP mainly derive by how we manage the LMS context and how we": "MCP 带来的缺点主要源于我们如何管理 LLM 上下文以及我们如何",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:execute tasks.": "执行任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, I remind you that MCP was intended to standardize how agents connect to data.": "我提醒一下，MCP 的初衷是标准化智能体连接数据的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, the current implementation is going to result us with slower, expensive, and a bit dumber": "然而，目前的实现会导致我们的智能体比预想的更慢、更昂贵，而且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:agents than we wanted to.": "稍微笨一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's talk about what's wrong with the MCP and how it's working.": "那么，让我们来谈谈 MCP 的问题所在以及它是如何运作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the first problem with MCP is context pollution.": "MCP 的第一个问题是上下文污染。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the most significant issue with the model context protocol, because it's requiring us to": "这是模型上下文协议最显著的问题，因为它要求我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:load tool definitions upfront into the model's context.": "预先将工具定义加载到模型的上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this eventually goes to the system prompt.": "所以这些最终会进入系统提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So because we are upfront loading all of the tool definitions and the arguments they need to receive": "因为我们预先加载了所有的工具定义、它们需要接收的参数",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and which output they output.": "以及它们输出的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this results in a massive token overhead.": "这导致了巨大的 Token 开销。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to use an FCP server, the agent must be giving all of the definitions for every available tool.": "要使用 MCP 服务器，智能体必须提供每个可用工具的所有定义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's take a concrete example where we have a setup of 58 tools across servers like GitHub, MCP, slack,": "让我们举一个具体的例子，假设我们在 GitHub、MCP、Slack 等服务器上设置了 58 个工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP, central, MCP, and we can see that we consume 55,000 tokens.": "MCP Central 等，我们可以看到消耗了 55,000 个 Token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is before the conversation even began.": "而这甚至是在对话开始之前。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we're not careful, we can easily find ourselves with cases where the tool definitions alone": "如果我们不小心，很容易就会遇到仅工具定义",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:can consume up to hundreds of thousands of tokens.": "就消耗多达数十万个 Token 的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in LM applications in in agents in general context is the number one resource we should optimize.": "在 LLM 应用和智能体中，上下文通常是我们应该优化的头号资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I like to say that context is the new gold.": "我喜欢说，上下文是新的黄金。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now Even if we have our context field.": "现在，即使我们的上下文被填满了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The problem with MCP is that we get irrelevant data.": "MCP 的问题在于我们会得到无关的数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, if an agent needs to perform a simple task, like maybe to change a front end page, it still": "现在，如果一个智能体需要执行一个简单的任务，比如修改一个前端页面，它仍然",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:carries the weight of thousands of lines of context.": "承载着数千行上下文的负担。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For unrelated tools you don't really need, like a database tool or maybe a PDF reader tool.": "这些是关于你并不真正需要的无关工具，比如数据库工具或 PDF 阅读器工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this irrelevant information persists through every step of the conversation and every iteration": "这些无关信息会贯穿对话的每一步以及智能体的每一次",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the agent.": "迭代。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, this is going to give us degraded performance because we are flooding the context video.": "现在，这将导致性能下降，因为我们使上下文窗口过载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to make models dumber.": "这会让模型变得更笨。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we talked about it in the context engineering section here.": "我们在上下文工程部分讨论过这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as the context is going to fill with irrelevant tool definitions, the model is going to struggle": "因此，当上下文中充满了无关的工具定义时，模型将会变得吃力",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to find this needle in the haystack leading to hallucinations or the inability to follow instructions": "在大海捞针中寻找这根针，会导致幻觉或无法遵循指令",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:or even selecting the wrong tool here.": "甚至在这里选择了错误的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So up until now we talked about context.": "所以到目前为止，我们讨论了上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's talk about our agents execution And specifically, I want to talk about inefficient execution": "现在让我们来谈谈智能体的执行，特别是，我想谈谈低效的执行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of our agent with the traditional MCP usage that is going to be relying on a ping pong interaction style": "在传统的 MCP 使用方式下，智能体将依赖于乒乓式的交互风格",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that is going to waste us a lot of time and money, because it's going to require us to have multiple": "这将浪费我们大量的时间和金钱，因为它需要我们进行多次",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:inference of the LLM just to perform one thing.": "大语言模型推理才能完成一件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in a standard workflow, every action is going to require a full round trip where first the model": "因此，在标准工作流中，每个动作都需要一个完整的往返过程，首先模型",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is going to request a tool, then the tool is going to run, then the result is going to be added to": "会请求一个工具，然后工具运行，接着结果会被添加到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the history, and the entire history is sent back to the model to decide what to do next.": "历史记录中，最后整个历史记录被发回给模型以决定下一步做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now if we need to make a couple of tool calls, then this thing is going to grow very, very fast.": "现在，如果我们需要进行几次工具调用，那么这个过程会增长得非常快。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are going to fill up the context window with those intermediate results, which we probably don't": "我们将用那些中间结果填满上下文窗口，而我们可能并不",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:need to the final answer.": "需要它们来得出最终答案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So at some point of the execution they can be removed anyways with the current MCP implementation.": "因此，在执行的某个阶段，无论如何它们都可以被移除。但在目前的 MCP 实现中，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we are going to be dragging all those intermediate results and we are going to pollute our context.": "我们将一直拖着所有这些中间结果，从而污染我们的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But not only that, this multiple inference passes with multiple tool calls.": "但不仅如此，这种带有多次工具调用的多次推理过程，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to cost us a lot of money, and it's going to take a lot of time because we're going to be": "这将花费我们很多钱，并且会耗费大量时间，因为我们将要",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:making a lot of LM calls.": "进行大量的语言模型调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's recap what we talked about so far.": "那么让我们回顾一下到目前为止我们讨论的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We talked about the MCP problem regarding context.": "我们讨论了关于上下文的 MCP 问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We talked about MCP problem regarding the agent's execution.": "我们讨论了关于智能体执行的 MCP 问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's talk about the native tongue problem.": "现在让我们来谈谈“母语”问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the JSON versus code.": "这就是 JSON 与代码之争。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So MCP forces the large language model to work in a way that contradicts their training.": "因此，MCP 迫使大语言模型以一种与其训练相矛盾的方式工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this unnatural tool tokens MCP relies on so much on these specific tool called tokens and JSON schemas": "所以 MCP 如此依赖的这些不自然的工具标记，即特定的工具调用标记和 JSON 模式，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:really contradicts what large language models are trained on.": "确实与大语言模型的训练内容相矛盾。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And they're primarily trained on text in code and not on those syntactic tool use tokens.": "它们主要是在文本和代码上训练的，而不是在那些语法工具使用标记上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So using them an LLM using tool calls.": "因此，让大语言模型使用这些工具调用，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's really unnatural to the model.": "对模型来说确实很不自然。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even though so far the vendors have made a great job generating these syntactic data and making them": "尽管到目前为止，厂商在生成这些语法数据并使其",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:work with tool calls.": "配合工具调用方面做得很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is really not the native tongue of the LLM.": "这确实不是大语言模型的母语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what Llms are really, really good on which are trained on are text and code.": "所以大语言模型真正擅长且经过训练的是文本和代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So code is much superior to those tool call mechanisms.": "因此，代码远优于那些工具调用机制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now another disadvantage of MCP is that the tool definitions and JSON schemas, they define what a tool": "现在，MCP 的另一个缺点是工具定义和 JSON 模式，它们定义了一个工具",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:looks like.": "看起来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But these schemas.": "但这些模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They do not capture the usage pattern, which is a far much deeper concept than a tool definition.": "它们没有捕捉到使用模式，而这比工具定义是一个深刻得多的概念。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even if we're going to tell the LLM how to use the tool or when, it doesn't really capture the usage": "即使我们要告诉大语言模型如何或何时使用该工具，它也并没有真正捕捉到使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:pattern and how and when to use and specifically when not to use.": "模式，以及如何、何时使用，特别是何时不使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hey there eating here.": "大家好，我是 Ethan。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video I want to cover the Cloudflare blog, which is called Code Mode.": "在这段视频中，我想介绍一下 Cloudflare 的博客，标题是《Code Mode》。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The better way to use MCP?": "使用 MCP 的更好方式？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this blog is actually super cool.": "这篇博客实际上非常酷。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It has some very cool ideas which I'm pretty sure are going to stay.": "它提出了一些非常棒的想法，我敢肯定这些想法会延续下去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we talked about the drawbacks and disadvantages of MCP in earlier videos, and the fact that if we're": "我们在之前的视频中讨论过 MCP 的缺点和不足，以及如果我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to use MCP, we are prone to have a context bloat, we're prone to have longer latency because": "打算使用 MCP，我们很容易遇到上下文膨胀，也很容易出现更长的延迟，因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tons of calls are going to happen.": "会发生大量的调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video, I'm going to cover this code mode approach, which is quite smart and quite elegant,": "在这段视频中，我将介绍这种 Code Mode 方法，它非常聪明且优雅，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I have to say.": "我不得不说。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, if you do not want to watch this video, feel free to skip it.": "现在，如果你不想看这段视频，请随意跳过。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to start with the gist of it and then I'm going to cover it.": "我将先从它的要点开始，然后再详细介绍。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So Cloudflare basically suggests here that instead of using MCP as we used to, we can go and take all": "所以 Cloudflare 在这里基本上建议，与其像以前那样使用 MCP，我们可以提取",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the tool definitions and tool interfaces and tool implementations that we have from the MCP and convert": "MCP 中所有的工具定义、工具接口和工具实现，并将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:everything into TypeScript API into TypeScript code.": "一切都转换为 TypeScript API，转换为 TypeScript 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then instead of letting the LLM make tool calls to choose which tool to call, we ask the Lem to": "然后，我们不再让 LLM 通过工具调用来选择调用哪个工具，而是要求 LLM",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:generate code that is going to use that TypeScript API here.": "生成将在这里使用该 TypeScript API 的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in fact, what we're going to do, we're going to ask the LLM to generate the entire code that needs": "所以实际上，我们要做的就是要求 LLM 生成需要执行的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be executed.": "全部代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And inside this code we're going to include many, many tool calls which are going to be actually function": "在这段代码中，我们将包含许多工具调用，这些调用实际上将是函数",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:invocations.": "调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we only execute once this code in a sandbox.": "然后我们只需在沙箱中执行一次这段代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is really smart because you save a lot of round trips of making a tool call, getting the result,": "这真的很聪明，因为你节省了大量的往返次数，即发起工具调用、获取结果、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then making another tool call.": "然后再发起另一个工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And all of this is actually really, really redundant because you can simply write code that will do": "所有这些实际上都非常冗余，因为你只需编写代码就能完成",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the advantages of using it is that we're going to get much more robust agents, because agents are": "使用它的优点是我们将获得更健壮的智能体，因为智能体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:really, really good in writing code.": "非常擅长编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And writing code for llms is the bread and butter.": "对于 LLM 来说，编写代码是拿手好戏。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And there are many advantages in this approach, but the main advantage is that llms are really, really": "这种方法有很多优点，但主要的优点是 LLM 真的非常",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:good at writing code.": "擅长编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, this is something which they excel in and they have lots of training data on code.": "事实上，这是它们擅长的领域，而且它们拥有大量的代码训练数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's very natural for an LLM to generate code.": "因此，让 LLM 生成代码是非常自然的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we save a lot of tokens because we do not need to send every time all the tool definitions, we": "而且我们节省了大量的 token，因为我们不需要每次都发送所有的工具定义，我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:write the code once we execute it and then we continue.": "编写一次代码，执行它，然后继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is really really interesting.": "所以这真的非常有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right let's go to the blog and let's go and read it.": "好了，让我们去看看那篇博客并阅读一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again feel free to skip this video.": "再次强调，请随意跳过这段视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I am going to give my $0.02 though when reading it.": "不过在阅读时，我会分享一下我个人的见解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it turns out we have been using MCP wrong.": "所以事实证明，我们一直以来使用 MCP 的方式都错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me show you now how we can run this MCP server.": "现在让我向您展示如何运行这个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to use the UV package manager.": "我将使用 UV 包管理器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see we have a UV log file which has the description of the MCP package we're going to be": "你可以看到我们有一个 UV 锁文件（uv.lock），其中包含我们将要使用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:using to run this MCP server with.": "用于运行此 MCP 服务器的 MCP 包的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and write UV sync.": "现在让我输入 uv sync。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me activate the virtual environment.": "让我激活虚拟环境。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to do that by writing source.": "我将通过输入 source 来实现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And under Venv we have been activate.": "在 .venv 下，我们有 bin/activate。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right now you can see I'm inside the virtual environment with the dependencies installed.": "现在你可以看到我已经进入了虚拟环境，并且依赖项已经安装好了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now I want to use the fast mcp cli.": "现在我想使用 fastmcp 命令行界面 (CLI)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm just going to make sure I have it working and we can see that it's working right now.": "我只是要确保它能正常工作，我们可以看到它现在运行正常。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to run fast MCP run.": "所以我将运行 fastmcp run。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to run the verbose MCP server dot pi.": "我将运行 verbose_mcp_server.py。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to run this in the transport of HTTP.": "我想在 HTTP 传输协议下运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we have our verbose mathematical operation server running in Streamable HTTP.": "现在我们的 verbose 数学运算服务器正在 Streamable HTTP 中运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the URL.": "这就是 URL。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I want to open cloud code.": "现在我想打开 Cloud Code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to add this MCP server to it.": "我想把这个 MCP 服务器添加到其中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to show you the context.": "我想给你们展示一下上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me go and create a file.": "现在让我去创建一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm going to call it.mc, dot JSON.": "我将把它命名为 .mcp.json。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I go to the repository again to the branch, you can see in this commit add project based NCP": "如果我再次回到代码仓库的分支，你可以在这个名为“add project based MCP”的提交中看到",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:configuration, you can copy here this configuration yourself.": "配置，你可以自己在这里复制这个配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And just put here your API keys.": "只需在这里填入你的 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be a project level configuration.": "这将是一个项目级的配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see the NCP we have configured is the verbose server which we have running locally.": "我们可以看到我们配置的 MCP 是正在本地运行的 verbose 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to use context seven which we covered in this course.": "它将使用我们在本课程中介绍过的 context-7。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to be using Tavileh.": "它将使用 Tavily。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And Tavileh is going to be used to search the internet, to crawl websites, to extract web pages.": "Tavily 将被用于搜索互联网、爬取网站、提取网页。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have also playwright NCP for browser automation.": "我们还有用于浏览器自动化的 Playwright MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have four NCP servers here that we're going to be connected.": "所以我们这里连接了四个 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be a project level NCP configuration.": "这将是一个项目级的 MCP 配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see, by the way, that I have obfuscated all my API keys.": "顺便说一下，你可以看到我已经混淆了我所有的 API 密钥。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I want to open the terminal and I'm going to CD into this directory which has all my code Call": "现在我想打开终端，我将进入包含我所有代码的这个目录，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and let me go and CD into this directory.": "让我进入这个目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me write git branch just to show you where in the branch context engineering MCP.": "让我输入 git branch，只是为了向你展示我们在 context-engineering-mcp 分支中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let me go and run cloud from here.": "现在让我从这里运行 cloud。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go to MCP to show you the MCP.": "让我去 MCP 界面向你展示 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see we have all the forums app servers that are connected.": "在这里我们可以看到所有四个已连接的服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let me show you something interesting and let's go now and click slash context.": "现在让我给你们看一些有趣的东西，让我们现在点击 /context。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is now going to show us all the context that is being used now in the session.": "现在这将向我们展示当前会话中正在使用的所有上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see I'm almost using half of my context window.": "所以你可以看到我几乎已经使用了我一半的上下文窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I didn't even write one single prompt.": "而我甚至还没写过一个提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have 2000 tokens are dedicated to the system prompt which is built in by Tropix.": "我们有 2000 个 token 专门用于 Tropix 内置的系统提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have the anthropic system tools which in their description which is 12 tokens 6%.": "我们有 Anthropic 系统工具，其描述占用了 12 个 token，比例为 6%。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now look at this plot.": "现在看这张图表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we have almost 20%, which is dedicated to MCP tools.": "这里有将近 20% 专门用于 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, depending on what I'm trying to do right now, I am probably not going to be needing all of those": "现在，取决于我正在尝试做什么，我可能并不需要所有这些",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers and especially all those mathematical MCP tools.": "MCP 服务器，尤其是所有那些数学 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is what we're going to be fixing soon.": "所以这就是我们很快要修复的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see the messages.": "我们可以看到消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't have any messages.": "我们没有任何消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Memory file.": "内存文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't have any.": "我们没有任何内存文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way here we don't have any subagents.": "顺便说一下，这里我们没有任何子代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But if we did have we would have seen them also in the context which tells cloud how and when to use": "但如果我们有的话，我们也会在上下文中看到它们，上下文会告诉 Claude 如何以及何时使用",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the subagent.": "子代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see we have almost 50% of our contacts window filled up.": "所以在这里我们可以看到，我们近 50% 的上下文窗口已经被填满了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right so how to fix this problem.": "好了，那么如何解决这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to do that we are going to go back to the browser here.": "为此，我们要回到这里的浏览器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are going to delete this dot MCP dot JSON file which is project based.": "我们要删除这个基于项目的 .mcp.json 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We don't want to use it.": "我们不想使用它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is pretty counter-intuitive.": "这非常违反直觉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me now create a new file.": "现在让我创建一个新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go and create dot mcp dot JSON dot file.": "让我去创建一个 .mcp.json 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go back to the repository.": "让我回到仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me get the configuration from here.": "让我从这里获取配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here.": "还有这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:let me paste in my CPU configuration here.": "让我在这里粘贴我的 MCP 配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is only going to have only the MCP configured right now.": "所以现在这里将只配置 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now back to the terminal and let me do the following.": "现在回到终端，让我执行以下操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now and run.": "现在让我去运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to run code with a specific argument here.": "我将在这里使用一个特定的参数来运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to run cloud code with a dash dash mcp config.": "所以我将运行带有 --mcp-config 的 Claude Code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this flag is going to receive as an input space separated path for MCP configurations.": "这个标志将接收以空格分隔的 MCP 配置路径作为输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to put the path here to our a dot mcp dot JSON dot.": "所以我要把我们的 .mcp.json 的路径放在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the MCP configuration containing only the MCP server.": "所以这是仅包含 MCP 服务器的 MCP 配置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and run it.": "让我们运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now when we run it let's go and check out MCC.": "现在当我们运行它时，让我们去检查一下 MCC。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is something very interesting that is happening right now.": "这是现在正在发生的一件非常有趣的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we can see we have the MCP which we expect.": "所以现在我们可以看到我们有了预期的 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can see we also have the verbose server and the contact seven.": "但我们可以看到我们还有 verbose server 和 contact seven。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see we don't have the playwright MCP.": "我们可以看到我们没有 playwright MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is cloud is loading right now.": "这是 Claude 正在加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Also the MCC from our user configuration here okay.": "还有我们这里用户配置中的 MCC，好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in my user configuration I have contact seven I have and I have verbose server.": "所以在我的用户配置中，我有 contact seven，我有，还有 verbose server。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's say I want to load only this configuration which is what we want.": "假设我只想加载这个配置，这正是我们想要的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We need to add another flag which is called dash dash strict MCP config.": "我们需要添加另一个名为 --strict-mcp-config 的标志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be loading only the MCP servers here.": "这将只加载这里的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to ignore the cloud code MCP hierarchy.": "并且它将忽略 Claude Code 的 MCP 层级结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let me write slash MCP.": "现在让我输入 /mcp。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right here we can see we have only the MCP.": "在这里我们可以看到我们只有 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's check out the context.": "现在让我们检查一下上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see that the context usage dropped from the MCP tools from 20% to 2.4%.": "现在我们可以看到 MCP 工具的上下文使用率从 20% 下降到了 2.4%。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to give us better results because our cloud code agent now is going to be much more": "这将为我们带来更好的结果，因为我们的云代码代理现在将变得更加",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:focused, and it's not going to have a bunch of useless tools that it's not really needing for the current": "专注，并且不会拥有一堆当前任务并不真正需要的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:task, which is Research.": "无用工具，当前任务是研究。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I restored the general MCP JSON.": "所以我恢复了通用的 MCP JSON。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to show you another way to do this.": "我想向你展示另一种实现方法。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now exit clog and let me now open cloud again.": "让我现在退出 clog，然后再次打开 cloud。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and check now the MCP servers.": "让我们现在检查一下 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see we have all the MCP servers here.": "现在我们可以看到这里有所有的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we have a new feature in cloud that within the session itself we can go.": "现在 cloud 中有一个新功能，我们可以在会话本身中进行操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go for example for the verbose MCP server.": "让我们以 verbose MCP 服务器为例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can go and we can disable the server.": "在这里我们可以禁用该服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now if we're going to check out the MCP server we're going to see that this is disabled.": "所以现在如果我们检查 MCP 服务器，我们会看到它已被禁用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and disable for example also playwright.": "让我们也禁用 playwright，例如。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and check the MCP.": "现在让我们去检查 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see both servers are now disabled.": "我们可以看到两个服务器现在都已禁用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if now we'll go and check out the context.": "如果现在我们去检查上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see that those are only MCP servers which are available and the MCP tools.": "我们可以看到这些是仅有的可用 MCP 服务器和 MCP 工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we reduce the context as well.": "现在我们也减少了上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's 3.2%.": "现在是 3.2%。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we did everything via the CLI.": "我们通过 CLI 完成了所有操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Most agents today use MCP by directly exposing the tools to the LLM like we saw in the course.": "如今大多数智能体通过直接向 LLM 暴露工具来使用 MCP，就像我们在课程中看到的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We tried something different to convert MCP tools into a TypeScript API, and then ask them to write": "我们尝试了一些不同的方法，将 MCP 工具转换为 TypeScript API，然后要求它们编写",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code that calls that API.": "调用该 API 的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The results were striking.": "结果非常显著。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We found agents are able to handle many more tools and more complex tools.": "我们发现智能体能够处理更多且更复杂的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is solving one issue with MCP.": "这解决了一个 MCP 的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we have too many tools, we're going to be bloating up the context, and the context is going to": "如果我们有太多的工具，上下文就会变得臃肿，而且上下文会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:explode.": "爆炸。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to cost us more.": "所以这会让我们花费更多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to take more time to process it.": "处理它需要更多的时间。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And probably the LLM is going to do a much worse job because we have that many tools.": "而且由于有这么多工具，LLM 的表现可能会差得多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when those tools are presented as a TypeScript API rather than directly, perhaps this is because": "当这些工具以 TypeScript API 而不是直接呈现时，也许是因为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Llms have enormous amounts of real world TypeScript in their training set, but only a small set of": "LLM 的训练集中有海量的真实世界 TypeScript 代码，但只有一小部分",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:contrived examples of tool calls.": "人为设计的工具调用示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the important part here.": "所以这是这里的重点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Llms are really good with code.": "LLM 非常擅长处理代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The approach really shines when an agent needs to string together multiple calls with the traditional": "当智能体需要使用传统方法串联多次调用时，这种方法",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:approach.": "大放异彩。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The output of each tool must be fed into the LMS neural network just to be copied over to the inputs": "每个工具的输出都必须输入到 LLM 的神经网络中，仅仅是为了被复制到下一次调用的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the next call.": "输入中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Wasting time, energy and tokens.": "浪费时间、能量和 Token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah, this is why agents these days are taking tons of time to execute.": "没错，这就是为什么现在的智能体需要花费大量时间来执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And when the LLM can write code, it can skip all of that and only read back the final result it needs.": "当 LLM 可以编写代码时，它可以跳过所有这些步骤，只读回它需要的最终结果。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very, very smart.": "所以这非常、非常聪明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In short, LMS are better at writing code to call MCP than calling MCP directly.": "简而言之，LLM 编写代码来调用 MCP 比直接调用 MCP 表现更好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what is MCP?": "那么什么是 MCP？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We know what is MCP.": "我们知道什么是 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to skip that.": "所以我会跳过那部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here they talk about the anatomy of a call.": "这里他们讨论了调用的结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see here an example with a weather tool where the LLM generates this kind of special token.": "你可以在这里看到一个天气工具的例子，LLM 生成了这种特殊的 Token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then it's going to be parsed into its content to be the name of the function to call and its arguments.": "然后它将被解析，其内容将成为要调用的函数名和参数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we had a video only discussing that.": "我们之前有一个专门讨论这个的视频。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here we can see an example of a tool result.": "这里我们可以看到一个工具结果的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what's wrong with this tool called mechanism.": "那么这种工具调用机制有什么问题呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Those special tokens used in tool calls are things Llms have never seen in the wild.": "工具调用中使用的那些特殊 Token 是 LLM 在现实世界中从未见过的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they're referring to here the training data.": "所以他们这里指的是训练数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They must be specially trained to use tools based on syntactic training data.": "它们必须基于语法训练数据进行专门训练才能使用工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I have to say, the vendors by now are doing a very good job of making all llms very good at tool": "我不得不说，现在的厂商在让所有 LLM 变得非常擅长工具",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:calling.": "调用方面做得非常好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But still, this is something synthetic.": "但这仍然是合成的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They aren't always good at doing it.": "它们并不总是擅长这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here I have to differ a bit because by now in the industry, all the top tier llms are really good at": "在这里我持保留意见，因为目前行业内所有顶级的 LLM 都非常擅长",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:function calling.": "函数调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But anyways, let's continue.": "但无论如何，让我们继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If you present an LLM with too many tools and overly complex tools, it might struggle to choose the": "如果你给大语言模型（LLM）提供过多的工具或过于复杂的工具，它可能会难以选择",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:right one or to use it incorrectly.": "正确的工具，或者使用方式不当。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is true.": "事实确实如此。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:As a result, MCP server designers are encouraged to present greatly simplified APIs as compared to": "因此，我们鼓励 MCP 服务端设计者提供比传统 API 大大简化的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the more traditional API.": "接口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They might exposed to developers.": "那些接口原本可能是直接暴露给开发者的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So yeah.": "所以，没错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So basically we as developers of the MCP servers, we we want to make those MCP servers lean.": "基本上，作为 MCP 服务端的开发者，我们希望让这些 MCP 服务端保持精简。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We want to make them not ambiguous, and we really need to make an effort to make it ingestible by LMS,": "我们希望它们没有歧义，并且确实需要努力让 LLM 易于理解和吸收，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because eventually LMS are what's going to consume those MCP servers.": "因为最终是 LLM 在调用这些 MCP 服务端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Meanwhile, LMS are really good at writing code.": "与此同时，LLM 非常擅长编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, LMS ask to write code against the full complex API normally exposed to.": "事实上，让 LLM 针对通常暴露给开发者的完整复杂 API 编写代码，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Developers don't seem to have too much trouble with it.": "它们似乎并没有遇到太多麻烦。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is so true because you can take tons of code, simply dump it into an LM, and it would be": "这确实是真的，因为你可以把海量代码直接丢给 LLM，它在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:just fine analyzing it and even modifying it and doing stuff with it.": "分析、修改甚至处理这些代码方面都表现得很好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So LMS are really, really good with writing code.": "所以 LLM 在写代码方面真的非常、非常出色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why then do MCP interface have to dumb things down?": "那么，为什么 MCP 接口必须把事情简单化呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They're saying here that writing code in calling tools are almost the same thing, but it seems that": "这里的意思是，编写代码和调用工具几乎是同一回事，但似乎",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LMS can do one better than the other.": "LLM 在其中一项上比另一项做得更好。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the answer is simple.": "答案很简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:LM have seen a lot of code, and to be honest, I have to say that I've seen tons of code.": "LLM 见过大量的代码，老实说，我也见过海量的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, they've seen a lot of bad code And this is why a lot of coding editors and including the best": "然而，它们也见过很多烂代码。这就是为什么许多代码编辑器，包括像 Cursor 这样最顶尖的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:ones like load code like cursor.": "工具，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Sometimes the code they produce is really, really bad because we have a lot of bad examples on GitHub.": "有时生成的代码非常糟糕，因为 GitHub 上有大量的负面示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, you got more bad examples of code on GitHub than good examples.": "事实上，GitHub 上的烂代码示例比好代码示例还要多。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They have not seen a lot of tool calls.": "但它们并没有见过太多的工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They haven't seen any tool calls almost.": "它们几乎没见过任何工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In fact, the tool calls they have seen are probably limited and contrived training set constructed": "事实上，它们见过的工具调用可能仅限于 LLM 开发者为了训练它而构建的、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:by the LMS own developers in order to try and train it.": "有限且人为设计的训练集。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Whereas they have seen real world code from millions of open source projects.": "相比之下，它们见过来自数百万个开源项目的真实世界代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And again, yes, they're open source, with the caveat that most open source code is quite garbage.": "再次强调，没错，虽然是开源的，但需要注意的是，大多数开源代码其实挺垃圾的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Making an LLM perform task with tool calling is just like putting Shakespeare through a month long class": "让 LLM 通过工具调用来执行任务，就像是让莎士比亚参加一个月的普通话速成班，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in Mandarin and then asking him to write a play in it.": "然后要求他用中文写一部剧本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's just not going to be his best work.": "这绝不会是他的巅峰之作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is a nice example.": "这是一个很棒的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Here they talk about MCP is still useful because it's uniform, and it helps us with a uniform way to": "这里提到 MCP 仍然很有用，因为它具有统一性，它为我们将",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:connect agents with tools and MCP tools.": "智能体（Agent）与工具以及 MCP 工具连接起来提供了一种统一的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So MCP is still useful because it is uniform.": "所以 MCP 仍然有用，因为它很统一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP is designed for tool calling, but it doesn't actually have to be used that way.": "MCP 是为工具调用而设计的，但实际上并不一定非要以那种方式使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The tools that MCP server exposes are really just an RPC interface with attached documentation.": "MCP 服务器公开的工具实际上只是一个附带文档的 RPC 接口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So a lot of times it's really the API that we're wrapping as an MCP.": "所以很多时候，我们实际上是将 API 封装成了 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we don't really need to have to present them as tools.": "因此，我们并不真的需要将它们作为工具来呈现。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can take those tools and turn them into a programming language API instead.": "我们可以将这些工具转化为编程语言 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But in fact most MCPs are going to be wrappers on APIs.": "但事实上，大多数 MCP 都会是 API 的封装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But why would we do that when the programming language API already exists independently?": "但既然编程语言 API 已经独立存在，我们为什么要这样做呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Almost every MCP server is just a wrapper around an existing traditional API like I mentioned.": "正如我提到的，几乎每个 MCP 服务器都只是对现有传统 API 的封装。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why not expose those APIs?": "为什么不直接公开这些 API 呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Well, it turns out MCP does something else that's really useful.": "嗯，事实证明 MCP 还做了一些非常有用的其他事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It provides a uniform way to connect to and learn about an API.": "它提供了一种统一的方式来连接和了解 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now regarding this, OpenAPI specification also provides a very good way to connect and learn about": "关于这一点，OpenAPI 规范也提供了一种非常好的连接和了解方式",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an API.": "API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But MCP does this really well and it has been really adopted for agents.": "但 MCP 在这方面做得非常好，并且已被智能体（agents）广泛采用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's see how does this code mode work.": "那么让我们来看看这种代码模式（code mode）是如何工作的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have already extended the Cloudfare agent SDK to support this model.": "我们已经扩展了 Cloudflare 智能体 SDK 以支持这种模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:By the way, never used Cloudflare Agent SDK.": "顺便说一下，我从未用过 Cloudflare 智能体 SDK。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, say you have an app built with SDK looks like this.": "例如，假设你有一个使用该 SDK 构建的应用，看起来像这样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we have the the model, the system prompt and the message.": "这里我们有模型、系统提示词和消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the tools that we give the agent.": "这里有我们提供给智能体的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You can wrap the tools in prompt with the code mode helper and use them in your app.": "你可以使用代码模式助手（code mode helper）将提示词中的工具封装起来，并在你的应用中使用它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we simply wrap everything with their code mode here.": "所以在这里，我们只需用代码模式封装一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we give it the user input.": "然后我们给它用户输入。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:With this change, your app will now start generating and running code.": "做出此更改后，你的应用现在将开始生成并运行代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That itself will make calls to the tools you defined, MCP servers included.": "这本身将调用你定义的工具，包括 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We will introduce variants for other libraries in the very near future.": "我们将在不久的将来为其他库引入变体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Read the docs for details and examples.": "阅读文档以获取详细信息和示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's open docs here.": "让我们在这里打开文档。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's see here we have a caveat.": "让我们看看这里有一个注意事项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The code mode is experimental.": "代码模式是实验性的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's continue converting MCP to TypeScript.": "让我们继续将 MCP 转换为 TypeScript。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When you connect to an MCP server in code mode, the agent SDK will fetch the MCP server's schema and": "当你在代码模式下连接到 MCP 服务器时，智能体 SDK 将获取 MCP 服务器的架构（schema），并且",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:then convert it into a TypeScript API, complete with doc comments based on the schema.": "然后将其转换为 TypeScript API，并包含基于该架构的文档注释。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to take the schema we already wrote for MCP server, and it's going to convert it into": "所以它将采用我们已经为 MCP 服务器编写的架构，并将其转换为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:TypeScript API, which is going to contain the actual code itself.": "TypeScript API，其中将包含实际的代码本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:For example, connecting to the MCP server at MCP, Cloudflare slash agents will generate these TypeScript": "例如，连接到位于 MCP, Cloudflare/agents 的 MCP 服务器将生成这些 TypeScript",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:definitions.": "定义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see all the definitions.": "所以在这里我们可以看到所有的定义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see here basically TypeScript code.": "我们在这里基本上可以看到 TypeScript 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This TypeScript is then loaded into the agents context.": "然后这些 TypeScript 会被加载到智能体的上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I remind you agents are really really good at code.": "我提醒你，智能体非常擅长编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Currently the entire API is loaded, but future improvements could allow an agent to search and browse": "目前整个 API 都会被加载，但未来的改进可能会允许智能体进行搜索和浏览",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the API more dynamically, much more.": "更加动态地，甚至更深入地浏览 API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:A genetic coding assistant would.": "一个通用的编程助手会这样做。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to give you my $0.02 on this paragraph.": "关于这一段，我想谈谈我个人的浅见。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when we're going to be loading the tools and their definitions and their implementations as TypeScript": "因此，当我们以 TypeScript 代码的形式加载工具及其定义和实现时，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:code, we still have the context bloat.": "仍然存在上下文膨胀的问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We talked earlier because we are still loading all of the tools and their implementations into the context": "我们之前讨论过，因为我们仍然将所有工具及其实现加载到上下文",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:window.": "窗口中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But the difference here in this approach is that we only do it once.": "但这种方法的不同之处在于，我们只需执行一次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the LLM reads it and writes the code.": "然后大语言模型（LLM）读取它并编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is one thing.": "这是其中一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And second, we have today the technology to have a progressive disclosure of all of those implementations": "其次，我们现在拥有实现所有这些工具实现方案渐进式披露的技术，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:of the tools and to load them in runtime.": "并在运行时加载它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I'm saying and to only load them when we need them.": "我的意思是，仅在我们需要时才加载它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm referencing now tools like context seven and maybe to perform some similarity search or to perform": "所以我现在参考的是像 context seven 这样的工具，也许可以执行一些相似性搜索，或者执行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:some kind of action that is going to fetch you the correct APIs and correct tools to use.": "某种能够为你获取正确 API 和正确工具的操作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And lastly, even if we're going to have lots of APIs to load in the context, LMS are really good at": "最后，即使我们需要在上下文中加载大量 API，大语言模型也非常擅长",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:processing these contexts.": "处理这些上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can compare it simply to giving it a very large document to process.": "我们可以简单地将其比作给它一个非常大的文档来处理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So LMS are really good at processing code.": "因此，大语言模型非常擅长处理代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the major advantage here.": "所以这是这里的主要优势。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Running the code in the sandbox, instead of being presented with all the tools of all the connected": "在沙箱中运行代码，而不是面对所有已连接的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:MCP servers, our agent is presented with just one tool which simply executes some TypeScript code.": "MCP 服务器的所有工具，我们的智能体只面对一个工具，即简单地执行一些 TypeScript 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One tool.": "仅一个工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Interesting.": "有意思。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The code is then executed in a secure sandbox.": "然后代码在安全的沙箱中执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The sandbox is totally isolated from the internet.": "该沙箱与互联网完全隔离。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's only accessed to the outside world is through the TypeScript APIs representing it's connected MCP": "它与外界的唯一访问途径是通过代表其连接的 MCP 的 TypeScript API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:These APIs are backed by RPC invocation, which call back to the agent loop There, the agent SDK dispatches": "这些 API 由 RPC 调用支持，RPC 调用会回调到智能体循环。在那里，智能体 SDK 将调用分发",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the call to the appropriate MCP server.": "到相应的 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The sandbox code returns results to the agent in the obvious way by invoking console dot log.": "沙箱代码通过调用 console.log 这种显而易见的方式将结果返回给智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:When the script finishes, all the output logs are passed back to the agent.": "脚本运行结束时，所有输出日志都会传回给智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here they talk about running it in a sandbox, which has a lot of security implications, but MCP": "这里他们谈到了在沙箱中运行，这涉及很多安全影响，但 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:as well has a lot of security implications.": "同样也涉及很多安全影响。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And do you remember the joke the S in MCP stands for security.": "你还记得那个笑话吗：MCP 中的 S 代表安全（Security）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a joke because there is no MCP like there is no MCP security.": "这是一个笑话，因为 MCP 里根本没有 S，就像 MCP 没有安全性一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the diagrams explaining this flow.": "这里我们有解释这个流程的图表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the middle we have the agent.": "中间是智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the right we have the MCP server.": "右边是 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in the left we have the LM.": "左边是大语言模型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We start by giving the agent all the tools schemas from the MCP server.": "我们首先将 MCP 服务器中的所有工具模式（schemas）提供给智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this happens in the MCP initialization.": "这发生在 MCP 初始化过程中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the handshake.": "在握手阶段。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the agent is going to make an LM call.": "然后代理将发起一个大语言模型调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And to the LM it's going to provide the Functions.": "并向大语言模型提供这些函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The function calls matching to the MCP tools.": "与 MCP 工具相匹配的函数调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the LM outputs the special text to express the function invocations.": "然后大语言模型输出特定的文本来表达函数调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are the function calls and then the agent.": "这些就是函数调用，然后是代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is here is going to be here.": "所以这里就是这个过程。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The MCP client is going to make the tool calls themselves.": "MCP 客户端将亲自执行这些工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then this process repeats.": "然后这个过程不断重复。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in code mode.": "而在代码模式下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The difference here is that we still have the MCP server.": "这里的区别在于我们仍然有 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to provide the agent with all of the tool schemas as well.": "我们也会向代理提供所有的工具模式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But when we make the LM call we're not going to provide a function matching MCP tools.": "但当我们发起大语言模型调用时，我们不会提供与 MCP 工具匹配的函数。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're not going to provide here tool definitions to use function calling.": "所以我们在这里不会为了使用函数调用而提供工具定义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we're going to provide a TypeScript API matching the MCP tools.": "但我们会提供一个与 MCP 工具相匹配的 TypeScript API。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're simply going to dump a bunch of TypeScript code.": "所以我们只是简单地丢出一堆 TypeScript 代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then the LM is not going to make a tool call.": "然后大语言模型将不会发起工具调用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to write the code against the API provided here.": "它将根据这里提供的 API 来编写代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we want to take the code that the LM wrote.": "然后我们要获取大语言模型编写的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Then we want to send it to execute in a sandbox.": "然后我们要将其发送到沙箱中执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here the sandbox itself with RPC bindings is going to be calling the MCP server.": "在这里，带有 RPC 绑定的沙箱本身将调用 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here they suggest that the code is going to be running in two places.": "所以在这里，他们建议代码将在两个地方运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:One is going to be in the in the sandbox, but the tools themselves are still going to be running in": "一个是在沙箱中，但工具本身仍然运行在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I really not that big of a fan.": "我真的不是特别喜欢这种方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Why not simply run everything in the sandbox, maybe deploy, um, the MCP server inside the sandbox?": "为什么不直接在沙箱里运行所有东西，比如把 MCP 服务器部署在沙箱内部？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I don't know this this looks a bit weird for me.": "我不知道，这对我来说看起来有点奇怪。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But anyways, the idea here is interesting.": "但无论如何，这里的想法很有趣。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And from here on and downwards, they simply promote all of their platform and how to run everything": "从这里往后，他们只是在推销他们的整个平台以及如何运行所有内容",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:on on cloud, specifically promoting Cloudflare workers, which is their serverless solution.": "在云端运行，特别是推销 Cloudflare Workers，这是他们的无服务器解决方案。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Alrighty, so this was the end of the video and we covered most of the blog.": "好了，视频到此结束，我们已经涵盖了博客的大部分内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the idea here of code mode is actually very interesting, and in my opinion, it's here to stay.": "这里的代码模式想法实际上非常有趣，而且在我看来，它将会持续存在。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this section I want to cover agent skills.": "在这一部分，我想介绍智能体技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And skills is a concept that was introduced by the anthropic team in the middle of October 2025, and": "技能是 Anthropic 团队在 2025 年 10 月中旬提出的一个概念，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:help us extend the power of our AI agents and skills is a very cool and interesting concept that is": "旨在帮助我们扩展 AI 智能体的能力。技能是一个非常酷且有趣的概念，它",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:going to allow us to package capabilities, which can be custom workflows and certain instructions to": "允许我们将各种能力封装起来，这些能力可以是自定义工作流和特定的指令，用于",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:perform certain kind of tasks, and they are going to empower our agents to achieve much more complex": "执行某些类型的任务，它们将赋予我们的智能体完成更复杂",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:tasks.": "任务的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I believe in learning and teaching things in depth.": "我一向主张深入透彻地学习和教学。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So that's exactly what we're going to be doing in this skill section.": "这正是我们在这个技能章节中要做的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're going to work through four layers.": "我们将从四个维度展开。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Each one is going to take us deeper in understanding skills.": "每一个维度都会带我们更深入地理解技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll start with the fundamentals and understand what are agent skills.": "我们将从基础开始，了解什么是智能体技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'll show you a demo of it so you can see them in action.": "我会进行演示，让你们看到它们的实际应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we'll move to a practical layer where we're going to learn how to use skills as users, whether": "接着，我们将进入实践层面，学习作为用户如何使用技能，无论",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:we're going to be working with cloud code or with tools like the link chain deep agent.": "是通过云端代码，还是使用像 LangChain Deep Agent 这样的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:After that, we're going to review under the hood and explore the context flow when using skills in": "之后，我们将剖析底层原理，探索在智能体中使用技能时的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:an agent.": "上下文流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to give us a much deeper understanding of how everything works behind the scenes.": "这将使我们对幕后的一切运作方式有更深刻的理解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And finally, I'm going to bring it all together with an example implementation of skills inside a real": "最后，我将通过在一个真实的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:agent.": "智能体中实现技能的示例，将所有内容整合在一起。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after understanding every layer here, we're going to have a genuinely deep understanding of skills,": "在掌握了这里的每一个层面后，我们将对技能产生真正深刻的见解，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:because it's one thing to know how to use the technology.": "因为仅仅知道如何使用这项技术是一回事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to do this in the beginning of the section.": "我们会在本章开始时学习如何使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But to know how the technology is implemented under the hood and what was the motivation when implementing": "但如果能了解这项技术在底层是如何实现的，以及实现它的初衷，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it, gives us a far better understanding and deeper understanding of that concept.": "就能让我们对这一概念有更全面、更透彻的认知。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and learn more about skills.": "那么，让我们开始深入探索技能吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we're going to see skills in action.": "在这段视频中，我们将看到技能的实际应用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to demo how to use skills as users.": "我们将演示作为用户如何使用技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to show you how I can achieve a task without skills and how I can achieve a task with skills.": "因此，我将向你展示在没有技能的情况下如何完成任务，以及在有技能的情况下如何完成任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can see the difference of what's happening in how the agent behaves in the courses repository.": "这样你就能看到在课程仓库中，智能体的行为会有什么不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to the Branch Hooks hub.": "让我们前往 Branch Hooks hub。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I'm going to go to the commit list.": "在这里，我要进入提交列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here I want to choose this commit here improved hook card and hero with multi-agent working.": "在这里，我想选择这个提交：'improved hook card and hero with multi-agent working'。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be our starting point.": "所以这将是我们的起点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because we're going to be adding a bunch of commits to this branch here, then you are going to": "因为我们将向这个分支添加一系列提交，所以你会",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:see some commits further ahead.": "看到后面还有一些提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However I want you to start from this commit.": "不过，我希望你从这个提交开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So please copy the hash of this commit.": "所以请复制这个提交的哈希值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go to the IDE.": "让我们前往 IDE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and switch to this commit and to this branch.": "让我们切换到这个提交和这个分支。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now you can see that I'm on the main branch currently.": "现在你可以看到我目前在 main 分支上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and open the terminal and let's go to switch to this commit.": "让我打开终端，切换到这个提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write git switch project slash hookup.": "让我输入 git switch project/hookup。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you would want to add here also the commit hash.": "你还需要在这里加上提交哈希值。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:You would have the exact code that I'm having right now.": "这样你就会拥有和我现在完全一样的代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now once we run it we're going to see we're going to have a new directory the hookup directory.": "运行之后，我们会看到出现了一个新目录，即 hookup 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have all the code that we had in previous sections in the course.": "这里包含了我们在课程之前章节中用到的所有代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me now CD into hookup directory and let me write npm install to install all the dependencies": "现在让我进入 hookup 目录，并输入 npm install 来安装所有的",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in that we have.": "依赖项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And after we're going to finish doing that let me go and let's run now npm run dev.": "完成后，让我们运行 npm run dev。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have now the hookup application running in our localhost port 3000.": "现在我们的 hookup 应用程序正在本地主机的 3000 端口运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is something we saw earlier in the course here.": "这是我们之前在课程中看到过的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this was the setup for us to have the same code.": "这就是为了让我们拥有相同代码的设置步骤。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and learn about skills here.": "现在，让我们来学习这里的技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's start with scenario.": "让我们从场景开始。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this is a very simple UI.": "现在这是一个非常简单的 UI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's say we want to make this hookup application look with a certain style and have a certain feel.": "假设我们想让这个 hookup 应用程序具有某种风格和感觉。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want it to be very, very beautiful.": "我们希望它非常非常漂亮。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we want it to be with a theme.": "我们希望它带有一个主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And for this example we want to use the anthropic theme.": "在这个例子中，我们想使用 Anthropic 主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we want the hookup application to look exactly like a tropic made it.": "所以我们希望 hookup 应用程序看起来就像是 Anthropic 制作的一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and fire up cloud.": "让我们启动 Claude。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the first way to do it is to simply prompt it.": "第一种方法是直接给它提示词。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to write in the prompt to make this web app anthropic style.": "所以我将在提示词中写道：让这个 Web 应用呈现 Anthropic 风格。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now here's the thing.": "现在问题来了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Currently don't have anything about the anthropic style in our cloud file and in our repo here.": "目前我们的 Claude 文件和仓库中没有任何关于 Anthropic 风格的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So cloud is going to skim through all the files here.": "所以 Claude 会浏览这里所有的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to skim through all the components.": "它会浏览所有的组件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now notice it's going to be fetching from anthropic comm.": "现在请注意，它将从 anthropic.com 获取信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Even here.": "甚至在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And in this video we're going to dive a bit deeper into agent skills.": "在这段视频中，我们将深入探讨智能体技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we are going to introduce custom skills in this video.": "所以我们将在视频中介绍自定义技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to review a skill which not only has a skill file, but also has its auxiliary scripts": "我们将审查一个技能，它不仅包含技能文件，还包含其辅助脚本",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that it's able to use run and to help us achieve our tasks.": "它可以运行这些脚本来帮助我们完成任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this skill is going to be found online from a skill repository, and we are going to be downloading": "这个技能可以从在线技能仓库中找到，我们将下载",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:that skill.": "那个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are going to reiterate and we're going to improve and adjust this skill into our needs.": "我们将反复迭代，并根据我们的需求改进和调整这个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to give us more flexibility as users how to use agent skills.": "这将作为用户在使用智能体技能方面赋予我们更大的灵活性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm in this repository called Cloud Skills Marketplace.": "我现在在这个名为 Cloud Skills Marketplace 的仓库中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is one of many repositories containing cloud code skills that we can download.": "这是包含我们可以下载的云代码技能的众多仓库之一。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can integrate into cloud code or to any other agent that supports skills like cloud desktop and": "我们可以将其集成到云代码或任何其他支持技能的智能体中，例如云桌面和",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like link chain deep agent.": "比如 link chain deep agent。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, this repository has many skills that we can download and we can install to our agent here.": "现在，这个仓库有很多技能，我们可以下载并安装到这里的智能体中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here I'm quickly reviewing the Readme file.": "这里我正在快速浏览 Readme 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go up a bit and let me show you that it's even a marketplace.": "让我们往上走一点，让我向你展示它甚至是一个市场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can add it as a marketplace in cloud code in the plugin system, like I showed you earlier.": "就像我之前向你展示的那样，我们可以将其作为市场添加到云代码的插件系统中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I want to show you the scale that we are going to make the video about.": "现在我想向你展示我们将要制作视频的那个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here under Engineering Workflows we have here a skills folder.": "在 Engineering Workflows 下，我们这里有一个 skills 文件夹。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have a skill called Git pushing.": "这里我们有一个名为 Git pushing 的技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to help us push our code to GitHub.": "它将帮助我们将代码推送到 GitHub。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go to the skill file here.": "让我们看看这里的技能文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here in the description we can see we have stage commit and push git changes with conventional commit": "在描述中，我们可以看到我们有使用常规提交消息进行暂存、提交和推送 git 更改的功能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:messages.": "消息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Use when user wants to commit and push changes mentions pushing to remote or ask to save their work.": "当用户想要提交和推送更改、提到推送到远程或要求保存他们的工作时使用。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then we can see when to use this skill.": "然后我们可以看到何时使用这个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when the user asks to push changes, commit and push to push this to push to GitHub or other similar": "当用户要求推送更改、提交并推送、将此推送到 GitHub 或其他类似",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:commands.": "命令时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I remind you that this YAML front matter.": "我提醒你，这个 YAML 前置元数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This is only what's going to the system prompt of the cloud code agent.": "这只是进入云代码智能体系统提示词的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The rest of this file is going to be read only when the skill is selected to be executed.": "文件的其余部分只有在选择执行该技能时才会被读取。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now interestingly enough, we can see that here under workflow, we can see that we are instructing": "现在有趣的是，我们可以在 workflow 下看到，我们正在指示",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the main agent to always use the script, which is called Smart Commit, and we do not want to use manual": "主智能体始终使用名为 Smart Commit 的脚本，而我们不想使用手动",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:git commands.": "git 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this script, Smart commit, which we're soon going to review, there are a bunch of git commands.": "在这个我们很快就会审查的 Smart commit 脚本中，有一堆 git 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when using this skill, we don't want I mean the skill writer didn't want the main agent to commit": "现在使用这个技能时，我们不希望——我的意思是技能编写者不希望主智能体去提交",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the code using standard git commands, because this is the designated workflow that the user has decided.": "使用标准 git 命令的代码，因为这是用户决定的指定工作流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the creator of this skill had an opinionated way to commit changes.": "所以这个技能的创建者对于提交更改有一种特定的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is exactly what skills are for.": "而这正是技能的用途。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:There are opinionated ways to perform things.": "执行事务有特定的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So if we want to commit in a certain style or with a certain commands, then skills help us to package": "因此，如果我们想以某种风格或使用某些命令进行提交，那么技能可以帮助我们打包",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this workflow and to give an AI agent an ability to do that.": "这个工作流，并赋予 AI 智能体执行该操作的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to have that skill.": "从而拥有那项技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go one directory back.": "那么让我们回到上一级目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the scripts directory.": "这里有 scripts 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have the smart commit script.": "这里有 smart commit 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this script has some logic to execute.": "这个脚本有一些要执行的逻辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So to run git add git status git commit with a certain message.": "比如运行带有特定消息的 git add、git status、git commit。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a script that the main agent is going to be able to run.": "这是一个主智能体将能够运行的脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to know about this script only when the agent is deciding to use that git push skill.": "只有当智能体决定使用那个 git push 技能时，它才会知道这个脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So comparing this skill to the previous skill we saw in the previous video, this skill not only has": "因此，将此技能与我们在上一个视频中看到的上一个技能相比，此技能不仅包含",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a skill file, but it has auxiliary scripts that are going to help the agent achieve the task that we": "一个技能文件，还包含辅助脚本，这些脚本将帮助智能体完成我们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:want, which is to commit our code to GitHub.": "想要的任务，即把我们的代码提交到 GitHub。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this script running ability within skills gives us as users tremendous flexibility to really implement": "技能内部的这种脚本运行能力为我们用户提供了巨大的灵活性，可以真正实现",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:everything we want and to give cloud the capability to really do anything.": "我们想要的一切，并赋予 Claude 真正做任何事情的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, if I say to give cloud or our agent capability, it might remind you of MCP, because with MCP": "现在，如果我说赋予 Claude 或我们的智能体能力，这可能会让你想起 MCP，因为通过 MCP",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:servers, we actually give cloud or the agent.": "服务器，我们实际上赋予了 Claude 或智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're using the ability to make API calls to talk with external services.": "我们正在使用进行 API 调用以与外部服务通信的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But they're really, really different mechanisms.": "但它们确实是完全不同的机制。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I will be making an entire video comparing skills with MCP and Subagents and slash commands.": "我将制作一个完整的视频来比较技能与 MCP、子智能体（Subagents）以及斜杠命令（slash commands）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to create some order with all of those primitives.": "所以我们将对所有这些原语进行梳理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go to the repository.": "让我进入仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice I am on the branch project slash skills.": "请注意，我目前在 project/skills 分支上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So you can check out in the videos resource in case you want to have the exact code as I'm using.": "如果你想获得与我使用的完全相同的代码，可以查看视频资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now let's go and create our own custom skill.": "现在让我们去创建我们自己的自定义技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is a custom skill which is going to be a project level skill.": "这是一个自定义技能，它将是一个项目级技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to be creating it under the Dot cloud directory in our project.": "所以我们将在项目的 .claude 目录下创建它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And because this is a project level skill, it's only going to be working with sessions cloud code sessions": "因为这是一个项目级技能，它只会在 Claude 代码会话中工作",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which we open from this directory.": "也就是我们从这个目录打开的会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and create a new directory under dot cloud.": "那么让我们在 .claude 下创建一个新目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's call it skills.": "把它命名为 skills。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let's create a subdirectory which is called git dash pushing.": "在这里创建一个名为 git-pushing 的子目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let's go and create a new file which is called skill.md.": "在这里创建一个名为 skill.md 的新文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's create another subdirectory under git pushing which is called scripts.": "在 git-pushing 下创建另一个名为 scripts 的子目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to have our auxiliary scripts.": "这里我们将存放我们的辅助脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here let's create a new file and call it smart commit dot is h.": "在这里，让我们创建一个新文件，并将其命名为 smart-commit.sh。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we did right now is replicate the directory structure of the skill that we saw in the GitHub": "所以我们现在所做的是复制我们在 GitHub 上看到的该技能的目录结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me now go back to the GitHub repository.": "现在让我回到 GitHub 仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's go and copy paste all the content of that skill.": "让我们去复制并粘贴该技能的所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's copy the cloud.md and the smart SSH script.": "让我们复制 cloud.md 和 smart-commit.sh 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it was under the git pushing directory.": "它位于 git-pushing 目录下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go to skill MD and let's go and copy all of this file.": "让我们转到 skill.md 并复制该文件的所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me paste it.": "让我把它粘贴过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if we're going to look through the implementation we can see that it is referring to a script a": "如果我们查看实现过程，可以看到它引用了一个脚本，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:smart commit script which is located under the skills slash git pushing slash scripts.": "即位于 skills/git-pushing/scripts 下的 smart-commit 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we have the exact directory structure in our repository right now.": "所以现在我们的仓库中拥有完全相同的目录结构。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go to Smart Commit dash and let's go and copy the content of the script from the repo.": "让我转到 smart-commit.sh，并从仓库中复制该脚本的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and let's go and paste it.": "然后让我们把它粘贴过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And so right now we simply copy pasted all of this skill to our local project here.": "所以现在我们只是简单地将所有这些技能复制粘贴到了我们的本地项目中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we could have simply installed it with the plugin system.": "当然，我们本可以简单地通过插件系统来安装它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But I want to have a lot more control.": "但我希望能有更多的控制权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to see in the rest of this video how we are going to be improving and re-editing this": "在本视频的剩余部分，我们将看到我们将如何改进和重新编辑这个",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:skill.": "技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, let's go and open an instance of cloud code.": "好了，让我们去打开一个 Claude Code 实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me open a terminal.": "让我打开一个终端。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me drag it.": "让我把它拖过来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, I'm not using the cloud code extension for cursor for a reason because I don't like": "顺便说一下，我没有使用 Cursor 的 Claude Code 扩展是有原因的，因为我不喜欢",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it like the plain old vanilla terminal cloud code.": "它，我更喜欢原汁原味的终端版 Claude Code。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me write in the prompt to cloud to list their skills.": "让我向 Claude 发出指令来列出它们的技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we see here the project level skill which we just created, the git pushing skill.": "我们可以看到这里有我们刚刚创建的项目级技能，即 git-pushing 技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see all the other skills skins that we installed through the plugin system in the previous": "我们还可以看到我们在上一个视频中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:video.": "通过插件系统安装的所有其他技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So those are from the Anthropic Example skills marketplace.": "那些来自 Anthropic 示例技能市场。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and write push changes.": "让我们输入 push changes。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see that cloud now is asking us if we want to use the skill of git pushing.": "我们可以看到 Claude 现在正询问我们是否要使用 git-pushing 技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to allow and say yes.": "我将允许并说 yes。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now it's going to load the skill and it's going to read it.": "现在它将加载该技能并读取它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to decide next what is going to be doing.": "接下来它将决定要做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to ask to run the script of smart commit SSH.": "它将请求运行 smart-commit.sh 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because this is what we told him to do in this file.": "因为这就是我们在这个文件中告诉它要做的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now instead of cloud code to come up with the git status git add git commit git push commands.": "所以现在 Claude Code 不再需要自己想出 git status、git add、git commit、git push 这些命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's doing everything.": "它正在处理一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's simply going to run one script where we have all of this configured right now.": "现在它只需运行一个脚本，而我们现在已经配置好了所有这些内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and approve it.": "让我去批准它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now the script is running and we can see we have an error from the script.": "现在脚本正在运行，我们可以看到脚本报错了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this error is simply because I created an orphan branch and it caused problems making the first": "这个错误仅仅是因为我创建了一个孤立分支，导致在这里进行第一次\n提交时出现了问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:commit here.": "提交在这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's take a look what cloud code is going to be doing next.": "那么让我们来看看 Cloud Code 接下来会做什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to resolve it.": "它将解决这个问题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it suggests to add git add a and then commit everything.": "所以它建议执行 git add .，然后提交所有内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now A it's going to ask me to to push it.": "现在它会要求我进行推送。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and say yes.": "让我点一下“是”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the skill failed.": "结果技能运行失败了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And then cloud code A resolved to its regular and behavior without this skill.": "然后 Cloud Code 回退到了没有该技能时的常规行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is also interesting to see.": "这看起来也挺有意思的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And yeah so right now it's pushing the code to the remote repository.": "是的，现在它正在将代码推送到远程仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Once it finishes let's go to the repo and check out the new commit.": "完成后，我们去仓库查看一下新的提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Go to the projects list skills branch to the commit list.": "进入项目列表、skills 分支，查看提交列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the commit that cloud code made.": "在这里我们可以看到 Cloud Code 所做的提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I just want to emphasize that this commit was not made via the skill because the skill failed.": "我想强调的是，这次提交并不是通过该技能完成的，因为技能失败了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Running the script and then cloud code defaulted to its regular behavior.": "运行脚本失败后，Cloud Code 默认执行了其常规行为。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:All right, so let's go back to the code here and let's start customizing the skill here.": "好了，让我们回到代码，开始在这里自定义技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I want to go and edit this when to use section.": "我想去编辑这个“何时使用 (when to use)”部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me add here another example of in some keywords.": "让我在这里添加另一个关键词示例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:To use this skill let me add here push to remote.": "为了使用这个技能，让我在这里添加“push to remote”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we added another keyword for cloud code to decide when to use this skill.": "这样我们就为 Cloud Code 添加了另一个关键词，用来决定何时使用该技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let me pause for a moment because we have here a gotcha.": "现在让我停顿一下，因为这里有一个需要注意的地方。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the only thing that is going to be loaded to the cloud code main agent context is the front matter": "唯一会被加载到 Cloud Code 主代理上下文中的是顶部的\n前置内容 (front matter)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:over here at the top.": "就在顶部的这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this front matter here with the name and the description.": "也就是包含名称和描述的这些前置内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we actually needed to put this push to remote right over here at the top.": "实际上，我们需要把这个“push to remote”直接放在顶部的这里。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Because this is what's going to be attached to the context every time we send a message to cloud code.": "因为这是每次我们向 Cloud Code 发送消息时都会附加到上下文中的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The bottom here is only going to be loaded once cloud code had already decided to use that skill.": "底部的内容只有在 Cloud Code 已经决定使用该技能后才会被加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the progressive disclosure only when cloud codes need to use the skill, it's going to be": "这就是渐进式披露：只有当 Cloud Code 需要使用该技能时，才会\n加载那部分上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:loading that context.": "加载那部分上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the change we just made here is really redundant.": "所以我们刚才在这里做的更改实际上是多余的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not going to affect anything.": "它不会产生任何影响。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Nevertheless let's go and let's go to cloud code and let's go and commit everything.": "尽管如此，我们还是去 Cloud Code 提交所有内容吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me clear up the context here.": "让我清理一下这里的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we'll have a fresh context.": "这样我们就有一个全新的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and write push to remote.": "让我输入“push to remote”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And funny enough it's going to work.": "有趣的是，它居然起作用了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's going to be asking to use this skill.": "它会询问是否使用这个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is no thanks to the change we made because the change we made is actually redundant.": "这并不是因为我们所做的更改，因为我们做的更改实际上是多余的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That was not loaded and was not part of the context when making this request.": "在发出此请求时，那部分内容并未被加载，也不是上下文的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now I'm going to say yes.": "现在我要选“是”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this time I want cloud code to keep using this skill without me consenting every time.": "这一次，我希望 Cloud Code 能一直使用这个技能，而不需要我每次都授权。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now cloud code is doing it because it's going to derive the design language from what it's going to": "现在 Cloud Code 正在这样做，因为它将从它要获取的内容中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:be fetching from this URL, which is quite smart.": "从这个 URL 提取设计语言，这非常聪明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm actually surprised it can do those kinds of things.": "事实上，我很惊讶它能做这类事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's not wrong to do it.": "这样做并没有错。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Don't get me wrong here, but let's say we need to do it 12 times.": "别误会我的意思，但假设我们需要做 12 次。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So every time now we're going to be fetching from the anthropic website and again and again and again.": "那么现在每次我们都要从 Anthropic 网站反复抓取。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can really have a reused workflow we can use here.": "所以我们这里确实可以有一个可重用的工作流。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:If we're going to dial down this design system and design language of the anthropic theme here.": "如果我们要确定这里的 Anthropic 主题的设计系统和设计语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now we can actually go and add this design language to the cloud file.": "现在我们实际上可以将这种设计语言添加到云文件中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, the problem with that is that it's going to be attached to the context always.": "然而，这样做的问题是它将始终附加到上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And even if we're going to be working on the back end system?": "即使我们是在处理后端系统？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We're still going to be attaching that context.": "我们仍然会附加那个上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And that's not ideal because we're going to bloat our context.": "这并不理想，因为我们会使上下文膨胀。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's going to lead us to context rot and a lot of bad things if we're going to misuse it.": "如果误用，会导致上下文腐烂以及很多糟糕的情况。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So skills are actually the most elegant way to do it.": "所以“技能”实际上是实现这一目标最优雅的方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can create a skill which is going to specify the design language of the anthropic theme.": "我们可以创建一个技能来指定 Anthropic 主题的设计语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And every time we're going to do something in the front end, cloud code is going to choose the skill,": "每当我们在前端进行操作时，Cloud Code 都会选择该技能，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it's going to be using it, and it's going to load this data dynamically.": "并使用它，动态加载这些数据。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what we're going to be seeing very, very soon.": "这就是我们很快就会看到的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and continue.": "那么让我们继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it fetched now all the information from anthropic comm.": "它现在已经从 anthropic.com 获取了所有信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it says that it has a clear picture of the design language.": "现在它说它对设计语言有了清晰的了解。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's creating a to do list.": "它正在创建一个待办事项列表。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let me go and fast forward this.": "现在让我快进一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And looks like it's already changed.": "看起来它已经改变了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the background colors.": "现在是背景颜色。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Added the theme so it kind of have this entropic theme right now.": "添加了主题，所以现在它有点像有了这种 Anthropic 主题。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and wait for it to finish.": "让我们等待它完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So looks like it's finished now.": "看起来现在已经完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the new design here with the entropic theme which honestly looks amazing.": "这是采用了 Anthropic 主题的新设计，老实说看起来棒极了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And really I'm really impressed with the quality of this result.": "我真的对这个结果的质量印象深刻。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Anyways, let's go now and let's talk about skills here because this is the entire section here.": "总之，现在让我们来谈谈“技能”，因为这是整个章节的内容。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to switch now to the entropic official skills repository.": "我现在要切换到 Anthropic 的官方技能仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we're going to have a bunch of example skills.": "这里有一堆示例技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And if I'm going to go up in the repository here every skill is going to have its own directory here.": "如果我查看仓库，这里的每个技能都有自己的目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you can see the different skills that we have to experiment with.": "你可以看到我们可以用来实验的不同技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now to the brand guidelines skills.": "现在让我看看品牌指南技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:This skill has a skill.": "这个技能包含一个技能定义。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice a skill may have a bunch of files, not only files, it can have executable files, and you": "注意，一个技能可能包含一堆文件，不仅是文件，它还可以包含可执行文件，而你",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to choose the second option.": "所以我打算选择第二个选项。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be changing the settings dot local dot JSON file like we saw earlier in the course.": "所以这将修改 settings.local.json 文件，就像我们在课程前面看到的那样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's going to ask to run the script.": "现在它会询问是否运行脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to run it again without any consent.": "所以我想在不需要任何许可的情况下再次运行它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this time the script ran successfully.": "这次脚本成功运行了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see here the the logs.": "所以我们可以在这里看到日志。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see current branch staging all changes and we can see everything has finished.": "我们可以看到当前分支暂存了所有更改，并且可以看到一切都已完成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let us go now and check out the commits.": "那么现在让我们去查看一下提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here we can see the second commit.": "在这里我们可以看到第二次提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now notice here that the commit message isn't that informative.": "现在请注意，这里的提交信息并没有提供太多信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It simply said that it edited one file.": "它只是简单地说明编辑了一个文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is because of the implementation of the smart commit sage script.": "这是因为 smart commit sage 脚本的实现方式。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back to the implementation in our IDE.": "让我们回到 IDE 中的实现代码。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see somewhere here we have the commit message.": "我们可以在这里的某个地方看到提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the commit message Sage is going to be very, very simple.": "提交信息 Sage 将会非常非常简单。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So here is the logic for what to write in the commit message.": "这里是关于在提交信息中写什么的逻辑。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it's actually quite stupid.": "所以它实际上挺笨的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in our case right now it simply wrote update with the number of files which were updated.": "在我们现在的情况下，它只是简单地写了 update 以及更新的文件数量。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is not using AI.": "所以这并没有使用 AI。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is really stupid to be honest to use this kind of of scale.": "说实话，使用这种程度的东西真的很蠢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so what I want to do now is I want to show you how we can edit this script and how we can customize": "嗯，所以我现在想做的是向你们展示我们如何编辑这个脚本，以及如何进行定制",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it to our own needs.": "以满足我们自己的需求。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to fire up cloud right now, and I'm going to ask cloud to edit this smart commit script": "所以我现在要启动 Claude，并要求 Claude 编辑这个 smart commit 脚本",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to use cloud CLI to generate the commit message.": "以使用 Claude Code CLI 来生成提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me fire up cloud again and we'll use the same session from before.": "让我再次启动 Claude，我们将使用之前的同一个会话。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's simply right here.": "就在这里写吧。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Can you please edit the smart commit message to use Cloud Code CLI to create a custom commit message": "请编辑 smart commit 信息，使用 Claude Code CLI 来创建一个自定义提交信息",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:like a pirate.": "像海盗一样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is the diff.": "这是差异对比（diff）。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see we are in line 87.": "我们可以看到我们在第 87 行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We are running cloud Dash P.": "我们正在运行 Claude -p。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we have here a prompt saying they are pirate.": "我们这里有一个提示词，说“像个海盗”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And one thing then to create a commit message.": "然后是创建一个提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a the suggestion cloud code made.": "所以这是 Claude Code 提出的建议。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's go and accept it.": "让我们接受它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's see what happens now when we're going to be asking it to push to remote.": "让我们看看现在当我们要求它推送到远程仓库时会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now let me write push to remote.": "现在让我输入 push to remote。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's going to probably run the script without me approving.": "现在它可能会在未经我批准的情况下运行脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So yeah we can see now the smart commit script is running.": "是的，我们现在可以看到 smart commit 脚本正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can already see in its output that we have some pirate slang here.": "我们已经可以在它的输出中看到这里有一些海盗俚语。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:See this ah thingy.": "看看这个 ah 之类的东西。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's now go to the repository.": "现在让我们去仓库看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's refresh now the commits and we can see the new commit This new comet has Ahoy has R at the end": "让我们刷新一下提交记录，我们可以看到新的提交。这个新的提交里有 Ahoy，结尾有 R",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:and it's talking like a pirate.": "并且说话像个海盗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it actually used cloud code to generate the commit message by running the smart commit message.": "它实际上是通过运行 smart commit 脚本，使用 Claude Code 来生成提交信息的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the smart commit message, it actually ran cloud code and then it generated the commit message for": "所以这个智能提交信息，它实际上运行了云代码，然后为",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:us.": "我们生成了提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to show you another aspect of cloud skills and show you how flexible they are.": "所以我想向你们展示云技能的另一个方面，看看它们有多灵活。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I want to go back to the IDE.": "所以我想回到 IDE。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I'm going to be a really bad boy here.": "现在我要在这里调皮一下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to take this smart commit ssh script, and I'm going to move it to be under the git pushing": "所以我要把这个智能提交 ssh 脚本移动到 git pushing 目录下，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But not only that I'm going to also delete the scripts directory.": "不仅如此，我还要删除 scripts 目录。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I actually created is a discrepancy because Skillmd required the script to be under the scripts": "所以我实际上制造了一个差异，因为 Skill.md 要求脚本位于 scripts 目录下，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now I removed it and I put this script and its existing under the git pushing directory.": "而现在我把它移走了，把这个脚本放在了 git pushing 目录下。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I really made a mess here.": "所以我真的把这里搞得一团糟。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what I want to show you is that even after everything I did right now, this skill is going to be": "我想向你们展示的是，即使在我做了刚才这一切之后，这个技能仍然可以",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:working fine.": "正常工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go and clear the context.": "让我去清除一下上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So right now we have a fresh context window.": "现在我们有了一个全新的上下文窗口。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me write Push to Remote.": "让我输入 Push to Remote。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now cloud code is running the script even though we changed the path here.": "我们可以看到，尽管我们更改了这里的路径，云代码现在仍在运行该脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it managed actually to do it without us to explicitly say it in the file.": "所以它实际上做到了这一点，而不需要我们在文件中明确说明。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the reason why it still worked and it ran still the script, even though we had a mismatch in the": "尽管目录结构不匹配，它仍然能够运行脚本的原因是，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:directory structure, is because skills are eventually context that we send the agent, even though": "技能最终是我们发送给智能体的上下文，即使",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the context we sent was not that accurate.": "我们发送的上下文并不那么准确。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The agent itself is smart enough to go and see and find the new location of the smart commit file.": "智能体本身足够聪明，能够去查看并找到智能提交文件的新位置。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to give you some homework now.": "现在我要给你们留点作业。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Try to delete the smart commit file and see what happens.": "尝试删除智能提交文件，看看会发生什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now the new commit.": "现在我们可以看到新的提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Hoist the script up from scripts folder wax.": "将脚本从 scripts 文件夹中提升出来。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me go now and bring everything back as it was.": "现在让我把一切恢复原样。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's create a scripts directory and let's go and add this script there.": "让我们创建一个 scripts 目录，并把脚本添加进去。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now let's write push to remote.": "现在让我们输入 push to remote。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now we can see it's running.": "现在我们可以看到它正在运行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And everything worked as we wanted.": "一切都如我们所愿。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me refresh the page here.": "让我刷新一下这个页面。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Boom.": "搞定。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see very the script in the scripts directory.": "我们可以清楚地看到脚本就在 scripts 目录中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in this video, we are going to be discussing the distinction between agent skills and MCP.": "在这段视频中，我们将讨论智能体技能与 MCP 之间的区别。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they are both essential tools in the modern agent toolkit.": "它们都是现代智能体工具箱中必不可少的工具。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But they solve different problems and they operate in different layers of the context architecture.": "但它们解决的是不同的问题，并且运行在上下文架构的不同层级。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So agent skills are procedural knowledge containers.": "智能体技能是程序性知识容器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:They are folders containing instructions containing scripts and containing resources.": "它们是包含指令、脚本和资源的文件夹。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That is going to teach our AI agents how to perform specialized tasks consistently and consistently": "这将教导我们的 AI 智能体如何一致地执行专门任务，而“一致性”",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:is the key word here, because with agent skills, we can package our workflow and teach and give it": "是这里的关键词，因为通过智能体技能，我们可以打包工作流，并将其传授给",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to our agent to perform it.": "我们的智能体去执行。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now, when it comes to context engineering, their context architecture is based on progressive disclosure.": "现在，谈到上下文工程，它们的上下文架构是基于渐进式披露的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is a system which is going to load the relevant context only when needed.": "这是一个仅在需要时才加载相关上下文的系统。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when a session with the coding agent or agent that supports skills starts, the agent loads only": "因此，当与编程智能体或支持技能的智能体开始会话时，智能体仅加载",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:a brief description and the names of the available skills and the context.": "可用技能的简短描述、名称以及上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Price here is very low because we are going to consume around 100, maybe 200 tokens in total for every": "这里的成本非常低，因为每次我们总共只会消耗大约 100 到 200 个 token，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is regardless of the complexity of each skill.": "且这与每个技能的复杂程度无关。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:However, when a skill becomes relevant to a certain task, and this is the agent to decide, the complete": "然而，当某个技能与特定任务相关时（这由智能体决定），",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:instructions of the skill which is derived from the skill file are being loaded.": "源自技能文件的完整技能指令将被加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And only when a skill is actively used and the agent decides to use an executable script, it loads": "只有当技能被积极使用且智能体决定使用可执行脚本时，它才会将其加载",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:it to the context.": "到上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we might have a bunch of scripts which are not going to be loaded to the context if they're not going": "因此，我们可能有一堆脚本，如果它们不被使用，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to be used.": "就不会被加载到上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So agent skills are very context efficient.": "所以智能体技能在上下文利用上非常高效。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go and talk about MCP.": "接下来，让我们谈谈 MCP。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:In the MCP architecture we do upfront provisioning of the tool definitions and the server specifications": "在 MCP 架构中，我们在对话开始时",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in the beginning of the conversation.": "预先配置工具定义和服务器规范。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So as far as context efficiency this is not so good because we can have for example five MCP server": "就上下文效率而言，这并不理想，因为例如我们可能有五个 MCP 服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which can consume 50,000 tokens.": "它们可能会消耗 50,000 个 token。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is even before our first prompt.": "而这甚至是在我们输入第一个提示词之前。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the problem that MCP is solving is to connect the agents into external resources.": "现在， MCP 解决的问题是将智能体连接到外部资源。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the problem MCP server, while the problem skill is solving, is to give an agent an ability": "这是 MCP 服务器解决的问题，而技能解决的问题是赋予智能体",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:to perform specialized tasks, which is going to be consistent.": "执行专门任务的能力，并保持一致性。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they both they solve different things.": "所以它们两者解决的是不同的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now when it comes when to use each one.": "现在谈谈何时使用每一种。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So when is an MCP tool invoked and when is a skill invoked.": "那么，什么时候调用 MCP 工具，什么时候调用技能呢？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they are both invoked by the agent's judgment.": "它们都是根据智能体的判断来调用的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So and this is depending on the skills description and the MCP server and MCP tools descriptions.": "这取决于技能描述以及 MCP 服务器和 MCP 工具的描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So the method of invoking them are both very very similar.": "所以调用它们的方法都非常非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And you know what's going to be interesting.": "你知道什么会很有趣吗。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Maybe if we'll create a skill and then we'll create from that skill an MCP server with an MCP tool with": "也许我们可以先创建一个技能，然后基于该技能创建一个带有 MCP 工具的 MCP 服务器，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the exact same skill.": "包含完全相同的技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we can see what the agent decides to execute the skill or the MCP server.": "我们可以看看智能体会决定执行技能还是 MCP 服务器。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And regarding the execution where the execution happens in the MCP server, the execution happens in": "关于执行，在 MCP 服务器中，执行发生在",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It can be running locally on our machine, it can be deployed in the cloud, but in skills the execution": "它可以在我们的机器上本地运行，也可以部署在云端，但在技能中，执行",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:usually happens locally.": "通常发生在本地。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So it usually happens in the main agent thread.": "所以它通常发生在主智能体线程中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is also something interesting to know.": "所以这也是一件很有趣的事情。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:can put really a lot of data and a lot of context here.": "这里可以放入大量数据和大量上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we're going to be seeing this later in this course.": "我们将在本课程的后续部分看到这一点。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But let's go to the file and let's have a look on it.": "但让我们打开文件看一看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what we're seeing right now is the skill itself.": "我们现在看到的是技能本身。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is the brand guidelines.": "这是品牌指南。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this applies on tropics official brand colors and typography and all the artifacts we may benefit": "这适用于 Anthropic 的官方品牌颜色、排版以及我们可能在 UI 中",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:in our UI here.": "受益的所有资产。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And what we're seeing here is the front matter.": "我们在这里看到的是前置元数据 (front matter)。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is what's going to be loaded in the clouds code or the agent system prompt and only this context.": "这就是将要加载到 Claude Code 或代理系统提示词中的内容，且仅包含此上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this concept is very similar to something we already covered when we talked about sub agents.": "这个概念与我们讨论子代理时已经涵盖的内容非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So only when the skill is selected we're going to load the rest of this context into the prompt.": "因此，只有在选择该技能时，我们才会将剩余的上下文加载到提示词中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here in the rest of this markdown file, we have all of the brand guidelines, the fonts, the colors,": "在这个 Markdown 文件的其余部分，我们拥有所有的品牌指南、字体、颜色、",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:the spacing and everything we need to build the entropic UI.": "间距以及构建 Anthropic UI 所需的一切。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So what I want to do right now is to go back in the repo here and let's go and equip our coding agent,": "所以我现在想做的是回到这个仓库，让我们去装备我们的编码代理，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:which is cloud code, and let's go and add those skills to cloud code.": "即 Claude Code，让我们把这些技能添加到 Claude Code 中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is very similar to how we add a plugin.": "这与我们添加插件的方式非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we use this plugin command.": "我们使用这个 plugin 命令。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we are adding a new marketplace which is going to point to this repo which is entropic slash skills.": "我们正在添加一个新的市场，它将指向这个名为 anthropic/skills 的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now once we're going to click enter then cloud code is going to clone this repository locally into our": "一旦我们按下回车键，Claude Code 就会将这个仓库克隆到我们的本地",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:machine.": "机器上。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to be cloned in our Cloud plugins sections in the root directory.": "它将被克隆到根目录下的 Claude 插件部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now if I'm going to go and let's go and check slash plugins, let's go and browse and install plugins.": "现在，如果我去检查 /plugins，让我们去浏览并安装插件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the anthropic agent skills.": "在这里我们可以看到 Anthropic 代理技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have two types of skills we can install.": "这里有两种我们可以安装的技能类型。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can install the document skills and the example skills.": "我们可以安装文档技能和示例技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the document skills are a collection of document processing suite including Excel, PowerPoint etc..": "文档技能是文档处理套件的集合，包括 Excel、PowerPoint 等。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And an interesting fact when clouds not cloud code, when cloud released um, their support to create": "一个有趣的事实是，当 Claude（不是 Claude Code），当 Claude 发布了",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:decks and create documents.": "创建幻灯片和创建文档的支持时。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It was in the same announcement where they introduced skills, because the fact is that they implement": "就在他们介绍技能的同一个公告中，因为事实是他们",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:this support using agent skills.": "使用代理技能实现了这种支持。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the example skills here, this is a collection of the example skills we reviewed earlier in the": "这里的示例技能中，包含了我们之前在课程中回顾过的示例技能集合。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go now and let's install now these skills.": "那么现在让我们来安装这些技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see a quick description of what skills we're installing.": "在这里我们可以看到我们要安装的技能的简要描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So after I installed it, let me now reboot cloud and let's see.": "安装完成后，让我重启 Claude 看看。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's ask which skills do you have.": "让我们问一下“你有哪些技能”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now we can see we have a bunch of new skills.": "现在我们可以看到我们有一堆新技能了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And the one that interests us is this brand guidelines, which we're going to be using very, very soon": "我们感兴趣的是这个品牌指南，我们很快就会用到它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me now clear the context and let me now create another cloud instance here.": "现在让我清除上下文，并在这里创建一个新的云实例。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let's now go and let me go.": "让我们现在开始，让我继续。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And right.": "好的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Can you make sure that the logo is according to anthropic brand.": "你能确保 Logo 符合 Anthropic 的品牌要求吗？",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So now what's going to happen.": "那么现在会发生什么呢。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And please take notice.": "请注意。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to skim through now the files here.": "它现在将浏览这里的文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And notice now what's happening.": "注意现在发生了什么。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now it's asking us to use the brand guideline skills.": "现在它要求我们使用品牌指南技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see the skill description as well.": "在这里我们也可以看到技能描述。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So I'm going to say yes I want to proceed.": "所以我会说“是的，我想继续”。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And by the way, we can always tell it to auto approve using skills.": "顺便说一下，我们总是可以告诉它自动批准使用技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And now it's going to load up to the context the directory under the brand guidelines.": "现在它将把品牌指南下的目录加载到上下文中。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we have only one markdown file.": "这里只有一个 Markdown 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to be a part of the context.": "所以这将成为上下文的一部分。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is going to help now the agent to achieve its task because it has now additional context.": "这将帮助智能体完成任务，因为它现在有了额外的上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now the important thing to note here that this is going to be dynamically loaded.": "这里需要注意的重要一点是，它是动态加载的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:The context here is dynamic.": "这里的上下文是动态的。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's not loaded every time in every prompt that we send the agent.": "它不是在我们发送给智能体的每一个提示词中都加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is why skills are very, very cool because we have this progressive context.": "这就是为什么技能非常酷，因为我们有了这种渐进式上下文。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Loading.": "加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now skills can also have scripts and executable files.": "现在技能也可以包含脚本和可执行文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to show you how it's done and how to use them later in this section.": "我将在本节稍后向你展示它是如何实现的以及如何使用它们。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So we can see now we've added a bunch of changes here.": "我们可以看到现在我们在这里添加了一系列更改。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And it's changing the colors a bit, the fonts and it's going to do everything according to the skill": "它正在稍微改变颜色和字体，并且会根据技能",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:description here and the skill information here.": "这里的描述和技能信息来完成所有工作。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So looks like it's going to be done now.": "看起来现在就要完成了。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and approve to run npm build and let's see the changes.": "现在让我去批准运行 npm build，看看有什么变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let me run again npm run dev.": "让我再次运行 npm run dev。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And okay so this is the new design.": "好的，这就是新的设计。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Looks very very similar.": "看起来非常相似。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We have maybe subtle changes.": "可能有一些细微的变化。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can see that the font is a bit different.": "我们可以看到字体有点不同。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So basically what I wanted to show here was the dynamic loading according to the skill.": "所以基本上我想在这里展示的是根据技能进行的动态加载。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:I want to show you another skill.": "我想向你展示另一个技能。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's take a look for example the skill creator here and here we can see we have a bunch of Python scripts.": "让我们以这里的技能创建器为例，我们可以看到这里有一堆 Python 脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And those are scripts that the agent can run if it loaded the skills.": "这些是智能体在加载技能后可以运行的脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So in the skill file we're going to write to the agent.": "所以在技能文件中，我们会写给智能体。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And we're going to specify there what kind of scripts does it has access to.": "我们将在那里指定它可以访问哪些脚本。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now those kids in this example are Python files.": "在这个例子中，这些技能是 Python 文件。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:But we can really put any kind of programming language that we want here.": "但我们真的可以在这里放入任何我们想要的编程语言。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can put here bash, we can put here JavaScript.": "我们可以放 Bash，也可以放 JavaScript。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It doesn't really matter as long as we describe it well in the markdown files of the skill.": "只要我们在技能的 Markdown 文件中描述清楚，这并不重要。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this is going to allow the agent which has these skills.": "所以这将允许拥有这些技能的代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:It's going to allow it to use those scripts in order to achieve the task here.": "它将允许它使用这些脚本来完成这里的任务。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Now this is very useful because if we have specific workflows that we can define deterministically with": "现在这非常有用，因为如果我们有可以用确定性方式定义的特定工作流，",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So they can be easily integrated with a skill.": "那么它们就可以很容易地与一项技能集成。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And this is how we can give the agent which is having those skills.": "这就是我们如何赋予拥有这些技能的代理。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:We can give it really complex capabilities.": "我们可以赋予它非常复杂的能力。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:That can really be a sequence of executions of scripts and combining the results so we can compose this": "这实际上可以是一系列脚本的执行并结合结果，因此我们可以将其组合得",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:very, very beautifully.": "非常、非常完美。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And I'm going to show you an example of this in the rest of this section.": "在本节的其余部分，我将向你们展示一个这方面的例子。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let me go now and let me now add a commit to this code here.": "现在让我去为这里的代码添加一个提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, so I'm going to ask lots to do it.": "嗯，所以我打算让 Lots 来做这件事。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And of course we can have a skill to do it.": "当然，我们可以用一项技能来完成它。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Um, anyways, so it's going now to review the files and it's going to draft a commit message for us.": "嗯，总之，它现在将审查文件，并为我们起草一条提交信息。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go and accept this.": "让我去接受这个。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And let me go now and push this to the repository.": "现在让我把它推送到仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So let's go back now to the repo here.": "现在让我们回到这里的仓库。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:Let's now go to the hookup branch.": "现在让我们转到 hookup 分支。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:And here we can see now the commit of applying a applying the brand guidelines.": "在这里我们可以看到应用品牌指南的提交。",
  "openai:按次gcli/gemini-3-flash-preview:EN:ZH:So this was generated with the cloud code skill.": "所以这是通过云代码技能生成的。"
}